# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/tests/io/json/test_pandas.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/tests/io/json/test_pandas.py
@@ -28,6 +28,21 @@
 
 
 def assert_json_roundtrip_equal(result, expected, orient):
+    """
+
+    Parameters
+    ----------
+    result :
+        
+    expected :
+        
+    orient :
+        
+
+    Returns
+    -------
+
+    """
     if orient == "records" or orient == "values":
         expected = expected.reset_index(drop=True)
     if orient == "values":
@@ -37,14 +52,17 @@
 
 @pytest.mark.filterwarnings("ignore:the 'numpy' keyword is deprecated:FutureWarning")
 class TestPandasContainer:
+    """ """
     @pytest.fixture(autouse=True)
     def setup(self):
+        """ """
         self.categorical = _cat_frame.copy()
 
         yield
 
     @pytest.fixture
     def datetime_series(self):
+        """ """
         # Same as usual datetime_series, but with index freq set to None,
         #  since that doesnt round-trip, see GH#33711
         ser = tm.makeTimeSeries()
@@ -54,6 +72,7 @@
 
     @pytest.fixture
     def datetime_frame(self):
+        """ """
         # Same as usual datetime_frame, but with index freq set to None,
         #  since that doesnt round-trip, see GH#33711
         df = DataFrame(tm.getTimeSeriesData())
@@ -61,6 +80,17 @@
         return df
 
     def test_frame_double_encoded_labels(self, orient):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame(
             [["a", "b"], ["c", "d"]],
             index=['index " 1', "index / 2"],
@@ -74,6 +104,17 @@
 
     @pytest.mark.parametrize("orient", ["split", "records", "values"])
     def test_frame_non_unique_index(self, orient):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame([["a", "b"], ["c", "d"]], index=[1, 1], columns=["x", "y"])
         result = read_json(df.to_json(orient=orient), orient=orient)
         expected = df.copy()
@@ -82,6 +123,17 @@
 
     @pytest.mark.parametrize("orient", ["index", "columns"])
     def test_frame_non_unique_index_raises(self, orient):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame([["a", "b"], ["c", "d"]], index=[1, 1], columns=["x", "y"])
         msg = f"DataFrame index must be unique for orient='{orient}'"
         with pytest.raises(ValueError, match=msg):
@@ -98,6 +150,19 @@
         ],
     )
     def test_frame_non_unique_columns(self, orient, data):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        data :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame(data, index=[1, 2], columns=["x", "x"])
 
         result = read_json(
@@ -118,6 +183,17 @@
 
     @pytest.mark.parametrize("orient", ["index", "columns", "records"])
     def test_frame_non_unique_columns_raises(self, orient):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame([["a", "b"], ["c", "d"]], index=[1, 2], columns=["x", "x"])
 
         msg = f"DataFrame columns must be unique for orient='{orient}'"
@@ -125,12 +201,42 @@
             df.to_json(orient=orient)
 
     def test_frame_default_orient(self, float_frame):
+        """
+
+        Parameters
+        ----------
+        float_frame :
+            
+
+        Returns
+        -------
+
+        """
         assert float_frame.to_json() == float_frame.to_json(orient="columns")
 
     @pytest.mark.parametrize("dtype", [False, float])
     @pytest.mark.parametrize("convert_axes", [True, False])
     @pytest.mark.parametrize("numpy", [True, False])
     def test_roundtrip_simple(self, orient, convert_axes, numpy, dtype, float_frame):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        convert_axes :
+            
+        numpy :
+            
+        dtype :
+            
+        float_frame :
+            
+
+        Returns
+        -------
+
+        """
         data = float_frame.to_json(orient=orient)
         result = pd.read_json(
             data, orient=orient, convert_axes=convert_axes, numpy=numpy, dtype=dtype
@@ -144,6 +250,25 @@
     @pytest.mark.parametrize("convert_axes", [True, False])
     @pytest.mark.parametrize("numpy", [True, False])
     def test_roundtrip_intframe(self, orient, convert_axes, numpy, dtype, int_frame):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        convert_axes :
+            
+        numpy :
+            
+        dtype :
+            
+        int_frame :
+            
+
+        Returns
+        -------
+
+        """
         data = int_frame.to_json(orient=orient)
         result = pd.read_json(
             data, orient=orient, convert_axes=convert_axes, numpy=numpy, dtype=dtype
@@ -164,6 +289,23 @@
     @pytest.mark.parametrize("convert_axes", [True, False])
     @pytest.mark.parametrize("numpy", [True, False])
     def test_roundtrip_str_axes(self, orient, convert_axes, numpy, dtype):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        convert_axes :
+            
+        numpy :
+            
+        dtype :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame(
             np.zeros((200, 4)),
             columns=[str(i) for i in range(4)],
@@ -201,6 +343,21 @@
     @pytest.mark.parametrize("convert_axes", [True, False])
     @pytest.mark.parametrize("numpy", [True, False])
     def test_roundtrip_categorical(self, orient, convert_axes, numpy):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        convert_axes :
+            
+        numpy :
+            
+
+        Returns
+        -------
+
+        """
         # TODO: create a better frame to test with and improve coverage
         if orient in ("index", "columns"):
             pytest.xfail(f"Can't have duplicate index values for orient '{orient}')")
@@ -225,6 +382,23 @@
     @pytest.mark.parametrize("convert_axes", [True, False])
     @pytest.mark.parametrize("numpy", [True, False])
     def test_roundtrip_empty(self, orient, convert_axes, numpy, empty_frame):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        convert_axes :
+            
+        numpy :
+            
+        empty_frame :
+            
+
+        Returns
+        -------
+
+        """
         data = empty_frame.to_json(orient=orient)
         result = pd.read_json(
             data, orient=orient, convert_axes=convert_axes, numpy=numpy
@@ -243,6 +417,23 @@
     @pytest.mark.parametrize("convert_axes", [True, False])
     @pytest.mark.parametrize("numpy", [True, False])
     def test_roundtrip_timestamp(self, orient, convert_axes, numpy, datetime_frame):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        convert_axes :
+            
+        numpy :
+            
+        datetime_frame :
+            
+
+        Returns
+        -------
+
+        """
         # TODO: improve coverage with date_format parameter
         data = datetime_frame.to_json(orient=orient)
         result = pd.read_json(
@@ -263,6 +454,21 @@
     @pytest.mark.parametrize("convert_axes", [True, False])
     @pytest.mark.parametrize("numpy", [True, False])
     def test_roundtrip_mixed(self, orient, convert_axes, numpy):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        convert_axes :
+            
+        numpy :
+            
+
+        Returns
+        -------
+
+        """
         if numpy and orient != "split":
             pytest.xfail("Can't decode directly to array")
 
@@ -320,6 +526,21 @@
         ],
     )
     def test_frame_from_json_bad_data_raises(self, data, msg, orient):
+        """
+
+        Parameters
+        ----------
+        data :
+            
+        msg :
+            
+        orient :
+            
+
+        Returns
+        -------
+
+        """
         with pytest.raises(ValueError, match=msg):
             read_json(StringIO(data), orient=orient)
 
@@ -327,6 +548,23 @@
     @pytest.mark.parametrize("convert_axes", [True, False])
     @pytest.mark.parametrize("numpy", [True, False])
     def test_frame_from_json_missing_data(self, orient, convert_axes, numpy, dtype):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        convert_axes :
+            
+        numpy :
+            
+        dtype :
+            
+
+        Returns
+        -------
+
+        """
         num_df = DataFrame([[1, 2], [4, 5, 6]])
         result = read_json(
             num_df.to_json(orient=orient),
@@ -351,6 +589,21 @@
     @pytest.mark.parametrize("inf", [np.inf, np.NINF])
     @pytest.mark.parametrize("dtype", [True, False])
     def test_frame_infinity(self, orient, inf, dtype):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        inf :
+            
+        dtype :
+            
+
+        Returns
+        -------
+
+        """
         # infinities get mapped to nulls which get mapped to NaNs during
         # deserialisation
         df = DataFrame([[1, 2], [4, 5, 6]])
@@ -373,17 +626,34 @@
         ],
     )
     def test_frame_to_json_float_precision(self, value, precision, expected_val):
+        """
+
+        Parameters
+        ----------
+        value :
+            
+        precision :
+            
+        expected_val :
+            
+
+        Returns
+        -------
+
+        """
         df = pd.DataFrame([dict(a_float=value)])
         encoded = df.to_json(double_precision=precision)
         assert encoded == f'{{"a_float":{{"0":{expected_val}}}}}'
 
     def test_frame_to_json_except(self):
+        """ """
         df = DataFrame([1, 2, 3])
         msg = "Invalid value 'garbage' for option 'orient'"
         with pytest.raises(ValueError, match=msg):
             df.to_json(orient="garbage")
 
     def test_frame_empty(self):
+        """ """
         df = DataFrame(columns=["jim", "joe"])
         assert not df._is_mixed_type
         tm.assert_frame_equal(
@@ -395,6 +665,7 @@
         assert result == expected
 
     def test_frame_empty_mixedtype(self):
+        """ """
         # mixed type
         df = DataFrame(columns=["jim", "joe"])
         df["joe"] = df["joe"].astype("i8")
@@ -404,6 +675,7 @@
         )
 
     def test_frame_mixedtype_orient(self):  # GH10289
+        """ """
         vals = [
             [10, 1, "foo", 0.1, 0.01],
             [20, 2, "bar", 0.2, 0.02],
@@ -434,6 +706,17 @@
         tm.assert_frame_equal(left, right)
 
     def test_v12_compat(self, datapath):
+        """
+
+        Parameters
+        ----------
+        datapath :
+            
+
+        Returns
+        -------
+
+        """
         dti = pd.date_range("2000-01-03", "2000-01-07")
         # freq doesnt roundtrip
         dti = pd.DatetimeIndex(np.asarray(dti), freq=None)
@@ -464,6 +747,7 @@
         tm.assert_frame_equal(df_iso, df_unser_iso)
 
     def test_blocks_compat_GH9037(self):
+        """ """
         index = pd.date_range("20000101", periods=10, freq="H")
         # freq doesnt round-trip
         index = pd.DatetimeIndex(list(index), freq=None)
@@ -560,9 +844,11 @@
         )
 
     def test_frame_nonprintable_bytes(self):
+        """ """
         # GH14256: failing column caused segfaults, if it is not the last one
 
         class BinaryThing:
+            """ """
             def __init__(self, hexed):
                 self.hexed = hexed
                 self.binary = bytes.fromhex(hexed)
@@ -598,12 +884,14 @@
         )
 
     def test_label_overflow(self):
+        """ """
         # GH14256: buffer length not checked when writing label
         result = pd.DataFrame({"bar" * 100000: [1], "foo": [1337]}).to_json()
         expected = f'{{"{"bar" * 100000}":{{"0":1}},"foo":{{"0":1337}}}}'
         assert result == expected
 
     def test_series_non_unique_index(self):
+        """ """
         s = Series(["a", "b"], index=[1, 1])
 
         msg = "Series index must be unique for orient='index'"
@@ -617,10 +905,36 @@
         tm.assert_numpy_array_equal(s.values, unser.values)
 
     def test_series_default_orient(self, string_series):
+        """
+
+        Parameters
+        ----------
+        string_series :
+            
+
+        Returns
+        -------
+
+        """
         assert string_series.to_json() == string_series.to_json(orient="index")
 
     @pytest.mark.parametrize("numpy", [True, False])
     def test_series_roundtrip_simple(self, orient, numpy, string_series):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        numpy :
+            
+        string_series :
+            
+
+        Returns
+        -------
+
+        """
         data = string_series.to_json(orient=orient)
         result = pd.read_json(data, typ="series", orient=orient, numpy=numpy)
 
@@ -635,6 +949,23 @@
     @pytest.mark.parametrize("dtype", [False, None])
     @pytest.mark.parametrize("numpy", [True, False])
     def test_series_roundtrip_object(self, orient, numpy, dtype, object_series):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        numpy :
+            
+        dtype :
+            
+        object_series :
+            
+
+        Returns
+        -------
+
+        """
         data = object_series.to_json(orient=orient)
         result = pd.read_json(
             data, typ="series", orient=orient, numpy=numpy, dtype=dtype
@@ -650,6 +981,21 @@
 
     @pytest.mark.parametrize("numpy", [True, False])
     def test_series_roundtrip_empty(self, orient, numpy, empty_series):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        numpy :
+            
+        empty_series :
+            
+
+        Returns
+        -------
+
+        """
         data = empty_series.to_json(orient=orient)
         result = pd.read_json(data, typ="series", orient=orient, numpy=numpy)
 
@@ -663,6 +1009,21 @@
 
     @pytest.mark.parametrize("numpy", [True, False])
     def test_series_roundtrip_timeseries(self, orient, numpy, datetime_series):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        numpy :
+            
+        datetime_series :
+            
+
+        Returns
+        -------
+
+        """
         data = datetime_series.to_json(orient=orient)
         result = pd.read_json(data, typ="series", orient=orient, numpy=numpy)
 
@@ -677,6 +1038,21 @@
     @pytest.mark.parametrize("dtype", [np.float64, int])
     @pytest.mark.parametrize("numpy", [True, False])
     def test_series_roundtrip_numeric(self, orient, numpy, dtype):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        numpy :
+            
+        dtype :
+            
+
+        Returns
+        -------
+
+        """
         s = Series(range(6), index=["a", "b", "c", "d", "e", "f"])
         data = s.to_json(orient=orient)
         result = pd.read_json(data, typ="series", orient=orient, numpy=numpy)
@@ -688,17 +1064,20 @@
         tm.assert_series_equal(result, expected)
 
     def test_series_to_json_except(self):
+        """ """
         s = Series([1, 2, 3])
         msg = "Invalid value 'garbage' for option 'orient'"
         with pytest.raises(ValueError, match=msg):
             s.to_json(orient="garbage")
 
     def test_series_from_json_precise_float(self):
+        """ """
         s = Series([4.56, 4.56, 4.56])
         result = read_json(s.to_json(), typ="series", precise_float=True)
         tm.assert_series_equal(result, s, check_index_type=False)
 
     def test_series_with_dtype(self):
+        """ """
         # GH 21986
         s = Series([4.56, 4.56, 4.56])
         result = read_json(s.to_json(), typ="series", dtype=np.int64)
@@ -713,12 +1092,26 @@
         ],
     )
     def test_series_with_dtype_datetime(self, dtype, expected):
+        """
+
+        Parameters
+        ----------
+        dtype :
+            
+        expected :
+            
+
+        Returns
+        -------
+
+        """
         s = Series(["2000-01-01"], dtype="datetime64[ns]")
         data = s.to_json()
         result = pd.read_json(data, typ="series", dtype=dtype)
         tm.assert_series_equal(result, expected)
 
     def test_frame_from_json_precise_float(self):
+        """ """
         df = DataFrame([[4.56, 4.56, 4.56], [4.56, 4.56, 4.56]])
         result = read_json(df.to_json(), precise_float=True)
         tm.assert_frame_equal(
@@ -726,12 +1119,14 @@
         )
 
     def test_typ(self):
+        """ """
 
         s = Series(range(6), index=["a", "b", "c", "d", "e", "f"], dtype="int64")
         result = read_json(s.to_json(), typ=None)
         tm.assert_series_equal(result, s)
 
     def test_reconstruction_index(self):
+        """ """
 
         df = DataFrame([[1, 2, 3], [4, 5, 6]])
         result = read_json(df.to_json())
@@ -743,6 +1138,21 @@
         tm.assert_frame_equal(result, df)
 
     def test_path(self, float_frame, int_frame, datetime_frame):
+        """
+
+        Parameters
+        ----------
+        float_frame :
+            
+        int_frame :
+            
+        datetime_frame :
+            
+
+        Returns
+        -------
+
+        """
         with tm.ensure_clean("test.json") as path:
             for df in [
                 float_frame,
@@ -753,6 +1163,19 @@
                 read_json(path)
 
     def test_axis_dates(self, datetime_series, datetime_frame):
+        """
+
+        Parameters
+        ----------
+        datetime_series :
+            
+        datetime_frame :
+            
+
+        Returns
+        -------
+
+        """
 
         # frame
         json = datetime_frame.to_json()
@@ -766,6 +1189,19 @@
         assert result.name is None
 
     def test_convert_dates(self, datetime_series, datetime_frame):
+        """
+
+        Parameters
+        ----------
+        datetime_series :
+            
+        datetime_frame :
+            
+
+        Returns
+        -------
+
+        """
 
         # frame
         df = datetime_frame
@@ -796,6 +1232,21 @@
         "date_typ", [datetime.date, datetime.datetime, pd.Timestamp]
     )
     def test_date_index_and_values(self, date_format, as_object, date_typ):
+        """
+
+        Parameters
+        ----------
+        date_format :
+            
+        as_object :
+            
+        date_typ :
+            
+
+        Returns
+        -------
+
+        """
         data = [date_typ(year=2020, month=1, day=1), pd.NaT]
         if as_object:
             data.append("a")
@@ -828,6 +1279,17 @@
         ],
     )
     def test_convert_dates_infer(self, infer_word):
+        """
+
+        Parameters
+        ----------
+        infer_word :
+            
+
+        Returns
+        -------
+
+        """
         # GH10747
         from pandas.io.json import dumps
 
@@ -849,6 +1311,21 @@
         ],
     )
     def test_date_format_frame(self, date, date_unit, datetime_frame):
+        """
+
+        Parameters
+        ----------
+        date :
+            
+        date_unit :
+            
+        datetime_frame :
+            
+
+        Returns
+        -------
+
+        """
         df = datetime_frame
 
         df["date"] = Timestamp(date)
@@ -865,6 +1342,17 @@
         tm.assert_frame_equal(result, expected)
 
     def test_date_format_frame_raises(self, datetime_frame):
+        """
+
+        Parameters
+        ----------
+        datetime_frame :
+            
+
+        Returns
+        -------
+
+        """
         df = datetime_frame
         msg = "Invalid value 'foo' for option 'date_unit'"
         with pytest.raises(ValueError, match=msg):
@@ -881,6 +1369,21 @@
         ],
     )
     def test_date_format_series(self, date, date_unit, datetime_series):
+        """
+
+        Parameters
+        ----------
+        date :
+            
+        date_unit :
+            
+        datetime_series :
+            
+
+        Returns
+        -------
+
+        """
         ts = Series(Timestamp(date), index=datetime_series.index)
         ts.iloc[1] = pd.NaT
         ts.iloc[5] = pd.NaT
@@ -895,6 +1398,17 @@
         tm.assert_series_equal(result, expected)
 
     def test_date_format_series_raises(self, datetime_series):
+        """
+
+        Parameters
+        ----------
+        datetime_series :
+            
+
+        Returns
+        -------
+
+        """
         ts = Series(Timestamp("20130101 20:43:42.123"), index=datetime_series.index)
         msg = "Invalid value 'foo' for option 'date_unit'"
         with pytest.raises(ValueError, match=msg):
@@ -902,6 +1416,19 @@
 
     @pytest.mark.parametrize("unit", ["s", "ms", "us", "ns"])
     def test_date_unit(self, unit, datetime_frame):
+        """
+
+        Parameters
+        ----------
+        unit :
+            
+        datetime_frame :
+            
+
+        Returns
+        -------
+
+        """
         df = datetime_frame
         df["date"] = Timestamp("20130101 20:43:42")
         dl = df.columns.get_loc("date")
@@ -920,6 +1447,7 @@
         tm.assert_frame_equal(result, df)
 
     def test_weird_nested_json(self):
+        """ """
         # this used to core dump the parser
         s = r"""{
         "status": "success",
@@ -942,6 +1470,7 @@
         read_json(s)
 
     def test_doc_example(self):
+        """ """
         dfj2 = DataFrame(np.random.randn(5, 2), columns=list("AB"))
         dfj2["date"] = Timestamp("20130101")
         dfj2["ints"] = range(5)
@@ -953,6 +1482,7 @@
         tm.assert_frame_equal(result, result)
 
     def test_misc_example(self):
+        """ """
 
         # parsing unordered input fails
         result = read_json('[{"a": 1, "b": 2}, {"b":2, "a" :1}]', numpy=True)
@@ -973,6 +1503,7 @@
     @tm.network
     @pytest.mark.single
     def test_round_trip_exception_(self):
+        """ """
         # GH 3867
         csv = "https://raw.github.com/hayd/lahman2012/master/csvs/Teams.csv"
         df = pd.read_csv(csv)
@@ -991,11 +1522,25 @@
         ],
     )
     def test_url(self, field, dtype):
+        """
+
+        Parameters
+        ----------
+        field :
+            
+        dtype :
+            
+
+        Returns
+        -------
+
+        """
         url = "https://api.github.com/repos/pandas-dev/pandas/issues?per_page=5"  # noqa
         result = read_json(url, convert_dates=True)
         assert result[field].dtype == dtype
 
     def test_timedelta(self):
+        """ """
         converter = lambda x: pd.to_timedelta(x, unit="ms")
 
         s = Series([timedelta(23), timedelta(seconds=5)])
@@ -1027,6 +1572,7 @@
         tm.assert_frame_equal(frame, result)
 
     def test_mixed_timedelta_datetime(self):
+        """ """
         frame = DataFrame(
             {"a": [timedelta(23), pd.Timestamp("20130101")]}, dtype=object
         )
@@ -1041,6 +1587,21 @@
     @pytest.mark.parametrize("date_format", ["iso", "epoch"])
     @pytest.mark.parametrize("timedelta_typ", [pd.Timedelta, timedelta])
     def test_timedelta_to_json(self, as_object, date_format, timedelta_typ):
+        """
+
+        Parameters
+        ----------
+        as_object :
+            
+        date_format :
+            
+        timedelta_typ :
+            
+
+        Returns
+        -------
+
+        """
         # GH28156: to_json not correctly formatting Timedelta
         data = [timedelta_typ(days=1), timedelta_typ(days=2), pd.NaT]
         if as_object:
@@ -1061,6 +1622,7 @@
         assert result == expected
 
     def test_default_handler(self):
+        """ """
         value = object()
         frame = DataFrame({"a": [7, value]})
         expected = DataFrame({"a": [7, str(value)]})
@@ -1068,9 +1630,21 @@
         tm.assert_frame_equal(expected, result, check_index_type=False)
 
     def test_default_handler_indirect(self):
+        """ """
         from pandas.io.json import dumps
 
         def default(obj):
+            """
+
+            Parameters
+            ----------
+            obj :
+                
+
+            Returns
+            -------
+
+            """
             if isinstance(obj, complex):
                 return [("mathjs", "Complex"), ("re", obj.real), ("im", obj.imag)]
             return str(obj)
@@ -1089,6 +1663,7 @@
         assert dumps(df_list, default_handler=default, orient="values") == expected
 
     def test_default_handler_numpy_unsupported_dtype(self):
+        """ """
         # GH12554 to_json raises 'Unhandled numpy dtype 15'
         df = DataFrame(
             {"a": [1, 2.3, complex(4, -5)], "b": [float("nan"), None, complex(1.2, 0)]},
@@ -1102,9 +1677,21 @@
         assert df.to_json(default_handler=str, orient="values") == expected
 
     def test_default_handler_raises(self):
+        """ """
         msg = "raisin"
 
         def my_handler_raises(obj):
+            """
+
+            Parameters
+            ----------
+            obj :
+                
+
+            Returns
+            -------
+
+            """
             raise TypeError(msg)
 
         with pytest.raises(TypeError, match=msg):
@@ -1117,6 +1704,7 @@
             )
 
     def test_categorical(self):
+        """ """
         # GH4377 df.to_json segfaults with non-ndarray blocks
         df = DataFrame({"A": ["a", "b", "c", "a", "b", "b", "a"]})
         df["B"] = df["A"]
@@ -1130,6 +1718,7 @@
         assert s.to_json() == sc.to_json()
 
     def test_datetime_tz(self):
+        """ """
         # GH4377 df.to_json segfaults with non-ndarray blocks
         tz_range = pd.date_range("20130101", periods=3, tz="US/Eastern")
         tz_naive = tz_range.tz_convert("utc").tz_localize(None)
@@ -1146,6 +1735,7 @@
         assert stz.to_json() == s_naive.to_json()
 
     def test_sparse(self):
+        """ """
         # GH4377 df.to_json segfaults with non-ndarray blocks
         df = pd.DataFrame(np.random.randn(10, 4))
         df.loc[:8] = np.nan
@@ -1170,6 +1760,17 @@
         ],
     )
     def test_tz_is_utc(self, ts):
+        """
+
+        Parameters
+        ----------
+        ts :
+            
+
+        Returns
+        -------
+
+        """
         from pandas.io.json import dumps
 
         exp = '"2013-01-10T05:00:00.000Z"'
@@ -1187,6 +1788,17 @@
         ],
     )
     def test_tz_range_is_utc(self, tz_range):
+        """
+
+        Parameters
+        ----------
+        tz_range :
+            
+
+        Returns
+        -------
+
+        """
         from pandas.io.json import dumps
 
         exp = '["2013-01-01T05:00:00.000Z","2013-01-02T05:00:00.000Z"]'
@@ -1204,6 +1816,7 @@
         assert result == dfexp
 
     def test_read_inline_jsonl(self):
+        """ """
         # GH9180
         result = read_json('{"a": 1, "b": 2}\n{"b":2, "a" :1}\n', lines=True)
         expected = DataFrame([[1, 2], [1, 2]], columns=["a", "b"])
@@ -1211,6 +1824,17 @@
 
     @td.skip_if_not_us_locale
     def test_read_s3_jsonl(self, s3_resource):
+        """
+
+        Parameters
+        ----------
+        s3_resource :
+            
+
+        Returns
+        -------
+
+        """
         # GH17200
 
         result = read_json("s3n://pandas-test/items.jsonl", lines=True)
@@ -1218,6 +1842,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_read_local_jsonl(self):
+        """ """
         # GH17200
         with tm.ensure_clean("tmp_items.json") as path:
             with open(path, "w") as infile:
@@ -1227,6 +1852,7 @@
             tm.assert_frame_equal(result, expected)
 
     def test_read_jsonl_unicode_chars(self):
+        """ """
         # GH15132: non-ascii unicode characters
         # \u201d == RIGHT DOUBLE QUOTATION MARK
 
@@ -1245,6 +1871,17 @@
 
     @pytest.mark.parametrize("bigNum", [sys.maxsize + 1, -(sys.maxsize + 2)])
     def test_to_json_large_numbers(self, bigNum):
+        """
+
+        Parameters
+        ----------
+        bigNum :
+            
+
+        Returns
+        -------
+
+        """
         # GH34473
         series = Series(bigNum, dtype=object, index=["articleId"])
         json = series.to_json()
@@ -1259,6 +1896,17 @@
     @pytest.mark.parametrize("bigNum", [sys.maxsize + 1, -(sys.maxsize + 2)])
     @pytest.mark.skipif(not compat.IS64, reason="GH-35279")
     def test_read_json_large_numbers(self, bigNum):
+        """
+
+        Parameters
+        ----------
+        bigNum :
+            
+
+        Returns
+        -------
+
+        """
         # GH20599
 
         series = Series(bigNum, dtype=object, index=["articleId"])
@@ -1276,6 +1924,7 @@
             tm.assert_frame_equal(df, result)
 
     def test_read_json_large_numbers2(self):
+        """ """
         # GH18842
         json = '{"articleId": "1404366058080022500245"}'
         json = StringIO(json)
@@ -1290,6 +1939,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_to_jsonl(self):
+        """ """
         # GH9180
         df = DataFrame([[1, 2], [1, 2]], columns=["a", "b"])
         result = df.to_json(orient="records", lines=True)
@@ -1311,6 +1961,7 @@
 
     # TODO: there is a near-identical test for pytables; can we share?
     def test_latin_encoding(self):
+        """ """
         # GH 13774
         pytest.skip("encoding not implemented in .to_json(), xref #13774")
 
@@ -1337,6 +1988,19 @@
                 examples.append(Series(val, dtype=dtype))
 
         def roundtrip(s, encoding="latin-1"):
+            """
+
+            Parameters
+            ----------
+            s :
+                
+            encoding :
+                 (Default value = "latin-1")
+
+            Returns
+            -------
+
+            """
             with tm.ensure_clean("test.json") as path:
                 s.to_json(path, encoding=encoding)
                 retr = read_json(path, encoding=encoding)
@@ -1346,6 +2010,7 @@
             roundtrip(s)
 
     def test_data_frame_size_after_to_json(self):
+        """ """
         # GH15344
         df = DataFrame({"a": [str(1)]})
 
@@ -1360,6 +2025,19 @@
     )
     @pytest.mark.parametrize("columns", [["a", "b"], ["1", "2"], ["1.", "2."]])
     def test_from_json_to_json_table_index_and_columns(self, index, columns):
+        """
+
+        Parameters
+        ----------
+        index :
+            
+        columns :
+            
+
+        Returns
+        -------
+
+        """
         # GH25433 GH25435
         expected = DataFrame([[1, 2], [3, 4]], index=index, columns=columns)
         dfjson = expected.to_json(orient="table")
@@ -1367,6 +2045,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_from_json_to_json_table_dtypes(self):
+        """ """
         # GH21345
         expected = pd.DataFrame({"a": [1, 2], "b": [3.0, 4.0], "c": ["5", "6"]})
         dfjson = expected.to_json(orient="table")
@@ -1375,6 +2054,17 @@
 
     @pytest.mark.parametrize("dtype", [True, {"b": int, "c": int}])
     def test_read_json_table_dtype_raises(self, dtype):
+        """
+
+        Parameters
+        ----------
+        dtype :
+            
+
+        Returns
+        -------
+
+        """
         # GH21345
         df = pd.DataFrame({"a": [1, 2], "b": [3.0, 4.0], "c": ["5", "6"]})
         dfjson = df.to_json(orient="table")
@@ -1383,6 +2073,7 @@
             pd.read_json(dfjson, orient="table", dtype=dtype)
 
     def test_read_json_table_convert_axes_raises(self):
+        """ """
         # GH25433 GH25435
         df = DataFrame([[1, 2], [3, 4]], index=[1.0, 2.0], columns=["1.", "2."])
         dfjson = df.to_json(orient="table")
@@ -1419,6 +2110,19 @@
         ],
     )
     def test_index_false_to_json_split(self, data, expected):
+        """
+
+        Parameters
+        ----------
+        data :
+            
+        expected :
+            
+
+        Returns
+        -------
+
+        """
         # GH 17394
         # Testing index=False in to_json with orient='split'
 
@@ -1443,6 +2147,17 @@
         ],
     )
     def test_index_false_to_json_table(self, data):
+        """
+
+        Parameters
+        ----------
+        data :
+            
+
+        Returns
+        -------
+
+        """
         # GH 17394
         # Testing index=False in to_json with orient='table'
 
@@ -1458,6 +2173,17 @@
 
     @pytest.mark.parametrize("orient", ["records", "index", "columns", "values"])
     def test_index_false_error_to_json(self, orient):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+
+        Returns
+        -------
+
+        """
         # GH 17394
         # Testing error message from to_json with index=False
 
@@ -1470,6 +2196,19 @@
     @pytest.mark.parametrize("orient", ["split", "table"])
     @pytest.mark.parametrize("index", [True, False])
     def test_index_false_from_json_to_json(self, orient, index):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        index :
+            
+
+        Returns
+        -------
+
+        """
         # GH25170
         # Test index=False in from_json to_json
         expected = DataFrame({"a": [1, 2], "b": [3, 4]})
@@ -1478,6 +2217,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_read_timezone_information(self):
+        """ """
         # GH 25546
         result = read_json(
             '{"2019-01-01T11:00:00.000Z":88}', typ="series", orient="index"
@@ -1489,6 +2229,19 @@
         "date_format,key", [("epoch", 86400000), ("iso", "P1DT0H0M0S")]
     )
     def test_timedelta_as_label(self, date_format, key):
+        """
+
+        Parameters
+        ----------
+        date_format :
+            
+        key :
+            
+
+        Returns
+        -------
+
+        """
         df = pd.DataFrame([[1]], columns=[pd.Timedelta("1D")])
         expected = f'{{"{key}":{{"0":1}}}}'
         result = df.to_json(date_format=date_format)
@@ -1507,6 +2260,19 @@
         ],
     )
     def test_tuple_labels(self, orient, expected):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        expected :
+            
+
+        Returns
+        -------
+
+        """
         # GH 20500
         df = pd.DataFrame([[1]], index=[("a", "b")], columns=[("c", "d")])
         result = df.to_json(orient=orient)
@@ -1514,6 +2280,17 @@
 
     @pytest.mark.parametrize("indent", [1, 2, 4])
     def test_to_json_indent(self, indent):
+        """
+
+        Parameters
+        ----------
+        indent :
+            
+
+        Returns
+        -------
+
+        """
         # GH 12004
         df = pd.DataFrame([["foo", "bar"], ["baz", "qux"]], columns=["a", "b"])
 
@@ -1650,16 +2427,31 @@
         ],
     )
     def test_json_indent_all_orients(self, orient, expected):
+        """
+
+        Parameters
+        ----------
+        orient :
+            
+        expected :
+            
+
+        Returns
+        -------
+
+        """
         # GH 12004
         df = pd.DataFrame([["foo", "bar"], ["baz", "qux"]], columns=["a", "b"])
         result = df.to_json(orient=orient, indent=4)
         assert result == expected
 
     def test_json_negative_indent_raises(self):
+        """ """
         with pytest.raises(ValueError, match="must be a nonnegative integer"):
             pd.DataFrame().to_json(indent=-1)
 
     def test_emca_262_nan_inf_support(self):
+        """ """
         # GH 12213
         data = '["a", NaN, "NaN", Infinity, "Infinity", -Infinity, "-Infinity"]'
         result = pd.read_json(data)
@@ -1669,6 +2461,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_deprecate_numpy_argument_read_json(self):
+        """ """
         # GH 28512
         expected = DataFrame([1, 2, 3])
         with tm.assert_produces_warning(FutureWarning):
@@ -1676,6 +2469,7 @@
             tm.assert_frame_equal(result, expected)
 
     def test_frame_int_overflow(self):
+        """ """
         # GH 30320
         encoded_json = json.dumps([{"col": "31900441201190696999"}, {"col": "Text"}])
         expected = DataFrame({"col": ["31900441201190696999", "Text"]})
@@ -1693,11 +2487,35 @@
         ],
     )
     def test_json_multiindex(self, dataframe, expected):
+        """
+
+        Parameters
+        ----------
+        dataframe :
+            
+        expected :
+            
+
+        Returns
+        -------
+
+        """
         series = dataframe.stack()
         result = series.to_json(orient="index")
         assert result == expected
 
     def test_to_s3(self, s3_resource):
+        """
+
+        Parameters
+        ----------
+        s3_resource :
+            
+
+        Returns
+        -------
+
+        """
         import time
 
         # GH 28375
@@ -1715,16 +2533,29 @@
             assert timeout > 0, "Timed out waiting for file to appear on moto"
 
     def test_json_pandas_na(self):
+        """ """
         # GH 31615
         result = pd.DataFrame([[pd.NA]]).to_json()
         assert result == '{"0":{"0":null}}'
 
     def test_json_pandas_nulls(self, nulls_fixture):
+        """
+
+        Parameters
+        ----------
+        nulls_fixture :
+            
+
+        Returns
+        -------
+
+        """
         # GH 31615
         result = pd.DataFrame([[nulls_fixture]]).to_json()
         assert result == '{"0":{"0":null}}'
 
     def test_readjson_bool_series(self):
+        """ """
         # GH31464
         result = read_json("[true, true, false]", typ="series")
         expected = pd.Series([True, True, False])
