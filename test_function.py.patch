# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/tests/groupby/test_function.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/tests/groupby/test_function.py
@@ -18,9 +18,17 @@
     ids=["np.int32", "np.int64", "np.float32", "np.float64"],
 )
 def numpy_dtypes_for_minmax(request):
-    """
-    Fixture of numpy dtypes with min and max values used for testing
+    """Fixture of numpy dtypes with min and max values used for testing
     cummin and cummax
+
+    Parameters
+    ----------
+    request :
+        
+
+    Returns
+    -------
+
     """
     dtype = request.param
     min_val = (
@@ -54,6 +62,21 @@
     ],
 )
 def test_groupby_bool_aggs(agg_func, skipna, vals):
+    """
+
+    Parameters
+    ----------
+    agg_func :
+        
+    skipna :
+        
+    vals :
+        
+
+    Returns
+    -------
+
+    """
     df = DataFrame({"key": ["a"] * 3 + ["b"] * 3, "val": vals * 2})
 
     # Figure out expectation using Python builtin
@@ -69,6 +92,7 @@
 
 
 def test_max_min_non_numeric():
+    """ """
     # #2700
     aa = DataFrame({"nn": [11, 11, 22, 22], "ii": [1, 2, 3, 4], "ss": 4 * ["mama"]})
 
@@ -86,6 +110,7 @@
 
 
 def test_min_date_with_nans():
+    """ """
     # GH26321
     dates = pd.to_datetime(
         pd.Series(["2019-05-09", "2019-05-09", "2019-05-09"]), format="%Y-%m-%d"
@@ -104,6 +129,7 @@
 
 
 def test_intercept_builtin_sum():
+    """ """
     s = Series([1.0, 2.0, np.nan, 3.0])
     grouped = s.groupby([0, 1, 2, 2])
 
@@ -121,6 +147,19 @@
 @pytest.mark.parametrize("f", [max, min, sum])
 @pytest.mark.parametrize("keys", ["jim", ["jim", "joe"]])  # Single key  # Multi-key
 def test_builtins_apply(keys, f):
+    """
+
+    Parameters
+    ----------
+    keys :
+        
+    f :
+        
+
+    Returns
+    -------
+
+    """
     # see gh-8155
     df = pd.DataFrame(np.random.randint(1, 50, (1000, 2)), columns=["jim", "joe"])
     df["jolie"] = np.random.randn(1000)
@@ -146,6 +185,7 @@
 
 
 def test_arg_passthru():
+    """ """
     # make sure that we are passing thru kwargs
     # to our agg functions
 
@@ -282,6 +322,7 @@
 
 
 def test_non_cython_api():
+    """ """
 
     # GH5610
     # non-cython calls should not include the grouper
@@ -345,6 +386,7 @@
 
 
 def test_cython_api2():
+    """ """
 
     # this takes the fast apply path
 
@@ -368,6 +410,7 @@
 
 
 def test_cython_median():
+    """ """
     df = DataFrame(np.random.randn(1000))
     df.values[::2] = np.nan
 
@@ -385,6 +428,17 @@
 
 
 def test_median_empty_bins(observed):
+    """
+
+    Parameters
+    ----------
+    observed :
+        
+
+    Returns
+    -------
+
+    """
     df = pd.DataFrame(np.random.randint(0, 44, 500))
 
     grps = range(0, 55, 5)
@@ -410,6 +464,21 @@
     ],
 )
 def test_groupby_non_arithmetic_agg_types(dtype, method, data):
+    """
+
+    Parameters
+    ----------
+    dtype :
+        
+    method :
+        
+    data :
+        
+
+    Returns
+    -------
+
+    """
     # GH9311, GH6620
     df = pd.DataFrame(
         [{"a": 1, "b": 1}, {"a": 1, "b": 2}, {"a": 2, "b": 3}, {"a": 2, "b": 4}]
@@ -447,6 +516,17 @@
     ],
 )
 def test_groupby_non_arithmetic_agg_int_like_precision(i):
+    """
+
+    Parameters
+    ----------
+    i :
+        
+
+    Returns
+    -------
+
+    """
     # see gh-6620, gh-9311
     df = pd.DataFrame([{"a": 1, "b": i[0]}, {"a": 1, "b": i[1]}])
 
@@ -477,6 +557,19 @@
     ],
 )
 def test_idxmin_idxmax_returns_int_types(func, values):
+    """
+
+    Parameters
+    ----------
+    func :
+        
+    values :
+        
+
+    Returns
+    -------
+
+    """
     # GH 25444
     df = pd.DataFrame(
         {
@@ -496,6 +589,7 @@
 
 
 def test_fill_consistency():
+    """ """
 
     # GH9221
     # pass thru keyword arguments to the generated wrapper
@@ -541,6 +635,7 @@
 
 
 def test_groupby_cumprod():
+    """ """
     # GH 4095
     df = pd.DataFrame({"key": ["b"] * 10, "value": 2})
 
@@ -560,6 +655,19 @@
 
 
 def scipy_sem(*args, **kwargs):
+    """
+
+    Parameters
+    ----------
+    *args :
+        
+    **kwargs :
+        
+
+    Returns
+    -------
+
+    """
     from scipy.stats import sem
 
     return sem(*args, ddof=1, **kwargs)
@@ -583,6 +691,19 @@
     ],
 )
 def test_ops_general(op, targop):
+    """
+
+    Parameters
+    ----------
+    op :
+        
+    targop :
+        
+
+    Returns
+    -------
+
+    """
     df = DataFrame(np.random.randn(1000))
     labels = np.random.randint(0, 50, size=1000).astype(float)
 
@@ -592,10 +713,16 @@
 
 
 def test_max_nan_bug():
-    raw = """,Date,app,File
--04-23,2013-04-23 00:00:00,,log080001.log
--05-06,2013-05-06 00:00:00,,log.log
--05-07,2013-05-07 00:00:00,OE,xlsx"""
+    """raw = """,Date,app,File
+    -04-23,2013-04-23 00:00:00,,log080001.log
+    -05-06,2013-05-06 00:00:00,,log.log
+    -05-07,2013-05-07 00:00:00,OE,xlsx
+
+    Parameters
+    ----------
+
+    Returns
+    -------
 
     df = pd.read_csv(StringIO(raw), parse_dates=[0])
     gb = df.groupby("Date")
@@ -606,6 +733,7 @@
 
 
 def test_nlargest():
+    """ """
     a = Series([1, 3, 5, 7, 2, 9, 0, 4, 6, 10])
     b = Series(list("a" * 5 + "b" * 5))
     gb = a.groupby(b)
@@ -626,6 +754,7 @@
 
 
 def test_nlargest_mi_grouper():
+    """ """
     # see gh-21411
     npr = np.random.RandomState(123456789)
 
@@ -671,6 +800,7 @@
 
 
 def test_nsmallest():
+    """ """
     a = Series([1, 3, 5, 7, 2, 9, 0, 4, 6, 10])
     b = Series(list("a" * 5 + "b" * 5))
     gb = a.groupby(b)
@@ -692,6 +822,17 @@
 
 @pytest.mark.parametrize("func", ["cumprod", "cumsum"])
 def test_numpy_compat(func):
+    """
+
+    Parameters
+    ----------
+    func :
+        
+
+    Returns
+    -------
+
+    """
     # see gh-12811
     df = pd.DataFrame({"A": [1, 2, 1], "B": [1, 2, 3]})
     g = df.groupby("A")
@@ -705,6 +846,17 @@
 
 
 def test_cummin(numpy_dtypes_for_minmax):
+    """
+
+    Parameters
+    ----------
+    numpy_dtypes_for_minmax :
+        
+
+    Returns
+    -------
+
+    """
     dtype = numpy_dtypes_for_minmax[0]
     min_val = numpy_dtypes_for_minmax[1]
 
@@ -753,6 +905,7 @@
 
 
 def test_cummin_all_nan_column():
+    """ """
     base_df = pd.DataFrame({"A": [1, 1, 1, 1, 2, 2, 2, 2], "B": [np.nan] * 8})
 
     expected = pd.DataFrame({"B": [np.nan] * 8})
@@ -763,6 +916,17 @@
 
 
 def test_cummax(numpy_dtypes_for_minmax):
+    """
+
+    Parameters
+    ----------
+    numpy_dtypes_for_minmax :
+        
+
+    Returns
+    -------
+
+    """
     dtype = numpy_dtypes_for_minmax[0]
     max_val = numpy_dtypes_for_minmax[2]
 
@@ -811,6 +975,7 @@
 
 
 def test_cummax_all_nan_column():
+    """ """
     base_df = pd.DataFrame({"A": [1, 1, 1, 1, 2, 2, 2, 2], "B": [np.nan] * 8})
 
     expected = pd.DataFrame({"B": [np.nan] * 8})
@@ -839,6 +1004,19 @@
     ],
 )
 def test_is_monotonic_increasing(in_vals, out_vals):
+    """
+
+    Parameters
+    ----------
+    in_vals :
+        
+    out_vals :
+        
+
+    Returns
+    -------
+
+    """
     # GH 17015
     source_dict = {
         "A": ["1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11"],
@@ -875,6 +1053,19 @@
     ],
 )
 def test_is_monotonic_decreasing(in_vals, out_vals):
+    """
+
+    Parameters
+    ----------
+    in_vals :
+        
+    out_vals :
+        
+
+    Returns
+    -------
+
+    """
     # GH 17015
     source_dict = {
         "A": ["1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11"],
@@ -894,11 +1085,23 @@
 
 
 def test_apply_describe_bug(mframe):
+    """
+
+    Parameters
+    ----------
+    mframe :
+        
+
+    Returns
+    -------
+
+    """
     grouped = mframe.groupby(level="first")
     grouped.describe()  # it works!
 
 
 def test_series_describe_multikey():
+    """ """
     ts = tm.makeTimeSeries()
     grouped = ts.groupby([lambda x: x.year, lambda x: x.month])
     result = grouped.describe()
@@ -908,6 +1111,7 @@
 
 
 def test_series_describe_single():
+    """ """
     ts = tm.makeTimeSeries()
     grouped = ts.groupby(lambda x: x.month)
     result = grouped.apply(lambda x: x.describe())
@@ -916,12 +1120,34 @@
 
 
 def test_series_index_name(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     grouped = df.loc[:, ["C"]].groupby(df["A"])
     result = grouped.agg(lambda x: x.mean())
     assert result.index.name == "A"
 
 
 def test_frame_describe_multikey(tsframe):
+    """
+
+    Parameters
+    ----------
+    tsframe :
+        
+
+    Returns
+    -------
+
+    """
     grouped = tsframe.groupby([lambda x: x.year, lambda x: x.month])
     result = grouped.describe()
     desc_groups = []
@@ -948,6 +1174,7 @@
 
 
 def test_frame_describe_tupleindex():
+    """ """
 
     # GH 14848 - regression from 0.19.0 to 0.19.1
     df1 = DataFrame(
@@ -967,6 +1194,7 @@
 
 
 def test_frame_describe_unstacked_format():
+    """ """
     # GH 4792
     prices = {
         pd.Timestamp("2011-01-06 10:59:05", tz=None): 24990,
@@ -993,6 +1221,7 @@
 
 
 def test_groupby_mean_no_overflow():
+    """ """
     # Regression test for (#22487)
     df = pd.DataFrame(
         {
@@ -1015,6 +1244,19 @@
 )
 @pytest.mark.parametrize("function", ["mean", "median", "var"])
 def test_apply_to_nullable_integer_returns_float(values, function):
+    """
+
+    Parameters
+    ----------
+    values :
+        
+    function :
+        
+
+    Returns
+    -------
+
+    """
     # https://github.com/pandas-dev/pandas/issues/32219
     output = 0.5 if function == "var" else 1.5
     arr = np.array([output] * 3, dtype=float)
@@ -1035,6 +1277,7 @@
 
 
 def test_groupby_sum_below_mincount_nullable_integer():
+    """ """
     # https://github.com/pandas-dev/pandas/issues/32861
     df = pd.DataFrame({"a": [0, 1, 2], "b": [0, 1, 2], "c": [0, 1, 2]}, dtype="Int64")
     grouped = df.groupby("a")
