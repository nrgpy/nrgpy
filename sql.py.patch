# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/io/sql.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/io/sql.py
@@ -24,10 +24,12 @@
 
 
 class SQLAlchemyRequired(ImportError):
+    """ """
     pass
 
 
 class DatabaseError(IOError):
+    """ """
     pass
 
 
@@ -38,6 +40,17 @@
 
 
 def _is_sqlalchemy_connectable(con):
+    """
+
+    Parameters
+    ----------
+    con :
+        
+
+    Returns
+    -------
+
+    """
     global _SQLALCHEMY_INSTALLED
     if _SQLALCHEMY_INSTALLED is None:
         try:
@@ -56,7 +69,19 @@
 
 
 def _convert_params(sql, params):
-    """Convert SQL and params args to DBAPI2.0 compliant format."""
+    """Convert SQL and params args to DBAPI2.0 compliant format.
+
+    Parameters
+    ----------
+    sql :
+        
+    params :
+        
+
+    Returns
+    -------
+
+    """
     args = [sql]
     if params is not None:
         if hasattr(params, "keys"):  # test if params is a mapping
@@ -67,7 +92,17 @@
 
 
 def _process_parse_dates_argument(parse_dates):
-    """Process parse_dates argument for read_sql functions"""
+    """Process parse_dates argument for read_sql functions
+
+    Parameters
+    ----------
+    parse_dates :
+        
+
+    Returns
+    -------
+
+    """
     # handle non-list entries for parse_dates gracefully
     if parse_dates is True or parse_dates is None or parse_dates is False:
         parse_dates = []
@@ -78,6 +113,21 @@
 
 
 def _handle_date_column(col, utc=None, format=None):
+    """
+
+    Parameters
+    ----------
+    col :
+        
+    utc :
+         (Default value = None)
+    format :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     if isinstance(format, dict):
         return to_datetime(col, errors="ignore", **format)
     else:
@@ -99,9 +149,19 @@
 
 
 def _parse_date_columns(data_frame, parse_dates):
-    """
-    Force non-datetime columns to be read as such.
+    """Force non-datetime columns to be read as such.
     Supports both string formatted and integer timestamp columns.
+
+    Parameters
+    ----------
+    data_frame :
+        
+    parse_dates :
+        
+
+    Returns
+    -------
+
     """
     parse_dates = _process_parse_dates_argument(parse_dates)
 
@@ -120,7 +180,25 @@
 
 
 def _wrap_result(data, columns, index_col=None, coerce_float=True, parse_dates=None):
-    """Wrap result set of query in a DataFrame."""
+    """Wrap result set of query in a DataFrame.
+
+    Parameters
+    ----------
+    data :
+        
+    columns :
+        
+    index_col :
+         (Default value = None)
+    coerce_float :
+         (Default value = True)
+    parse_dates :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     frame = DataFrame.from_records(data, columns=columns, coerce_float=coerce_float)
 
     frame = _parse_date_columns(frame, parse_dates)
@@ -132,8 +210,7 @@
 
 
 def execute(sql, con, cur=None, params=None):
-    """
-    Execute the given SQL query using the provided connection object.
+    """Execute the given SQL query using the provided connection object.
 
     Parameters
     ----------
@@ -144,12 +221,14 @@
         library.
         If a DBAPI2 object, only sqlite3 is supported.
     cur : deprecated, cursor is obtained from connection, default: None
+         (Default value = None)
     params : list or tuple, optional, default: None
-        List of parameters to pass to execute method.
-
-    Returns
-    -------
-    Results Iterable
+        List of parameters to pass to execute method. (Default value = None)
+
+    Returns
+    -------
+
+    
     """
     if cur is None:
         pandas_sql = pandasSQL_builder(con)
@@ -174,6 +253,31 @@
     columns=None,
     chunksize: None = None,
 ) -> DataFrame:
+    """
+
+    Parameters
+    ----------
+    table_name :
+        
+    con :
+        
+    schema :
+         (Default value = None)
+    index_col :
+         (Default value = None)
+    coerce_float :
+         (Default value = True)
+    parse_dates :
+         (Default value = None)
+    columns :
+         (Default value = None)
+    chunksize: None :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     ...
 
 
@@ -188,6 +292,31 @@
     columns=None,
     chunksize: int = 1,
 ) -> Iterator[DataFrame]:
+    """
+
+    Parameters
+    ----------
+    table_name :
+        
+    con :
+        
+    schema :
+         (Default value = None)
+    index_col :
+         (Default value = None)
+    coerce_float :
+         (Default value = True)
+    parse_dates :
+         (Default value = None)
+    columns :
+         (Default value = None)
+    chunksize: int :
+         (Default value = 1)
+
+    Returns
+    -------
+
+    """
     ...
 
 
@@ -201,9 +330,8 @@
     columns=None,
     chunksize: Optional[int] = None,
 ) -> Union[DataFrame, Iterator[DataFrame]]:
-    """
-    Read SQL database table into a DataFrame.
-
+    """Read SQL database table into a DataFrame.
+    
     Given a table name and a SQLAlchemy connectable, returns a DataFrame.
     This function does not support DBAPI connections.
 
@@ -218,24 +346,26 @@
         Name of SQL schema in database to query (if database flavor
         supports this). Uses default schema if None (default).
     index_col : str or list of str, optional, default: None
-        Column(s) to set as index(MultiIndex).
+        Column(s) to set as index(MultiIndex). (Default value = None)
     coerce_float : bool, default True
         Attempts to convert values of non-string, non-numeric objects (like
-        decimal.Decimal) to floating point. Can result in loss of Precision.
+        decimal.Decimal) to floating point. Can result in loss of Precision. (Default value = True)
     parse_dates : list or dict, default None
         - List of column names to parse as dates.
         - Dict of ``{column_name: format string}`` where format string is
-          strftime compatible in case of parsing string times or is one of
-          (D, s, ns, ms, us) in case of parsing integer timestamps.
+        strftime compatible in case of parsing string times or is one of
+        (D, s, ns, ms, us) in case of parsing integer timestamps.
         - Dict of ``{column_name: arg dict}``, where the arg dict corresponds
-          to the keyword arguments of :func:`pandas.to_datetime`
-          Especially useful with databases without native Datetime support,
-          such as SQLite.
+        to the keyword arguments of :func:`pandas.to_datetime`
+        Especially useful with databases without native Datetime support,
+        such as SQLite. (Default value = None)
     columns : list, default None
-        List of column names to select from SQL table.
+        List of column names to select from SQL table. (Default value = None)
     chunksize : int, default None
         If specified, returns an iterator where `chunksize` is the number of
         rows to include in each chunk.
+    chunksize: Optional[int] :
+         (Default value = None)
 
     Returns
     -------
@@ -247,11 +377,9 @@
     --------
     read_sql_query : Read SQL query into a DataFrame.
     read_sql : Read SQL query or database table into a DataFrame.
-
     Notes
     -----
     Any datetime values with time zone information will be converted to UTC.
-
     Examples
     --------
     >>> pd.read_sql_table('table_name', 'postgres:///db_name')  # doctest:+SKIP
@@ -296,6 +424,29 @@
     parse_dates=None,
     chunksize: None = None,
 ) -> DataFrame:
+    """
+
+    Parameters
+    ----------
+    sql :
+        
+    con :
+        
+    index_col :
+         (Default value = None)
+    coerce_float :
+         (Default value = True)
+    params :
+         (Default value = None)
+    parse_dates :
+         (Default value = None)
+    chunksize: None :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     ...
 
 
@@ -309,6 +460,29 @@
     parse_dates=None,
     chunksize: int = 1,
 ) -> Iterator[DataFrame]:
+    """
+
+    Parameters
+    ----------
+    sql :
+        
+    con :
+        
+    index_col :
+         (Default value = None)
+    coerce_float :
+         (Default value = True)
+    params :
+         (Default value = None)
+    parse_dates :
+         (Default value = None)
+    chunksize: int :
+         (Default value = 1)
+
+    Returns
+    -------
+
+    """
     ...
 
 
@@ -321,9 +495,8 @@
     parse_dates=None,
     chunksize: Optional[int] = None,
 ) -> Union[DataFrame, Iterator[DataFrame]]:
-    """
-    Read SQL query into a DataFrame.
-
+    """Read SQL query into a DataFrame.
+    
     Returns a DataFrame corresponding to the result set of the query
     string. Optionally provide an `index_col` parameter to use one of the
     columns as the index, otherwise default integer index will be used.
@@ -336,38 +509,40 @@
         Using SQLAlchemy makes it possible to use any DB supported by that
         library. If a DBAPI2 object, only sqlite3 is supported.
     index_col : str or list of str, optional, default: None
-        Column(s) to set as index(MultiIndex).
+        Column(s) to set as index(MultiIndex). (Default value = None)
     coerce_float : bool, default True
         Attempts to convert values of non-string, non-numeric objects (like
-        decimal.Decimal) to floating point. Useful for SQL result sets.
+        decimal.Decimal) to floating point. Useful for SQL result sets. (Default value = True)
     params : list, tuple or dict, optional, default: None
         List of parameters to pass to execute method.  The syntax used
         to pass parameters is database driver dependent. Check your
         database driver documentation for which of the five syntax styles,
         described in PEP 249's paramstyle, is supported.
-        Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'}.
+        Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'}. (Default value = None)
     parse_dates : list or dict, default: None
         - List of column names to parse as dates.
         - Dict of ``{column_name: format string}`` where format string is
-          strftime compatible in case of parsing string times, or is one of
-          (D, s, ns, ms, us) in case of parsing integer timestamps.
+        strftime compatible in case of parsing string times, or is one of
+        (D, s, ns, ms, us) in case of parsing integer timestamps.
         - Dict of ``{column_name: arg dict}``, where the arg dict corresponds
-          to the keyword arguments of :func:`pandas.to_datetime`
-          Especially useful with databases without native Datetime support,
-          such as SQLite.
+        to the keyword arguments of :func:`pandas.to_datetime`
+        Especially useful with databases without native Datetime support,
+        such as SQLite. (Default value = None)
     chunksize : int, default None
         If specified, return an iterator where `chunksize` is the number of
         rows to include in each chunk.
+    chunksize: Optional[int] :
+         (Default value = None)
 
     Returns
     -------
     DataFrame or Iterator[DataFrame]
+        
 
     See Also
     --------
     read_sql_table : Read SQL database table into a DataFrame.
     read_sql : Read SQL query or database table into a DataFrame.
-
     Notes
     -----
     Any datetime values with time zone information parsed via the `parse_dates`
@@ -395,6 +570,31 @@
     columns=None,
     chunksize: None = None,
 ) -> DataFrame:
+    """
+
+    Parameters
+    ----------
+    sql :
+        
+    con :
+        
+    index_col :
+         (Default value = None)
+    coerce_float :
+         (Default value = True)
+    params :
+         (Default value = None)
+    parse_dates :
+         (Default value = None)
+    columns :
+         (Default value = None)
+    chunksize: None :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     ...
 
 
@@ -409,6 +609,31 @@
     columns=None,
     chunksize: int = 1,
 ) -> Iterator[DataFrame]:
+    """
+
+    Parameters
+    ----------
+    sql :
+        
+    con :
+        
+    index_col :
+         (Default value = None)
+    coerce_float :
+         (Default value = True)
+    params :
+         (Default value = None)
+    parse_dates :
+         (Default value = None)
+    columns :
+         (Default value = None)
+    chunksize: int :
+         (Default value = 1)
+
+    Returns
+    -------
+
+    """
     ...
 
 
@@ -422,9 +647,8 @@
     columns=None,
     chunksize: Optional[int] = None,
 ) -> Union[DataFrame, Iterator[DataFrame]]:
-    """
-    Read SQL query or database table into a DataFrame.
-
+    """Read SQL query or database table into a DataFrame.
+    
     This function is a convenience wrapper around ``read_sql_table`` and
     ``read_sql_query`` (for backward compatibility). It will delegate
     to the specific function depending on the provided input. A SQL query
@@ -442,35 +666,38 @@
         for engine disposal and connection closure for the SQLAlchemy connectable. See
         `here <https://docs.sqlalchemy.org/en/13/core/connections.html>`_.
     index_col : str or list of str, optional, default: None
-        Column(s) to set as index(MultiIndex).
+        Column(s) to set as index(MultiIndex). (Default value = None)
     coerce_float : bool, default True
         Attempts to convert values of non-string, non-numeric objects (like
-        decimal.Decimal) to floating point, useful for SQL result sets.
+        decimal.Decimal) to floating point, useful for SQL result sets. (Default value = True)
     params : list, tuple or dict, optional, default: None
         List of parameters to pass to execute method.  The syntax used
         to pass parameters is database driver dependent. Check your
         database driver documentation for which of the five syntax styles,
         described in PEP 249's paramstyle, is supported.
-        Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'}.
+        Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'}. (Default value = None)
     parse_dates : list or dict, default: None
         - List of column names to parse as dates.
         - Dict of ``{column_name: format string}`` where format string is
-          strftime compatible in case of parsing string times, or is one of
-          (D, s, ns, ms, us) in case of parsing integer timestamps.
+        strftime compatible in case of parsing string times, or is one of
+        (D, s, ns, ms, us) in case of parsing integer timestamps.
         - Dict of ``{column_name: arg dict}``, where the arg dict corresponds
-          to the keyword arguments of :func:`pandas.to_datetime`
-          Especially useful with databases without native Datetime support,
-          such as SQLite.
+        to the keyword arguments of :func:`pandas.to_datetime`
+        Especially useful with databases without native Datetime support,
+        such as SQLite. (Default value = None)
     columns : list, default: None
         List of column names to select from SQL table (only used when reading
-        a table).
+        a table). (Default value = None)
     chunksize : int, default None
         If specified, return an iterator where `chunksize` is the
         number of rows to include in each chunk.
+    chunksize: Optional[int] :
+         (Default value = None)
 
     Returns
     -------
     DataFrame or Iterator[DataFrame]
+        
 
     See Also
     --------
@@ -528,51 +755,35 @@
     dtype=None,
     method=None,
 ) -> None:
-    """
-    Write records stored in a DataFrame to a SQL database.
-
-    Parameters
-    ----------
-    frame : DataFrame, Series
-    name : str
-        Name of SQL table.
-    con : SQLAlchemy connectable(engine/connection) or database string URI
-        or sqlite3 DBAPI2 connection
-        Using SQLAlchemy makes it possible to use any DB supported by that
-        library.
-        If a DBAPI2 object, only sqlite3 is supported.
-    schema : str, optional
-        Name of SQL schema in database to write to (if database flavor
-        supports this). If None, use default schema (default).
-    if_exists : {'fail', 'replace', 'append'}, default 'fail'
-        - fail: If table exists, do nothing.
-        - replace: If table exists, drop it, recreate it, and insert data.
-        - append: If table exists, insert data. Create if does not exist.
-    index : boolean, default True
-        Write DataFrame index as a column.
-    index_label : str or sequence, optional
-        Column label for index column(s). If None is given (default) and
-        `index` is True, then the index names are used.
-        A sequence should be given if the DataFrame uses MultiIndex.
-    chunksize : int, optional
-        Specify the number of rows in each batch to be written at a time.
-        By default, all rows will be written at once.
-    dtype : dict or scalar, optional
-        Specifying the datatype for columns. If a dictionary is used, the
-        keys should be the column names and the values should be the
-        SQLAlchemy types or strings for the sqlite3 fallback mode. If a
-        scalar is provided, it will be applied to all columns.
-    method : {None, 'multi', callable}, optional
-        Controls the SQL insertion clause used:
-
-        - None : Uses standard SQL ``INSERT`` clause (one per row).
-        - 'multi': Pass multiple values in a single ``INSERT`` clause.
-        - callable with signature ``(pd_table, conn, keys, data_iter)``.
-
-        Details and a sample callable implementation can be found in the
-        section :ref:`insert method <io.sql.method>`.
-
-        .. versionadded:: 0.24.0
+    """Write records stored in a DataFrame to a SQL database.
+
+    Parameters
+    ----------
+    frame :
+        
+    name :
+        
+    con :
+        
+    schema :
+         (Default value = None)
+    if_exists :
+         (Default value = "fail")
+    index :
+         (Default value = True)
+    index_label :
+         (Default value = None)
+    chunksize :
+         (Default value = None)
+    dtype :
+         (Default value = None)
+    method :
+         (Default value = None)
+
+    Returns
+    -------
+
+    
     """
     if if_exists not in ("fail", "replace", "append"):
         raise ValueError(f"'{if_exists}' is not valid for if_exists")
@@ -600,14 +811,13 @@
 
 
 def has_table(table_name, con, schema=None):
-    """
-    Check if DataBase has named table.
-
-    Parameters
-    ----------
-    table_name: string
+    """Check if DataBase has named table.
+
+    Parameters
+    ----------
+    table_name : string
         Name of SQL table.
-    con: SQLAlchemy connectable(engine/connection) or sqlite3 DBAPI2 connection
+    con : SQLAlchemy connectable(engine/connection) or sqlite3 DBAPI2 connection
         Using SQLAlchemy makes it possible to use any DB supported by that
         library.
         If a DBAPI2 object, only sqlite3 is supported.
@@ -617,7 +827,8 @@
 
     Returns
     -------
-    boolean
+
+    
     """
     pandas_sql = pandasSQL_builder(con, schema=schema)
     return pandas_sql.has_table(table_name)
@@ -627,9 +838,17 @@
 
 
 def _engine_builder(con):
-    """
-    Returns a SQLAlchemy engine from a URI (if con is a string)
+    """Returns a SQLAlchemy engine from a URI (if con is a string)
     else it just return con without modifying it.
+
+    Parameters
+    ----------
+    con :
+        
+
+    Returns
+    -------
+
     """
     global _SQLALCHEMY_INSTALLED
     if isinstance(con, str):
@@ -645,9 +864,23 @@
 
 
 def pandasSQL_builder(con, schema=None, meta=None, is_cursor=False):
-    """
-    Convenience function to return the correct PandasSQL subclass based on the
+    """Convenience function to return the correct PandasSQL subclass based on the
     provided parameters.
+
+    Parameters
+    ----------
+    con :
+        
+    schema :
+         (Default value = None)
+    meta :
+         (Default value = None)
+    is_cursor :
+         (Default value = False)
+
+    Returns
+    -------
+
     """
     # When support for DBAPI connections is removed,
     # is_cursor should not be necessary.
@@ -661,12 +894,18 @@
 
 
 class SQLTable(PandasObject):
-    """
-    For mapping Pandas tables to SQL tables.
+    """For mapping Pandas tables to SQL tables.
     Uses fact that table is reflected by SQLAlchemy to
     do better type conversions.
     Also holds various flags needed to avoid having to
     pass them between functions all the time.
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
 
     # TODO: support for multiIndex
@@ -705,19 +944,23 @@
             raise ValueError(f"Could not init table '{name}'")
 
     def exists(self):
+        """ """
         return self.pd_sql.has_table(self.name, self.schema)
 
     def sql_schema(self):
+        """ """
         from sqlalchemy.schema import CreateTable
 
         return str(CreateTable(self.table).compile(self.pd_sql.connectable))
 
     def _execute_create(self):
+        """ """
         # Inserting table into database, add to MetaData object
         self.table = self.table.tometadata(self.pd_sql.meta)
         self.table.create()
 
     def create(self):
+        """ """
         if self.exists():
             if self.if_exists == "fail":
                 raise ValueError(f"Table '{self.name}' already exists.")
@@ -732,32 +975,50 @@
             self._execute_create()
 
     def _execute_insert(self, conn, keys, data_iter):
-        """
-        Execute SQL statement inserting data
-
-        Parameters
-        ----------
-        conn : sqlalchemy.engine.Engine or sqlalchemy.engine.Connection
-        keys : list of str
-           Column names
-        data_iter : generator of list
-           Each item contains a list of values to be inserted
+        """Execute SQL statement inserting data
+
+        Parameters
+        ----------
+        conn :
+            
+        keys :
+            
+        data_iter :
+            
+
+        Returns
+        -------
+
+        
         """
         data = [dict(zip(keys, row)) for row in data_iter]
         conn.execute(self.table.insert(), data)
 
     def _execute_insert_multi(self, conn, keys, data_iter):
-        """
-        Alternative to _execute_insert for DBs support multivalue INSERT.
-
+        """Alternative to _execute_insert for DBs support multivalue INSERT.
+        
         Note: multi-value insert is usually faster for analytics DBs
         and tables containing a few columns
         but performance degrades quickly with increase of columns.
+
+        Parameters
+        ----------
+        conn :
+            
+        keys :
+            
+        data_iter :
+            
+
+        Returns
+        -------
+
         """
         data = [dict(zip(keys, row)) for row in data_iter]
         conn.execute(self.table.insert(data))
 
     def insert_data(self):
+        """ """
         if self.index is not None:
             temp = self.frame.copy()
             temp.index.names = self.index
@@ -794,6 +1055,19 @@
         return column_names, data_list
 
     def insert(self, chunksize=None, method=None):
+        """
+
+        Parameters
+        ----------
+        chunksize :
+             (Default value = None)
+        method :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
 
         # set insert method
         if method is None:
@@ -832,7 +1106,27 @@
     def _query_iterator(
         self, result, chunksize, columns, coerce_float=True, parse_dates=None
     ):
-        """Return generator through chunked result set."""
+        """
+
+        Parameters
+        ----------
+        result :
+            
+        chunksize :
+            
+        columns :
+            
+        coerce_float :
+             (Default value = True)
+        parse_dates :
+             (Default value = None)
+
+        Returns
+        -------
+        type
+            
+
+        """
         while True:
             data = result.fetchmany(chunksize)
             if not data:
@@ -850,6 +1144,23 @@
                 yield self.frame
 
     def read(self, coerce_float=True, parse_dates=None, columns=None, chunksize=None):
+        """
+
+        Parameters
+        ----------
+        coerce_float :
+             (Default value = True)
+        parse_dates :
+             (Default value = None)
+        columns :
+             (Default value = None)
+        chunksize :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
 
         if columns is not None and len(columns) > 0:
             from sqlalchemy import select
@@ -887,6 +1198,19 @@
             return self.frame
 
     def _index_name(self, index, index_label):
+        """
+
+        Parameters
+        ----------
+        index :
+            
+        index_label :
+            
+
+        Returns
+        -------
+
+        """
         # for writing: index=True to include index in sql table
         if index is True:
             nlevels = self.frame.index.nlevels
@@ -923,6 +1247,17 @@
             return None
 
     def _get_column_names_and_types(self, dtype_mapper):
+        """
+
+        Parameters
+        ----------
+        dtype_mapper :
+            
+
+        Returns
+        -------
+
+        """
         column_names_and_types = []
         if self.index is not None:
             for i, idx_label in enumerate(self.index):
@@ -937,6 +1272,7 @@
         return column_names_and_types
 
     def _create_table_setup(self):
+        """ """
         from sqlalchemy import Column, PrimaryKeyConstraint, Table
 
         column_names_and_types = self._get_column_names_and_types(self._sqlalchemy_type)
@@ -965,8 +1301,7 @@
         return Table(self.name, meta, *columns, schema=schema)
 
     def _harmonize_columns(self, parse_dates=None):
-        """
-        Make the DataFrame's column types align with the SQL table
+        """Make the DataFrame's column types align with the SQL table
         column types.
         Need to work around limited NA value support. Floats are always
         fine, ints must always be floats if there are Null values.
@@ -975,6 +1310,15 @@
         NA values.
         Datetimes should already be converted to np.datetime64 if supported,
         but here we also force conversion if required.
+
+        Parameters
+        ----------
+        parse_dates :
+             (Default value = None)
+
+        Returns
+        -------
+
         """
         parse_dates = _process_parse_dates_argument(parse_dates)
 
@@ -1016,6 +1360,17 @@
                 pass  # this column not in results
 
     def _sqlalchemy_type(self, col):
+        """
+
+        Parameters
+        ----------
+        col :
+            
+
+        Returns
+        -------
+
+        """
 
         dtype = self.dtype or {}
         if col.name in dtype:
@@ -1079,6 +1434,17 @@
         return Text
 
     def _get_dtype(self, sqltype):
+        """
+
+        Parameters
+        ----------
+        sqltype :
+            
+
+        Returns
+        -------
+
+        """
         from sqlalchemy.types import TIMESTAMP, Boolean, Date, DateTime, Float, Integer
 
         if isinstance(sqltype, Float):
@@ -1102,17 +1468,41 @@
 
 
 class PandasSQL(PandasObject):
-    """
-    Subclasses Should define read_sql and to_sql.
-    """
+    """Subclasses Should define read_sql and to_sql."""
 
     def read_sql(self, *args, **kwargs):
+        """
+
+        Parameters
+        ----------
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         raise ValueError(
             "PandasSQL must be created with an SQLAlchemy "
             "connectable or sqlite connection"
         )
 
     def to_sql(self, *args, **kwargs):
+        """
+
+        Parameters
+        ----------
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         raise ValueError(
             "PandasSQL must be created with an SQLAlchemy "
             "connectable or sqlite connection"
@@ -1120,23 +1510,16 @@
 
 
 class SQLDatabase(PandasSQL):
-    """
-    This class enables conversion between DataFrame and SQL databases
+    """This class enables conversion between DataFrame and SQL databases
     using SQLAlchemy to handle DataBase abstraction.
 
     Parameters
     ----------
-    engine : SQLAlchemy connectable
-        Connectable to connect with the database. Using SQLAlchemy makes it
-        possible to use any DB supported by that library.
-    schema : string, default None
-        Name of SQL schema in database to write to (if database flavor
-        supports this). If None, use default schema (default).
-    meta : SQLAlchemy MetaData object, default None
-        If provided, this MetaData object is used instead of a newly
-        created. This allows to specify database flavor specific
-        arguments in the MetaData object.
-
+
+    Returns
+    -------
+
+    
     """
 
     def __init__(self, engine, schema=None, meta=None):
@@ -1150,6 +1533,7 @@
 
     @contextmanager
     def run_transaction(self):
+        """ """
         with self.connectable.begin() as tx:
             if hasattr(tx, "execute"):
                 yield tx
@@ -1157,7 +1541,19 @@
                 yield self.connectable
 
     def execute(self, *args, **kwargs):
-        """Simple passthrough to SQLAlchemy connectable"""
+        """Simple passthrough to SQLAlchemy connectable
+
+        Parameters
+        ----------
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         return self.connectable.execution_options(no_parameters=True).execute(
             *args, **kwargs
         )
@@ -1172,47 +1568,46 @@
         schema=None,
         chunksize=None,
     ):
-        """
-        Read SQL database table into a DataFrame.
+        """Read SQL database table into a DataFrame.
 
         Parameters
         ----------
         table_name : string
             Name of SQL table in database.
         index_col : string, optional, default: None
-            Column to set as index.
+            Column to set as index. (Default value = None)
         coerce_float : boolean, default True
             Attempts to convert values of non-string, non-numeric objects
             (like decimal.Decimal) to floating point. This can result in
-            loss of precision.
+            loss of precision. (Default value = True)
         parse_dates : list or dict, default: None
             - List of column names to parse as dates.
             - Dict of ``{column_name: format string}`` where format string is
-              strftime compatible in case of parsing string times, or is one of
-              (D, s, ns, ms, us) in case of parsing integer timestamps.
+            strftime compatible in case of parsing string times, or is one of
+            (D, s, ns, ms, us) in case of parsing integer timestamps.
             - Dict of ``{column_name: arg}``, where the arg corresponds
-              to the keyword arguments of :func:`pandas.to_datetime`.
-              Especially useful with databases without native Datetime support,
-              such as SQLite.
+            to the keyword arguments of :func:`pandas.to_datetime`.
+            Especially useful with databases without native Datetime support,
+            such as SQLite. (Default value = None)
         columns : list, default: None
-            List of column names to select from SQL table.
+            List of column names to select from SQL table. (Default value = None)
         schema : string, default None
             Name of SQL schema in database to query (if database flavor
             supports this).  If specified, this overwrites the default
             schema of the SQL database object.
         chunksize : int, default None
             If specified, return an iterator where `chunksize` is the number
-            of rows to include in each chunk.
+            of rows to include in each chunk. (Default value = None)
 
         Returns
         -------
         DataFrame
+            
 
         See Also
         --------
         pandas.read_sql_table
         SQLDatabase.read_query
-
         """
         table = SQLTable(table_name, self, index=index_col, schema=schema)
         return table.read(
@@ -1226,7 +1621,29 @@
     def _query_iterator(
         result, chunksize, columns, index_col=None, coerce_float=True, parse_dates=None
     ):
-        """Return generator through chunked result set"""
+        """
+
+        Parameters
+        ----------
+        result :
+            
+        chunksize :
+            
+        columns :
+            
+        index_col :
+             (Default value = None)
+        coerce_float :
+             (Default value = True)
+        parse_dates :
+             (Default value = None)
+
+        Returns
+        -------
+        type
+            
+
+        """
         while True:
             data = result.fetchmany(chunksize)
             if not data:
@@ -1249,46 +1666,45 @@
         params=None,
         chunksize=None,
     ):
-        """
-        Read SQL query into a DataFrame.
+        """Read SQL query into a DataFrame.
 
         Parameters
         ----------
         sql : string
             SQL query to be executed.
         index_col : string, optional, default: None
-            Column name to use as index for the returned DataFrame object.
+            Column name to use as index for the returned DataFrame object. (Default value = None)
         coerce_float : boolean, default True
             Attempt to convert values of non-string, non-numeric objects (like
-            decimal.Decimal) to floating point, useful for SQL result sets.
+            decimal.Decimal) to floating point, useful for SQL result sets. (Default value = True)
         params : list, tuple or dict, optional, default: None
             List of parameters to pass to execute method.  The syntax used
             to pass parameters is database driver dependent. Check your
             database driver documentation for which of the five syntax styles,
             described in PEP 249's paramstyle, is supported.
-            Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'}
+            Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'} (Default value = None)
         parse_dates : list or dict, default: None
             - List of column names to parse as dates.
             - Dict of ``{column_name: format string}`` where format string is
-              strftime compatible in case of parsing string times, or is one of
-              (D, s, ns, ms, us) in case of parsing integer timestamps.
+            strftime compatible in case of parsing string times, or is one of
+            (D, s, ns, ms, us) in case of parsing integer timestamps.
             - Dict of ``{column_name: arg dict}``, where the arg dict
-              corresponds to the keyword arguments of
-              :func:`pandas.to_datetime` Especially useful with databases
-              without native Datetime support, such as SQLite.
+            corresponds to the keyword arguments of
+            :func:`pandas.to_datetime` Especially useful with databases
+            without native Datetime support, such as SQLite. (Default value = None)
         chunksize : int, default None
             If specified, return an iterator where `chunksize` is the number
-            of rows to include in each chunk.
+            of rows to include in each chunk. (Default value = None)
 
         Returns
         -------
         DataFrame
+            
 
         See Also
         --------
         read_sql_table : Read SQL database table into a DataFrame.
         read_sql
-
         """
         args = _convert_params(sql, params)
 
@@ -1329,46 +1745,33 @@
         dtype=None,
         method=None,
     ):
-        """
-        Write records stored in a DataFrame to a SQL database.
-
-        Parameters
-        ----------
-        frame : DataFrame
-        name : string
-            Name of SQL table.
-        if_exists : {'fail', 'replace', 'append'}, default 'fail'
-            - fail: If table exists, do nothing.
-            - replace: If table exists, drop it, recreate it, and insert data.
-            - append: If table exists, insert data. Create if does not exist.
-        index : boolean, default True
-            Write DataFrame index as a column.
-        index_label : string or sequence, default None
-            Column label for index column(s). If None is given (default) and
-            `index` is True, then the index names are used.
-            A sequence should be given if the DataFrame uses MultiIndex.
-        schema : string, default None
-            Name of SQL schema in database to write to (if database flavor
-            supports this). If specified, this overwrites the default
-            schema of the SQLDatabase object.
-        chunksize : int, default None
-            If not None, then rows will be written in batches of this size at a
-            time.  If None, all rows will be written at once.
-        dtype : single type or dict of column name to SQL type, default None
-            Optional specifying the datatype for columns. The SQL type should
-            be a SQLAlchemy type. If all columns are of the same type, one
-            single value can be used.
-        method : {None', 'multi', callable}, default None
-            Controls the SQL insertion clause used:
-
-            * None : Uses standard SQL ``INSERT`` clause (one per row).
-            * 'multi': Pass multiple values in a single ``INSERT`` clause.
-            * callable with signature ``(pd_table, conn, keys, data_iter)``.
-
-            Details and a sample callable implementation can be found in the
-            section :ref:`insert method <io.sql.method>`.
-
-            .. versionadded:: 0.24.0
+        """Write records stored in a DataFrame to a SQL database.
+
+        Parameters
+        ----------
+        frame :
+            
+        name :
+            
+        if_exists :
+             (Default value = "fail")
+        index :
+             (Default value = True)
+        index_label :
+             (Default value = None)
+        schema :
+             (Default value = None)
+        chunksize :
+             (Default value = None)
+        dtype :
+             (Default value = None)
+        method :
+             (Default value = None)
+
+        Returns
+        -------
+
+        
         """
         if dtype and not is_dict_like(dtype):
             dtype = {col_name: dtype for col_name in frame}
@@ -1424,14 +1827,41 @@
 
     @property
     def tables(self):
+        """ """
         return self.meta.tables
 
     def has_table(self, name, schema=None):
+        """
+
+        Parameters
+        ----------
+        name :
+            
+        schema :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         return self.connectable.run_callable(
             self.connectable.dialect.has_table, name, schema or self.meta.schema
         )
 
     def get_table(self, table_name, schema=None):
+        """
+
+        Parameters
+        ----------
+        table_name :
+            
+        schema :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         schema = schema or self.meta.schema
         if schema:
             tbl = self.meta.tables.get(".".join([schema, table_name]))
@@ -1448,6 +1878,19 @@
         return tbl
 
     def drop_table(self, table_name, schema=None):
+        """
+
+        Parameters
+        ----------
+        table_name :
+            
+        schema :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         schema = schema or self.meta.schema
         if self.has_table(table_name, schema):
             self.meta.reflect(only=[table_name], schema=schema)
@@ -1455,6 +1898,23 @@
             self.meta.clear()
 
     def _create_sql_schema(self, frame, table_name, keys=None, dtype=None):
+        """
+
+        Parameters
+        ----------
+        frame :
+            
+        table_name :
+            
+        keys :
+             (Default value = None)
+        dtype :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         table = SQLTable(
             table_name, self, frame=frame, index=False, keys=keys, dtype=dtype
         )
@@ -1476,6 +1936,17 @@
 
 
 def _get_unicode_name(name):
+    """
+
+    Parameters
+    ----------
+    name :
+        
+
+    Returns
+    -------
+
+    """
     try:
         uname = str(name).encode("utf-8", "strict").decode("utf-8")
     except UnicodeError as err:
@@ -1484,6 +1955,17 @@
 
 
 def _get_valid_sqlite_name(name):
+    """
+
+    Parameters
+    ----------
+    name :
+        
+
+    Returns
+    -------
+
+    """
     # See https://stackoverflow.com/questions/6514274/how-do-you-escape-strings\
     # -for-sqlite-table-column-names-in-python
     # Ensure the string can be encoded as UTF-8.
@@ -1508,9 +1990,15 @@
 
 
 class SQLiteTable(SQLTable):
-    """
-    Patch the SQLTable for fallback support.
+    """Patch the SQLTable for fallback support.
     Instead of a table variable just use the Create Table statement.
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
 
     def __init__(self, *args, **kwargs):
@@ -1524,14 +2012,29 @@
         super().__init__(*args, **kwargs)
 
     def sql_schema(self):
+        """ """
         return str(";\n".join(self.table))
 
     def _execute_create(self):
+        """ """
         with self.pd_sql.run_transaction() as conn:
             for stmt in self.table:
                 conn.execute(stmt)
 
     def insert_statement(self, *, num_rows):
+        """
+
+        Parameters
+        ----------
+        * :
+            
+        num_rows :
+            
+
+        Returns
+        -------
+
+        """
         names = list(map(str, self.frame.columns))
         wld = "?"  # wildcard char
         escape = _get_valid_sqlite_name
@@ -1551,19 +2054,56 @@
         return insert_statement
 
     def _execute_insert(self, conn, keys, data_iter):
+        """
+
+        Parameters
+        ----------
+        conn :
+            
+        keys :
+            
+        data_iter :
+            
+
+        Returns
+        -------
+
+        """
         data_list = list(data_iter)
         conn.executemany(self.insert_statement(num_rows=1), data_list)
 
     def _execute_insert_multi(self, conn, keys, data_iter):
+        """
+
+        Parameters
+        ----------
+        conn :
+            
+        keys :
+            
+        data_iter :
+            
+
+        Returns
+        -------
+
+        """
         data_list = list(data_iter)
         flattened_data = [x for row in data_list for x in row]
         conn.execute(self.insert_statement(num_rows=len(data_list)), flattened_data)
 
     def _create_table_setup(self):
         """
-        Return a list of SQL statements that creates a table reflecting the
-        structure of a DataFrame.  The first entry will be a CREATE TABLE
-        statement while the rest will be CREATE INDEX statements.
+
+        Parameters
+        ----------
+
+        Returns
+        -------
+        type
+            structure of a DataFrame.  The first entry will be a CREATE TABLE
+            statement while the rest will be CREATE INDEX statements.
+
         """
         column_names_and_types = self._get_column_names_and_types(self._sql_type_name)
 
@@ -1613,6 +2153,17 @@
         return create_stmts
 
     def _sql_type_name(self, col):
+        """
+
+        Parameters
+        ----------
+        col :
+            
+
+        Returns
+        -------
+
+        """
         dtype = self.dtype or {}
         if col.name in dtype:
             return dtype[col.name]
@@ -1646,14 +2197,16 @@
 
 
 class SQLiteDatabase(PandasSQL):
-    """
-    Version of SQLDatabase to support SQLite connections (fallback without
+    """Version of SQLDatabase to support SQLite connections (fallback without
     SQLAlchemy). This should only be used internally.
 
     Parameters
     ----------
-    con : sqlite connection object
-
+
+    Returns
+    -------
+
+    
     """
 
     def __init__(self, con, is_cursor=False):
@@ -1662,6 +2215,7 @@
 
     @contextmanager
     def run_transaction(self):
+        """ """
         cur = self.con.cursor()
         try:
             yield cur
@@ -1673,6 +2227,19 @@
             cur.close()
 
     def execute(self, *args, **kwargs):
+        """
+
+        Parameters
+        ----------
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         if self.is_cursor:
             cur = self.con
         else:
@@ -1696,7 +2263,29 @@
     def _query_iterator(
         cursor, chunksize, columns, index_col=None, coerce_float=True, parse_dates=None
     ):
-        """Return generator through chunked result set"""
+        """
+
+        Parameters
+        ----------
+        cursor :
+            
+        chunksize :
+            
+        columns :
+            
+        index_col :
+             (Default value = None)
+        coerce_float :
+             (Default value = True)
+        parse_dates :
+             (Default value = None)
+
+        Returns
+        -------
+        type
+            
+
+        """
         while True:
             data = cursor.fetchmany(chunksize)
             if type(data) == tuple:
@@ -1722,6 +2311,27 @@
         parse_dates=None,
         chunksize=None,
     ):
+        """
+
+        Parameters
+        ----------
+        sql :
+            
+        index_col :
+             (Default value = None)
+        coerce_float :
+             (Default value = True)
+        params :
+             (Default value = None)
+        parse_dates :
+             (Default value = None)
+        chunksize :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
 
         args = _convert_params(sql, params)
         cursor = self.execute(*args)
@@ -1750,6 +2360,17 @@
             return frame
 
     def _fetchall_as_list(self, cur):
+        """
+
+        Parameters
+        ----------
+        cur :
+            
+
+        Returns
+        -------
+
+        """
         result = cur.fetchall()
         if not isinstance(result, list):
             result = list(result)
@@ -1767,45 +2388,33 @@
         dtype=None,
         method=None,
     ):
-        """
-        Write records stored in a DataFrame to a SQL database.
-
-        Parameters
-        ----------
-        frame: DataFrame
-        name: string
-            Name of SQL table.
-        if_exists: {'fail', 'replace', 'append'}, default 'fail'
-            fail: If table exists, do nothing.
-            replace: If table exists, drop it, recreate it, and insert data.
-            append: If table exists, insert data. Create if it does not exist.
-        index : boolean, default True
-            Write DataFrame index as a column
-        index_label : string or sequence, default None
-            Column label for index column(s). If None is given (default) and
-            `index` is True, then the index names are used.
-            A sequence should be given if the DataFrame uses MultiIndex.
-        schema : string, default None
-            Ignored parameter included for compatibility with SQLAlchemy
-            version of ``to_sql``.
-        chunksize : int, default None
-            If not None, then rows will be written in batches of this
-            size at a time. If None, all rows will be written at once.
-        dtype : single type or dict of column name to SQL type, default None
-            Optional specifying the datatype for columns. The SQL type should
-            be a string. If all columns are of the same type, one single value
-            can be used.
-        method : {None, 'multi', callable}, default None
-            Controls the SQL insertion clause used:
-
-            * None : Uses standard SQL ``INSERT`` clause (one per row).
-            * 'multi': Pass multiple values in a single ``INSERT`` clause.
-            * callable with signature ``(pd_table, conn, keys, data_iter)``.
-
-            Details and a sample callable implementation can be found in the
-            section :ref:`insert method <io.sql.method>`.
-
-            .. versionadded:: 0.24.0
+        """Write records stored in a DataFrame to a SQL database.
+
+        Parameters
+        ----------
+        frame :
+            
+        name :
+            
+        if_exists :
+             (Default value = "fail")
+        index :
+             (Default value = True)
+        index_label :
+             (Default value = None)
+        schema :
+             (Default value = None)
+        chunksize :
+             (Default value = None)
+        dtype :
+             (Default value = None)
+        method :
+             (Default value = None)
+
+        Returns
+        -------
+
+        
         """
         if dtype and not is_dict_like(dtype):
             dtype = {col_name: dtype for col_name in frame}
@@ -1828,6 +2437,19 @@
         table.insert(chunksize, method)
 
     def has_table(self, name, schema=None):
+        """
+
+        Parameters
+        ----------
+        name :
+            
+        schema :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         # TODO(wesm): unused?
         # escape = _get_valid_sqlite_name
         # esc_name = escape(name)
@@ -1838,13 +2460,56 @@
         return len(self.execute(query, [name]).fetchall()) > 0
 
     def get_table(self, table_name, schema=None):
+        """
+
+        Parameters
+        ----------
+        table_name :
+            
+        schema :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         return None  # not supported in fallback mode
 
     def drop_table(self, name, schema=None):
+        """
+
+        Parameters
+        ----------
+        name :
+            
+        schema :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         drop_sql = f"DROP TABLE {_get_valid_sqlite_name(name)}"
         self.execute(drop_sql)
 
     def _create_sql_schema(self, frame, table_name, keys=None, dtype=None):
+        """
+
+        Parameters
+        ----------
+        frame :
+            
+        table_name :
+            
+        keys :
+             (Default value = None)
+        dtype :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         table = SQLiteTable(
             table_name, self, frame=frame, index=False, keys=keys, dtype=dtype
         )
@@ -1852,24 +2517,25 @@
 
 
 def get_schema(frame, name, keys=None, con=None, dtype=None):
-    """
-    Get the SQL db table schema for the given frame.
-
-    Parameters
-    ----------
-    frame : DataFrame
-    name : string
-        name of SQL table
-    keys : string or sequence, default: None
-        columns to use a primary key
-    con: an open SQL database connection object or a SQLAlchemy connectable
-        Using SQLAlchemy makes it possible to use any DB supported by that
-        library, default: None
-        If a DBAPI2 object, only sqlite3 is supported.
-    dtype : dict of column name to SQL type, default None
-        Optional specifying the datatype for columns. The SQL type should
-        be a SQLAlchemy type, or a string for sqlite3 fallback connection.
-
+    """Get the SQL db table schema for the given frame.
+
+    Parameters
+    ----------
+    frame :
+        
+    name :
+        
+    keys :
+         (Default value = None)
+    con :
+         (Default value = None)
+    dtype :
+         (Default value = None)
+
+    Returns
+    -------
+
+    
     """
     pandas_sql = pandasSQL_builder(con=con)
     return pandas_sql._create_sql_schema(frame, name, keys=keys, dtype=dtype)
