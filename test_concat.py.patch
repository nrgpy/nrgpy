# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/tests/reshape/test_concat.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/tests/reshape/test_concat.py
@@ -35,16 +35,35 @@
 
 @pytest.fixture(params=[True, False])
 def sort(request):
-    """Boolean sort keyword for concat and DataFrame.append."""
+    """Boolean sort keyword for concat and DataFrame.append.
+
+    Parameters
+    ----------
+    request :
+        
+
+    Returns
+    -------
+
+    """
     return request.param
 
 
 class TestConcatAppendCommon:
-    """
-    Test common dtype coercion rules between concat and append.
-    """
+    """Test common dtype coercion rules between concat and append."""
 
     def setup_method(self, method):
+        """
+
+        Parameters
+        ----------
+        method :
+            
+
+        Returns
+        -------
+
+        """
 
         dt_data = [
             pd.Timestamp("2011-01-01"),
@@ -82,9 +101,19 @@
         }
 
     def _check_expected_dtype(self, obj, label):
-        """
-        Check whether obj has expected dtype depending on label
+        """Check whether obj has expected dtype depending on label
         considering not-supported dtypes
+
+        Parameters
+        ----------
+        obj :
+            
+        label :
+            
+
+        Returns
+        -------
+
         """
         if isinstance(obj, pd.Index):
             if label == "bool":
@@ -100,12 +129,14 @@
             raise ValueError
 
     def test_dtypes(self):
+        """ """
         # to confirm test case covers intended dtypes
         for typ, vals in self.data.items():
             self._check_expected_dtype(pd.Index(vals), typ)
             self._check_expected_dtype(pd.Series(vals), typ)
 
     def test_concatlike_same_dtypes(self):
+        """ """
         # GH 13660
         for typ1, vals1 in self.data.items():
 
@@ -214,6 +245,7 @@
                 pd.concat([pd.Series(vals1), pd.Series(vals2), vals3])
 
     def test_concatlike_dtypes_coercion(self):
+        """ """
         # GH 13660
         for typ1, vals1 in self.data.items():
             for typ2, vals2 in self.data.items():
@@ -287,6 +319,7 @@
                 tm.assert_series_equal(res, exp)
 
     def test_concatlike_common_coerce_to_pandas_object(self):
+        """ """
         # GH 13626
         # result must be Timestamp/Timedelta, not datetime.datetime/timedelta
         dti = pd.DatetimeIndex(["2011-01-01", "2011-01-02"])
@@ -319,6 +352,17 @@
         assert isinstance(res.iloc[-1], pd.Timedelta)
 
     def test_concatlike_datetimetz(self, tz_aware_fixture):
+        """
+
+        Parameters
+        ----------
+        tz_aware_fixture :
+            
+
+        Returns
+        -------
+
+        """
         tz = tz_aware_fixture
         # GH 7795
         dti1 = pd.DatetimeIndex(["2011-01-01", "2011-01-02"], tz=tz)
@@ -341,6 +385,17 @@
 
     @pytest.mark.parametrize("tz", ["UTC", "US/Eastern", "Asia/Tokyo", "EST5EDT"])
     def test_concatlike_datetimetz_short(self, tz):
+        """
+
+        Parameters
+        ----------
+        tz :
+            
+
+        Returns
+        -------
+
+        """
         # GH#7795
         ix1 = pd.date_range(start="2014-07-15", end="2014-07-17", freq="D", tz=tz)
         ix2 = pd.DatetimeIndex(["2014-07-11", "2014-07-21"], tz=tz)
@@ -357,6 +412,17 @@
         tm.assert_frame_equal(pd.concat([df1, df2]), exp)
 
     def test_concatlike_datetimetz_to_object(self, tz_aware_fixture):
+        """
+
+        Parameters
+        ----------
+        tz_aware_fixture :
+            
+
+        Returns
+        -------
+
+        """
         tz = tz_aware_fixture
         # GH 13660
 
@@ -410,6 +476,7 @@
         tm.assert_series_equal(res, pd.Series(exp, index=[0, 1, 0, 1]))
 
     def test_concatlike_common_period(self):
+        """ """
         # GH 13660
         pi1 = pd.PeriodIndex(["2011-01", "2011-02"], freq="M")
         pi2 = pd.PeriodIndex(["2012-01", "2012-02"], freq="M")
@@ -428,6 +495,7 @@
         tm.assert_series_equal(res, pd.Series(exp, index=[0, 1, 0, 1]))
 
     def test_concatlike_common_period_diff_freq_to_object(self):
+        """ """
         # GH 13221
         pi1 = pd.PeriodIndex(["2011-01", "2011-02"], freq="M")
         pi2 = pd.PeriodIndex(["2012-01-01", "2012-02-01"], freq="D")
@@ -454,6 +522,7 @@
         tm.assert_series_equal(res, pd.Series(exp, index=[0, 1, 0, 1]))
 
     def test_concatlike_common_period_mixed_dt_to_object(self):
+        """ """
         # GH 13221
         # different datetimelike
         pi1 = pd.PeriodIndex(["2011-01", "2011-02"], freq="M")
@@ -502,6 +571,7 @@
         tm.assert_series_equal(res, pd.Series(exp, index=[0, 1, 0, 1]))
 
     def test_concat_categorical(self):
+        """ """
         # GH 13524
 
         # same categories -> category
@@ -529,6 +599,7 @@
         tm.assert_series_equal(s1.append(s2, ignore_index=True), exp)
 
     def test_union_categorical_same_categories_different_order(self):
+        """ """
         # https://github.com/pandas-dev/pandas/issues/19096
         a = pd.Series(Categorical(["a", "b", "c"], categories=["a", "b", "c"]))
         b = pd.Series(Categorical(["a", "b", "c"], categories=["b", "a", "c"]))
@@ -539,6 +610,7 @@
         tm.assert_series_equal(result, expected)
 
     def test_concat_categorical_coercion(self):
+        """ """
         # GH 13524
 
         # category + not-category => not-category
@@ -603,6 +675,7 @@
         tm.assert_series_equal(s2.append(s1, ignore_index=True), exp)
 
     def test_concat_categorical_3elem_coercion(self):
+        """ """
         # GH 13524
 
         # mixed dtypes => not-category
@@ -645,6 +718,7 @@
         tm.assert_series_equal(s3.append([s1, s2], ignore_index=True), exp)
 
     def test_concat_categorical_multi_coercion(self):
+        """ """
         # GH 13524
 
         s1 = pd.Series([1, 3], dtype="category")
@@ -668,6 +742,7 @@
         tm.assert_series_equal(res, exp)
 
     def test_concat_categorical_ordered(self):
+        """ """
         # GH 13524
 
         s1 = pd.Series(pd.Categorical([1, 2, np.nan], ordered=True))
@@ -684,6 +759,7 @@
         tm.assert_series_equal(s1.append([s2, s1], ignore_index=True), exp)
 
     def test_concat_categorical_coercion_nan(self):
+        """ """
         # GH 13524
 
         # some edge cases
@@ -722,6 +798,7 @@
         tm.assert_series_equal(s1.append(s2, ignore_index=True), exp)
 
     def test_concat_categorical_empty(self):
+        """ """
         # GH 13524
 
         s1 = pd.Series([], dtype="category")
@@ -761,7 +838,21 @@
 
 
 class TestAppend:
+    """ """
     def test_append(self, sort, float_frame):
+        """
+
+        Parameters
+        ----------
+        sort :
+            
+        float_frame :
+            
+
+        Returns
+        -------
+
+        """
         mixed_frame = float_frame.copy()
         mixed_frame["foo"] = "bar"
 
@@ -796,6 +887,17 @@
         )
 
     def test_append_empty(self, float_frame):
+        """
+
+        Parameters
+        ----------
+        float_frame :
+            
+
+        Returns
+        -------
+
+        """
         empty = DataFrame()
 
         appended = float_frame.append(empty)
@@ -807,11 +909,23 @@
         assert appended is not float_frame
 
     def test_append_overlap_raises(self, float_frame):
+        """
+
+        Parameters
+        ----------
+        float_frame :
+            
+
+        Returns
+        -------
+
+        """
         msg = "Indexes have overlapping values"
         with pytest.raises(ValueError, match=msg):
             float_frame.append(float_frame, verify_integrity=True)
 
     def test_append_new_columns(self):
+        """ """
         # see gh-6129: new columns
         df = DataFrame({"a": {"x": 1, "y": 2}, "b": {"x": 3, "y": 4}})
         row = Series([5, 6, 7], index=["a", "b", "c"], name="z")
@@ -826,6 +940,17 @@
         tm.assert_frame_equal(result, expected)
 
     def test_append_length0_frame(self, sort):
+        """
+
+        Parameters
+        ----------
+        sort :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame(columns=["A", "B", "C"])
         df3 = DataFrame(index=[0, 1], columns=["A", "B"])
         df5 = df.append(df3, sort=sort)
@@ -834,6 +959,7 @@
         tm.assert_frame_equal(df5, expected)
 
     def test_append_records(self):
+        """ """
         arr1 = np.zeros((2,), dtype=("i4,f4,a10"))
         arr1[:] = [(1, 2.0, "Hello"), (2, 3.0, "World")]
 
@@ -849,6 +975,17 @@
 
     # rewrite sort fixture, since we also want to test default of None
     def test_append_sorts(self, sort):
+        """
+
+        Parameters
+        ----------
+        sort :
+            
+
+        Returns
+        -------
+
+        """
         df1 = pd.DataFrame({"a": [1, 2], "b": [1, 2]}, columns=["b", "a"])
         df2 = pd.DataFrame({"a": [1, 2], "c": [3, 4]}, index=[2, 3])
 
@@ -865,6 +1002,17 @@
         tm.assert_frame_equal(result, expected)
 
     def test_append_different_columns(self, sort):
+        """
+
+        Parameters
+        ----------
+        sort :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame(
             {
                 "bools": np.random.randn(10) > 0,
@@ -882,6 +1030,19 @@
         assert isna(appended["bools"][5:]).all()
 
     def test_append_many(self, sort, float_frame):
+        """
+
+        Parameters
+        ----------
+        sort :
+            
+        float_frame :
+            
+
+        Returns
+        -------
+
+        """
         chunks = [
             float_frame[:5],
             float_frame[5:10],
@@ -900,6 +1061,7 @@
         assert result["foo"][:15].isna().all()
 
     def test_append_preserve_index_name(self):
+        """ """
         # #980
         df1 = DataFrame(columns=["A", "B", "C"])
         df1 = df1.set_index(["A"])
@@ -934,6 +1096,17 @@
 
     @pytest.mark.parametrize("index", all_indexes, ids=lambda x: type(x).__name__)
     def test_append_same_columns_type(self, index):
+        """
+
+        Parameters
+        ----------
+        index :
+            
+
+        Returns
+        -------
+
+        """
         # GH18359
 
         # df wider than ser
@@ -965,6 +1138,19 @@
         ids=lambda x: type(x).__name__,
     )
     def test_append_different_columns_types(self, df_columns, series_index):
+        """
+
+        Parameters
+        ----------
+        df_columns :
+            
+        series_index :
+            
+
+        Returns
+        -------
+
+        """
         # GH18359
         # See also test 'test_append_different_columns_types_raises' below
         # for errors raised when appending
@@ -997,6 +1183,19 @@
     def test_append_different_columns_types_raises(
         self, index_can_append, index_cannot_append_with_other
     ):
+        """
+
+        Parameters
+        ----------
+        index_can_append :
+            
+        index_cannot_append_with_other :
+            
+
+        Returns
+        -------
+
+        """
         # GH18359
         # Dataframe.append will raise if MultiIndex appends
         # or is appended to a different index type
@@ -1024,6 +1223,17 @@
             df.append(ser)
 
     def test_append_dtype_coerce(self, sort):
+        """
+
+        Parameters
+        ----------
+        sort :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH 4993
         # appending with datetime will incorrectly convert datetime64
@@ -1075,6 +1285,17 @@
         tm.assert_frame_equal(result, expected)
 
     def test_append_missing_column_proper_upcast(self, sort):
+        """
+
+        Parameters
+        ----------
+        sort :
+            
+
+        Returns
+        -------
+
+        """
         df1 = DataFrame({"A": np.array([1, 2, 3, 4], dtype="i8")})
         df2 = DataFrame({"B": np.array([True, False, True, False], dtype=bool)})
 
@@ -1083,6 +1304,7 @@
         assert appended["B"].dtype == "O"
 
     def test_append_empty_frame_to_series_with_dateutil_tz(self):
+        """ """
         # GH 23682
         date = Timestamp("2018-10-24 07:30:00", tz=dateutil.tz.tzutc())
         s = Series({"date": date, "a": 1.0, "b": 2.0})
@@ -1111,6 +1333,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_append_empty_tz_frame_with_datetime64ns(self):
+        """ """
         # https://github.com/pandas-dev/pandas/issues/35460
         df = pd.DataFrame(columns=["a"]).astype("datetime64[ns, UTC]")
 
@@ -1129,7 +1352,9 @@
 
 
 class TestConcatenate:
+    """ """
     def test_concat_copy(self):
+        """ """
         df = DataFrame(np.random.randn(4, 3))
         df2 = DataFrame(np.random.randint(0, 10, size=4).reshape(4, 1))
         df3 = DataFrame({5: "foo"}, index=range(4))
@@ -1163,6 +1388,7 @@
                 assert b.values.base is not None
 
     def test_concat_with_group_keys(self):
+        """ """
         df = DataFrame(np.random.randn(4, 3))
         df2 = DataFrame(np.random.randn(4, 4))
 
@@ -1195,6 +1421,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_concat_keys_specific_levels(self):
+        """ """
         df = DataFrame(np.random.randn(10, 4))
         pieces = [df.iloc[:, [0, 1]], df.iloc[:, [2]], df.iloc[:, [3]]]
         level = ["three", "two", "one", "zero"]
@@ -1212,6 +1439,17 @@
         assert result.columns.names == ["group_key", None]
 
     def test_concat_dataframe_keys_bug(self, sort):
+        """
+
+        Parameters
+        ----------
+        sort :
+            
+
+        Returns
+        -------
+
+        """
         t1 = DataFrame(
             {"value": Series([1, 2, 3], index=Index(["a", "b", "c"], name="id"))}
         )
@@ -1222,6 +1460,7 @@
         assert list(result.columns) == [("t1", "value"), ("t2", "value")]
 
     def test_concat_series_partial_columns_names(self):
+        """ """
         # GH10698
         foo = Series([1, 2], name="foo")
         bar = Series([1, 2])
@@ -1246,6 +1485,19 @@
 
     @pytest.mark.parametrize("mapping", ["mapping", "dict"])
     def test_concat_mapping(self, mapping, non_dict_mapping_subclass):
+        """
+
+        Parameters
+        ----------
+        mapping :
+            
+        non_dict_mapping_subclass :
+            
+
+        Returns
+        -------
+
+        """
         constructor = dict if mapping == "dict" else non_dict_mapping_subclass
         frames = constructor(
             {
@@ -1272,6 +1524,17 @@
         tm.assert_frame_equal(result, expected)
 
     def test_concat_ignore_index(self, sort):
+        """
+
+        Parameters
+        ----------
+        sort :
+            
+
+        Returns
+        -------
+
+        """
         frame1 = DataFrame(
             {"test1": ["a", "b", "c"], "test2": [1, 2, 3], "test3": [4.5, 3.2, 1.2]}
         )
@@ -1297,6 +1560,7 @@
         tm.assert_frame_equal(v1, expected)
 
     def test_concat_multiindex_with_keys(self):
+        """ """
         index = MultiIndex(
             levels=[["foo", "bar", "baz", "qux"], ["one", "two", "three"]],
             codes=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3], [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
@@ -1315,6 +1579,7 @@
         assert result.index.nlevels == 3
 
     def test_concat_multiindex_with_tz(self):
+        """ """
         # GH 6606
         df = DataFrame(
             {
@@ -1344,6 +1609,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_concat_multiindex_with_none_in_index_names(self):
+        """ """
         # GH 15787
         index = pd.MultiIndex.from_product([[1], range(5)], names=["level1", None])
         df = pd.DataFrame({"col": range(5)}, index=index, dtype=np.int32)
@@ -1367,6 +1633,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_concat_keys_and_levels(self):
+        """ """
         df = DataFrame(np.random.randn(1, 3))
         df2 = DataFrame(np.random.randn(1, 4))
 
@@ -1408,6 +1675,7 @@
         )
 
     def test_concat_keys_levels_no_overlap(self):
+        """ """
         # GH #1406
         df = DataFrame(np.random.randn(1, 3), index=["a"])
         df2 = DataFrame(np.random.randn(1, 4), index=["b"])
@@ -1421,6 +1689,7 @@
             concat([df, df2], keys=["one", "two"], levels=[["foo", "bar", "baz"]])
 
     def test_concat_rename_index(self):
+        """ """
         a = DataFrame(
             np.random.rand(3, 3),
             columns=list("ABC"),
@@ -1443,6 +1712,7 @@
         assert result.index.names == exp.index.names
 
     def test_crossed_dtypes_weird_corner(self):
+        """ """
         columns = ["A", "B", "C", "D"]
         df1 = DataFrame(
             {
@@ -1476,6 +1746,7 @@
         assert result.index.names == ("first", "second")
 
     def test_dups_index(self):
+        """ """
         # GH 4771
 
         # single dtypes
@@ -1523,6 +1794,17 @@
         tm.assert_frame_equal(result, expected)
 
     def test_with_mixed_tuples(self, sort):
+        """
+
+        Parameters
+        ----------
+        sort :
+            
+
+        Returns
+        -------
+
+        """
         # 10697
         # columns have mixed tuples, so handle properly
         df1 = DataFrame({"A": "foo", ("B", 1): "bar"}, index=range(2))
@@ -1532,6 +1814,17 @@
         concat([df1, df2], sort=sort)
 
     def test_handle_empty_objects(self, sort):
+        """
+
+        Parameters
+        ----------
+        sort :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame(np.random.randn(10, 4), columns=list("abcd"))
 
         baz = df[:5].copy()
@@ -1564,6 +1857,7 @@
         tm.assert_frame_equal(result, df)
 
     def test_concat_mixed_objs(self):
+        """ """
 
         # concat mixed series/frames
         # G2385
@@ -1633,6 +1927,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_empty_dtype_coerce(self):
+        """ """
 
         # xref to #12411
         # xref to #12045
@@ -1647,6 +1942,7 @@
         tm.assert_series_equal(result.dtypes, expected)
 
     def test_dtype_coerceion(self):
+        """ """
 
         # 12411
         df = DataFrame({"date": [pd.Timestamp("20130101").tz_localize("UTC"), pd.NaT]})
@@ -1669,6 +1965,7 @@
         tm.assert_series_equal(result.dtypes, df.dtypes)
 
     def test_concat_series(self):
+        """ """
 
         ts = tm.makeTimeSeries()
         ts.name = "foo"
@@ -1690,6 +1987,17 @@
         tm.assert_series_equal(result, expected)
 
     def test_concat_series_axis1(self, sort=sort):
+        """
+
+        Parameters
+        ----------
+        sort :
+             (Default value = sort)
+
+        Returns
+        -------
+
+        """
         ts = tm.makeTimeSeries()
 
         pieces = [ts[:-2], ts[2:], ts[2:-2]]
@@ -1722,6 +2030,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_concat_series_axis1_names_applied(self):
+        """ """
         # ensure names argument is not ignored on axis=1, #23490
         s = Series([1, 2, 3])
         s2 = Series([4, 5, 6])
@@ -1739,6 +2048,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_concat_single_with_key(self):
+        """ """
         df = DataFrame(np.random.randn(10, 4))
 
         result = concat([df], keys=["foo"])
@@ -1746,6 +2056,7 @@
         tm.assert_frame_equal(result, expected[:10])
 
     def test_concat_exclude_none(self):
+        """ """
         df = DataFrame(np.random.randn(10, 4))
 
         pieces = [df[:5], None, None, df[5:]]
@@ -1755,6 +2066,7 @@
             concat([None, None])
 
     def test_concat_datetime64_block(self):
+        """ """
         from pandas.core.indexes.datetimes import date_range
 
         rng = date_range("1/1/2000", periods=10)
@@ -1766,6 +2078,7 @@
         assert (result.iloc[10:]["time"] == rng).all()
 
     def test_concat_timedelta64_block(self):
+        """ """
         from pandas import to_timedelta
 
         rng = to_timedelta(np.arange(10), unit="s")
@@ -1777,6 +2090,7 @@
         assert (result.iloc[10:]["time"] == rng).all()
 
     def test_concat_keys_with_none(self):
+        """ """
         # #1649
         df0 = DataFrame([[10, 20, 30], [10, 20, 30], [10, 20, 30]])
 
@@ -1791,6 +2105,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_concat_bug_1719(self):
+        """ """
         ts1 = tm.makeTimeSeries()
         ts2 = tm.makeTimeSeries()[::2]
 
@@ -1802,6 +2117,7 @@
         assert len(left) == len(right)
 
     def test_concat_bug_2972(self):
+        """ """
         ts0 = Series(np.zeros(5))
         ts1 = Series(np.ones(5))
         ts0.name = ts1.name = "same name"
@@ -1812,6 +2128,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_concat_bug_3602(self):
+        """ """
 
         # GH 3602, duplicate columns
         df1 = DataFrame(
@@ -1838,6 +2155,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_concat_inner_join_empty(self):
+        """ """
         # GH 15328
         df_empty = pd.DataFrame()
         df_a = pd.DataFrame({"a": [1, 2]}, index=[0, 1], dtype="int64")
@@ -1848,6 +2166,7 @@
             tm.assert_frame_equal(result, expected)
 
     def test_concat_series_axis1_same_names_ignore_index(self):
+        """ """
         dates = date_range("01-Jan-2013", "01-Jan-2014", freq="MS")[0:-1]
         s1 = Series(randn(len(dates)), index=dates, name="value")
         s2 = Series(randn(len(dates)), index=dates, name="value")
@@ -1858,6 +2177,7 @@
         tm.assert_index_equal(result.columns, expected)
 
     def test_concat_iterables(self):
+        """ """
         # GH8645 check concat works with tuples, list, generators, and weird
         # stuff like deque and custom iterables
         df1 = DataFrame([1, 2, 3])
@@ -1871,6 +2191,7 @@
         tm.assert_frame_equal(concat(deque((df1, df2)), ignore_index=True), expected)
 
         class CustomIterator1:
+            """ """
             def __len__(self) -> int:
                 return 2
 
@@ -1883,6 +2204,7 @@
         tm.assert_frame_equal(pd.concat(CustomIterator1(), ignore_index=True), expected)
 
         class CustomIterator2(abc.Iterable):
+            """ """
             def __iter__(self):
                 yield df1
                 yield df2
@@ -1890,6 +2212,7 @@
         tm.assert_frame_equal(pd.concat(CustomIterator2(), ignore_index=True), expected)
 
     def test_concat_invalid(self):
+        """ """
 
         # trying to concat a ndframe with a non-ndframe
         df1 = tm.makeCustomDataframe(10, 2)
@@ -1903,6 +2226,7 @@
                 concat([df1, obj])
 
     def test_concat_invalid_first_argument(self):
+        """ """
         df1 = tm.makeCustomDataframe(10, 2)
         df2 = tm.makeCustomDataframe(10, 2)
         msg = (
@@ -1932,6 +2256,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_concat_NaT_series(self):
+        """ """
         # GH 11693
         # test for merging NaT series with datetime series.
         x = Series(
@@ -1963,6 +2288,7 @@
         tm.assert_series_equal(result, expected)
 
     def test_concat_tz_frame(self):
+        """ """
         df2 = DataFrame(
             dict(
                 A=pd.Timestamp("20130102", tz="US/Eastern"),
@@ -1976,6 +2302,7 @@
         tm.assert_frame_equal(df2, df3)
 
     def test_concat_tz_series(self):
+        """ """
         # gh-11755: tz and no tz
         x = Series(date_range("20151124 08:00", "20151124 09:00", freq="1h", tz="UTC"))
         y = Series(date_range("2012-01-01", "2012-01-02"))
@@ -2032,6 +2359,7 @@
         assert result[0].dtype == "datetime64[ns, Europe/London]"
 
     def test_concat_tz_series_with_datetimelike(self):
+        """ """
         # see gh-12620: tz and timedelta
         x = [
             pd.Timestamp("2011-01-01", tz="US/Eastern"),
@@ -2047,6 +2375,7 @@
         tm.assert_series_equal(result, pd.Series(x + y, dtype="object"))
 
     def test_concat_tz_series_tzlocal(self):
+        """ """
         # see gh-13583
         x = [
             pd.Timestamp("2011-01-01", tz=dateutil.tz.tzlocal()),
@@ -2065,6 +2394,21 @@
     @pytest.mark.parametrize("tz2", [None, "UTC"])
     @pytest.mark.parametrize("s", [pd.NaT, pd.Timestamp("20150101")])
     def test_concat_NaT_dataframes_all_NaT_axis_0(self, tz1, tz2, s):
+        """
+
+        Parameters
+        ----------
+        tz1 :
+            
+        tz2 :
+            
+        s :
+            
+
+        Returns
+        -------
+
+        """
         # GH 12396
 
         # tz-naive
@@ -2084,6 +2428,19 @@
     @pytest.mark.parametrize("tz1", [None, "UTC"])
     @pytest.mark.parametrize("tz2", [None, "UTC"])
     def test_concat_NaT_dataframes_all_NaT_axis_1(self, tz1, tz2):
+        """
+
+        Parameters
+        ----------
+        tz1 :
+            
+        tz2 :
+            
+
+        Returns
+        -------
+
+        """
         # GH 12396
 
         first = pd.DataFrame(pd.Series([pd.NaT, pd.NaT]).dt.tz_localize(tz1))
@@ -2100,6 +2457,19 @@
     @pytest.mark.parametrize("tz1", [None, "UTC"])
     @pytest.mark.parametrize("tz2", [None, "UTC"])
     def test_concat_NaT_series_dataframe_all_NaT(self, tz1, tz2):
+        """
+
+        Parameters
+        ----------
+        tz1 :
+            
+        tz2 :
+            
+
+        Returns
+        -------
+
+        """
         # GH 12396
 
         # tz-naive
@@ -2128,6 +2498,17 @@
 
     @pytest.mark.parametrize("tz", [None, "UTC"])
     def test_concat_NaT_dataframes(self, tz):
+        """
+
+        Parameters
+        ----------
+        tz :
+            
+
+        Returns
+        -------
+
+        """
         # GH 12396
 
         first = pd.DataFrame([[pd.NaT], [pd.NaT]])
@@ -2149,6 +2530,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_concat_period_series(self):
+        """ """
         x = Series(pd.PeriodIndex(["2015-11-01", "2015-12-01"], freq="D"))
         y = Series(pd.PeriodIndex(["2015-10-01", "2016-01-01"], freq="D"))
         expected = Series([x[0], x[1], y[0], y[1]], dtype="Period[D]")
@@ -2156,6 +2538,7 @@
         tm.assert_series_equal(result, expected)
 
     def test_concat_period_multiple_freq_series(self):
+        """ """
         x = Series(pd.PeriodIndex(["2015-11-01", "2015-12-01"], freq="D"))
         y = Series(pd.PeriodIndex(["2015-10-01", "2016-01-01"], freq="M"))
         expected = Series([x[0], x[1], y[0], y[1]], dtype="object")
@@ -2164,6 +2547,7 @@
         assert result.dtype == "object"
 
     def test_concat_period_other_series(self):
+        """ """
         x = Series(pd.PeriodIndex(["2015-11-01", "2015-12-01"], freq="D"))
         y = Series(pd.PeriodIndex(["2015-11-01", "2015-12-01"], freq="M"))
         expected = Series([x[0], x[1], y[0], y[1]], dtype="object")
@@ -2187,6 +2571,7 @@
         assert result.dtype == "object"
 
     def test_concat_empty_series(self):
+        """ """
         # GH 11082
         s1 = pd.Series([1, 2, 3], name="x")
         s2 = pd.Series(name="y", dtype="float64")
@@ -2218,6 +2603,19 @@
     @pytest.mark.parametrize("tz", [None, "UTC"])
     @pytest.mark.parametrize("values", [[], [1, 2, 3]])
     def test_concat_empty_series_timelike(self, tz, values):
+        """
+
+        Parameters
+        ----------
+        tz :
+            
+        values :
+            
+
+        Returns
+        -------
+
+        """
         # GH 18447
 
         first = Series([], dtype="M8[ns]").dt.tz_localize(tz)
@@ -2234,6 +2632,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_default_index(self):
+        """ """
         # is_series and ignore_index
         s1 = pd.Series([1, 2, 3], name="x")
         s2 = pd.Series([4, 5, 6], name="y")
@@ -2266,6 +2665,7 @@
         tm.assert_frame_equal(res, exp, check_index_type=True, check_column_type=True)
 
     def test_concat_multiindex_rangeindex(self):
+        """ """
         # GH13542
         # when multi-index levels are RangeIndex objects
         # there is a bug in concat with objects of len 1
@@ -2281,6 +2681,7 @@
         tm.assert_frame_equal(res, exp)
 
     def test_concat_multiindex_dfs_with_deepcopy(self):
+        """ """
         # GH 9967
         from copy import deepcopy
 
@@ -2303,6 +2704,7 @@
         tm.assert_frame_equal(result_no_copy, expected)
 
     def test_categorical_concat_append(self):
+        """ """
         cat = Categorical(["a", "b"], categories=["a", "b"])
         vals = [1, 2]
         df = DataFrame({"cats": cat, "vals": vals})
@@ -2326,6 +2728,7 @@
         tm.assert_frame_equal(res, exp)
 
     def test_categorical_concat_dtypes(self):
+        """ """
 
         # GH8143
         index = ["cat", "obj", "num"]
@@ -2347,6 +2750,17 @@
         tm.assert_series_equal(result, expected)
 
     def test_categorical_concat(self, sort):
+        """
+
+        Parameters
+        ----------
+        sort :
+            
+
+        Returns
+        -------
+
+        """
         # See GH 10177
         df1 = DataFrame(
             np.arange(18, dtype="int64").reshape(6, 3), columns=["a", "b", "c"]
@@ -2383,6 +2797,7 @@
         tm.assert_frame_equal(res, exp)
 
     def test_categorical_concat_gh7864(self):
+        """ """
         # GH 7864
         # make sure ordering is preserved
         df = DataFrame({"id": [1, 2, 3, 4, 5, 6], "raw_grade": list("abbaae")})
@@ -2402,6 +2817,7 @@
         tm.assert_index_equal(df["grade"].cat.categories, dfa["grade"].cat.categories)
 
     def test_categorical_concat_preserve(self):
+        """ """
 
         # GH 8641  series concat not preserving category dtype
         # GH 13524 can concat different categories
@@ -2434,6 +2850,7 @@
         tm.assert_frame_equal(res, exp)
 
     def test_categorical_index_preserver(self):
+        """ """
 
         a = Series(np.arange(6, dtype="int64"))
         b = Series(list("aabbca"))
@@ -2459,6 +2876,7 @@
             pd.concat([df2, df3])
 
     def test_concat_categoricalindex(self):
+        """ """
         # GH 16111, categories that aren't lexsorted
         categories = [9, 0, 1, 2, 3]
 
@@ -2481,6 +2899,7 @@
         tm.assert_frame_equal(result, exp)
 
     def test_concat_order(self):
+        """ """
         # GH 17344
         dfs = [pd.DataFrame(index=range(3), columns=["a", 1, None])]
         dfs += [
@@ -2492,6 +2911,7 @@
         tm.assert_index_equal(result, expected)
 
     def test_concat_datetime_timezone(self):
+        """ """
         # GH 18523
         idx1 = pd.date_range("2011-01-01", periods=3, freq="H", tz="Europe/Paris")
         idx2 = pd.date_range(start=idx1[0], end=idx1[-1], freq="H")
@@ -2559,6 +2979,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_concat_different_extension_dtypes_upcasts(self):
+        """ """
         a = pd.Series(pd.core.arrays.integer_array([1, 2]))
         b = pd.Series(to_decimal([1, 2]))
 
@@ -2567,6 +2988,7 @@
         tm.assert_series_equal(result, expected)
 
     def test_concat_odered_dict(self):
+        """ """
         # GH 21510
         expected = pd.concat(
             [pd.Series(range(3)), pd.Series(range(4))], keys=["First", "Another"]
@@ -2582,6 +3004,19 @@
 @pytest.mark.parametrize("pdt", [pd.Series, pd.DataFrame])
 @pytest.mark.parametrize("dt", np.sctypes["float"])
 def test_concat_no_unnecessary_upcast(dt, pdt):
+    """
+
+    Parameters
+    ----------
+    dt :
+        
+    pdt :
+        
+
+    Returns
+    -------
+
+    """
     # GH 13247
     dims = pdt(dtype=object).ndim
 
@@ -2597,6 +3032,19 @@
 @pytest.mark.parametrize("pdt", [create_series_with_explicit_dtype, pd.DataFrame])
 @pytest.mark.parametrize("dt", np.sctypes["int"])
 def test_concat_will_upcast(dt, pdt):
+    """
+
+    Parameters
+    ----------
+    dt :
+        
+    pdt :
+        
+
+    Returns
+    -------
+
+    """
     with catch_warnings(record=True):
         dims = pdt().ndim
         dfs = [
@@ -2609,6 +3057,7 @@
 
 
 def test_concat_empty_and_non_empty_frame_regression():
+    """ """
     # GH 18178 regression test
     df1 = pd.DataFrame({"foo": [1]})
     df2 = pd.DataFrame({"foo": []})
@@ -2618,6 +3067,7 @@
 
 
 def test_concat_empty_and_non_empty_series_regression():
+    """ """
     # GH 18187 regression test
     s1 = pd.Series([1])
     s2 = pd.Series([], dtype=object)
@@ -2628,6 +3078,17 @@
 
 
 def test_concat_sorts_columns(sort):
+    """
+
+    Parameters
+    ----------
+    sort :
+        
+
+    Returns
+    -------
+
+    """
     # GH-4588
     df1 = pd.DataFrame({"a": [1, 2], "b": [1, 2]}, columns=["b", "a"])
     df2 = pd.DataFrame({"a": [3, 4], "c": [5, 6]})
@@ -2648,6 +3109,17 @@
 
 
 def test_concat_sorts_index(sort):
+    """
+
+    Parameters
+    ----------
+    sort :
+        
+
+    Returns
+    -------
+
+    """
     df1 = pd.DataFrame({"a": [1, 2, 3]}, index=["c", "a", "b"])
     df2 = pd.DataFrame({"b": [1, 2]}, index=["a", "b"])
 
@@ -2665,6 +3137,17 @@
 
 
 def test_concat_inner_sort(sort):
+    """
+
+    Parameters
+    ----------
+    sort :
+        
+
+    Returns
+    -------
+
+    """
     # https://github.com/pandas-dev/pandas/pull/20613
     df1 = pd.DataFrame({"a": [1, 2], "b": [1, 2], "c": [1, 2]}, columns=["b", "a", "c"])
     df2 = pd.DataFrame({"a": [1, 2], "b": [3, 4]}, index=[3, 4])
@@ -2681,6 +3164,7 @@
 
 
 def test_concat_aligned_sort():
+    """ """
     # GH-4588
     df = pd.DataFrame({"c": [1, 2], "b": [3, 4], "a": [5, 6]}, columns=["c", "b", "a"])
     result = pd.concat([df, df], sort=True, ignore_index=True)
@@ -2696,6 +3180,7 @@
 
 
 def test_concat_aligned_sort_does_not_raise():
+    """ """
     # GH-4588
     # We catch TypeErrors from sorting internally and do not re-raise.
     df = pd.DataFrame({1: [1, 2], "a": [3, 4]}, columns=[1, "a"])
@@ -2706,6 +3191,19 @@
 
 @pytest.mark.parametrize("s1name,s2name", [(np.int64(190), (43, 0)), (190, (43, 0))])
 def test_concat_series_name_npscalar_tuple(s1name, s2name):
+    """
+
+    Parameters
+    ----------
+    s1name :
+        
+    s2name :
+        
+
+    Returns
+    -------
+
+    """
     # GH21015
     s1 = pd.Series({"a": 1, "b": 2}, name=s1name)
     s2 = pd.Series({"c": 5, "d": 6}, name=s2name)
@@ -2715,6 +3213,7 @@
 
 
 def test_concat_categorical_tz():
+    """ """
     # GH-23816
     a = pd.Series(pd.date_range("2017-01-01", periods=2, tz="US/Pacific"))
     b = pd.Series(["a", "b"], dtype="category")
@@ -2731,6 +3230,7 @@
 
 
 def test_concat_categorical_unchanged():
+    """ """
     # GH-12007
     # test fix for when concat on categorical and float
     # coerces dtype categorical -> float
@@ -2747,6 +3247,7 @@
 
 
 def test_concat_datetimeindex_freq():
+    """ """
     # GH 3232
     # Monotonic index result
     dr = pd.date_range("01-Jan-2013", periods=100, freq="50L", tz="UTC")
@@ -2763,6 +3264,7 @@
 
 
 def test_concat_empty_df_object_dtype():
+    """ """
     # GH 9149
     df_1 = pd.DataFrame({"Row": [0, 1, 1], "EmptyCol": np.nan, "NumberCol": [1, 2, 3]})
     df_2 = pd.DataFrame(columns=df_1.columns)
@@ -2772,6 +3274,7 @@
 
 
 def test_concat_sparse():
+    """ """
     # GH 23557
     a = pd.Series(SparseArray([0, 1, 2]))
     expected = pd.DataFrame(data=[[0, 0], [1, 1], [2, 2]]).astype(
@@ -2782,6 +3285,7 @@
 
 
 def test_concat_dense_sparse():
+    """ """
     # GH 30668
     a = pd.Series(pd.arrays.SparseArray([1, None]), dtype=float)
     b = pd.Series([1], dtype=float)
@@ -2794,6 +3298,19 @@
 
 @pytest.mark.parametrize("test_series", [True, False])
 def test_concat_copy_index(test_series, axis):
+    """
+
+    Parameters
+    ----------
+    test_series :
+        
+    axis :
+        
+
+    Returns
+    -------
+
+    """
     # GH 29879
     if test_series:
         ser = Series([1, 2])
@@ -2807,6 +3324,7 @@
 
 
 def test_concat_multiindex_datetime_object_index():
+    """ """
     # https://github.com/pandas-dev/pandas/issues/11058
     s = Series(
         ["a", "b"],
@@ -2842,6 +3360,17 @@
 
 @pytest.mark.parametrize("keys", [["e", "f", "f"], ["f", "e", "f"]])
 def test_duplicate_keys(keys):
+    """
+
+    Parameters
+    ----------
+    keys :
+        
+
+    Returns
+    -------
+
+    """
     # GH 33654
     df = DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})
     s1 = Series([7, 8, 9], name="c")
@@ -2863,6 +3392,17 @@
     ],
 )
 def test_concat_preserves_subclass(obj):
+    """
+
+    Parameters
+    ----------
+    obj :
+        
+
+    Returns
+    -------
+
+    """
     # GH28330 -- preserve subclass
 
     result = concat([obj, obj])
@@ -2870,6 +3410,7 @@
 
 
 def test_concat_frame_axis0_extension_dtypes():
+    """ """
     # preserve extension dtype (through common_dtype mechanism)
     df1 = pd.DataFrame({"a": pd.array([1, 2, 3], dtype="Int64")})
     df2 = pd.DataFrame({"a": np.array([4, 5, 6])})
