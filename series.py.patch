# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/core/series.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/core/series.py
@@ -119,11 +119,20 @@
 
 
 def _coerce_method(converter):
+    """Install the scalar coercion methods.
+
+    Parameters
+    ----------
+    converter :
+        
+
+    Returns
+    -------
+
     """
-    Install the scalar coercion methods.
-    """
 
     def wrapper(self):
+        """ """
         if len(self) == 1:
             return converter(self.iloc[0])
         raise TypeError(f"cannot convert the series to {converter}")
@@ -137,42 +146,25 @@
 
 
 class Series(base.IndexOpsMixin, generic.NDFrame):
-    """
-    One-dimensional ndarray with axis labels (including time series).
-
+    """One-dimensional ndarray with axis labels (including time series).
+    
     Labels need not be unique but must be a hashable type. The object
     supports both integer- and label-based indexing and provides a host of
     methods for performing operations involving the index. Statistical
     methods from ndarray have been overridden to automatically exclude
     missing data (currently represented as NaN).
-
+    
     Operations between Series (+, -, /, *, **) align values based on their
     associated index values-- they need not be the same length. The result
     index will be the sorted union of the two indexes.
 
     Parameters
     ----------
-    data : array-like, Iterable, dict, or scalar value
-        Contains data stored in Series.
-
-        .. versionchanged:: 0.23.0
-           If data is a dict, argument order is maintained for Python 3.6
-           and later.
-
-    index : array-like or Index (1d)
-        Values must be hashable and have the same length as `data`.
-        Non-unique index values are allowed. Will default to
-        RangeIndex (0, 1, 2, ..., n) if not provided. If both a dict and index
-        sequence are used, the index will override the keys found in the
-        dict.
-    dtype : str, numpy.dtype, or ExtensionDtype, optional
-        Data type for the output Series. If not specified, this will be
-        inferred from `data`.
-        See the :ref:`user guide <basics.dtypes>` for more usages.
-    name : str, optional
-        The name to give to the Series.
-    copy : bool, default False
-        Copy input data.
+
+    Returns
+    -------
+
+    
     """
 
     _typ = "series"
@@ -333,8 +325,7 @@
         self._set_axis(0, index, fastpath=True)
 
     def _init_dict(self, data, index=None, dtype=None):
-        """
-        Derive the "_mgr" and "index" attributes of a new Series from a
+        """Derive the "_mgr" and "index" attributes of a new Series from a
         dictionary input.
 
         Parameters
@@ -342,14 +333,14 @@
         data : dict or dict-like
             Data used to populate the new Series.
         index : Index or index-like, default None
-            Index for the new Series: if None, use dict keys.
+            Index for the new Series: if None, use dict keys. (Default value = None)
         dtype : dtype, default None
-            The dtype for the new Series: if None, infer from data.
-
-        Returns
-        -------
-        _data : BlockManager for the new Series
-        index : index for the new Series
+            The dtype for the new Series: if None, infer from data. (Default value = None)
+
+        Returns
+        -------
+
+        
         """
         # Looking for NaN in dict doesn't work ({np.nan : 1}[float('nan')]
         # raises KeyError), so we iterate the entire dict, and align
@@ -380,10 +371,12 @@
 
     @property
     def _constructor(self) -> Type["Series"]:
+        """ """
         return Series
 
     @property
     def _constructor_expanddim(self) -> Type["DataFrame"]:
+        """ """
         from pandas.core.frame import DataFrame
 
         return DataFrame
@@ -391,16 +384,29 @@
     # types
     @property
     def _can_hold_na(self):
+        """ """
         return self._mgr._can_hold_na
 
     _index = None
 
     def _set_axis(self, axis: int, labels, fastpath: bool = False) -> None:
-        """
-        Override generic, we want to set the _typ here.
-
+        """Override generic, we want to set the _typ here.
+        
         This is called from the cython code when we set the `index` attribute
         directly, e.g. `series.index = [1, 2, 3]`.
+
+        Parameters
+        ----------
+        axis: int :
+            
+        labels :
+            
+        fastpath: bool :
+             (Default value = False)
+
+        Returns
+        -------
+
         """
         if not fastpath:
             labels = ensure_index(labels)
@@ -426,28 +432,26 @@
     # ndarray compatibility
     @property
     def dtype(self) -> DtypeObj:
-        """
-        Return the dtype object of the underlying data.
-        """
+        """ """
         return self._mgr.dtype
 
     @property
     def dtypes(self) -> DtypeObj:
-        """
-        Return the dtype object of the underlying data.
-        """
+        """ """
         # DataFrame compatibility
         return self.dtype
 
     @property
     def name(self) -> Label:
-        """
-        Return the name of the Series.
-
+        """Return the name of the Series.
+        
         The name of a Series becomes its index or column name if it is used
         to form a DataFrame. It is also used whenever displaying the Series
         using the interpreter.
 
+        Parameters
+        ----------
+
         Returns
         -------
         label (hashable object)
@@ -457,11 +461,12 @@
         --------
         Series.rename : Sets the Series name when given a scalar input.
         Index.name : Corresponding Index property.
-
         Examples
         --------
         The Series name can be set initially when calling the constructor.
-
+        
+        
+        The name of a Series within a DataFrame is its column name.
         >>> s = pd.Series([1, 2, 3], dtype=np.int64, name='Numbers')
         >>> s
         0    1
@@ -474,9 +479,7 @@
         1    2
         2    3
         Name: Integers, dtype: int64
-
-        The name of a Series within a DataFrame is its column name.
-
+        
         >>> df = pd.DataFrame([[1, 2], [3, 4], [5, 6]],
         ...                   columns=["Odd Numbers", "Even Numbers"])
         >>> df
@@ -491,44 +494,59 @@
 
     @name.setter
     def name(self, value: Label) -> None:
+        """
+
+        Parameters
+        ----------
+        value: Label :
+            
+
+        Returns
+        -------
+
+        """
         if not is_hashable(value):
             raise TypeError("Series.name must be a hashable type")
         object.__setattr__(self, "_name", value)
 
     @property
     def values(self):
-        """
-        Return Series as ndarray or ndarray-like depending on the dtype.
-
+        """Return Series as ndarray or ndarray-like depending on the dtype.
+        
         .. warning::
-
+        
            We recommend using :attr:`Series.array` or
            :meth:`Series.to_numpy`, depending on whether you need
            a reference to the underlying data or a NumPy array.
 
+        Parameters
+        ----------
+
         Returns
         -------
         numpy.ndarray or ndarray-like
+            
 
         See Also
         --------
         Series.array : Reference to the underlying data.
         Series.to_numpy : A NumPy array representing the underlying data.
-
         Examples
         --------
+        
+        
+        
+        Timezone aware datetime data is converted to UTC:
         >>> pd.Series([1, 2, 3]).values
         array([1, 2, 3])
-
+        
         >>> pd.Series(list('aabc')).values
         array(['a', 'a', 'b', 'c'], dtype=object)
-
+        
         >>> pd.Series(list('aabc')).astype('category').values
         ['a', 'a', 'b', 'c']
         Categories (3, object): ['a', 'b', 'c']
-
-        Timezone aware datetime data is converted to UTC:
-
+        
         >>> pd.Series(pd.date_range('20130101', periods=3,
         ...                         tz='US/Eastern')).values
         array(['2013-01-01T05:00:00.000000000',
@@ -539,34 +557,39 @@
 
     @property
     def _values(self):
-        """
-        Return the internal repr of this data (defined by Block.interval_values).
+        """Return the internal repr of this data (defined by Block.interval_values).
         This are the values as stored in the Block (ndarray or ExtensionArray
         depending on the Block class), with datetime64[ns] and timedelta64[ns]
         wrapped in ExtensionArrays to match Index._values behavior.
-
+        
         Differs from the public ``.values`` for certain data types, because of
         historical backwards compatibility of the public attribute (e.g. period
-        returns object ndarray and datetimetz a datetime64[ns] ndarray for
-        ``.values`` while it returns an ExtensionArray for ``._values`` in those
-        cases).
-
-        Differs from ``.array`` in that this still returns the numpy array if
-        the Block is backed by a numpy array (except for datetime64 and
-        timedelta64 dtypes), while ``.array`` ensures to always return an
-        ExtensionArray.
-
-        Overview:
-
-        dtype       | values        | _values       | array         |
-        ----------- | ------------- | ------------- | ------------- |
-        Numeric     | ndarray       | ndarray       | PandasArray   |
-        Category    | Categorical   | Categorical   | Categorical   |
-        dt64[ns]    | ndarray[M8ns] | DatetimeArray | DatetimeArray |
-        dt64[ns tz] | ndarray[M8ns] | DatetimeArray | DatetimeArray |
-        td64[ns]    | ndarray[m8ns] | TimedeltaArray| ndarray[m8ns] |
-        Period      | ndarray[obj]  | PeriodArray   | PeriodArray   |
-        Nullable    | EA            | EA            | EA            |
+
+        Parameters
+        ----------
+
+        Returns
+        -------
+        type
+            ``.values`` while it returns an ExtensionArray for ``._values`` in those
+            cases).
+            
+            Differs from ``.array`` in that this still returns the numpy array if
+            the Block is backed by a numpy array (except for datetime64 and
+            timedelta64 dtypes), while ``.array`` ensures to always return an
+            ExtensionArray.
+            
+            Overview:
+            
+            dtype       | values        | _values       | array         |
+            ----------- | ------------- | ------------- | ------------- |
+            Numeric     | ndarray       | ndarray       | PandasArray   |
+            Category    | Categorical   | Categorical   | Categorical   |
+            dt64[ns]    | ndarray[M8ns] | DatetimeArray | DatetimeArray |
+            dt64[ns tz] | ndarray[M8ns] | DatetimeArray | DatetimeArray |
+            td64[ns]    | ndarray[m8ns] | TimedeltaArray| ndarray[m8ns] |
+            Period      | ndarray[obj]  | PeriodArray   | PeriodArray   |
+            Nullable    | EA            | EA            | EA            |
 
         """
         return self._mgr.internal_values()
@@ -574,12 +597,17 @@
     @Appender(base.IndexOpsMixin.array.__doc__)  # type: ignore
     @property
     def array(self) -> ExtensionArray:
+        """ """
         return self._mgr._block.array_values()
 
     # ops
     def ravel(self, order="C"):
-        """
-        Return the flattened underlying data as an ndarray.
+        """Return the flattened underlying data as an ndarray.
+
+        Parameters
+        ----------
+        order :
+             (Default value = "C")
 
         Returns
         -------
@@ -599,9 +627,8 @@
         return len(self._mgr)
 
     def view(self, dtype=None) -> "Series":
-        """
-        Create a new view of the Series.
-
+        """Create a new view of the Series.
+        
         This function will return a new Series with a view of the same
         underlying values in memory, optionally reinterpreted with a new data
         type. The new data type must preserve the same size in bytes as to not
@@ -610,7 +637,7 @@
         Parameters
         ----------
         dtype : data type
-            Data type object or one of their string representations.
+            Data type object or one of their string representations. (Default value = None)
 
         Returns
         -------
@@ -621,7 +648,6 @@
         --------
         numpy.ndarray.view : Equivalent numpy function to create a new view of
             the same data in memory.
-
         Notes
         -----
         Series are instantiated with ``dtype=float64`` by default. While
@@ -629,9 +655,14 @@
         the original array, ``Series.view()`` (without specified dtype)
         will try using ``float64`` and may fail if the original data type size
         in bytes is not the same.
-
         Examples
         --------
+        
+        The 8 bit signed integer representation of `-1` is `0b11111111`, but
+        the same bytes represent 255 if read as an 8 bit unsigned integer:
+        
+        
+        The views share the same underlying values:
         >>> s = pd.Series([-2, -1, 0, 1, 2], dtype='int8')
         >>> s
         0   -2
@@ -640,10 +671,7 @@
         3    1
         4    2
         dtype: int8
-
-        The 8 bit signed integer representation of `-1` is `0b11111111`, but
-        the same bytes represent 255 if read as an 8 bit unsigned integer:
-
+        
         >>> us = s.view('uint8')
         >>> us
         0    254
@@ -652,9 +680,7 @@
         3      1
         4      2
         dtype: uint8
-
-        The views share the same underlying values:
-
+        
         >>> us[0] = 128
         >>> s
         0   -128
@@ -728,6 +754,17 @@
         name = names[0] if len(set(names)) == 1 else None
 
         def construct_return(result):
+            """
+
+            Parameters
+            ----------
+            result :
+                
+
+            Returns
+            -------
+
+            """
             if lib.is_scalar(result):
                 return result
             elif result.ndim > 1:
@@ -809,9 +846,7 @@
     # indexers
     @property
     def axes(self) -> List[Index]:
-        """
-        Return a list of the row axis labels.
-        """
+        """ """
         return [self.index]
 
     # ----------------------------------------------------------------------
@@ -819,6 +854,23 @@
 
     @Appender(generic.NDFrame.take.__doc__)
     def take(self, indices, axis=0, is_copy=None, **kwargs) -> "Series":
+        """
+
+        Parameters
+        ----------
+        indices :
+            
+        axis :
+             (Default value = 0)
+        is_copy :
+             (Default value = None)
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         if is_copy is not None:
             warnings.warn(
                 "is_copy is deprecated and will be removed in a future version. "
@@ -836,31 +888,59 @@
         return result.__finalize__(self, method="take")
 
     def _take_with_is_copy(self, indices, axis=0):
-        """
-        Internal version of the `take` method that sets the `_is_copy`
+        """Internal version of the `take` method that sets the `_is_copy`
         attribute to keep track of the parent dataframe (using in indexing
         for the SettingWithCopyWarning). For Series this does the same
         as the public take (it never sets `_is_copy`).
-
+        
         See the docstring of `take` for full explanation of the parameters.
+
+        Parameters
+        ----------
+        indices :
+            
+        axis :
+             (Default value = 0)
+
+        Returns
+        -------
+
         """
         return self.take(indices=indices, axis=axis)
 
     def _ixs(self, i: int, axis: int = 0):
-        """
-        Return the i-th value or values in the Series by location.
+        """Return the i-th value or values in the Series by location.
 
         Parameters
         ----------
         i : int
-
-        Returns
-        -------
-        scalar (int) or Series (slice, sequence)
+            
+        i: int :
+            
+        axis: int :
+             (Default value = 0)
+
+        Returns
+        -------
+
+        
         """
         return self._values[i]
 
     def _slice(self, slobj: slice, axis: int = 0) -> "Series":
+        """
+
+        Parameters
+        ----------
+        slobj: slice :
+            
+        axis: int :
+             (Default value = 0)
+
+        Returns
+        -------
+
+        """
         # axis kwarg is retained for compat with NDFrame method
         #  _slice is *always* positional
         return self._get_values(slobj)
@@ -906,6 +986,17 @@
         return self._get_with(key)
 
     def _get_with(self, key):
+        """
+
+        Parameters
+        ----------
+        key :
+            
+
+        Returns
+        -------
+
+        """
         # other: fancy integer or otherwise
         if isinstance(key, slice):
             # _convert_slice_indexer to determine if this slice is positional
@@ -946,6 +1037,17 @@
         return self.loc[key]
 
     def _get_values_tuple(self, key):
+        """
+
+        Parameters
+        ----------
+        key :
+            
+
+        Returns
+        -------
+
+        """
         # mpl hackaround
         if com.any_none(*key):
             result = self._get_values(key)
@@ -962,6 +1064,17 @@
         )
 
     def _get_values(self, indexer):
+        """
+
+        Parameters
+        ----------
+        indexer :
+            
+
+        Returns
+        -------
+
+        """
         try:
             return self._constructor(self._mgr.get_slice(indexer)).__finalize__(self,)
         except ValueError:
@@ -970,17 +1083,21 @@
             return self._values[indexer]
 
     def _get_value(self, label, takeable: bool = False):
-        """
-        Quickly retrieve single value at passed index label.
+        """Quickly retrieve single value at passed index label.
 
         Parameters
         ----------
         label : object
+            
         takeable : interpret the index as indexers, default False
-
-        Returns
-        -------
-        scalar value
+            
+        takeable: bool :
+             (Default value = False)
+
+        Returns
+        -------
+
+        
         """
         if takeable:
             return self._values[label]
@@ -1029,12 +1146,38 @@
             self._maybe_update_cacher()
 
     def _set_with_engine(self, key, value):
+        """
+
+        Parameters
+        ----------
+        key :
+            
+        value :
+            
+
+        Returns
+        -------
+
+        """
         # fails with AttributeError for IntervalIndex
         loc = self.index._engine.get_loc(key)
         validate_numeric_casting(self.dtype, value)
         self._values[loc] = value
 
     def _set_with(self, key, value):
+        """
+
+        Parameters
+        ----------
+        key :
+            
+        value :
+            
+
+        Returns
+        -------
+
+        """
         # other: fancy integer or otherwise
         if isinstance(key, slice):
             indexer = self.index._convert_slice_indexer(key, kind="getitem")
@@ -1063,6 +1206,19 @@
                 self.loc[key] = value
 
     def _set_labels(self, key, value):
+        """
+
+        Parameters
+        ----------
+        key :
+            
+        value :
+            
+
+        Returns
+        -------
+
+        """
         key = com.asarray_tuplesafe(key)
         indexer: np.ndarray = self.index.get_indexer(key)
         mask = indexer == -1
@@ -1071,25 +1227,43 @@
         self._set_values(indexer, value)
 
     def _set_values(self, key, value):
+        """
+
+        Parameters
+        ----------
+        key :
+            
+        value :
+            
+
+        Returns
+        -------
+
+        """
         if isinstance(key, Series):
             key = key._values
         self._mgr = self._mgr.setitem(indexer=key, value=value)
         self._maybe_update_cacher()
 
     def _set_value(self, label, value, takeable: bool = False):
-        """
-        Quickly set single value at passed label.
-
+        """Quickly set single value at passed label.
+        
         If label is not contained, a new object is created with the label
         placed at the end of the result index.
 
         Parameters
         ----------
-        label : object
-            Partial indexing with MultiIndex not allowed.
-        value : object
-            Scalar value.
-        takeable : interpret the index as indexers, default False
+        label :
+            
+        value :
+            
+        takeable: bool :
+             (Default value = False)
+
+        Returns
+        -------
+
+        
         """
         try:
             if takeable:
@@ -1108,12 +1282,12 @@
 
     @property
     def _is_mixed_type(self):
+        """ """
         return False
 
     def repeat(self, repeats, axis=None) -> "Series":
-        """
-        Repeat elements of a Series.
-
+        """Repeat elements of a Series.
+        
         Returns a new Series where each element of the current Series
         is repeated consecutively a given number of times.
 
@@ -1125,7 +1299,7 @@
             Series.
         axis : None
             Must be ``None``. Has no effect but is accepted for compatibility
-            with numpy.
+            with numpy. (Default value = None)
 
         Returns
         -------
@@ -1136,7 +1310,6 @@
         --------
         Index.repeat : Equivalent function for Index.
         numpy.repeat : Similar method for :class:`numpy.ndarray`.
-
         Examples
         --------
         >>> s = pd.Series(['a', 'b', 'c'])
@@ -1170,9 +1343,8 @@
         )
 
     def reset_index(self, level=None, drop=False, name=None, inplace=False):
-        """
-        Generate a new DataFrame or Series with the index reset.
-
+        """Generate a new DataFrame or Series with the index reset.
+        
         This is useful when the index needs to be treated as a column, or
         when the index is meaningless and needs to be reset to the default
         before another operation.
@@ -1184,13 +1356,13 @@
             from the index. Removes all levels by default.
         drop : bool, default False
             Just reset the index, without inserting it as a column in
-            the new DataFrame.
+            the new DataFrame. (Default value = False)
         name : object, optional
             The name to use for the column containing the original Series
             values. Uses ``self.name`` by default. This argument is ignored
             when `drop` is True.
         inplace : bool, default False
-            Modify the Series in place (do not create a new object).
+            Modify the Series in place (do not create a new object). (Default value = False)
 
         Returns
         -------
@@ -1204,42 +1376,54 @@
         See Also
         --------
         DataFrame.reset_index: Analogous function for DataFrame.
-
         Examples
         --------
+        
+        Generate a DataFrame with default index.
+        
+        
+        To specify the name of the new column use `name`.
+        
+        
+        To generate a new Series with the default set `drop` to True.
+        
+        
+        To update the Series in place, without generating a new one
+        set `inplace` to True. Note that it also requires ``drop=True``.
+        
+        
+        The `level` parameter is interesting for Series with a multi-level
+        index.
+        
+        
+        To remove a specific level from the Index, use `level`.
+        
+        
+        If `level` is not set, all levels are removed from the Index.
         >>> s = pd.Series([1, 2, 3, 4], name='foo',
         ...               index=pd.Index(['a', 'b', 'c', 'd'], name='idx'))
-
-        Generate a DataFrame with default index.
-
+        
         >>> s.reset_index()
           idx  foo
         0   a    1
         1   b    2
         2   c    3
         3   d    4
-
-        To specify the name of the new column use `name`.
-
+        
         >>> s.reset_index(name='values')
           idx  values
         0   a       1
         1   b       2
         2   c       3
         3   d       4
-
-        To generate a new Series with the default set `drop` to True.
-
+        
         >>> s.reset_index(drop=True)
         0    1
         1    2
         2    3
         3    4
         Name: foo, dtype: int64
-
-        To update the Series in place, without generating a new one
-        set `inplace` to True. Note that it also requires ``drop=True``.
-
+        
         >>> s.reset_index(inplace=True, drop=True)
         >>> s
         0    1
@@ -1247,19 +1431,14 @@
         2    3
         3    4
         Name: foo, dtype: int64
-
-        The `level` parameter is interesting for Series with a multi-level
-        index.
-
+        
         >>> arrays = [np.array(['bar', 'bar', 'baz', 'baz']),
         ...           np.array(['one', 'two', 'one', 'two'])]
         >>> s2 = pd.Series(
         ...     range(4), name='foo',
         ...     index=pd.MultiIndex.from_arrays(arrays,
         ...                                     names=['a', 'b']))
-
-        To remove a specific level from the Index, use `level`.
-
+        
         >>> s2.reset_index(level='a')
                a  foo
         b
@@ -1267,9 +1446,7 @@
         two  bar    1
         one  baz    2
         two  baz    3
-
-        If `level` is not set, all levels are removed from the Index.
-
+        
         >>> s2.reset_index()
              a    b  foo
         0  bar  one    0
@@ -1349,39 +1526,38 @@
         max_rows=None,
         min_rows=None,
     ):
-        """
-        Render a string representation of the Series.
+        """Render a string representation of the Series.
 
         Parameters
         ----------
         buf : StringIO-like, optional
-            Buffer to write to.
+            Buffer to write to. (Default value = None)
         na_rep : str, optional
             String representation of NaN to use, default 'NaN'.
         float_format : one-parameter function, optional
             Formatter function to apply to columns' elements if they are
             floats, default None.
         header : bool, default True
-            Add the Series header (index name).
+            Add the Series header (index name). (Default value = True)
         index : bool, optional
             Add index (row) labels, default True.
         length : bool, default False
-            Add the Series length.
+            Add the Series length. (Default value = False)
         dtype : bool, default False
-            Add the Series dtype.
+            Add the Series dtype. (Default value = False)
         name : bool, default False
-            Add the Series name if not None.
+            Add the Series name if not None. (Default value = False)
         max_rows : int, optional
             Maximum number of rows to show before truncating. If None, show
-            all.
+            all. (Default value = None)
         min_rows : int, optional
             The number of rows to display in a truncated repr (when number
-            of rows is above `max_rows`).
-
-        Returns
-        -------
-        str or None
-            String representation of Series if ``buf=None``, otherwise None.
+            of rows is above `max_rows`). (Default value = None)
+
+        Returns
+        -------
+
+        
         """
         formatter = fmt.SeriesFormatter(
             self,
@@ -1437,9 +1613,8 @@
         index: bool = True,
         **kwargs,
     ) -> Optional[str]:
-        """
-        Print {klass} in Markdown-friendly format.
-
+        """Print {klass} in Markdown-friendly format.
+        
         .. versionadded:: 1.0.0
 
         Parameters
@@ -1450,12 +1625,16 @@
             Mode in which file is opened.
         index : bool, optional, default True
             Add index (row) labels.
-
             .. versionadded:: 1.1.0
-
-        **kwargs
+        **kwargs :
             These parameters will be passed to `tabulate \
-                <https://pypi.org/project/tabulate>`_.
+            <https://pypi.org/project/tabulate>`_.
+        buf: Optional[IO[str]] :
+             (Default value = None)
+        mode: Optional[str] :
+             (Default value = None)
+        index: bool :
+             (Default value = True)
 
         Returns
         -------
@@ -1464,6 +1643,8 @@
 
         Examples
         --------
+        
+        Output markdown with a tabulate option.
         >>> s = pd.Series(["elk", "pig", "dog", "quetzal"], name="animal")
         >>> print(s.to_markdown())
         |    | animal   |
@@ -1472,9 +1653,7 @@
         |  1 | pig      |
         |  2 | dog      |
         |  3 | quetzal  |
-
-        Output markdown with a tabulate option.
-
+        
         >>> print(s.to_markdown(tablefmt="grid"))
         +----+----------+
         |    | animal   |
@@ -1493,11 +1672,13 @@
     # ----------------------------------------------------------------------
 
     def items(self) -> Iterable[Tuple[Label, Any]]:
-        """
-        Lazily iterate over (index, value) tuples.
-
+        """Lazily iterate over (index, value) tuples.
+        
         This method returns an iterable tuple (index, value). This is
         convenient if you want to create a lazy iterator.
+
+        Parameters
+        ----------
 
         Returns
         -------
@@ -1509,7 +1690,6 @@
         --------
         DataFrame.items : Iterate over (column name, Series) pairs.
         DataFrame.iterrows : Iterate over DataFrame rows as (index, Series) pairs.
-
         Examples
         --------
         >>> s = pd.Series(['A', 'B', 'C'])
@@ -1523,25 +1703,18 @@
 
     @Appender(items.__doc__)
     def iteritems(self) -> Iterable[Tuple[Label, Any]]:
+        """ """
         return self.items()
 
     # ----------------------------------------------------------------------
     # Misc public methods
 
     def keys(self) -> Index:
-        """
-        Return alias for index.
-
-        Returns
-        -------
-        Index
-            Index of the Series.
-        """
+        """Return alias for index."""
         return self.index
 
     def to_dict(self, into=dict):
-        """
-        Convert Series to {label -> value} dict or dict-like object.
+        """Convert Series to {label -> value} dict or dict-like object.
 
         Parameters
         ----------
@@ -1573,14 +1746,13 @@
         return into_c(self.items())
 
     def to_frame(self, name=None) -> "DataFrame":
-        """
-        Convert Series to DataFrame.
+        """Convert Series to DataFrame.
 
         Parameters
         ----------
         name : object, default None
             The passed name should substitute for the series name (if it has
-            one).
+            one). (Default value = None)
 
         Returns
         -------
@@ -1605,14 +1777,19 @@
         return df
 
     def _set_name(self, name, inplace=False) -> "Series":
-        """
-        Set the Series name.
-
-        Parameters
-        ----------
-        name : str
-        inplace : bool
-            Whether to modify `self` directly or return a copy.
+        """Set the Series name.
+
+        Parameters
+        ----------
+        name :
+            
+        inplace :
+             (Default value = False)
+
+        Returns
+        -------
+
+        
         """
         inplace = validate_bool_kwarg(inplace, "inplace")
         ser = self if inplace else self.copy()
@@ -1714,6 +1891,33 @@
         observed: bool = False,
         dropna: bool = True,
     ) -> "SeriesGroupBy":
+        """
+
+        Parameters
+        ----------
+        by :
+             (Default value = None)
+        axis :
+             (Default value = 0)
+        level :
+             (Default value = None)
+        as_index: bool :
+             (Default value = True)
+        sort: bool :
+             (Default value = True)
+        group_keys: bool :
+             (Default value = True)
+        squeeze: bool :
+             (Default value = no_default)
+        observed: bool :
+             (Default value = False)
+        dropna: bool :
+             (Default value = True)
+
+        Returns
+        -------
+
+        """
         from pandas.core.groupby.generic import SeriesGroupBy
 
         if squeeze is not no_default:
@@ -1751,14 +1955,13 @@
     # TODO: integrate bottleneck
 
     def count(self, level=None):
-        """
-        Return number of non-NA/null observations in the Series.
+        """Return number of non-NA/null observations in the Series.
 
         Parameters
         ----------
         level : int or level name, default None
             If the axis is a MultiIndex (hierarchical), count along a
-            particular level, collapsing into a smaller Series.
+            particular level, collapsing into a smaller Series. (Default value = None)
 
         Returns
         -------
@@ -1768,7 +1971,6 @@
         See Also
         --------
         DataFrame.count : Count non-NA cells for each column or row.
-
         Examples
         --------
         >>> s = pd.Series([0.0, 1.0, np.nan])
@@ -1796,33 +1998,33 @@
         )
 
     def mode(self, dropna=True) -> "Series":
-        """
-        Return the mode(s) of the dataset.
-
+        """Return the mode(s) of the dataset.
+        
         Always returns Series even if only one value is returned.
 
         Parameters
         ----------
         dropna : bool, default True
             Don't consider counts of NaN/NaT.
-
-            .. versionadded:: 0.24.0
-
-        Returns
-        -------
-        Series
-            Modes of the Series in sorted order.
+            .. versionadded:: 0.24.0 (Default value = True)
+
+        Returns
+        -------
+
+        
         """
         # TODO: Add option for bins like value_counts()
         return algorithms.mode(self, dropna=dropna)
 
     def unique(self):
-        """
-        Return unique values of Series object.
-
+        """Return unique values of Series object.
+        
         Uniques are returned in order of appearance. Hash table-based unique,
         therefore does NOT sort.
 
+        Parameters
+        ----------
+
         Returns
         -------
         ndarray or ExtensionArray
@@ -1832,46 +2034,47 @@
         --------
         unique : Top-level unique method for any 1-d array-like object.
         Index.unique : Return Index with unique values from an Index object.
-
         Notes
         -----
         Returns the unique values as a NumPy array. In case of an
         extension-array backed Series, a new
         :class:`~api.extensions.ExtensionArray` of that type with just
         the unique values is returned. This includes
-
+        
             * Categorical
             * Period
             * Datetime with Timezone
             * Interval
             * Sparse
             * IntegerNA
-
+        
         See Examples section.
-
         Examples
         --------
+        
+        
+        
+        An unordered Categorical will return categories in the order of
+        appearance.
+        
+        
+        An ordered Categorical preserves the category ordering.
         >>> pd.Series([2, 1, 3, 3], name='A').unique()
         array([2, 1, 3])
-
+        
         >>> pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()
         array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]')
-
+        
         >>> pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')
         ...            for _ in range(3)]).unique()
         <DatetimeArray>
         ['2016-01-01 00:00:00-05:00']
         Length: 1, dtype: datetime64[ns, US/Eastern]
-
-        An unordered Categorical will return categories in the order of
-        appearance.
-
+        
         >>> pd.Series(pd.Categorical(list('baabc'))).unique()
         ['b', 'a', 'c']
         Categories (3, object): ['b', 'a', 'c']
-
-        An ordered Categorical preserves the category ordering.
-
+        
         >>> pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),
         ...                          ordered=True)).unique()
         ['b', 'a', 'c']
@@ -1881,20 +2084,17 @@
         return result
 
     def drop_duplicates(self, keep="first", inplace=False) -> Optional["Series"]:
-        """
-        Return Series with duplicate values removed.
+        """Return Series with duplicate values removed.
 
         Parameters
         ----------
         keep : {'first', 'last', ``False``}, default 'first'
             Method to handle dropping duplicates:
-
             - 'first' : Drop duplicates except for the first occurrence.
             - 'last' : Drop duplicates except for the last occurrence.
-            - ``False`` : Drop all duplicates.
-
+            - ``False`` : Drop all duplicates. (Default value = "first")
         inplace : bool, default ``False``
-            If ``True``, performs operation inplace and returns None.
+            If ``True``, performs operation inplace and returns None. (Default value = False)
 
         Returns
         -------
@@ -1907,11 +2107,23 @@
         DataFrame.drop_duplicates : Equivalent method on DataFrame.
         Series.duplicated : Related method on Series, indicating duplicate
             Series values.
-
         Examples
         --------
         Generate a Series with duplicated entries.
-
+        
+        
+        With the 'keep' parameter, the selection behaviour of duplicated values
+        can be changed. The value 'first' keeps the first occurrence for each
+        set of duplicated entries. The default value of keep is 'first'.
+        
+        
+        The value 'last' for parameter 'keep' keeps the last occurrence for
+        each set of duplicated entries.
+        
+        
+        The value ``False`` for parameter 'keep' discards all sets of
+        duplicated entries. Setting the value of 'inplace' to ``True`` performs
+        the operation inplace and returns ``None``.
         >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama', 'hippo'],
         ...               name='animal')
         >>> s
@@ -1922,32 +2134,21 @@
         4      lama
         5     hippo
         Name: animal, dtype: object
-
-        With the 'keep' parameter, the selection behaviour of duplicated values
-        can be changed. The value 'first' keeps the first occurrence for each
-        set of duplicated entries. The default value of keep is 'first'.
-
+        
         >>> s.drop_duplicates()
         0      lama
         1       cow
         3    beetle
         5     hippo
         Name: animal, dtype: object
-
-        The value 'last' for parameter 'keep' keeps the last occurrence for
-        each set of duplicated entries.
-
+        
         >>> s.drop_duplicates(keep='last')
         1       cow
         3    beetle
         4      lama
         5     hippo
         Name: animal, dtype: object
-
-        The value ``False`` for parameter 'keep' discards all sets of
-        duplicated entries. Setting the value of 'inplace' to ``True`` performs
-        the operation inplace and returns ``None``.
-
+        
         >>> s.drop_duplicates(keep=False, inplace=True)
         >>> s
         1       cow
@@ -1964,9 +2165,8 @@
             return result
 
     def duplicated(self, keep="first") -> "Series":
-        """
-        Indicate duplicate Series values.
-
+        """Indicate duplicate Series values.
+        
         Duplicated values are indicated as ``True`` values in the resulting
         Series. Either all duplicates, all except the first or all except the
         last occurrence of duplicates can be indicated.
@@ -1975,12 +2175,11 @@
         ----------
         keep : {'first', 'last', False}, default 'first'
             Method to handle dropping duplicates:
-
             - 'first' : Mark duplicates as ``True`` except for the first
-              occurrence.
+            occurrence.
             - 'last' : Mark duplicates as ``True`` except for the last
-              occurrence.
-            - ``False`` : Mark all duplicates as ``True``.
+            occurrence.
+            - ``False`` : Mark all duplicates as ``True``. (Default value = "first")
 
         Returns
         -------
@@ -1993,12 +2192,20 @@
         Index.duplicated : Equivalent method on pandas.Index.
         DataFrame.duplicated : Equivalent method on pandas.DataFrame.
         Series.drop_duplicates : Remove duplicate values from Series.
-
         Examples
         --------
         By default, for each set of duplicated values, the first occurrence is
         set on False and all others on True:
-
+        
+        
+        which is equivalent to
+        
+        
+        By using 'last', the last occurrence of each set of duplicated values
+        is set on False and all others on True:
+        
+        
+        By setting keep on ``False``, all duplicates are True:
         >>> animals = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama'])
         >>> animals.duplicated()
         0    False
@@ -2007,9 +2214,7 @@
         3    False
         4     True
         dtype: bool
-
-        which is equivalent to
-
+        
         >>> animals.duplicated(keep='first')
         0    False
         1    False
@@ -2017,10 +2222,7 @@
         3    False
         4     True
         dtype: bool
-
-        By using 'last', the last occurrence of each set of duplicated values
-        is set on False and all others on True:
-
+        
         >>> animals.duplicated(keep='last')
         0     True
         1    False
@@ -2028,9 +2230,7 @@
         3    False
         4    False
         dtype: bool
-
-        By setting keep on ``False``, all duplicates are True:
-
+        
         >>> animals.duplicated(keep=False)
         0     True
         1    False
@@ -2042,9 +2242,8 @@
         return super().duplicated(keep=keep)
 
     def idxmin(self, axis=0, skipna=True, *args, **kwargs):
-        """
-        Return the row label of the minimum value.
-
+        """Return the row label of the minimum value.
+        
         If multiple values equal the minimum, the first row label with that
         value is returned.
 
@@ -2052,13 +2251,17 @@
         ----------
         axis : int, default 0
             For compatibility with DataFrame.idxmin. Redundant for application
-            on Series.
+            on Series. (Default value = 0)
         skipna : bool, default True
             Exclude NA/null values. If the entire Series is NA, the result
-            will be NA.
-        *args, **kwargs
+            will be NA. (Default value = True)
+        *args, **kwargs :
             Additional arguments and keywords have no effect but might be
             accepted for compatibility with NumPy.
+        *args :
+            
+        **kwargs :
+            
 
         Returns
         -------
@@ -2078,15 +2281,17 @@
             over requested axis.
         Series.idxmax : Return index *label* of the first occurrence
             of maximum of values.
-
         Notes
         -----
         This method is the Series version of ``ndarray.argmin``. This method
         returns the label of the minimum, while ``ndarray.argmin`` returns
         the position. To get the position, use ``series.values.argmin()``.
-
         Examples
         --------
+        
+        
+        If `skipna` is False and there is an NA value in the data,
+        the function returns ``nan``.
         >>> s = pd.Series(data=[1, None, 4, 1],
         ...               index=['A', 'B', 'C', 'D'])
         >>> s
@@ -2095,13 +2300,10 @@
         C    4.0
         D    1.0
         dtype: float64
-
+        
         >>> s.idxmin()
         'A'
-
-        If `skipna` is False and there is an NA value in the data,
-        the function returns ``nan``.
-
+        
         >>> s.idxmin(skipna=False)
         nan
         """
@@ -2112,9 +2314,8 @@
         return self.index[i]
 
     def idxmax(self, axis=0, skipna=True, *args, **kwargs):
-        """
-        Return the row label of the maximum value.
-
+        """Return the row label of the maximum value.
+        
         If multiple values equal the maximum, the first row label with that
         value is returned.
 
@@ -2122,13 +2323,17 @@
         ----------
         axis : int, default 0
             For compatibility with DataFrame.idxmax. Redundant for application
-            on Series.
+            on Series. (Default value = 0)
         skipna : bool, default True
             Exclude NA/null values. If the entire Series is NA, the result
-            will be NA.
-        *args, **kwargs
+            will be NA. (Default value = True)
+        *args, **kwargs :
             Additional arguments and keywords have no effect but might be
             accepted for compatibility with NumPy.
+        *args :
+            
+        **kwargs :
+            
 
         Returns
         -------
@@ -2148,15 +2353,17 @@
             over requested axis.
         Series.idxmin : Return index *label* of the first occurrence
             of minimum of values.
-
         Notes
         -----
         This method is the Series version of ``ndarray.argmax``. This method
         returns the label of the maximum, while ``ndarray.argmax`` returns
         the position. To get the position, use ``series.values.argmax()``.
-
         Examples
         --------
+        
+        
+        If `skipna` is False and there is an NA value in the data,
+        the function returns ``nan``.
         >>> s = pd.Series(data=[1, None, 4, 3, 4],
         ...               index=['A', 'B', 'C', 'D', 'E'])
         >>> s
@@ -2166,13 +2373,10 @@
         D    3.0
         E    4.0
         dtype: float64
-
+        
         >>> s.idxmax()
         'C'
-
-        If `skipna` is False and there is an NA value in the data,
-        the function returns ``nan``.
-
+        
         >>> s.idxmax(skipna=False)
         nan
         """
@@ -2183,17 +2387,20 @@
         return self.index[i]
 
     def round(self, decimals=0, *args, **kwargs) -> "Series":
-        """
-        Round each value in a Series to the given number of decimals.
+        """Round each value in a Series to the given number of decimals.
 
         Parameters
         ----------
         decimals : int, default 0
             Number of decimal places to round to. If decimals is negative,
-            it specifies the number of positions to the left of the decimal point.
-        *args, **kwargs
+            it specifies the number of positions to the left of the decimal point. (Default value = 0)
+        *args, **kwargs :
             Additional arguments and keywords have no effect but might be
             accepted for compatibility with NumPy.
+        *args :
+            
+        **kwargs :
+            
 
         Returns
         -------
@@ -2204,7 +2411,6 @@
         --------
         numpy.around : Round values of an np.array.
         DataFrame.round : Round values of a DataFrame.
-
         Examples
         --------
         >>> s = pd.Series([0.1, 1.3, 2.7])
@@ -2223,23 +2429,21 @@
         return result
 
     def quantile(self, q=0.5, interpolation="linear"):
-        """
-        Return value at the given quantile.
+        """Return value at the given quantile.
 
         Parameters
         ----------
         q : float or array-like, default 0.5 (50% quantile)
-            The quantile(s) to compute, which can lie in range: 0 <= q <= 1.
+            The quantile(s) to compute, which can lie in range: 0 <= q <= 1. (Default value = 0.5)
         interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}
             This optional parameter specifies the interpolation method to use,
             when the desired quantile lies between two data points `i` and `j`:
-
-                * linear: `i + (j - i) * fraction`, where `fraction` is the
-                  fractional part of the index surrounded by `i` and `j`.
-                * lower: `i`.
-                * higher: `j`.
-                * nearest: `i` or `j` whichever is nearest.
-                * midpoint: (`i` + `j`) / 2.
+            * linear: `i + (j - i) * fraction`, where `fraction` is the
+            fractional part of the index surrounded by `i` and `j`.
+            * lower: `i`.
+            * higher: `j`.
+            * nearest: `i` or `j` whichever is nearest.
+            * midpoint: (`i` + `j`) / 2. (Default value = "linear")
 
         Returns
         -------
@@ -2252,7 +2456,6 @@
         --------
         core.window.Rolling.quantile : Calculate the rolling quantile.
         numpy.percentile : Returns the q-th percentile(s) of the array elements.
-
         Examples
         --------
         >>> s = pd.Series([1, 2, 3, 4])
@@ -2282,8 +2485,7 @@
             return result.iloc[0]
 
     def corr(self, other, method="pearson", min_periods=None) -> float:
-        """
-        Compute correlation with `other` Series, excluding missing values.
+        """Compute correlation with `other` Series, excluding missing values.
 
         Parameters
         ----------
@@ -2291,18 +2493,16 @@
             Series with which to compute the correlation.
         method : {'pearson', 'kendall', 'spearman'} or callable
             Method used to compute correlation:
-
             - pearson : Standard correlation coefficient
             - kendall : Kendall Tau correlation coefficient
             - spearman : Spearman rank correlation
             - callable: Callable with input two 1d ndarrays and returning a float.
-
             .. versionadded:: 0.24.0
-                Note that the returned matrix from corr will have 1 along the
-                diagonals and will be symmetric regardless of the callable's
-                behavior.
+            Note that the returned matrix from corr will have 1 along the
+            diagonals and will be symmetric regardless of the callable's
+            behavior. (Default value = "pearson")
         min_periods : int, optional
-            Minimum number of observations needed to have a valid result.
+            Minimum number of observations needed to have a valid result. (Default value = None)
 
         Returns
         -------
@@ -2314,7 +2514,6 @@
         DataFrame.corr : Compute pairwise correlation between columns.
         DataFrame.corrwith : Compute pairwise correlation with another
             DataFrame or Series.
-
         Examples
         --------
         >>> def histogram_intersection(a, b):
@@ -2346,8 +2545,7 @@
         min_periods: Optional[int] = None,
         ddof: Optional[int] = 1,
     ) -> float:
-        """
-        Compute covariance with Series, excluding missing values.
+        """Compute covariance with Series, excluding missing values.
 
         Parameters
         ----------
@@ -2358,8 +2556,13 @@
         ddof : int, default 1
             Delta degrees of freedom.  The divisor used in calculations
             is ``N - ddof``, where ``N`` represents the number of elements.
-
             .. versionadded:: 1.1.0
+        other: "Series" :
+            
+        min_periods: Optional[int] :
+             (Default value = None)
+        ddof: Optional[int] :
+             (Default value = 1)
 
         Returns
         -------
@@ -2370,7 +2573,6 @@
         See Also
         --------
         DataFrame.cov : Compute pairwise covariance of columns.
-
         Examples
         --------
         >>> s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])
@@ -2435,9 +2637,8 @@
         ),
     )
     def diff(self, periods: int = 1) -> "Series":
-        """
-        First discrete difference of element.
-
+        """First discrete difference of element.
+        
         Calculates the difference of a {klass} element compared with another
         element in the {klass} (default is element in previous row).
 
@@ -2446,7 +2647,9 @@
         periods : int, default 1
             Periods to shift for calculating difference, accepts negative
             values.
-        {extra_params}
+        periods: int :
+             (Default value = 1)
+
         Returns
         -------
         {klass}
@@ -2458,14 +2661,12 @@
         {klass}.shift: Shift index by desired number of periods with an
             optional time freq.
         {other_klass}.diff: First discrete difference of object.
-
         Notes
         -----
         For boolean dtypes, this uses :meth:`operator.xor` rather than
         :meth:`operator.sub`.
         The result is calculated according to current dtype in {klass},
         however dtype of the result is always float64.
-
         Examples
         --------
         {examples}
@@ -2476,16 +2677,15 @@
         )
 
     def autocorr(self, lag=1) -> float:
-        """
-        Compute the lag-N autocorrelation.
-
+        """Compute the lag-N autocorrelation.
+        
         This method computes the Pearson correlation between
         the Series and its shifted self.
 
         Parameters
         ----------
         lag : int, default 1
-            Number of lags to apply before performing autocorrelation.
+            Number of lags to apply before performing autocorrelation. (Default value = 1)
 
         Returns
         -------
@@ -2499,21 +2699,19 @@
         DataFrame.corr : Compute pairwise correlation of columns.
         DataFrame.corrwith : Compute pairwise correlation between rows or
             columns of two DataFrame objects.
-
         Notes
         -----
         If the Pearson correlation is not well defined return 'NaN'.
-
         Examples
         --------
+        
+        If the Pearson correlation is not well defined, then 'NaN' is returned.
         >>> s = pd.Series([0.25, 0.5, 0.2, -0.05])
         >>> s.autocorr()  # doctest: +ELLIPSIS
         0.10355...
         >>> s.autocorr(lag=2)  # doctest: +ELLIPSIS
         -0.99999...
-
-        If the Pearson correlation is not well defined, then 'NaN' is returned.
-
+        
         >>> s = pd.Series([1, 0, 0, 0])
         >>> s.autocorr()
         nan
@@ -2521,13 +2719,12 @@
         return self.corr(self.shift(lag))
 
     def dot(self, other):
-        """
-        Compute the dot product between the Series and the columns of other.
-
+        """Compute the dot product between the Series and the columns of other.
+        
         This method computes the dot product between the Series and another
         one, or the Series and each columns of a DataFrame, or the Series and
         each columns of an array.
-
+        
         It can also be called using `self @ other` in Python >= 3.5.
 
         Parameters
@@ -2547,12 +2744,10 @@
         --------
         DataFrame.dot: Compute the matrix product with the DataFrame.
         Series.mul: Multiplication of series and other, element-wise.
-
         Notes
         -----
         The Series and other has to share the same index if other is a Series
         or a DataFrame.
-
         Examples
         --------
         >>> s = pd.Series([0, 1, 2, 3])
@@ -2612,23 +2807,37 @@
 
     @doc(base.IndexOpsMixin.searchsorted, klass="Series")
     def searchsorted(self, value, side="left", sorter=None):
+        """
+
+        Parameters
+        ----------
+        value :
+            
+        side :
+             (Default value = "left")
+        sorter :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         return algorithms.searchsorted(self._values, value, side=side, sorter=sorter)
 
     # -------------------------------------------------------------------
     # Combination
 
     def append(self, to_append, ignore_index=False, verify_integrity=False):
-        """
-        Concatenate two or more Series.
+        """Concatenate two or more Series.
 
         Parameters
         ----------
         to_append : Series or list/tuple of Series
             Series to append with self.
         ignore_index : bool, default False
-            If True, the resulting axis will be labeled 0, 1, …, n - 1.
+            If True, the resulting axis will be labeled 0, 1, …, n - 1. (Default value = False)
         verify_integrity : bool, default False
-            If True, raise Exception on creating index with duplicates.
+            If True, raise Exception on creating index with duplicates. (Default value = False)
 
         Returns
         -------
@@ -2638,16 +2847,20 @@
         See Also
         --------
         concat : General function to concatenate DataFrame or Series objects.
-
         Notes
         -----
         Iteratively appending to a Series can be more computationally intensive
         than a single concatenate. A better solution is to append values to a
         list and then concatenate the list with the original Series all at
         once.
-
         Examples
         --------
+        
+        
+        With `ignore_index` set to True:
+        
+        
+        With `verify_integrity` set to True:
         >>> s1 = pd.Series([1, 2, 3])
         >>> s2 = pd.Series([4, 5, 6])
         >>> s3 = pd.Series([4, 5, 6], index=[3, 4, 5])
@@ -2659,7 +2872,7 @@
         1    5
         2    6
         dtype: int64
-
+        
         >>> s1.append(s3)
         0    1
         1    2
@@ -2668,9 +2881,7 @@
         4    5
         5    6
         dtype: int64
-
-        With `ignore_index` set to True:
-
+        
         >>> s1.append(s2, ignore_index=True)
         0    1
         1    2
@@ -2679,9 +2890,7 @@
         4    5
         5    6
         dtype: int64
-
-        With `verify_integrity` set to True:
-
+        
         >>> s1.append(s2, verify_integrity=True)
         Traceback (most recent call last):
         ...
@@ -2702,23 +2911,25 @@
         )
 
     def _binop(self, other, func, level=None, fill_value=None):
-        """
-        Perform generic binary operation with optional fill value.
+        """Perform generic binary operation with optional fill value.
 
         Parameters
         ----------
         other : Series
+            
         func : binary operator
+            
         fill_value : float or object
             Value to substitute for NA/null values. If both Series are NA in a
-            location, the result will be NA regardless of the passed fill value.
+            location, the result will be NA regardless of the passed fill value. (Default value = None)
         level : int or level name, default None
             Broadcast across a level, matching Index values on the
-            passed MultiIndex level.
-
-        Returns
-        -------
-        Series
+            passed MultiIndex level. (Default value = None)
+
+        Returns
+        -------
+
+        
         """
         if not isinstance(other, Series):
             raise AssertionError("Other operand must be Series")
@@ -2740,18 +2951,27 @@
     def _construct_result(
         self, result: Union[ArrayLike, Tuple[ArrayLike, ArrayLike]], name: Label
     ) -> Union["Series", Tuple["Series", "Series"]]:
-        """
-        Construct an appropriately-labelled Series from the result of an op.
+        """Construct an appropriately-labelled Series from the result of an op.
 
         Parameters
         ----------
         result : ndarray or ExtensionArray
+            
         name : Label
-
-        Returns
-        -------
-        Series
-            In the case of __divmod__ or __rdivmod__, a 2-tuple of Series.
+            
+        result: Union[ArrayLike :
+            
+        Tuple[ArrayLike :
+            
+        ArrayLike]] :
+            
+        name: Label :
+            
+
+        Returns
+        -------
+
+        
         """
         if isinstance(result, tuple):
             # produced by divmod or rdivmod
@@ -2844,6 +3064,23 @@
         keep_shape: bool = False,
         keep_equal: bool = False,
     ) -> FrameOrSeriesUnion:
+        """
+
+        Parameters
+        ----------
+        other: "Series" :
+            
+        align_axis: Axis :
+             (Default value = 1)
+        keep_shape: bool :
+             (Default value = False)
+        keep_equal: bool :
+             (Default value = False)
+
+        Returns
+        -------
+
+        """
         return super().compare(
             other=other,
             align_axis=align_axis,
@@ -2852,9 +3089,8 @@
         )
 
     def combine(self, other, func, fill_value=None) -> "Series":
-        """
-        Combine the Series with a Series or scalar according to `func`.
-
+        """Combine the Series with a Series or scalar according to `func`.
+        
         Combine the Series and `other` using `func` to perform elementwise
         selection for combined Series.
         `fill_value` is assumed when value is missing at some index
@@ -2880,12 +3116,20 @@
         --------
         Series.combine_first : Combine Series values, choosing the calling
             Series' values first.
-
         Examples
         --------
         Consider 2 Datasets ``s1`` and ``s2`` containing
         highest clocked speeds of different birds.
-
+        
+        
+        Now, to combine the two datasets and view the highest speeds
+        of the birds across the two datasets
+        
+        
+        In the previous example, the resulting value for duck is missing,
+        because the maximum of a NaN and a float is a NaN.
+        So, in the example, we set ``fill_value=0``,
+        so the maximum value returned will be the value from some dataset.
         >>> s1 = pd.Series({'falcon': 330.0, 'eagle': 160.0})
         >>> s1
         falcon    330.0
@@ -2897,21 +3141,13 @@
         eagle     200.0
         duck       30.0
         dtype: float64
-
-        Now, to combine the two datasets and view the highest speeds
-        of the birds across the two datasets
-
+        
         >>> s1.combine(s2, max)
         duck        NaN
         eagle     200.0
         falcon    345.0
         dtype: float64
-
-        In the previous example, the resulting value for duck is missing,
-        because the maximum of a NaN and a float is a NaN.
-        So, in the example, we set ``fill_value=0``,
-        so the maximum value returned will be the value from some dataset.
-
+        
         >>> s1.combine(s2, max, fill_value=0)
         duck       30.0
         eagle     200.0
@@ -2950,8 +3186,7 @@
         return self._constructor(new_values, index=new_index, name=new_name)
 
     def combine_first(self, other) -> "Series":
-        """
-        Combine Series values, choosing the calling Series's values first.
+        """Combine Series values, choosing the calling Series's values first.
 
         Parameters
         ----------
@@ -2967,11 +3202,9 @@
         --------
         Series.combine : Perform elementwise operation on two Series
             using a given function.
-
         Notes
         -----
         Result index will be the union of the two indexes.
-
         Examples
         --------
         >>> s1 = pd.Series([1, np.nan])
@@ -2990,18 +3223,30 @@
         return this.where(notna(this), other)
 
     def update(self, other) -> None:
-        """
-        Modify Series in place using values from passed Series.
-
+        """Modify Series in place using values from passed Series.
+        
         Uses non-NA values from passed Series to make updates. Aligns
         on index.
 
         Parameters
         ----------
         other : Series, or object coercible into Series
+            
+
+        Returns
+        -------
 
         Examples
         --------
+        
+        
+        
+        If ``other`` contains NaNs the corresponding values are not updated
+        in the original Series.
+        
+        
+        ``other`` can also be a non-Series object type
+        that is coercible into a Series
         >>> s = pd.Series([1, 2, 3])
         >>> s.update(pd.Series([4, 5, 6]))
         >>> s
@@ -3009,7 +3254,7 @@
         1    5
         2    6
         dtype: int64
-
+        
         >>> s = pd.Series(['a', 'b', 'c'])
         >>> s.update(pd.Series(['d', 'e'], index=[0, 2]))
         >>> s
@@ -3017,7 +3262,7 @@
         1    b
         2    e
         dtype: object
-
+        
         >>> s = pd.Series([1, 2, 3])
         >>> s.update(pd.Series([4, 5, 6, 7, 8]))
         >>> s
@@ -3025,10 +3270,7 @@
         1    5
         2    6
         dtype: int64
-
-        If ``other`` contains NaNs the corresponding values are not updated
-        in the original Series.
-
+        
         >>> s = pd.Series([1, 2, 3])
         >>> s.update(pd.Series([4, np.nan, 6]))
         >>> s
@@ -3036,10 +3278,7 @@
         1    2
         2    6
         dtype: int64
-
-        ``other`` can also be a non-Series object type
-        that is coercible into a Series
-
+        
         >>> s = pd.Series([1, 2, 3])
         >>> s.update([4, np.nan, 6])
         >>> s
@@ -3047,7 +3286,7 @@
         1    2
         2    6
         dtype: int64
-
+        
         >>> s = pd.Series([1, 2, 3])
         >>> s.update({1: 9})
         >>> s
@@ -3079,9 +3318,8 @@
         ignore_index: bool = False,
         key: ValueKeyFunc = None,
     ):
-        """
-        Sort by the values.
-
+        """Sort by the values.
+        
         Sort a Series in ascending or descending order by some
         criterion.
 
@@ -3089,9 +3327,9 @@
         ----------
         axis : {0 or 'index'}, default 0
             Axis to direct sorting. The value 'index' is accepted for
-            compatibility with DataFrame.sort_values.
+            compatibility with DataFrame.sort_values. (Default value = 0)
         ascending : bool, default True
-            If True, sort values in ascending order, otherwise descending.
+            If True, sort values in ascending order, otherwise descending. (Default value = True)
         inplace : bool, default False
             If True, perform operation in-place.
         kind : {'quicksort', 'mergesort' or 'heapsort'}, default 'quicksort'
@@ -3102,17 +3340,24 @@
             the end.
         ignore_index : bool, default False
             If True, the resulting axis will be labeled 0, 1, …, n - 1.
-
             .. versionadded:: 1.0.0
-
         key : callable, optional
             If not None, apply the key function to the series values
             before sorting. This is similar to the `key` argument in the
             builtin :meth:`sorted` function, with the notable difference that
             this `key` function should be *vectorized*. It should expect a
             ``Series`` and return an array-like.
-
             .. versionadded:: 1.1.0
+        inplace: bool :
+             (Default value = False)
+        kind: str :
+             (Default value = "quicksort")
+        na_position: str :
+             (Default value = "last")
+        ignore_index: bool :
+             (Default value = False)
+        key: ValueKeyFunc :
+             (Default value = None)
 
         Returns
         -------
@@ -3124,9 +3369,35 @@
         Series.sort_index : Sort by the Series indices.
         DataFrame.sort_values : Sort DataFrame by the values along either axis.
         DataFrame.sort_index : Sort DataFrame by indices.
-
         Examples
         --------
+        
+        Sort values ascending order (default behaviour)
+        
+        
+        Sort values descending order
+        
+        
+        Sort values inplace
+        
+        
+        Sort values putting NAs first
+        
+        
+        Sort a series of strings
+        
+        
+        
+        Sort using a key function. Your `key` function will be
+        given the ``Series`` of values and should return an array-like.
+        
+        
+        NumPy ufuncs work well here. For example, we can
+        sort by the ``sin`` of the value
+        
+        
+        More complicated user-defined functions can be used,
+        as long as they expect a Series and return an array-like
         >>> s = pd.Series([np.nan, 1, 3, 10, 5])
         >>> s
         0     NaN
@@ -3135,9 +3406,7 @@
         3     10.0
         4     5.0
         dtype: float64
-
-        Sort values ascending order (default behaviour)
-
+        
         >>> s.sort_values(ascending=True)
         1     1.0
         2     3.0
@@ -3145,9 +3414,7 @@
         3    10.0
         0     NaN
         dtype: float64
-
-        Sort values descending order
-
+        
         >>> s.sort_values(ascending=False)
         3    10.0
         4     5.0
@@ -3155,9 +3422,7 @@
         1     1.0
         0     NaN
         dtype: float64
-
-        Sort values inplace
-
+        
         >>> s.sort_values(ascending=False, inplace=True)
         >>> s
         3    10.0
@@ -3166,9 +3431,7 @@
         1     1.0
         0     NaN
         dtype: float64
-
-        Sort values putting NAs first
-
+        
         >>> s.sort_values(na_position='first')
         0     NaN
         1     1.0
@@ -3176,9 +3439,7 @@
         4     5.0
         3    10.0
         dtype: float64
-
-        Sort a series of strings
-
+        
         >>> s = pd.Series(['z', 'b', 'd', 'a', 'c'])
         >>> s
         0    z
@@ -3187,7 +3448,7 @@
         3    a
         4    c
         dtype: object
-
+        
         >>> s.sort_values()
         3    a
         1    b
@@ -3195,10 +3456,7 @@
         2    d
         0    z
         dtype: object
-
-        Sort using a key function. Your `key` function will be
-        given the ``Series`` of values and should return an array-like.
-
+        
         >>> s = pd.Series(['a', 'B', 'c', 'D', 'e'])
         >>> s.sort_values()
         1    B
@@ -3214,10 +3472,7 @@
         3    D
         4    e
         dtype: object
-
-        NumPy ufuncs work well here. For example, we can
-        sort by the ``sin`` of the value
-
+        
         >>> s = pd.Series([-4, -2, 0, 2, 4])
         >>> s.sort_values(key=np.sin)
         1   -2
@@ -3226,10 +3481,7 @@
         0   -4
         3    2
         dtype: int64
-
-        More complicated user-defined functions can be used,
-        as long as they expect a Series and return an array-like
-
+        
         >>> s.sort_values(key=lambda x: (np.tan(x.cumsum())))
         0   -4
         3    2
@@ -3250,6 +3502,17 @@
             )
 
         def _try_kind_sort(arr):
+            """
+
+            Parameters
+            ----------
+            arr :
+                
+
+            Returns
+            -------
+
+            """
             arr = ensure_key_mapped(arr, key)
             arr = getattr(arr, "_values", arr)
 
@@ -3318,18 +3581,17 @@
         ignore_index: bool = False,
         key: IndexKeyFunc = None,
     ):
-        """
-        Sort Series by index labels.
-
+        """Sort Series by index labels.
+        
         Returns a new Series sorted by label if `inplace` argument is
         ``False``, otherwise updates the original series and returns None.
 
         Parameters
         ----------
         axis : int, default 0
-            Axis to direct sorting. This can only be 0 for Series.
+            Axis to direct sorting. This can only be 0 for Series. (Default value = 0)
         level : int, optional
-            If not None, sort on values in specified index level(s).
+            If not None, sort on values in specified index level(s). (Default value = None)
         ascending : bool or list of bools, default True
             Sort ascending vs. descending. When the index is a MultiIndex the
             sort direction can be controlled for each level individually.
@@ -3348,17 +3610,28 @@
             levels too (in order) after sorting by specified level.
         ignore_index : bool, default False
             If True, the resulting axis will be labeled 0, 1, …, n - 1.
-
             .. versionadded:: 1.0.0
-
         key : callable, optional
             If not None, apply the key function to the index values
             before sorting. This is similar to the `key` argument in the
             builtin :meth:`sorted` function, with the notable difference that
             this `key` function should be *vectorized*. It should expect an
             ``Index`` and return an ``Index`` of the same shape.
-
             .. versionadded:: 1.1.0
+        ascending: bool :
+             (Default value = True)
+        inplace: bool :
+             (Default value = False)
+        kind: str :
+             (Default value = "quicksort")
+        na_position: str :
+             (Default value = "last")
+        sort_remaining: bool :
+             (Default value = True)
+        ignore_index: bool :
+             (Default value = False)
+        key: IndexKeyFunc :
+             (Default value = None)
 
         Returns
         -------
@@ -3370,9 +3643,26 @@
         DataFrame.sort_index: Sort DataFrame by the index.
         DataFrame.sort_values: Sort DataFrame by the value.
         Series.sort_values : Sort Series by the value.
-
         Examples
         --------
+        
+        Sort Descending
+        
+        
+        Sort Inplace
+        
+        
+        By default NaNs are put at the end, but use `na_position` to place
+        them at the beginning
+        
+        
+        Specify index level to sort
+        
+        
+        Does not sort by remaining levels when sorting by levels
+        
+        
+        Apply a key function before sorting
         >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, 4])
         >>> s.sort_index()
         1    c
@@ -3380,18 +3670,14 @@
         3    a
         4    d
         dtype: object
-
-        Sort Descending
-
+        
         >>> s.sort_index(ascending=False)
         4    d
         3    a
         2    b
         1    c
         dtype: object
-
-        Sort Inplace
-
+        
         >>> s.sort_index(inplace=True)
         >>> s
         1    c
@@ -3399,10 +3685,7 @@
         3    a
         4    d
         dtype: object
-
-        By default NaNs are put at the end, but use `na_position` to place
-        them at the beginning
-
+        
         >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, np.nan])
         >>> s.sort_index(na_position='first')
         NaN     d
@@ -3410,9 +3693,7 @@
          2.0    b
          3.0    a
         dtype: object
-
-        Specify index level to sort
-
+        
         >>> arrays = [np.array(['qux', 'qux', 'foo', 'foo',
         ...                     'baz', 'baz', 'bar', 'bar']),
         ...           np.array(['two', 'one', 'two', 'one',
@@ -3428,9 +3709,7 @@
         foo  two    3
         qux  two    1
         dtype: int64
-
-        Does not sort by remaining levels when sorting by levels
-
+        
         >>> s.sort_index(level=1, sort_remaining=False)
         qux  one    2
         foo  one    4
@@ -3441,9 +3720,7 @@
         baz  two    5
         bar  two    7
         dtype: int64
-
-        Apply a key function before sorting
-
+        
         >>> s = pd.Series([1, 2, 3, 4], index=['A', 'b', 'C', 'd'])
         >>> s.sort_index(key=lambda x : x.str.lower())
         A    1
@@ -3508,21 +3785,20 @@
             return result.__finalize__(self, method="sort_index")
 
     def argsort(self, axis=0, kind="quicksort", order=None) -> "Series":
-        """
-        Return the integer indices that would sort the Series values.
-
+        """Return the integer indices that would sort the Series values.
+        
         Override ndarray.argsort. Argsorts the value, omitting NA/null values,
         and places the result in the same locations as the non-NA values.
 
         Parameters
         ----------
         axis : {0 or "index"}
-            Has no effect but is accepted for compatibility with numpy.
+            Has no effect but is accepted for compatibility with numpy. (Default value = 0)
         kind : {'mergesort', 'quicksort', 'heapsort'}, default 'quicksort'
             Choice of sorting algorithm. See np.sort for more
-            information. 'mergesort' is the only stable algorithm.
+            information. 'mergesort' is the only stable algorithm. (Default value = "quicksort")
         order : None
-            Has no effect but is accepted for compatibility with numpy.
+            Has no effect but is accepted for compatibility with numpy. (Default value = None)
 
         Returns
         -------
@@ -3550,23 +3826,21 @@
             ).__finalize__(self, method="argsort")
 
     def nlargest(self, n=5, keep="first") -> "Series":
-        """
-        Return the largest `n` elements.
+        """Return the largest `n` elements.
 
         Parameters
         ----------
         n : int, default 5
-            Return this many descending sorted values.
+            Return this many descending sorted values. (Default value = 5)
         keep : {'first', 'last', 'all'}, default 'first'
             When there are duplicate values that cannot all fit in a
             Series of `n` elements:
-
             - ``first`` : return the first `n` occurrences in order
-                of appearance.
+            of appearance.
             - ``last`` : return the last `n` occurrences in reverse
-                order of appearance.
+            order of appearance.
             - ``all`` : keep all occurrences. This can result in a Series of
-                size larger than `n`.
+            size larger than `n`. (Default value = "first")
 
         Returns
         -------
@@ -3578,14 +3852,27 @@
         Series.nsmallest: Get the `n` smallest elements.
         Series.sort_values: Sort Series by values.
         Series.head: Return the first `n` rows.
-
         Notes
         -----
         Faster than ``.sort_values(ascending=False).head(n)`` for small `n`
         relative to the size of the ``Series`` object.
-
         Examples
         --------
+        
+        The `n` largest elements where ``n=5`` by default.
+        
+        
+        The `n` largest elements where ``n=3``. Default `keep` value is 'first'
+        so Malta will be kept.
+        
+        
+        The `n` largest elements where ``n=3`` and keeping the last duplicates.
+        Brunei will be kept since it is the last with value 434000 based on
+        the index order.
+        
+        
+        The `n` largest elements where ``n=3`` with all duplicates kept. Note
+        that the returned Series has five elements due to the three duplicates.
         >>> countries_population = {"Italy": 59000000, "France": 65000000,
         ...                         "Malta": 434000, "Maldives": 434000,
         ...                         "Brunei": 434000, "Iceland": 337000,
@@ -3604,9 +3891,7 @@
         Anguilla       11300
         Montserrat      5200
         dtype: int64
-
-        The `n` largest elements where ``n=5`` by default.
-
+        
         >>> s.nlargest()
         France      65000000
         Italy       59000000
@@ -3614,29 +3899,19 @@
         Maldives      434000
         Brunei        434000
         dtype: int64
-
-        The `n` largest elements where ``n=3``. Default `keep` value is 'first'
-        so Malta will be kept.
-
+        
         >>> s.nlargest(3)
         France    65000000
         Italy     59000000
         Malta       434000
         dtype: int64
-
-        The `n` largest elements where ``n=3`` and keeping the last duplicates.
-        Brunei will be kept since it is the last with value 434000 based on
-        the index order.
-
+        
         >>> s.nlargest(3, keep='last')
         France      65000000
         Italy       59000000
         Brunei        434000
         dtype: int64
-
-        The `n` largest elements where ``n=3`` with all duplicates kept. Note
-        that the returned Series has five elements due to the three duplicates.
-
+        
         >>> s.nlargest(3, keep='all')
         France      65000000
         Italy       59000000
@@ -3648,23 +3923,21 @@
         return algorithms.SelectNSeries(self, n=n, keep=keep).nlargest()
 
     def nsmallest(self, n=5, keep="first") -> "Series":
-        """
-        Return the smallest `n` elements.
+        """Return the smallest `n` elements.
 
         Parameters
         ----------
         n : int, default 5
-            Return this many ascending sorted values.
+            Return this many ascending sorted values. (Default value = 5)
         keep : {'first', 'last', 'all'}, default 'first'
             When there are duplicate values that cannot all fit in a
             Series of `n` elements:
-
             - ``first`` : return the first `n` occurrences in order
-                of appearance.
+            of appearance.
             - ``last`` : return the last `n` occurrences in reverse
-                order of appearance.
+            order of appearance.
             - ``all`` : keep all occurrences. This can result in a Series of
-                size larger than `n`.
+            size larger than `n`. (Default value = "first")
 
         Returns
         -------
@@ -3676,14 +3949,27 @@
         Series.nlargest: Get the `n` largest elements.
         Series.sort_values: Sort Series by values.
         Series.head: Return the first `n` rows.
-
         Notes
         -----
         Faster than ``.sort_values().head(n)`` for small `n` relative to
         the size of the ``Series`` object.
-
         Examples
         --------
+        
+        The `n` smallest elements where ``n=5`` by default.
+        
+        
+        The `n` smallest elements where ``n=3``. Default `keep` value is
+        'first' so Nauru and Tuvalu will be kept.
+        
+        
+        The `n` smallest elements where ``n=3`` and keeping the last
+        duplicates. Anguilla and Tuvalu will be kept since they are the last
+        with value 11300 based on the index order.
+        
+        
+        The `n` smallest elements where ``n=3`` with all duplicates kept. Note
+        that the returned Series has four elements due to the three duplicates.
         >>> countries_population = {"Italy": 59000000, "France": 65000000,
         ...                         "Brunei": 434000, "Malta": 434000,
         ...                         "Maldives": 434000, "Iceland": 337000,
@@ -3702,9 +3988,7 @@
         Anguilla       11300
         Montserrat      5200
         dtype: int64
-
-        The `n` smallest elements where ``n=5`` by default.
-
+        
         >>> s.nsmallest()
         Montserrat    5200
         Nauru        11300
@@ -3712,29 +3996,19 @@
         Anguilla     11300
         Iceland     337000
         dtype: int64
-
-        The `n` smallest elements where ``n=3``. Default `keep` value is
-        'first' so Nauru and Tuvalu will be kept.
-
+        
         >>> s.nsmallest(3)
         Montserrat   5200
         Nauru       11300
         Tuvalu      11300
         dtype: int64
-
-        The `n` smallest elements where ``n=3`` and keeping the last
-        duplicates. Anguilla and Tuvalu will be kept since they are the last
-        with value 11300 based on the index order.
-
+        
         >>> s.nsmallest(3, keep='last')
         Montserrat   5200
         Anguilla    11300
         Tuvalu      11300
         dtype: int64
-
-        The `n` smallest elements where ``n=3`` with all duplicates kept. Note
-        that the returned Series has four elements due to the three duplicates.
-
+        
         >>> s.nsmallest(3, keep='all')
         Montserrat   5200
         Nauru       11300
@@ -3745,9 +4019,8 @@
         return algorithms.SelectNSeries(self, n=n, keep=keep).nsmallest()
 
     def swaplevel(self, i=-2, j=-1, copy=True) -> "Series":
-        """
-        Swap levels i and j in a :class:`MultiIndex`.
-
+        """Swap levels i and j in a :class:`MultiIndex`.
+        
         Default is to swap the two innermost levels of the index.
 
         Parameters
@@ -3755,12 +4028,16 @@
         i, j : int, str
             Level of the indices to be swapped. Can pass level name as string.
         copy : bool, default True
-            Whether to copy underlying data.
-
-        Returns
-        -------
-        Series
-            Series with levels swapped in MultiIndex.
+            Whether to copy underlying data. (Default value = True)
+        i :
+             (Default value = -2)
+        j :
+             (Default value = -1)
+
+        Returns
+        -------
+
+        
         """
         assert isinstance(self.index, MultiIndex)
         new_index = self.index.swaplevel(i, j)
@@ -3769,9 +4046,8 @@
         )
 
     def reorder_levels(self, order) -> "Series":
-        """
-        Rearrange index levels using input order.
-
+        """Rearrange index levels using input order.
+        
         May not drop or duplicate levels.
 
         Parameters
@@ -3781,7 +4057,8 @@
 
         Returns
         -------
-        type of caller (new object)
+
+        
         """
         if not isinstance(self.index, MultiIndex):  # pragma: no cover
             raise Exception("Can only reorder levels on a hierarchical axis.")
@@ -3792,17 +4069,17 @@
         return result
 
     def explode(self, ignore_index: bool = False) -> "Series":
-        """
-        Transform each element of a list-like to a row.
-
+        """Transform each element of a list-like to a row.
+        
         .. versionadded:: 0.25.0
 
         Parameters
         ----------
         ignore_index : bool, default False
             If True, the resulting index will be labeled 0, 1, …, n - 1.
-
             .. versionadded:: 1.1.0
+        ignore_index: bool :
+             (Default value = False)
 
         Returns
         -------
@@ -3817,14 +4094,12 @@
         DataFrame.melt : Unpivot a DataFrame from wide format to long format.
         DataFrame.explode : Explode a DataFrame from list-like
             columns to long format.
-
         Notes
         -----
         This routine will explode list-likes including lists, tuples,
         Series, and np.ndarray. The result dtype of the subset rows will
         be object. Scalars will be returned unchanged. Empty list-likes will
         result in a np.nan for that row.
-
         Examples
         --------
         >>> s = pd.Series([[1, 2, 3], 'foo', [], [3, 4]])
@@ -3834,7 +4109,7 @@
         2           []
         3       [3, 4]
         dtype: object
-
+        
         >>> s.explode()
         0      1
         0      2
@@ -3860,15 +4135,14 @@
         return result
 
     def unstack(self, level=-1, fill_value=None):
-        """
-        Unstack, also known as pivot, Series with MultiIndex to produce DataFrame.
+        """Unstack, also known as pivot, Series with MultiIndex to produce DataFrame.
 
         Parameters
         ----------
         level : int, str, or list of these, default last level
-            Level(s) to unstack, can pass level name.
+            Level(s) to unstack, can pass level name. (Default value = -1)
         fill_value : scalar value, default None
-            Value to use when replacing NaN values.
+            Value to use when replacing NaN values. (Default value = None)
 
         Returns
         -------
@@ -3886,12 +4160,12 @@
         two  a    3
              b    4
         dtype: int64
-
+        
         >>> s.unstack(level=-1)
              a  b
         one  1  2
         two  3  4
-
+        
         >>> s.unstack(level=0)
            one  two
         a    1    3
@@ -3905,9 +4179,8 @@
     # function application
 
     def map(self, arg, na_action=None) -> "Series":
-        """
-        Map values of Series according to input correspondence.
-
+        """Map values of Series according to input correspondence.
+        
         Used for substituting each value in a Series with another value,
         that may be derived from a function, a ``dict`` or
         a :class:`Series`.
@@ -3918,7 +4191,7 @@
             Mapping correspondence.
         na_action : {None, 'ignore'}, default None
             If 'ignore', propagate NaN values, without passing them to the
-            mapping correspondence.
+            mapping correspondence. (Default value = None)
 
         Returns
         -------
@@ -3930,7 +4203,6 @@
         Series.apply : For applying more complex functions on a Series.
         DataFrame.apply : Apply a function row-/column-wise.
         DataFrame.applymap : Apply a function elementwise on a whole DataFrame.
-
         Notes
         -----
         When ``arg`` is a dictionary, values in Series that are not in the
@@ -3938,9 +4210,19 @@
         dictionary is a ``dict`` subclass that defines ``__missing__`` (i.e.
         provides a method for default values), then this default is used
         rather than ``NaN``.
-
         Examples
         --------
+        
+        ``map`` accepts a ``dict`` or a ``Series``. Values that are not found
+        in the ``dict`` are converted to ``NaN``, unless the dict has a default
+        value (e.g. ``defaultdict``):
+        
+        
+        It also accepts a function:
+        
+        
+        To avoid applying the function to missing values (and keep them as
+        ``NaN``) ``na_action='ignore'`` can be used:
         >>> s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])
         >>> s
         0      cat
@@ -3948,30 +4230,21 @@
         2      NaN
         3   rabbit
         dtype: object
-
-        ``map`` accepts a ``dict`` or a ``Series``. Values that are not found
-        in the ``dict`` are converted to ``NaN``, unless the dict has a default
-        value (e.g. ``defaultdict``):
-
+        
         >>> s.map({'cat': 'kitten', 'dog': 'puppy'})
         0   kitten
         1    puppy
         2      NaN
         3      NaN
         dtype: object
-
-        It also accepts a function:
-
+        
         >>> s.map('I am a {}'.format)
         0       I am a cat
         1       I am a dog
         2       I am a nan
         3    I am a rabbit
         dtype: object
-
-        To avoid applying the function to missing values (and keep them as
-        ``NaN``) ``na_action='ignore'`` can be used:
-
+        
         >>> s.map('I am a {}'.format, na_action='ignore')
         0     I am a cat
         1     I am a dog
@@ -3985,16 +4258,21 @@
         )
 
     def _gotitem(self, key, ndim, subset=None) -> "Series":
-        """
-        Sub-classes to define. Return a sliced object.
-
-        Parameters
-        ----------
-        key : string / list of selections
-        ndim : 1,2
-            Requested ndim of result.
-        subset : object, default None
-            Subset to act on.
+        """Sub-classes to define. Return a sliced object.
+
+        Parameters
+        ----------
+        key :
+            
+        ndim :
+            
+        subset :
+             (Default value = None)
+
+        Returns
+        -------
+
+        
         """
         return self
 
@@ -4038,6 +4316,23 @@
         versionadded="\n.. versionadded:: 0.20.0\n",
     )
     def aggregate(self, func=None, axis=0, *args, **kwargs):
+        """
+
+        Parameters
+        ----------
+        func :
+             (Default value = None)
+        axis :
+             (Default value = 0)
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         # Validate the axis parameter
         self._get_axis_number(axis)
 
@@ -4076,14 +4371,30 @@
         axis=_shared_doc_kwargs["axis"],
     )
     def transform(self, func, axis=0, *args, **kwargs):
+        """
+
+        Parameters
+        ----------
+        func :
+            
+        axis :
+             (Default value = 0)
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         # Validate the axis parameter
         self._get_axis_number(axis)
         return super().transform(func, *args, **kwargs)
 
     def apply(self, func, convert_dtype=True, args=(), **kwds):
-        """
-        Invoke function on values of Series.
-
+        """Invoke function on values of Series.
+        
         Can be ufunc (a NumPy function that applies to the entire Series)
         or a Python function that only works on single values.
 
@@ -4093,10 +4404,10 @@
             Python function or NumPy ufunc to apply.
         convert_dtype : bool, default True
             Try to find better dtype for elementwise function results. If
-            False, leave as dtype=object.
+            False, leave as dtype=object. (Default value = True)
         args : tuple
-            Positional arguments passed to func after the series value.
-        **kwds
+            Positional arguments passed to func after the series value. (Default value = ())
+        **kwds :
             Additional keyword arguments passed to func.
 
         Returns
@@ -4109,11 +4420,31 @@
         Series.map: For element-wise operations.
         Series.agg: Only perform aggregating type operations.
         Series.transform: Only perform transforming type operations.
-
         Examples
         --------
         Create a series with typical summer temperatures for each city.
-
+        
+        
+        Square the values by defining a function and passing it as an
+        argument to ``apply()``.
+        
+        
+        Square the values by passing an anonymous function as an
+        argument to ``apply()``.
+        
+        
+        Define a custom function that needs additional positional
+        arguments and pass these additional arguments using the
+        ``args`` keyword.
+        
+        
+        
+        Define a custom function that takes keyword arguments
+        and pass these arguments to ``apply``.
+        
+        
+        
+        Use a function from the Numpy library.
         >>> s = pd.Series([20, 21, 12],
         ...               index=['London', 'New York', 'Helsinki'])
         >>> s
@@ -4121,10 +4452,7 @@
         New York    21
         Helsinki    12
         dtype: int64
-
-        Square the values by defining a function and passing it as an
-        argument to ``apply()``.
-
+        
         >>> def square(x):
         ...     return x ** 2
         >>> s.apply(square)
@@ -4132,45 +4460,33 @@
         New York    441
         Helsinki    144
         dtype: int64
-
-        Square the values by passing an anonymous function as an
-        argument to ``apply()``.
-
+        
         >>> s.apply(lambda x: x ** 2)
         London      400
         New York    441
         Helsinki    144
         dtype: int64
-
-        Define a custom function that needs additional positional
-        arguments and pass these additional arguments using the
-        ``args`` keyword.
-
+        
         >>> def subtract_custom_value(x, custom_value):
         ...     return x - custom_value
-
+        
         >>> s.apply(subtract_custom_value, args=(5,))
         London      15
         New York    16
         Helsinki     7
         dtype: int64
-
-        Define a custom function that takes keyword arguments
-        and pass these arguments to ``apply``.
-
+        
         >>> def add_custom_values(x, **kwargs):
         ...     for month in kwargs:
         ...         x += kwargs[month]
         ...     return x
-
+        
         >>> s.apply(add_custom_values, june=30, july=20, august=25)
         London      95
         New York    96
         Helsinki    87
         dtype: int64
-
-        Use a function from the Numpy library.
-
+        
         >>> s.apply(np.log)
         London      2.995732
         New York    3.044522
@@ -4194,6 +4510,17 @@
         if kwds or args and not isinstance(func, np.ufunc):
 
             def f(x):
+                """
+
+                Parameters
+                ----------
+                x :
+                    
+
+                Returns
+                -------
+
+                """
                 return func(x, *args, **kwds)
 
         else:
@@ -4223,11 +4550,31 @@
     def _reduce(
         self, op, name, axis=0, skipna=True, numeric_only=None, filter_type=None, **kwds
     ):
-        """
-        Perform a reduction operation.
-
+        """Perform a reduction operation.
+        
         If we have an ndarray as a value, then simply perform the operation,
         otherwise delegate to the object.
+
+        Parameters
+        ----------
+        op :
+            
+        name :
+            
+        axis :
+             (Default value = 0)
+        skipna :
+             (Default value = True)
+        numeric_only :
+             (Default value = None)
+        filter_type :
+             (Default value = None)
+        **kwds :
+            
+
+        Returns
+        -------
+
         """
         delegate = self._values
 
@@ -4248,6 +4595,21 @@
                 return op(delegate, skipna=skipna, **kwds)
 
     def _reindex_indexer(self, new_index, indexer, copy):
+        """
+
+        Parameters
+        ----------
+        new_index :
+            
+        indexer :
+            
+        copy :
+            
+
+        Returns
+        -------
+
+        """
         if indexer is None:
             if copy:
                 return self.copy()
@@ -4259,9 +4621,21 @@
         return self._constructor(new_values, index=new_index)
 
     def _needs_reindex_multi(self, axes, method, level):
-        """
-        Check if we do need a multi reindex; this is for compat with
+        """Check if we do need a multi reindex; this is for compat with
         higher dims.
+
+        Parameters
+        ----------
+        axes :
+            
+        method :
+            
+        level :
+            
+
+        Returns
+        -------
+
         """
         return False
 
@@ -4283,6 +4657,35 @@
         fill_axis=0,
         broadcast_axis=None,
     ):
+        """
+
+        Parameters
+        ----------
+        other :
+            
+        join :
+             (Default value = "outer")
+        axis :
+             (Default value = None)
+        level :
+             (Default value = None)
+        copy :
+             (Default value = True)
+        fill_value :
+             (Default value = None)
+        method :
+             (Default value = None)
+        limit :
+             (Default value = None)
+        fill_axis :
+             (Default value = 0)
+        broadcast_axis :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         return super().align(
             other,
             join=join,
@@ -4306,30 +4709,38 @@
         level=None,
         errors="ignore",
     ):
-        """
-        Alter Series index labels or name.
-
+        """Alter Series index labels or name.
+        
         Function / dict values must be unique (1-to-1). Labels not contained in
         a dict / Series will be left as-is. Extra labels listed don't throw an
         error.
-
+        
         Alternatively, change ``Series.name`` with a scalar value.
-
+        
         See the :ref:`user guide <basics.rename>` for more.
 
         Parameters
         ----------
         axis : {0 or "index"}
-            Unused. Accepted for compatibility with DataFrame method only.
+            Unused. Accepted for compatibility with DataFrame method only. (Default value = None)
         index : scalar, hashable sequence, dict-like or function, optional
             Functions or dict-like are transformations to apply to
             the index.
             Scalar or hashable sequence-like will alter the ``Series.name``
-            attribute.
-
-        **kwargs
+            attribute. (Default value = None)
+        **kwargs :
             Additional keyword arguments passed to the function. Only the
             "inplace" keyword is used.
+        * :
+            
+        copy :
+             (Default value = True)
+        inplace :
+             (Default value = False)
+        level :
+             (Default value = None)
+        errors :
+             (Default value = "ignore")
 
         Returns
         -------
@@ -4340,7 +4751,6 @@
         --------
         DataFrame.rename : Corresponding DataFrame method.
         Series.rename_axis : Set the name of the axis.
-
         Examples
         --------
         >>> s = pd.Series([1, 2, 3])
@@ -4398,6 +4808,21 @@
     )
     @Appender(generic.NDFrame.set_axis.__doc__)
     def set_axis(self, labels, axis: Axis = 0, inplace: bool = False):
+        """
+
+        Parameters
+        ----------
+        labels :
+            
+        axis: Axis :
+             (Default value = 0)
+        inplace: bool :
+             (Default value = False)
+
+        Returns
+        -------
+
+        """
         return super().set_axis(labels, axis=axis, inplace=inplace)
 
     @doc(
@@ -4408,6 +4833,19 @@
         optional_axis=_shared_doc_kwargs["optional_axis"],
     )
     def reindex(self, index=None, **kwargs):
+        """
+
+        Parameters
+        ----------
+        index :
+             (Default value = None)
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         return super().reindex(index=index, **kwargs)
 
     def drop(
@@ -4420,9 +4858,8 @@
         inplace=False,
         errors="raise",
     ) -> "Series":
-        """
-        Return Series with specified index labels removed.
-
+        """Return Series with specified index labels removed.
+        
         Remove elements of a Series based on specifying the index labels.
         When using a multi-index, labels on different levels can be removed
         by specifying the level.
@@ -4430,20 +4867,20 @@
         Parameters
         ----------
         labels : single label or list-like
-            Index labels to drop.
+            Index labels to drop. (Default value = None)
         axis : 0, default 0
-            Redundant for application on Series.
+            Redundant for application on Series. (Default value = 0)
         index : single label or list-like
             Redundant for application on Series, but 'index' can be used instead
-            of 'labels'.
+            of 'labels'. (Default value = None)
         columns : single label or list-like
-            No change is made to the Series; use 'index' or 'labels' instead.
+            No change is made to the Series; use 'index' or 'labels' instead. (Default value = None)
         level : int or level name, optional
-            For MultiIndex, level for which the labels will be removed.
+            For MultiIndex, level for which the labels will be removed. (Default value = None)
         inplace : bool, default False
-            If True, do operation inplace and return None.
+            If True, do operation inplace and return None. (Default value = False)
         errors : {'ignore', 'raise'}, default 'raise'
-            If 'ignore', suppress error and only existing labels are dropped.
+            If 'ignore', suppress error and only existing labels are dropped. (Default value = "raise")
 
         Returns
         -------
@@ -4461,24 +4898,24 @@
         Series.dropna : Return series without null values.
         Series.drop_duplicates : Return Series with duplicate values removed.
         DataFrame.drop : Drop specified labels from rows or columns.
-
         Examples
         --------
+        
+        Drop labels B en C
+        
+        
+        Drop 2nd level label in MultiIndex Series
         >>> s = pd.Series(data=np.arange(3), index=['A', 'B', 'C'])
         >>> s
         A  0
         B  1
         C  2
         dtype: int64
-
-        Drop labels B en C
-
+        
         >>> s.drop(labels=['B', 'C'])
         A  0
         dtype: int64
-
-        Drop 2nd level label in MultiIndex Series
-
+        
         >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],
         ...                              ['speed', 'weight', 'length']],
         ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],
@@ -4496,7 +4933,7 @@
                 weight      1.0
                 length      0.3
         dtype: float64
-
+        
         >>> s.drop(labels='weight', level=1)
         lama    speed      45.0
                 length      1.2
@@ -4526,6 +4963,27 @@
         limit=None,
         downcast=None,
     ) -> Optional["Series"]:
+        """
+
+        Parameters
+        ----------
+        value :
+             (Default value = None)
+        method :
+             (Default value = None)
+        axis :
+             (Default value = None)
+        inplace :
+             (Default value = False)
+        limit :
+             (Default value = None)
+        downcast :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         return super().fillna(
             value=value,
             method=method,
@@ -4536,25 +4994,27 @@
         )
 
     def pop(self, item: Label) -> Any:
-        """
-        Return item and drops from series. Raise KeyError if not found.
+        """Return item and drops from series. Raise KeyError if not found.
 
         Parameters
         ----------
         item : label
             Index of the element that needs to be removed.
+        item: Label :
+            
 
         Returns
         -------
         Value that is popped from series.
+            
 
         Examples
         --------
         >>> ser = pd.Series([1,2,3])
-
+        
         >>> ser.pop(0)
         1
-
+        
         >>> ser
         1    2
         2    3
@@ -4572,6 +5032,27 @@
         regex=False,
         method="pad",
     ):
+        """
+
+        Parameters
+        ----------
+        to_replace :
+             (Default value = None)
+        value :
+             (Default value = None)
+        inplace :
+             (Default value = False)
+        limit :
+             (Default value = None)
+        regex :
+             (Default value = False)
+        method :
+             (Default value = "pad")
+
+        Returns
+        -------
+
+        """
         return super().replace(
             to_replace=to_replace,
             value=value,
@@ -4583,25 +5064,41 @@
 
     @doc(NDFrame.shift, klass=_shared_doc_kwargs["klass"])
     def shift(self, periods=1, freq=None, axis=0, fill_value=None) -> "Series":
+        """
+
+        Parameters
+        ----------
+        periods :
+             (Default value = 1)
+        freq :
+             (Default value = None)
+        axis :
+             (Default value = 0)
+        fill_value :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         return super().shift(
             periods=periods, freq=freq, axis=axis, fill_value=fill_value
         )
 
     def memory_usage(self, index=True, deep=False):
-        """
-        Return the memory usage of the Series.
-
+        """Return the memory usage of the Series.
+        
         The memory usage can optionally include the contribution of
         the index and of elements of `object` dtype.
 
         Parameters
         ----------
         index : bool, default True
-            Specifies whether to include the memory usage of the Series index.
+            Specifies whether to include the memory usage of the Series index. (Default value = True)
         deep : bool, default False
             If True, introspect the data deeply by interrogating
             `object` dtypes for system-level memory consumption, and include
-            it in the returned value.
+            it in the returned value. (Default value = False)
 
         Returns
         -------
@@ -4613,21 +5110,21 @@
         numpy.ndarray.nbytes : Total bytes consumed by the elements of the
             array.
         DataFrame.memory_usage : Bytes consumed by a DataFrame.
-
         Examples
         --------
+        
+        Not including the index gives the size of the rest of the data, which
+        is necessarily smaller:
+        
+        
+        The memory footprint of `object` values is ignored by default:
         >>> s = pd.Series(range(3))
         >>> s.memory_usage()
         152
-
-        Not including the index gives the size of the rest of the data, which
-        is necessarily smaller:
-
+        
         >>> s.memory_usage(index=False)
         24
-
-        The memory footprint of `object` values is ignored by default:
-
+        
         >>> s = pd.Series(["a", "b"])
         >>> s.values
         array(['a', 'b'], dtype=object)
@@ -4642,9 +5139,8 @@
         return v
 
     def isin(self, values) -> "Series":
-        """
-        Whether elements in Series are contained in `values`.
-
+        """Whether elements in Series are contained in `values`.
+        
         Return a boolean Series showing whether each element in the Series
         matches an element in the passed sequence of `values` exactly.
 
@@ -4663,14 +5159,16 @@
         Raises
         ------
         TypeError
-          * If `values` is a string
+            * If `values` is a string
 
         See Also
         --------
         DataFrame.isin : Equivalent method on DataFrame.
-
         Examples
         --------
+        
+        Passing a single string as ``s.isin('lama')`` will raise an error. Use
+        a list of one element instead:
         >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama',
         ...                'hippo'], name='animal')
         >>> s.isin(['cow', 'lama'])
@@ -4681,10 +5179,7 @@
         4     True
         5    False
         Name: animal, dtype: bool
-
-        Passing a single string as ``s.isin('lama')`` will raise an error. Use
-        a list of one element instead:
-
+        
         >>> s.isin(['lama'])
         0     True
         1    False
@@ -4700,9 +5195,8 @@
         )
 
     def between(self, left, right, inclusive=True) -> "Series":
-        """
-        Return boolean Series equivalent to left <= series <= right.
-
+        """Return boolean Series equivalent to left <= series <= right.
+        
         This function returns a boolean vector containing `True` wherever the
         corresponding Series element is between the boundary values `left` and
         `right`. NA values are treated as `False`.
@@ -4714,7 +5208,7 @@
         right : scalar or list-like
             Right boundary.
         inclusive : bool, default True
-            Include boundaries.
+            Include boundaries. (Default value = True)
 
         Returns
         -------
@@ -4726,17 +5220,21 @@
         --------
         Series.gt : Greater than of series and other.
         Series.lt : Less than of series and other.
-
         Notes
         -----
         This function is equivalent to ``(left <= ser) & (ser <= right)``
-
         Examples
         --------
+        
+        Boundary values are included by default:
+        
+        
+        With `inclusive` set to ``False`` boundary values are excluded:
+        
+        
+        `left` and `right` can be any scalar value:
         >>> s = pd.Series([2, 0, 4, 8, np.nan])
-
-        Boundary values are included by default:
-
+        
         >>> s.between(1, 4)
         0     True
         1    False
@@ -4744,9 +5242,7 @@
         3    False
         4    False
         dtype: bool
-
-        With `inclusive` set to ``False`` boundary values are excluded:
-
+        
         >>> s.between(1, 4, inclusive=False)
         0     True
         1    False
@@ -4754,9 +5250,7 @@
         3    False
         4    False
         dtype: bool
-
-        `left` and `right` can be any scalar value:
-
+        
         >>> s = pd.Series(['Alice', 'Bob', 'Carol', 'Eve'])
         >>> s.between('Anna', 'Daniel')
         0    False
@@ -4784,6 +5278,23 @@
         convert_integer: bool = True,
         convert_boolean: bool = True,
     ) -> "Series":
+        """
+
+        Parameters
+        ----------
+        infer_objects: bool :
+             (Default value = True)
+        convert_string: bool :
+             (Default value = True)
+        convert_integer: bool :
+             (Default value = True)
+        convert_boolean: bool :
+             (Default value = True)
+
+        Returns
+        -------
+
+        """
         input_series = self
         if infer_objects:
             input_series = input_series.infer_objects()
@@ -4804,35 +5315,38 @@
 
     @doc(NDFrame.isna, klass=_shared_doc_kwargs["klass"])
     def isna(self) -> "Series":
+        """ """
         return super().isna()
 
     @doc(NDFrame.isna, klass=_shared_doc_kwargs["klass"])
     def isnull(self) -> "Series":
+        """ """
         return super().isnull()
 
     @doc(NDFrame.notna, klass=_shared_doc_kwargs["klass"])
     def notna(self) -> "Series":
+        """ """
         return super().notna()
 
     @doc(NDFrame.notna, klass=_shared_doc_kwargs["klass"])
     def notnull(self) -> "Series":
+        """ """
         return super().notnull()
 
     def dropna(self, axis=0, inplace=False, how=None):
-        """
-        Return a new Series with missing values removed.
-
+        """Return a new Series with missing values removed.
+        
         See the :ref:`User Guide <missing_data>` for more on which values are
         considered missing, and how to work with missing data.
 
         Parameters
         ----------
         axis : {0 or 'index'}, default 0
-            There is only one axis to drop values from.
+            There is only one axis to drop values from. (Default value = 0)
         inplace : bool, default False
-            If True, do operation inplace and return None.
+            If True, do operation inplace and return None. (Default value = False)
         how : str, optional
-            Not in use. Kept for compatibility.
+            Not in use. Kept for compatibility. (Default value = None)
 
         Returns
         -------
@@ -4846,34 +5360,35 @@
         Series.fillna : Replace missing values.
         DataFrame.dropna : Drop rows or columns which contain NA values.
         Index.dropna : Drop missing indices.
-
         Examples
         --------
+        
+        Drop NA values from a Series.
+        
+        
+        Keep the Series with valid entries in the same variable.
+        
+        
+        Empty strings are not considered NA values. ``None`` is considered an
+        NA value.
         >>> ser = pd.Series([1., 2., np.nan])
         >>> ser
         0    1.0
         1    2.0
         2    NaN
         dtype: float64
-
-        Drop NA values from a Series.
-
+        
         >>> ser.dropna()
         0    1.0
         1    2.0
         dtype: float64
-
-        Keep the Series with valid entries in the same variable.
-
+        
         >>> ser.dropna(inplace=True)
         >>> ser
         0    1.0
         1    2.0
         dtype: float64
-
-        Empty strings are not considered NA values. ``None`` is considered an
-        NA value.
-
+        
         >>> ser = pd.Series([np.NaN, 2, pd.NaT, '', None, 'I stay'])
         >>> ser
         0       NaN
@@ -4910,22 +5425,22 @@
     # Time series-oriented methods
 
     def to_timestamp(self, freq=None, how="start", copy=True) -> "Series":
-        """
-        Cast to DatetimeIndex of Timestamps, at *beginning* of period.
+        """Cast to DatetimeIndex of Timestamps, at *beginning* of period.
 
         Parameters
         ----------
         freq : str, default frequency of PeriodIndex
-            Desired frequency.
+            Desired frequency. (Default value = None)
         how : {'s', 'e', 'start', 'end'}
             Convention for converting period to timestamp; start of period
-            vs. end.
+            vs. end. (Default value = "start")
         copy : bool, default True
-            Whether or not to return a copy.
-
-        Returns
-        -------
-        Series with DatetimeIndex
+            Whether or not to return a copy. (Default value = True)
+
+        Returns
+        -------
+
+        
         """
         new_values = self._values
         if copy:
@@ -4939,20 +5454,19 @@
         )
 
     def to_period(self, freq=None, copy=True) -> "Series":
-        """
-        Convert Series from DatetimeIndex to PeriodIndex.
+        """Convert Series from DatetimeIndex to PeriodIndex.
 
         Parameters
         ----------
         freq : str, default None
-            Frequency associated with the PeriodIndex.
+            Frequency associated with the PeriodIndex. (Default value = None)
         copy : bool, default True
-            Whether or not to return a copy.
-
-        Returns
-        -------
-        Series
-            Series with index converted to PeriodIndex.
+            Whether or not to return a copy. (Default value = True)
+
+        Returns
+        -------
+
+        
         """
         new_values = self._values
         if copy:
