# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pygments/lexers/perl.py
+++ b/..//venv/lib/python3.8/site-packages/pygments/lexers/perl.py
@@ -21,9 +21,7 @@
 
 
 class PerlLexer(RegexLexer):
-    """
-    For `Perl <https://www.perl.org>`_ source code.
-    """
+    """For `Perl <https://www.perl.org>`_ source code."""
 
     name = 'Perl'
     aliases = ['perl', 'pl']
@@ -206,6 +204,17 @@
     }
 
     def analyse_text(text):
+        """
+
+        Parameters
+        ----------
+        text :
+            
+
+        Returns
+        -------
+
+        """
         if shebang_matches(text, r'perl'):
             return True
 
@@ -223,10 +232,16 @@
 
 
 class Perl6Lexer(ExtendedRegexLexer):
-    """
-    For `Raku <https://www.raku.org>`_ (a.k.a. Perl 6) source code.
-
+    """For `Raku <https://www.raku.org>`_ (a.k.a. Perl 6) source code.
+    
     .. versionadded:: 2.0
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
 
     name = 'Perl6'
@@ -492,6 +507,23 @@
     }
 
     def _build_word_match(words, boundary_regex_fragment=None, prefix='', suffix=''):
+        """
+
+        Parameters
+        ----------
+        words :
+            
+        boundary_regex_fragment :
+             (Default value = None)
+        prefix :
+             (Default value = '')
+        suffix :
+             (Default value = '')
+
+        Returns
+        -------
+
+        """
         if boundary_regex_fragment is None:
             return r'\b(' + prefix + r'|'.join(re.escape(x) for x in words) + \
                 suffix + r')\b'
@@ -501,7 +533,33 @@
                 boundary_regex_fragment + r')'
 
     def brackets_callback(token_class):
+        """
+
+        Parameters
+        ----------
+        token_class :
+            
+
+        Returns
+        -------
+
+        """
         def callback(lexer, match, context):
+            """
+
+            Parameters
+            ----------
+            lexer :
+                
+            match :
+                
+            context :
+                
+
+            Returns
+            -------
+
+            """
             groups = match.groupdict()
             opening_chars = groups['delimiter']
             n_chars = len(opening_chars)
@@ -557,6 +615,21 @@
         return callback
 
     def opening_brace_callback(lexer, match, context):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        context :
+            
+
+        Returns
+        -------
+
+        """
         stack = context.stack
 
         yield match.start(), Text, context.text[match.start():match.end()]
@@ -570,6 +643,21 @@
             context.perl6_token_nesting_level += 1
 
     def closing_brace_callback(lexer, match, context):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        context :
+            
+
+        Returns
+        -------
+
+        """
         stack = context.stack
 
         yield match.start(), Text, context.text[match.start():match.end()]
@@ -584,6 +672,21 @@
                 stack.pop()
 
     def embedded_perl6_callback(lexer, match, context):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        context :
+            
+
+        Returns
+        -------
+
+        """
         context.perl6_token_nesting_level = 1
         yield match.start(), Text, context.text[match.start():match.end()]
         context.pos = match.end()
@@ -673,7 +776,29 @@
     }
 
     def analyse_text(text):
+        """
+
+        Parameters
+        ----------
+        text :
+            
+
+        Returns
+        -------
+
+        """
         def strip_pod(lines):
+            """
+
+            Parameters
+            ----------
+            lines :
+                
+
+            Returns
+            -------
+
+            """
             in_pod = False
             stripped_lines = []
 
