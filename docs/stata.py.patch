# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/io/stata.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/io/stata.py
@@ -201,8 +201,7 @@
 #  mypy doesn't understand that a Series and an int can be combined using mathematical
 #  operations. (+, -).
 def _stata_elapsed_date_to_datetime_vec(dates, fmt) -> Series:
-    """
-    Convert from SIF to datetime. https://www.stata.com/help.cgi?datetime
+    """Convert from SIF to datetime. https://www.stata.com/help.cgi?datetime
 
     Parameters
     ----------
@@ -219,11 +218,6 @@
 
     Examples
     --------
-    >>> dates = pd.Series([52])
-    >>> _stata_elapsed_date_to_datetime_vec(dates , "%tw")
-    0   1961-01-01
-    dtype: datetime64[ns]
-
     Notes
     -----
     datetime/c - tc
@@ -245,6 +239,10 @@
         half-years since 1960h1 yearly
     date - ty
         years since 0000
+    >>> dates = pd.Series([52])
+    >>> _stata_elapsed_date_to_datetime_vec(dates , "%tw")
+    0   1961-01-01
+    dtype: datetime64[ns]
     """
     MIN_YEAR, MAX_YEAR = Timestamp.min.year, Timestamp.max.year
     MAX_DAY_DELTA = (Timestamp.max - datetime.datetime(1960, 1, 1)).days
@@ -253,11 +251,21 @@
     MAX_MS_DELTA = MAX_DAY_DELTA * 24 * 3600 * 1000
 
     def convert_year_month_safe(year, month) -> Series:
-        """
-        Convert year and month to datetimes, using pandas vectorized versions
+        """Convert year and month to datetimes, using pandas vectorized versions
         when the date range falls within the range supported by pandas.
         Otherwise it falls back to a slower but more robust method
         using datetime.
+
+        Parameters
+        ----------
+        year :
+            
+        month :
+            
+
+        Returns
+        -------
+
         """
         if year.max() < MAX_YEAR and year.min() > MIN_YEAR:
             return to_datetime(100 * year + month, format="%Y%m")
@@ -268,9 +276,19 @@
             )
 
     def convert_year_days_safe(year, days) -> Series:
-        """
-        Converts year (e.g. 1999) and days since the start of the year to a
+        """Converts year (e.g. 1999) and days since the start of the year to a
         datetime or datetime64 Series
+
+        Parameters
+        ----------
+        year :
+            
+        days :
+            
+
+        Returns
+        -------
+
         """
         if year.max() < (MAX_YEAR - 1) and year.min() > MIN_YEAR:
             return to_datetime(year, format="%Y") + to_timedelta(days, unit="d")
@@ -283,10 +301,22 @@
             return Series(value, index=index)
 
     def convert_delta_safe(base, deltas, unit) -> Series:
-        """
-        Convert base dates and deltas to datetimes, using pandas vectorized
+        """Convert base dates and deltas to datetimes, using pandas vectorized
         versions if the deltas satisfy restrictions required to be expressed
         as dates in pandas.
+
+        Parameters
+        ----------
+        base :
+            
+        deltas :
+            
+        unit :
+            
+
+        Returns
+        -------
+
         """
         index = getattr(deltas, "index", None)
         if unit == "d":
@@ -363,22 +393,42 @@
 
 
 def _datetime_to_stata_elapsed_vec(dates: Series, fmt: str) -> Series:
-    """
-    Convert from datetime to SIF. https://www.stata.com/help.cgi?datetime
+    """Convert from datetime to SIF. https://www.stata.com/help.cgi?datetime
 
     Parameters
     ----------
-    dates : Series
-        Series or array containing datetime.datetime or datetime64[ns] to
-        convert to the Stata Internal Format given by fmt
-    fmt : str
-        The format to convert to. Can be, tc, td, tw, tm, tq, th, ty
+    dates: Series :
+        
+    fmt: str :
+        
+
+    Returns
+    -------
+
+    
     """
     index = dates.index
     NS_PER_DAY = 24 * 3600 * 1000 * 1000 * 1000
     US_PER_DAY = NS_PER_DAY / 1000
 
     def parse_dates_safe(dates, delta=False, year=False, days=False):
+        """
+
+        Parameters
+        ----------
+        dates :
+            
+        delta :
+             (Default value = False)
+        year :
+             (Default value = False)
+        days :
+             (Default value = False)
+
+        Returns
+        -------
+
+        """
         d = {}
         if is_datetime64_dtype(dates.dtype):
             if delta:
@@ -399,6 +449,17 @@
                 delta = dates._values - stata_epoch
 
                 def f(x: datetime.timedelta) -> float:
+                    """
+
+                    Parameters
+                    ----------
+                    x: datetime.timedelta :
+                        
+
+                    Returns
+                    -------
+
+                    """
                     return US_PER_DAY * x.days + 1000000 * x.seconds + x.microseconds
 
                 v = np.vectorize(f)
@@ -410,6 +471,17 @@
             if days:
 
                 def g(x: datetime.datetime) -> int:
+                    """
+
+                    Parameters
+                    ----------
+                    x: datetime.datetime :
+                        
+
+                    Returns
+                    -------
+
+                    """
                     return (x - datetime.datetime(x.year, 1, 1)).days
 
                 v = np.vectorize(g)
@@ -473,6 +545,7 @@
 
 
 class PossiblePrecisionLoss(Warning):
+    """ """
     pass
 
 
@@ -483,6 +556,7 @@
 
 
 class ValueLabelTypeMismatch(Warning):
+    """ """
     pass
 
 
@@ -494,6 +568,7 @@
 
 
 class InvalidColumnName(Warning):
+    """ """
     pass
 
 
@@ -510,6 +585,7 @@
 
 
 class CategoricalConversionWarning(Warning):
+    """ """
     pass
 
 
@@ -525,8 +601,7 @@
 
 
 def _cast_to_stata_types(data: DataFrame) -> DataFrame:
-    """
-    Checks the dtypes of the columns of a pandas DataFrame for
+    """Checks the dtypes of the columns of a pandas DataFrame for
     compatibility with the data types and ranges supported by Stata, and
     converts if necessary.
 
@@ -534,6 +609,11 @@
     ----------
     data : DataFrame
         The DataFrame to check and convert
+    data: DataFrame :
+        
+
+    Returns
+    -------
 
     Notes
     -----
@@ -544,7 +624,7 @@
     the value are in the int32 range, and sidecast to float64 when larger than
     this range.  If the int64 values are outside of the range of those
     perfectly representable as float64 values, a warning is raised.
-
+    
     bool columns are cast to int8.  uint columns are converted to int of the
     same size if there is no loss in precision, otherwise are upcast to a
     larger type.  uint64 is currently not supported since it is concerted to
@@ -614,16 +694,7 @@
 
 
 class StataValueLabel:
-    """
-    Parse a categorical column and prepare formatted output
-
-    Parameters
-    ----------
-    catarray : Series
-        Categorical Series to encode
-    encoding : {"latin-1", "utf-8"}
-        Encoding to use for value labels.
-    """
+    """Parse a categorical column and prepare formatted output"""
 
     def __init__(self, catarray: Series, encoding: str = "latin-1"):
 
@@ -670,18 +741,19 @@
         self.len = 4 + 4 + 4 * self.n + 4 * self.n + self.text_len
 
     def generate_value_label(self, byteorder: str) -> bytes:
-        """
-        Generate the binary representation of the value labels.
+        """Generate the binary representation of the value labels.
 
         Parameters
         ----------
         byteorder : str
             Byte order of the output
-
-        Returns
-        -------
-        value_label : bytes
-            Bytes containing the formatted value label
+        byteorder: str :
+            
+
+        Returns
+        -------
+
+        
         """
         encoding = self._encoding
         bio = BytesIO()
@@ -724,23 +796,25 @@
 
 
 class StataMissingValue:
-    """
-    An observation's missing value.
+    """An observation's missing value.
 
     Parameters
     ----------
     value : {int, float}
         The Stata missing value code
 
+    Returns
+    -------
+
     Notes
     -----
     More information: <https://www.stata.com/help.cgi?missing>
-
+    
     Integer missing values make the code '.', '.a', ..., '.z' to the ranges
     101 ... 127 (for int8), 32741 ... 32767  (for int16) and 2147483621 ...
     2147483647 (for int32).  Missing values for floating point data types are
     more complex but the pattern is simple to discern from the following table.
-
+    
     np.float32 missing values (float in Stata)
     0000007f    .
     0008007f    .a
@@ -749,7 +823,7 @@
     00c0007f    .x
     00c8007f    .y
     00d0007f    .z
-
+    
     np.float64 missing values (double in Stata)
     000000000000e07f    .
     000000000001e07f    .a
@@ -805,26 +879,12 @@
 
     @property
     def string(self) -> str:
-        """
-        The Stata representation of the missing value: '.', '.a'..'.z'
-
-        Returns
-        -------
-        str
-            The representation of the missing value.
-        """
+        """The Stata representation of the missing value: '.', '.a'..'.z'"""
         return self._str
 
     @property
     def value(self) -> Union[int, float]:
-        """
-        The binary representation of the missing value.
-
-        Returns
-        -------
-        {int, float}
-            The binary representation of the missing value.
-        """
+        """The binary representation of the missing value."""
         return self._value
 
     def __str__(self) -> str:
@@ -842,6 +902,17 @@
 
     @classmethod
     def get_base_missing_value(cls, dtype: np.dtype) -> Union[int, float]:
+        """
+
+        Parameters
+        ----------
+        dtype: np.dtype :
+            
+
+        Returns
+        -------
+
+        """
         if dtype == np.int8:
             value = cls.BASE_MISSING_VALUES["int8"]
         elif dtype == np.int16:
@@ -858,6 +929,7 @@
 
 
 class StataParser:
+    """ """
     def __init__(self):
 
         # type          code.
@@ -1022,6 +1094,7 @@
 
 
 class StataReader(StataParser, abc.Iterator):
+    """ """
     __doc__ = _stata_reader_doc
 
     def __init__(
@@ -1090,22 +1163,21 @@
         self.close()
 
     def close(self) -> None:
-        """ close the handle if its open """
+        """close the handle if its open"""
         try:
             self.path_or_buf.close()
         except IOError:
             pass
 
     def _set_encoding(self) -> None:
-        """
-        Set string encoding which depends on file version
-        """
+        """Set string encoding which depends on file version"""
         if self.format_version < 118:
             self._encoding = "latin-1"
         else:
             self._encoding = "utf-8"
 
     def _read_header(self) -> None:
+        """ """
         first_char = self.path_or_buf.read(1)
         if struct.unpack("c", first_char)[0] == b"<":
             self._read_new_header()
@@ -1118,6 +1190,7 @@
         self.col_sizes = [self._calcsize(typ) for typ in self.typlist]
 
     def _read_new_header(self) -> None:
+        """ """
         # The first part of the header is common to 117 - 119.
         self.path_or_buf.read(27)  # stata_dta><header><release>
         self.format_version = int(self.path_or_buf.read(3))
@@ -1197,6 +1270,17 @@
     def _get_dtypes(
         self, seek_vartypes: int
     ) -> Tuple[List[Union[int, str]], List[Union[str, np.dtype]]]:
+        """
+
+        Parameters
+        ----------
+        seek_vartypes: int :
+            
+
+        Returns
+        -------
+
+        """
 
         self.path_or_buf.seek(seek_vartypes)
         raw_typlist = [
@@ -1205,6 +1289,17 @@
         ]
 
         def f(typ: int) -> Union[int, str]:
+            """
+
+            Parameters
+            ----------
+            typ: int :
+                
+
+            Returns
+            -------
+
+            """
             if typ <= 2045:
                 return typ
             try:
@@ -1215,6 +1310,17 @@
         typlist = [f(x) for x in raw_typlist]
 
         def g(typ: int) -> Union[str, np.dtype]:
+            """
+
+            Parameters
+            ----------
+            typ: int :
+                
+
+            Returns
+            -------
+
+            """
             if typ <= 2045:
                 return str(typ)
             try:
@@ -1227,12 +1333,14 @@
         return typlist, dtyplist
 
     def _get_varlist(self) -> List[str]:
+        """ """
         # 33 in order formats, 129 in formats 118 and 119
         b = 33 if self.format_version < 118 else 129
         return [self._decode(self.path_or_buf.read(b)) for _ in range(self.nvar)]
 
     # Returns the format list
     def _get_fmtlist(self) -> List[str]:
+        """ """
         if self.format_version >= 118:
             b = 57
         elif self.format_version > 113:
@@ -1246,6 +1354,7 @@
 
     # Returns the label list
     def _get_lbllist(self) -> List[str]:
+        """ """
         if self.format_version >= 118:
             b = 129
         elif self.format_version > 108:
@@ -1255,6 +1364,7 @@
         return [self._decode(self.path_or_buf.read(b)) for _ in range(self.nvar)]
 
     def _get_variable_labels(self) -> List[str]:
+        """ """
         if self.format_version >= 118:
             vlblist = [
                 self._decode(self.path_or_buf.read(321)) for _ in range(self.nvar)
@@ -1270,12 +1380,14 @@
         return vlblist
 
     def _get_nobs(self) -> int:
+        """ """
         if self.format_version >= 118:
             return struct.unpack(self.byteorder + "Q", self.path_or_buf.read(8))[0]
         else:
             return struct.unpack(self.byteorder + "I", self.path_or_buf.read(4))[0]
 
     def _get_data_label(self) -> str:
+        """ """
         if self.format_version >= 118:
             strlen = struct.unpack(self.byteorder + "H", self.path_or_buf.read(2))[0]
             return self._decode(self.path_or_buf.read(strlen))
@@ -1288,6 +1400,7 @@
             return self._decode(self.path_or_buf.read(32))
 
     def _get_time_stamp(self) -> str:
+        """ """
         if self.format_version >= 118:
             strlen = struct.unpack("b", self.path_or_buf.read(1))[0]
             return self.path_or_buf.read(strlen).decode("utf-8")
@@ -1300,6 +1413,7 @@
             raise ValueError()
 
     def _get_seek_variable_labels(self) -> int:
+        """ """
         if self.format_version == 117:
             self.path_or_buf.read(8)  # <variable_labels>, throw away
             # Stata 117 data files do not follow the described format.  This is
@@ -1312,6 +1426,17 @@
             raise ValueError()
 
     def _read_old_header(self, first_char: bytes) -> None:
+        """
+
+        Parameters
+        ----------
+        first_char: bytes :
+            
+
+        Returns
+        -------
+
+        """
         self.format_version = struct.unpack("b", first_char)[0]
         if self.format_version not in [104, 105, 108, 111, 113, 114, 115]:
             raise ValueError(_version_error.format(version=self.format_version))
@@ -1413,11 +1538,35 @@
         return self._dtype
 
     def _calcsize(self, fmt: Union[int, str]) -> int:
+        """
+
+        Parameters
+        ----------
+        fmt: Union[int :
+            
+        str] :
+            
+
+        Returns
+        -------
+
+        """
         if isinstance(fmt, int):
             return fmt
         return struct.calcsize(self.byteorder + fmt)
 
     def _decode(self, s: bytes) -> str:
+        """
+
+        Parameters
+        ----------
+        s: bytes :
+            
+
+        Returns
+        -------
+
+        """
         # have bytes not strings, so must decode
         s = s.partition(b"\0")[0]
         try:
@@ -1435,6 +1584,7 @@
             return s.decode("latin-1")
 
     def _read_value_labels(self) -> None:
+        """ """
         if self._value_labels_read:
             # Don't read twice
             return
@@ -1489,6 +1639,7 @@
         self._value_labels_read = True
 
     def _read_strls(self) -> None:
+        """ """
         self.path_or_buf.seek(self.seek_strls)
         # Wrap v_o in a string to allow uint64 values as keys on 32bit OS
         self.GSO = {"0": ""}
@@ -1524,17 +1675,19 @@
         return self.read(nrows=self._chunksize)
 
     def get_chunk(self, size: Optional[int] = None) -> DataFrame:
-        """
-        Reads lines from Stata file and returns as dataframe
+        """Reads lines from Stata file and returns as dataframe
 
         Parameters
         ----------
         size : int, defaults to None
             Number of lines to read.  If None, reads whole file.
-
-        Returns
-        -------
-        DataFrame
+        size: Optional[int] :
+             (Default value = None)
+
+        Returns
+        -------
+
+        
         """
         if size is None:
             size = self._chunksize
@@ -1552,6 +1705,31 @@
         columns: Optional[Sequence[str]] = None,
         order_categoricals: Optional[bool] = None,
     ) -> DataFrame:
+        """
+
+        Parameters
+        ----------
+        nrows: Optional[int] :
+             (Default value = None)
+        convert_dates: Optional[bool] :
+             (Default value = None)
+        convert_categoricals: Optional[bool] :
+             (Default value = None)
+        index_col: Optional[str] :
+             (Default value = None)
+        convert_missing: Optional[bool] :
+             (Default value = None)
+        preserve_dtypes: Optional[bool] :
+             (Default value = None)
+        columns: Optional[Sequence[str]] :
+             (Default value = None)
+        order_categoricals: Optional[bool] :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         # Handle empty file or chunk.  If reading incrementally raise
         # StopIteration.  If reading the whole thing return an empty
         # data frame.
@@ -1667,6 +1845,17 @@
         if convert_dates:
 
             def any_startswith(x: str) -> bool:
+                """
+
+                Parameters
+                ----------
+                x: str :
+                    
+
+                Returns
+                -------
+
+                """
                 return any(x.startswith(fmt) for fmt in _date_formats)
 
             cols = np.where([any_startswith(x) for x in self.fmtlist])[0]
@@ -1710,6 +1899,19 @@
         return data
 
     def _do_convert_missing(self, data: DataFrame, convert_missing: bool) -> DataFrame:
+        """
+
+        Parameters
+        ----------
+        data: DataFrame :
+            
+        convert_missing: bool :
+            
+
+        Returns
+        -------
+
+        """
         # Check for missing values, and replace if found
         replacements = {}
         for i, colname in enumerate(data):
@@ -1748,6 +1950,17 @@
         return data
 
     def _insert_strls(self, data: DataFrame) -> DataFrame:
+        """
+
+        Parameters
+        ----------
+        data: DataFrame :
+            
+
+        Returns
+        -------
+
+        """
         if not hasattr(self, "GSO") or len(self.GSO) == 0:
             return data
         for i, typ in enumerate(self.typlist):
@@ -1758,6 +1971,19 @@
         return data
 
     def _do_select_columns(self, data: DataFrame, columns: Sequence[str]) -> DataFrame:
+        """
+
+        Parameters
+        ----------
+        data: DataFrame :
+            
+        columns: Sequence[str] :
+            
+
+        Returns
+        -------
+
+        """
 
         if not self._column_selector_set:
             column_set = set(columns)
@@ -1797,8 +2023,28 @@
         lbllist: Sequence[str],
         order_categoricals: bool,
     ) -> DataFrame:
-        """
-        Converts categorical columns to Categorical type.
+        """Converts categorical columns to Categorical type.
+
+        Parameters
+        ----------
+        data: DataFrame :
+            
+        value_label_dict: Dict[str :
+            
+        Dict[Union[float :
+            
+        int] :
+            
+        str]] :
+            
+        lbllist: Sequence[str] :
+            
+        order_categoricals: bool :
+            
+
+        Returns
+        -------
+
         """
         value_labels = list(value_label_dict.keys())
         cat_converted_data = []
@@ -1866,30 +2112,34 @@
 
     @property
     def data_label(self) -> str:
-        """
-        Return data label of Stata file.
-        """
+        """ """
         return self._data_label
 
     def variable_labels(self) -> Dict[str, str]:
-        """
-        Return variable labels as a dict, associating each variable name
+        """Return variable labels as a dict, associating each variable name
         with corresponding label.
 
-        Returns
-        -------
-        dict
+        Parameters
+        ----------
+
+        Returns
+        -------
+
+        
         """
         return dict(zip(self.varlist, self._variable_labels))
 
     def value_labels(self) -> Dict[str, Dict[Union[float, int], str]]:
-        """
-        Return a dict, associating each variable name a dict, associating
+        """Return a dict, associating each variable name a dict, associating
         each value its corresponding label.
 
-        Returns
-        -------
-        dict
+        Parameters
+        ----------
+
+        Returns
+        -------
+
+        
         """
         if not self._value_labels_read:
             self._read_value_labels()
@@ -1910,6 +2160,35 @@
     chunksize: Optional[int] = None,
     iterator: bool = False,
 ) -> Union[DataFrame, StataReader]:
+    """
+
+    Parameters
+    ----------
+    filepath_or_buffer: FilePathOrBuffer :
+        
+    convert_dates: bool :
+         (Default value = True)
+    convert_categoricals: bool :
+         (Default value = True)
+    index_col: Optional[str] :
+         (Default value = None)
+    convert_missing: bool :
+         (Default value = False)
+    preserve_dtypes: bool :
+         (Default value = True)
+    columns: Optional[Sequence[str]] :
+         (Default value = None)
+    order_categoricals: bool :
+         (Default value = True)
+    chunksize: Optional[int] :
+         (Default value = None)
+    iterator: bool :
+         (Default value = False)
+
+    Returns
+    -------
+
+    """
 
     reader = StataReader(
         filepath_or_buffer,
@@ -1936,8 +2215,7 @@
 def _open_file_binary_write(
     fname: FilePathOrBuffer, compression: Union[str, Mapping[str, str], None],
 ) -> Tuple[BinaryIO, bool, Optional[Union[str, Mapping[str, str]]]]:
-    """
-    Open a binary file or no-op if file-like.
+    """Open a binary file or no-op if file-like.
 
     Parameters
     ----------
@@ -1945,13 +2223,21 @@
         The file name or buffer.
     compression : {str, dict, None}
         The compression method to use.
+    fname: FilePathOrBuffer :
+        
+    compression: Union[str :
+        
+    Mapping[str :
+        
+    str] :
+        
+    None] :
+        
 
     Returns
     -------
-    file : file-like object
-        File object supporting write
-    own : bool
-        True if the file was created, otherwise False
+
+    
     """
     if hasattr(fname, "write"):
         # See https://github.com/python/mypy/issues/1424 for hasattr challenges
@@ -1975,6 +2261,17 @@
 
 
 def _set_endianness(endianness: str) -> str:
+    """
+
+    Parameters
+    ----------
+    endianness: str :
+        
+
+    Returns
+    -------
+
+    """
     if endianness.lower() in ["<", "little"]:
         return "<"
     elif endianness.lower() in [">", "big"]:
@@ -1984,8 +2281,18 @@
 
 
 def _pad_bytes(name: AnyStr, length: int) -> AnyStr:
-    """
-    Take a char string and pads it with null bytes until it's length chars.
+    """Take a char string and pads it with null bytes until it's length chars.
+
+    Parameters
+    ----------
+    name: AnyStr :
+        
+    length: int :
+        
+
+    Returns
+    -------
+
     """
     if isinstance(name, bytes):
         return name + b"\x00" * (length - len(name))
@@ -1993,8 +2300,16 @@
 
 
 def _convert_datetime_to_stata_type(fmt: str) -> np.dtype:
-    """
-    Convert from one of the stata date formats to a type in TYPE_MAP.
+    """Convert from one of the stata date formats to a type in TYPE_MAP.
+
+    Parameters
+    ----------
+    fmt: str :
+        
+
+    Returns
+    -------
+
     """
     if fmt in [
         "tc",
@@ -2018,6 +2333,19 @@
 
 
 def _maybe_convert_to_int_keys(convert_dates: Dict, varlist: List[Label]) -> Dict:
+    """
+
+    Parameters
+    ----------
+    convert_dates: Dict :
+        
+    varlist: List[Label] :
+        
+
+    Returns
+    -------
+
+    """
     new_dict = {}
     for key in convert_dates:
         if not convert_dates[key].startswith("%"):  # make sure proper fmts
@@ -2032,8 +2360,7 @@
 
 
 def _dtype_to_stata_type(dtype: np.dtype, column: Series) -> int:
-    """
-    Convert dtype types to stata types. Returns the byte of the given ordinal.
+    """Convert dtype types to stata types. Returns the byte of the given ordinal.
     See TYPE_MAP and comments for an explanation. This is also explained in
     the dta spec.
     1 - 244 are strings of this length
@@ -2043,9 +2370,20 @@
     253 - for int32     long
     254 - for float32   float
     255 - for double    double
-
+    
     If there are dates to convert, then dtype will already have the correct
     type inserted.
+
+    Parameters
+    ----------
+    dtype: np.dtype :
+        
+    column: Series :
+        
+
+    Returns
+    -------
+
     """
     # TODO: expand to handle datetime to integer conversion
     if dtype.type == np.object_:  # try to coerce it to the biggest string
@@ -2070,19 +2408,42 @@
 def _dtype_to_default_stata_fmt(
     dtype, column: Series, dta_version: int = 114, force_strl: bool = False
 ) -> str:
-    """
-    Map numpy dtype to stata's default format for this type. Not terribly
+    """Map numpy dtype to stata's default format for this type. Not terribly
     important since users can change this in Stata. Semantics are
-
+    
     object  -> "%DDs" where DD is the length of the string.  If not a string,
-                raise ValueError
-    float64 -> "%10.0g"
-    float32 -> "%9.0g"
-    int64   -> "%9.0g"
-    int32   -> "%12.0g"
-    int16   -> "%8.0g"
-    int8    -> "%8.0g"
-    strl    -> "%9s"
+
+    Parameters
+    ----------
+    dtype :
+        
+    column: Series :
+        
+    dta_version: int :
+         (Default value = 114)
+    force_strl: bool :
+         (Default value = False)
+
+    Returns
+    -------
+
+    Raises
+    ------
+    float64
+        10
+    float32
+        
+    int64
+        
+    int32
+        12
+    int16
+        
+    int8
+        
+    strl
+        9s
+
     """
     # TODO: Refactor to combine type with format
     # TODO: expand this to handle a default datetime format?
@@ -2113,8 +2474,7 @@
 
 
 class StataWriter(StataParser):
-    """
-    A class for writing Stata binary dta files
+    """A class for writing Stata binary dta files
 
     Parameters
     ----------
@@ -2123,9 +2483,7 @@
         object implementing a binary write() functions. If using a buffer
         then the buffer will not be automatically closed after the file
         is written.
-
         .. versionadded:: 0.23.0 support for pathlib, py.path.
-
     data : DataFrame
         Input to save
     convert_dates : dict
@@ -2155,7 +2513,6 @@
         '.zip', or '.xz' (otherwise no compression). If dict and compression
         mode is one of {'zip', 'gzip', 'bz2'}, or inferred as one of the above,
         other entries passed as additional compression options.
-
         .. versionadded:: 1.1.0
 
     Returns
@@ -2170,23 +2527,25 @@
         * If datetimes contain timezone information
     ValueError
         * Columns listed in convert_dates are neither datetime64[ns]
-          or datetime.datetime
+        or datetime.datetime
         * Column dtype is not representable in Stata
         * Column listed in convert_dates is not in DataFrame
         * Categorical label contains more than 32,000 characters
 
     Examples
     --------
+    
+    Directly write a zip file
+    
+    Save a DataFrame with dates
     >>> data = pd.DataFrame([[1.0, 1]], columns=['a', 'b'])
     >>> writer = StataWriter('./data_file.dta', data)
     >>> writer.write_file()
-
-    Directly write a zip file
+    
     >>> compression = {"method": "zip", "archive_name": "data_file.dta"}
     >>> writer = StataWriter('./data_file.zip', data, compression=compression)
     >>> writer.write_file()
-
-    Save a DataFrame with dates
+    
     >>> from datetime import datetime
     >>> data = pd.DataFrame([[datetime(2000,1,1)]], columns=['date'])
     >>> writer = StataWriter('./date_data_file.dta', data, {'date' : 'tw'})
@@ -2229,23 +2588,47 @@
         self._file: Optional[BinaryIO] = None
 
     def _write(self, to_write: str) -> None:
-        """
-        Helper to call encode before writing to file for Python 3 compat.
+        """Helper to call encode before writing to file for Python 3 compat.
+
+        Parameters
+        ----------
+        to_write: str :
+            
+
+        Returns
+        -------
+
         """
         assert self._file is not None
         self._file.write(to_write.encode(self._encoding))
 
     def _write_bytes(self, value: bytes) -> None:
-        """
-        Helper to assert file is open before writing.
+        """Helper to assert file is open before writing.
+
+        Parameters
+        ----------
+        value: bytes :
+            
+
+        Returns
+        -------
+
         """
         assert self._file is not None
         self._file.write(value)
 
     def _prepare_categoricals(self, data: DataFrame) -> DataFrame:
-        """
-        Check for categorical columns, retain categorical information for
+        """Check for categorical columns, retain categorical information for
         Stata file and convert categorical data to int
+
+        Parameters
+        ----------
+        data: DataFrame :
+            
+
+        Returns
+        -------
+
         """
         is_cat = [is_categorical_dtype(data[col].dtype) for col in data]
         self._is_col_cat = is_cat
@@ -2285,6 +2668,17 @@
         return DataFrame.from_dict(dict(data_formatted))
 
     def _replace_nans(self, data: DataFrame) -> DataFrame:
+        """
+
+        Parameters
+        ----------
+        data: DataFrame :
+            
+
+        Returns
+        -------
+
+        """
         # return data
         """
         Checks floating point data columns for nans, and replaces these with
@@ -2306,13 +2700,14 @@
         pass
 
     def _validate_variable_name(self, name: str) -> str:
-        """
-        Validate variable names for Stata export.
+        """Validate variable names for Stata export.
 
         Parameters
         ----------
         name : str
             Variable name
+        name: str :
+            
 
         Returns
         -------
@@ -2336,17 +2731,25 @@
         return name
 
     def _check_column_names(self, data: DataFrame) -> DataFrame:
-        """
-        Checks column names to ensure that they are valid Stata column names.
+        """Checks column names to ensure that they are valid Stata column names.
         This includes checks for:
             * Non-string names
             * Stata keywords
             * Variables that start with numbers
             * Variables with names that are too long
-
+        
         When an illegal variable name is detected, it is converted, and if
         dates are exported, the variable name is propagated to the date
         conversion dictionary
+
+        Parameters
+        ----------
+        data: DataFrame :
+            
+
+        Returns
+        -------
+
         """
         converted_names: Dict[Label, str] = {}
         columns: List[Label] = list(data.columns)
@@ -2405,6 +2808,17 @@
         return data
 
     def _set_formats_and_types(self, dtypes: Series) -> None:
+        """
+
+        Parameters
+        ----------
+        dtypes: Series :
+            
+
+        Returns
+        -------
+
+        """
         self.fmtlist: List[str] = []
         self.typlist: List[int] = []
         for col, dtype in dtypes.items():
@@ -2412,6 +2826,17 @@
             self.typlist.append(_dtype_to_stata_type(dtype, self.data[col]))
 
     def _prepare_pandas(self, data: DataFrame) -> None:
+        """
+
+        Parameters
+        ----------
+        data: DataFrame :
+            
+
+        Returns
+        -------
+
+        """
         # NOTE: we might need a different API / class for pandas objects so
         # we can set different semantics - handle this with a PR to pandas.io
 
@@ -2467,12 +2892,18 @@
                     self.fmtlist[key] = self._convert_dates[key]
 
     def _encode_strings(self) -> None:
-        """
-        Encode strings in dta-specific encoding
-
+        """Encode strings in dta-specific encoding
+        
         Do not encode columns marked for date conversion or for strL
         conversion. The strL converter independently handles conversion and
         also accepts empty string arrays.
+
+        Parameters
+        ----------
+
+        Returns
+        -------
+
         """
         convert_dates = self._convert_dates
         # _convert_strl is not available in dta 114
@@ -2504,6 +2935,7 @@
                     self.data[col] = encoded
 
     def write_file(self) -> None:
+        """ """
         self._file, self._own_file, compression = _open_file_binary_write(
             self._fname, self._compression
         )
@@ -2544,13 +2976,19 @@
             self._close()
 
     def _close(self) -> None:
-        """
-        Close the file if it was created by the writer.
-
+        """Close the file if it was created by the writer.
+        
         If a buffer or file-like object was passed in, for example a GzipFile,
         then leave this file open for the caller to close. In either case,
         attempt to flush the file contents to ensure they are written to disk
         (if supported)
+
+        Parameters
+        ----------
+
+        Returns
+        -------
+
         """
         # Some file-like objects might not support flush
         assert self._file is not None
@@ -2588,6 +3026,7 @@
         self._write(_pad_bytes("", 5))
 
     def _write_value_labels(self) -> None:
+        """ """
         for vl in self._value_labels:
             self._write_bytes(vl.generate_value_label(self._byteorder))
 
@@ -2596,6 +3035,19 @@
         data_label: Optional[str] = None,
         time_stamp: Optional[datetime.datetime] = None,
     ) -> None:
+        """
+
+        Parameters
+        ----------
+        data_label: Optional[str] :
+             (Default value = None)
+        time_stamp: Optional[datetime.datetime] :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         byteorder = self._byteorder
         # ds_format - just use 114
         self._write_bytes(struct.pack("b", 114))
@@ -2647,10 +3099,12 @@
         self._write_bytes(self._null_terminate_bytes(ts))
 
     def _write_variable_types(self) -> None:
+        """ """
         for typ in self.typlist:
             self._write_bytes(struct.pack("B", typ))
 
     def _write_varnames(self) -> None:
+        """ """
         # varlist names are checked by _check_column_names
         # varlist, requires null terminated
         for name in self.varlist:
@@ -2659,16 +3113,19 @@
             self._write(name)
 
     def _write_sortlist(self) -> None:
+        """ """
         # srtlist, 2*(nvar+1), int array, encoded by byteorder
         srtlist = _pad_bytes("", 2 * (self.nvar + 1))
         self._write(srtlist)
 
     def _write_formats(self) -> None:
+        """ """
         # fmtlist, 49*nvar, char array
         for fmt in self.fmtlist:
             self._write(_pad_bytes(fmt, 49))
 
     def _write_value_label_names(self) -> None:
+        """ """
         # lbllist, 33*nvar, char array
         for i in range(self.nvar):
             # Use variable name when categorical
@@ -2681,6 +3138,7 @@
                 self._write(_pad_bytes("", 33))
 
     def _write_variable_labels(self) -> None:
+        """ """
         # Missing labels are 80 blank characters plus null termination
         blank = _pad_bytes("", 81)
 
@@ -2705,10 +3163,21 @@
                 self._write(blank)
 
     def _convert_strls(self, data: DataFrame) -> DataFrame:
-        """No-op, future compatibility"""
+        """No-op, future compatibility
+
+        Parameters
+        ----------
+        data: DataFrame :
+            
+
+        Returns
+        -------
+
+        """
         return data
 
     def _prepare_data(self) -> np.recarray:
+        """ """
         data = self.data
         typlist = self.typlist
         convert_dates = self._convert_dates
@@ -2741,20 +3210,52 @@
         return data.to_records(index=False, column_dtypes=dtypes)
 
     def _write_data(self, records: np.recarray) -> None:
+        """
+
+        Parameters
+        ----------
+        records: np.recarray :
+            
+
+        Returns
+        -------
+
+        """
         self._write_bytes(records.tobytes())
 
     @staticmethod
     def _null_terminate_str(s: str) -> str:
+        """
+
+        Parameters
+        ----------
+        s: str :
+            
+
+        Returns
+        -------
+
+        """
         s += "\x00"
         return s
 
     def _null_terminate_bytes(self, s: str) -> bytes:
+        """
+
+        Parameters
+        ----------
+        s: str :
+            
+
+        Returns
+        -------
+
+        """
         return self._null_terminate_str(s).encode(self._encoding)
 
 
 def _dtype_to_stata_type_117(dtype: np.dtype, column: Series, force_strl: bool) -> int:
-    """
-    Converts dtype types to stata types. Returns the byte of the given ordinal.
+    """Converts dtype types to stata types. Returns the byte of the given ordinal.
     See TYPE_MAP and comments for an explanation. This is also explained in
     the dta spec.
     1 - 2045 are strings of this length
@@ -2765,9 +3266,22 @@
     65528 - for int32     long
     65529 - for float32   float
     65530 - for double    double
-
+    
     If there are dates to convert, then dtype will already have the correct
     type inserted.
+
+    Parameters
+    ----------
+    dtype: np.dtype :
+        
+    column: Series :
+        
+    force_strl: bool :
+        
+
+    Returns
+    -------
+
     """
     # TODO: expand to handle datetime to integer conversion
     if force_strl:
@@ -2795,8 +3309,20 @@
 
 
 def _pad_bytes_new(name: Union[str, bytes], length: int) -> bytes:
-    """
-    Takes a bytes instance and pads it with null bytes until it's length chars.
+    """Takes a bytes instance and pads it with null bytes until it's length chars.
+
+    Parameters
+    ----------
+    name: Union[str :
+        
+    bytes] :
+        
+    length: int :
+        
+
+    Returns
+    -------
+
     """
     if isinstance(name, str):
         name = bytes(name, "utf-8")
@@ -2804,9 +3330,8 @@
 
 
 class StataStrLWriter:
-    """
-    Converter for Stata StrLs
-
+    """Converter for Stata StrLs
+    
     Stata StrLs map 8 byte values to strings which are stored using a
     dictionary-like format where strings are keyed to two values.
 
@@ -2820,6 +3345,9 @@
         dta version.  Currently supports 117, 118 and 119
     byteorder : str, optional
         Can be ">", "<", "little", or "big". default is `sys.byteorder`
+
+    Returns
+    -------
 
     Notes
     -----
@@ -2866,12 +3394,27 @@
         self._gso_v_type = gso_v_type
 
     def _convert_key(self, key: Tuple[int, int]) -> int:
+        """
+
+        Parameters
+        ----------
+        key: Tuple[int :
+            
+        int] :
+            
+
+        Returns
+        -------
+
+        """
         v, o = key
         return v + self._o_offet * o
 
     def generate_table(self) -> Tuple[Dict[str, Tuple[int, int]], DataFrame]:
-        """
-        Generates the GSO lookup table for the DataFrame
+        """Generates the GSO lookup table for the DataFrame
+
+        Parameters
+        ----------
 
         Returns
         -------
@@ -2885,15 +3428,15 @@
         Notes
         -----
         Modifies the DataFrame in-place.
-
+        
         The DataFrame returned encodes the (v,o) values as uint64s. The
         encoding depends on the dta version, and can be expressed as
-
+        
         enc = v + o * 2 ** (o_size * 8)
-
+        
         so that v is stored in the lower bits and o is in the upper
         bits. o_size is
-
+        
           * 117: 4
           * 118: 6
           * 119: 5
@@ -2921,13 +3464,18 @@
         return gso_table, gso_df
 
     def generate_blob(self, gso_table: Dict[str, Tuple[int, int]]) -> bytes:
-        """
-        Generates the binary blob of GSOs that is written to the dta file.
+        """Generates the binary blob of GSOs that is written to the dta file.
 
         Parameters
         ----------
         gso_table : dict
             Ordered dictionary (str, vo)
+        gso_table: Dict[str :
+            
+        Tuple[int :
+            
+        int]] :
+            
 
         Returns
         -------
@@ -2986,9 +3534,8 @@
 
 
 class StataWriter117(StataWriter):
-    """
-    A class for writing Stata binary dta files in Stata 13 format (117)
-
+    """A class for writing Stata binary dta files in Stata 13 format (117)
+    
     .. versionadded:: 0.23.0
 
     Parameters
@@ -3033,7 +3580,6 @@
         '.zip', or '.xz' (otherwise no compression). If dict and compression
         mode is one of {'zip', 'gzip', 'bz2'}, or inferred as one of the above,
         other entries passed as additional compression options.
-
         .. versionadded:: 1.1.0
 
     Returns
@@ -3048,24 +3594,26 @@
         * If datetimes contain timezone information
     ValueError
         * Columns listed in convert_dates are neither datetime64[ns]
-          or datetime.datetime
+        or datetime.datetime
         * Column dtype is not representable in Stata
         * Column listed in convert_dates is not in DataFrame
         * Categorical label contains more than 32,000 characters
 
     Examples
     --------
+    
+    Directly write a zip file
+    
+    Or with long strings stored in strl format
     >>> from pandas.io.stata import StataWriter117
     >>> data = pd.DataFrame([[1.0, 1, 'a']], columns=['a', 'b', 'c'])
     >>> writer = StataWriter117('./data_file.dta', data)
     >>> writer.write_file()
-
-    Directly write a zip file
+    
     >>> compression = {"method": "zip", "archive_name": "data_file.dta"}
     >>> writer = StataWriter117('./data_file.zip', data, compression=compression)
     >>> writer.write_file()
-
-    Or with long strings stored in strl format
+    
     >>> data = pd.DataFrame([['A relatively long string'], [''], ['']],
     ...                     columns=['strls'])
     >>> writer = StataWriter117('./data_file_with_long_strings.dta', data,
@@ -3110,13 +3658,37 @@
 
     @staticmethod
     def _tag(val: Union[str, bytes], tag: str) -> bytes:
-        """Surround val with <tag></tag>"""
+        """Surround val with <tag></tag>
+
+        Parameters
+        ----------
+        val: Union[str :
+            
+        bytes] :
+            
+        tag: str :
+            
+
+        Returns
+        -------
+
+        """
         if isinstance(val, str):
             val = bytes(val, "utf-8")
         return bytes("<" + tag + ">", "utf-8") + val + bytes("</" + tag + ">", "utf-8")
 
     def _update_map(self, tag: str) -> None:
-        """Update map location for tag with file position"""
+        """Update map location for tag with file position
+
+        Parameters
+        ----------
+        tag: str :
+            
+
+        Returns
+        -------
+
+        """
         assert self._file is not None
         self._map[tag] = self._file.tell()
 
@@ -3125,7 +3697,19 @@
         data_label: Optional[str] = None,
         time_stamp: Optional[datetime.datetime] = None,
     ) -> None:
-        """Write the file header"""
+        """Write the file header
+
+        Parameters
+        ----------
+        data_label: Optional[str] :
+             (Default value = None)
+        time_stamp: Optional[datetime.datetime] :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         byteorder = self._byteorder
         self._write_bytes(bytes("<stata_dta>", "utf-8"))
         bio = BytesIO()
@@ -3180,10 +3764,16 @@
         self._write_bytes(self._tag(bio.read(), "header"))
 
     def _write_map(self) -> None:
-        """
-        Called twice during file write. The first populates the values in
+        """Called twice during file write. The first populates the values in
         the map with 0s.  The second call writes the final map locations when
         all blocks have been written.
+
+        Parameters
+        ----------
+
+        Returns
+        -------
+
         """
         assert self._file is not None
         if not self._map:
@@ -3214,6 +3804,7 @@
         self._write_bytes(self._tag(bio.read(), "map"))
 
     def _write_variable_types(self) -> None:
+        """ """
         self._update_map("variable_types")
         bio = BytesIO()
         for typ in self.typlist:
@@ -3222,6 +3813,7 @@
         self._write_bytes(self._tag(bio.read(), "variable_types"))
 
     def _write_varnames(self) -> None:
+        """ """
         self._update_map("varnames")
         bio = BytesIO()
         # 118 scales by 4 to accommodate utf-8 data worst case encoding
@@ -3234,11 +3826,13 @@
         self._write_bytes(self._tag(bio.read(), "varnames"))
 
     def _write_sortlist(self) -> None:
+        """ """
         self._update_map("sortlist")
         sort_size = 2 if self._dta_version < 119 else 4
         self._write_bytes(self._tag(b"\x00" * sort_size * (self.nvar + 1), "sortlist"))
 
     def _write_formats(self) -> None:
+        """ """
         self._update_map("formats")
         bio = BytesIO()
         fmt_len = 49 if self._dta_version == 117 else 57
@@ -3248,6 +3842,7 @@
         self._write_bytes(self._tag(bio.read(), "formats"))
 
     def _write_value_label_names(self) -> None:
+        """ """
         self._update_map("value_label_names")
         bio = BytesIO()
         # 118 scales by 4 to accommodate utf-8 data worst case encoding
@@ -3264,6 +3859,7 @@
         self._write_bytes(self._tag(bio.read(), "value_label_names"))
 
     def _write_variable_labels(self) -> None:
+        """ """
         # Missing labels are 80 blank characters plus null termination
         self._update_map("variable_labels")
         bio = BytesIO()
@@ -3298,16 +3894,29 @@
         self._write_bytes(self._tag(bio.read(), "variable_labels"))
 
     def _write_characteristics(self) -> None:
+        """ """
         self._update_map("characteristics")
         self._write_bytes(self._tag(b"", "characteristics"))
 
     def _write_data(self, records) -> None:
+        """
+
+        Parameters
+        ----------
+        records :
+            
+
+        Returns
+        -------
+
+        """
         self._update_map("data")
         self._write_bytes(b"<data>")
         self._write_bytes(records.tobytes())
         self._write_bytes(b"</data>")
 
     def _write_strls(self) -> None:
+        """ """
         self._update_map("strls")
         self._write_bytes(self._tag(self._strl_blob, "strls"))
 
@@ -3316,6 +3925,7 @@
         pass
 
     def _write_value_labels(self) -> None:
+        """ """
         self._update_map("value_labels")
         bio = BytesIO()
         for vl in self._value_labels:
@@ -3326,14 +3936,21 @@
         self._write_bytes(self._tag(bio.read(), "value_labels"))
 
     def _write_file_close_tag(self) -> None:
+        """ """
         self._update_map("stata_data_close")
         self._write_bytes(bytes("</stata_dta>", "utf-8"))
         self._update_map("end-of-file")
 
     def _update_strl_names(self) -> None:
-        """
-        Update column names for conversion to strl if they might have been
+        """Update column names for conversion to strl if they might have been
         changed to comply with Stata naming rules
+
+        Parameters
+        ----------
+
+        Returns
+        -------
+
         """
         # Update convert_strl if names changed
         for orig, new in self._converted_names.items():
@@ -3342,9 +3959,17 @@
                 self._convert_strl[idx] = new
 
     def _convert_strls(self, data: DataFrame) -> DataFrame:
-        """
-        Convert columns to StrLs if either very large or in the
+        """Convert columns to StrLs if either very large or in the
         convert_strl variable
+
+        Parameters
+        ----------
+        data: DataFrame :
+            
+
+        Returns
+        -------
+
         """
         convert_cols = [
             col
@@ -3360,6 +3985,17 @@
         return data
 
     def _set_formats_and_types(self, dtypes: Series) -> None:
+        """
+
+        Parameters
+        ----------
+        dtypes: Series :
+            
+
+        Returns
+        -------
+
+        """
         self.typlist = []
         self.fmtlist = []
         for col, dtype in dtypes.items():
@@ -3377,14 +4013,13 @@
 
 
 class StataWriterUTF8(StataWriter117):
-    """
-    Stata binary dta file writing in Stata 15 (118) and 16 (119) formats
-
+    """Stata binary dta file writing in Stata 15 (118) and 16 (119) formats
+    
     DTA 118 and 119 format files support unicode string data (both fixed
     and strL) format. Unicode is also supported in value labels, variable
     labels and the dataset label. Format 119 is automatically used if the
     file contains more than 32,767 variables.
-
+    
     .. versionadded:: 1.0.0
 
     Parameters
@@ -3433,7 +4068,6 @@
         '.zip', or '.xz' (otherwise no compression). If dict and compression
         mode is one of {'zip', 'gzip', 'bz2'}, or inferred as one of the above,
         other entries passed as additional compression options.
-
         .. versionadded:: 1.1.0
 
     Returns
@@ -3448,7 +4082,7 @@
         * If datetimes contain timezone information
     ValueError
         * Columns listed in convert_dates are neither datetime64[ns]
-          or datetime.datetime
+        or datetime.datetime
         * Column dtype is not representable in Stata
         * Column listed in convert_dates is not in DataFrame
         * Categorical label contains more than 32,000 characters
@@ -3456,19 +4090,20 @@
     Examples
     --------
     Using Unicode data and column names
-
+    
+    
+    Directly write a zip file
+    
+    Or with long strings stored in strl format
     >>> from pandas.io.stata import StataWriterUTF8
     >>> data = pd.DataFrame([[1.0, 1, '']], columns=['a', '', ''])
     >>> writer = StataWriterUTF8('./data_file.dta', data)
     >>> writer.write_file()
-
-    Directly write a zip file
+    
     >>> compression = {"method": "zip", "archive_name": "data_file.dta"}
     >>> writer = StataWriterUTF8('./data_file.zip', data, compression=compression)
     >>> writer.write_file()
-
-    Or with long strings stored in strl format
-
+    
     >>> data = pd.DataFrame([[' relatively long tring'], [''], ['']],
     ...                     columns=['strls'])
     >>> writer = StataWriterUTF8('./data_file_with_long_strings.dta', data,
@@ -3518,13 +4153,14 @@
         self._dta_version = version
 
     def _validate_variable_name(self, name: str) -> str:
-        """
-        Validate variable names for Stata export.
+        """Validate variable names for Stata export.
 
         Parameters
         ----------
         name : str
             Variable name
+        name: str :
+            
 
         Returns
         -------
