# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/bleach/html5lib_shim.py
+++ b/..//venv/lib/python3.8/site-packages/bleach/html5lib_shim.py
@@ -195,9 +195,15 @@
 
 class InputStreamWithMemory(object):
     """Wraps an HTMLInputStream to remember characters since last <
-
+    
     This wraps existing HTMLInputStream classes to keep track of the stream
     since the last < which marked an open tag state.
+
+    Parameters
+    ----------
+
+    Returns
+    -------
 
     """
 
@@ -209,17 +215,21 @@
 
     @property
     def errors(self):
+        """ """
         return self._inner_stream.errors
 
     @property
     def charEncoding(self):
+        """ """
         return self._inner_stream.charEncoding
 
     @property
     def changeEncoding(self):
+        """ """
         return self._inner_stream.changeEncoding
 
     def char(self):
+        """ """
         c = self._inner_stream.char()
         # char() can return None if EOF, so ignore that
         if c:
@@ -227,30 +237,66 @@
         return c
 
     def charsUntil(self, characters, opposite=False):
+        """
+
+        Parameters
+        ----------
+        characters :
+            
+        opposite :
+             (Default value = False)
+
+        Returns
+        -------
+
+        """
         chars = self._inner_stream.charsUntil(characters, opposite=opposite)
         self._buffer.extend(list(chars))
         return chars
 
     def unget(self, char):
+        """
+
+        Parameters
+        ----------
+        char :
+            
+
+        Returns
+        -------
+
+        """
         if self._buffer:
             self._buffer.pop(-1)
         return self._inner_stream.unget(char)
 
     def get_tag(self):
         """Returns the stream history since last '<'
-
+        
         Since the buffer starts at the last '<' as as seen by tagOpenState(),
         we know that everything from that point to when this method is called
         is the "tag" that is being tokenized.
 
+        Parameters
+        ----------
+
+        Returns
+        -------
+
         """
         return six.text_type("").join(self._buffer)
 
     def start_tag(self):
         """Resets stream history to just '<'
-
+        
         This gets called by tagOpenState() which marks a '<' that denotes an
         open tag. Any time we see that, we reset the buffer.
+
+        Parameters
+        ----------
+
+        Returns
+        -------
 
         """
         self._buffer = ["<"]
@@ -342,6 +388,19 @@
             yield last_error_token
 
     def consumeEntity(self, allowedChar=None, fromAttribute=False):
+        """
+
+        Parameters
+        ----------
+        allowedChar :
+             (Default value = None)
+        fromAttribute :
+             (Default value = False)
+
+        Returns
+        -------
+
+        """
         # If this tokenizer is set to consume entities, then we can let the
         # superclass do its thing.
         if self.consume_entities:
@@ -362,6 +421,7 @@
             self.tokenQueue.append({"type": CHARACTERS_TYPE, "data": "&"})
 
     def tagOpenState(self):
+        """ """
         # This state marks a < that is either a StartTag, EndTag, EmptyTag,
         # or ParseError. In all cases, we want to drop any stream history
         # we've collected so far and we do that by calling start_tag() on
@@ -370,6 +430,7 @@
         return super(BleachHTMLTokenizer, self).tagOpenState()
 
     def emitCurrentToken(self):
+        """ """
         token = self.currentToken
 
         if (
@@ -424,6 +485,25 @@
     def _parse(
         self, stream, innerHTML=False, container="div", scripting=True, **kwargs
     ):
+        """
+
+        Parameters
+        ----------
+        stream :
+            
+        innerHTML :
+             (Default value = False)
+        container :
+             (Default value = "div")
+        scripting :
+             (Default value = True)
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         # set scripting=True to parse <noscript> as though JS is enabled to
         # match the expected context in browsers
         #
@@ -447,12 +527,20 @@
 
 def convert_entity(value):
     """Convert an entity (minus the & and ; part) into what it represents
-
+    
     This handles numeric, hex, and text entities.
-
+    
     :arg value: the string (minus the ``&`` and ``;`` part) to convert
 
-    :returns: unicode character or None if it's an ambiguous ampersand that
+    Parameters
+    ----------
+    value :
+        
+
+    Returns
+    -------
+    type
+        unicode character or None if it's an ambiguous ampersand that
         doesn't match a character entity
 
     """
@@ -466,10 +554,18 @@
 
 def convert_entities(text):
     """Converts all found entities in the text
-
+    
     :arg text: the text to convert entities in
 
-    :returns: unicode text with converted entities
+    Parameters
+    ----------
+    text :
+        
+
+    Returns
+    -------
+    type
+        unicode text with converted entities
 
     """
     if "&" not in text:
@@ -501,14 +597,22 @@
 
 def match_entity(stream):
     """Returns first entity in stream or None if no entity exists
-
+    
     Note: For Bleach purposes, entities must start with a "&" and end with
     a ";". This ignoresambiguous character entities that have no ";" at the
     end.
-
+    
     :arg stream: the character stream
 
-    :returns: ``None`` or the entity string without "&" or ";"
+    Parameters
+    ----------
+    stream :
+        
+
+    Returns
+    -------
+    type
+        None`` or the entity string without "&" or ";"
 
     """
     # Nix the & at the beginning
@@ -562,10 +666,18 @@
 
 def next_possible_entity(text):
     """Takes a text and generates a list of possible entities
-
+    
     :arg text: the text to look at
 
-    :returns: generator where each part (except the first) starts with an
+    Parameters
+    ----------
+    text :
+        
+
+    Returns
+    -------
+    type
+        generator where each part (except the first) starts with an
         "&"
 
     """
@@ -579,6 +691,13 @@
 class BleachHTMLSerializer(HTMLSerializer):
     """HTMLSerializer that undoes & -> &amp; in attributes and sets
     escape_rcdata to True
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
 
     # per the HTMLSerializer.__init__ docstring:
@@ -590,7 +709,17 @@
     escape_rcdata = True
 
     def escape_base_amp(self, stoken):
-        """Escapes just bare & in HTML attribute values"""
+        """Escapes just bare & in HTML attribute values
+
+        Parameters
+        ----------
+        stoken :
+            
+
+        Returns
+        -------
+
+        """
         # First, undo escaping of &. We need to do this because html5lib's
         # HTMLSerializer expected the tokenizer to consume all the character
         # entities and convert them to their respective characters, but the
@@ -622,9 +751,19 @@
 
     def serialize(self, treewalker, encoding=None):
         """Wrap HTMLSerializer.serialize and conver & to &amp; in attribute values
-
+        
         Note that this converts & to &amp; in attribute values where the & isn't
         already part of an unambiguous character entity.
+
+        Parameters
+        ----------
+        treewalker :
+            
+        encoding :
+             (Default value = None)
+
+        Returns
+        -------
 
         """
         in_tag = False
