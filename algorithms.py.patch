# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/core/algorithms.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/core/algorithms.py
@@ -69,10 +69,9 @@
 def _ensure_data(
     values, dtype: Optional[DtypeObj] = None
 ) -> Tuple[np.ndarray, DtypeObj]:
-    """
-    routine to ensure that our data is of the correct
+    """routine to ensure that our data is of the correct
     input dtype for lower-level routines
-
+    
     This will coerce:
     - ints -> int64
     - uint -> uint64
@@ -84,13 +83,16 @@
     Parameters
     ----------
     values : array-like
+        
     dtype : pandas_dtype, optional
         coerce to this dtype
-
-    Returns
-    -------
-    values : ndarray
-    pandas_dtype : np.dtype or ExtensionDtype
+    dtype: Optional[DtypeObj] :
+         (Default value = None)
+
+    Returns
+    -------
+
+    
     """
 
     if not isinstance(values, ABCMultiIndex):
@@ -178,18 +180,27 @@
 def _reconstruct_data(
     values: ArrayLike, dtype: DtypeObj, original: AnyArrayLike
 ) -> ArrayLike:
-    """
-    reverse of _ensure_data
+    """reverse of _ensure_data
 
     Parameters
     ----------
     values : np.ndarray or ExtensionArray
+        
     dtype : np.ndtype or ExtensionDtype
+        
     original : AnyArrayLike
-
-    Returns
-    -------
-    ExtensionArray or np.ndarray
+        
+    values: ArrayLike :
+        
+    dtype: DtypeObj :
+        
+    original: AnyArrayLike :
+        
+
+    Returns
+    -------
+
+    
     """
     if is_extension_array_dtype(dtype):
         values = dtype.construct_array_type()._from_sequence(values)
@@ -211,8 +222,16 @@
 
 
 def _ensure_arraylike(values):
-    """
-    ensure that we are arraylike if not already
+    """ensure that we are arraylike if not already
+
+    Parameters
+    ----------
+    values :
+        
+
+    Returns
+    -------
+
     """
     if not is_array_like(values):
         inferred = lib.infer_dtype(values, skipna=False)
@@ -236,14 +255,16 @@
 
 def _get_hashtable_algo(values):
     """
+
     Parameters
     ----------
     values : arraylike
-
-    Returns
-    -------
-    htable : HashTable subclass
-    values : ndarray
+        
+
+    Returns
+    -------
+
+    
     """
     values, _ = _ensure_data(values)
 
@@ -253,6 +274,17 @@
 
 
 def _get_values_for_rank(values):
+    """
+
+    Parameters
+    ----------
+    values :
+        
+
+    Returns
+    -------
+
+    """
     if is_categorical_dtype(values):
         values = values._values_for_rank()
 
@@ -261,6 +293,17 @@
 
 
 def _get_data_algo(values):
+    """
+
+    Parameters
+    ----------
+    values :
+        
+
+    Returns
+    -------
+
+    """
     values = _get_values_for_rank(values)
 
     ndtype = _check_object_for_strings(values)
@@ -270,17 +313,19 @@
 
 
 def _check_object_for_strings(values) -> str:
-    """
-    Check if we can use string hashtable instead of object hashtable.
+    """Check if we can use string hashtable instead of object hashtable.
 
     Parameters
     ----------
     values : ndarray
+        
     ndtype : str
-
-    Returns
-    -------
-    str
+        
+
+    Returns
+    -------
+
+    
     """
     ndtype = values.dtype.name
     if ndtype == "object":
@@ -299,80 +344,84 @@
 
 
 def unique(values):
-    """
-    Hash table-based unique. Uniques are returned in order
+    """Hash table-based unique. Uniques are returned in order
     of appearance. This does NOT sort.
-
+    
     Significantly faster than numpy.unique. Includes NA values.
 
     Parameters
     ----------
     values : 1d array-like
+        
 
     Returns
     -------
     numpy.ndarray or ExtensionArray
-
         The return can be:
-
         * Index : when the input is an Index
         * Categorical : when the input is a Categorical dtype
         * ndarray : when the input is a Series/ndarray
-
         Return numpy.ndarray or ExtensionArray.
 
     See Also
     --------
     Index.unique : Return unique values from an Index.
     Series.unique : Return unique values of Series object.
-
     Examples
     --------
+    
+    
+    
+    
+    
+    
+    An unordered Categorical will return categories in the
+    order of appearance.
+    
+    
+    
+    An ordered Categorical preserves the category ordering.
+    
+    
+    An array of tuples
     >>> pd.unique(pd.Series([2, 1, 3, 3]))
     array([2, 1, 3])
-
+    
     >>> pd.unique(pd.Series([2] + [1] * 5))
     array([2, 1])
-
+    
     >>> pd.unique(pd.Series([pd.Timestamp('20160101'),
     ...                     pd.Timestamp('20160101')]))
     array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]')
-
+    
     >>> pd.unique(pd.Series([pd.Timestamp('20160101', tz='US/Eastern'),
     ...                      pd.Timestamp('20160101', tz='US/Eastern')]))
     array([Timestamp('2016-01-01 00:00:00-0500', tz='US/Eastern')],
           dtype=object)
-
+    
     >>> pd.unique(pd.Index([pd.Timestamp('20160101', tz='US/Eastern'),
     ...                     pd.Timestamp('20160101', tz='US/Eastern')]))
     DatetimeIndex(['2016-01-01 00:00:00-05:00'],
     ...           dtype='datetime64[ns, US/Eastern]', freq=None)
-
+    
     >>> pd.unique(list('baabc'))
     array(['b', 'a', 'c'], dtype=object)
-
-    An unordered Categorical will return categories in the
-    order of appearance.
-
+    
     >>> pd.unique(pd.Series(pd.Categorical(list('baabc'))))
     [b, a, c]
     Categories (3, object): [b, a, c]
-
+    
     >>> pd.unique(pd.Series(pd.Categorical(list('baabc'),
     ...                                    categories=list('abc'))))
     [b, a, c]
     Categories (3, object): [b, a, c]
-
-    An ordered Categorical preserves the category ordering.
-
+    
     >>> pd.unique(pd.Series(pd.Categorical(list('baabc'),
     ...                                    categories=list('abc'),
     ...                                    ordered=True)))
     [b, a, c]
     Categories (3, object): [a < b < c]
-
-    An array of tuples
-
+    
     >>> pd.unique([('a', 'b'), ('b', 'a'), ('a', 'c'), ('b', 'a')])
     array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)
     """
@@ -395,18 +444,23 @@
 
 
 def isin(comps: AnyArrayLike, values: AnyArrayLike) -> np.ndarray:
-    """
-    Compute the isin boolean array.
+    """Compute the isin boolean array.
 
     Parameters
     ----------
     comps : array-like
+        
     values : array-like
-
-    Returns
-    -------
-    ndarray[bool]
-        Same length as `comps`.
+        
+    comps: AnyArrayLike :
+        
+    values: AnyArrayLike :
+        
+
+    Returns
+    -------
+
+    
     """
     if not is_list_like(comps):
         raise TypeError(
@@ -468,31 +522,34 @@
 def _factorize_array(
     values, na_sentinel: int = -1, size_hint=None, na_value=None, mask=None,
 ) -> Tuple[np.ndarray, np.ndarray]:
-    """
-    Factorize an array-like to codes and uniques.
-
+    """Factorize an array-like to codes and uniques.
+    
     This doesn't do any coercion of types or unboxing before factorization.
 
     Parameters
     ----------
     values : ndarray
+        
     na_sentinel : int, default -1
+        
     size_hint : int, optional
-        Passed through to the hashtable's 'get_labels' method
+        Passed through to the hashtable's 'get_labels' method (Default value = None)
     na_value : object, optional
         A value in `values` to consider missing. Note: only use this
         parameter when you know that you don't have any values pandas would
         consider missing in the array (NaN for float data, iNaT for
-        datetimes, etc.).
+        datetimes, etc.). (Default value = None)
     mask : ndarray[bool], optional
         If not None, the mask is used as indicator for missing values
         (True = missing, False = valid) instead of `na_value` or
-        condition "val != val".
-
-    Returns
-    -------
-    codes : ndarray
-    uniques : ndarray
+        condition "val != val". (Default value = None)
+    na_sentinel: int :
+         (Default value = -1)
+
+    Returns
+    -------
+
+    
     """
     hash_klass, values = _get_data_algo(values)
 
@@ -533,9 +590,8 @@
     na_sentinel: Optional[int] = -1,
     size_hint: Optional[int] = None,
 ) -> Tuple[np.ndarray, Union[np.ndarray, ABCIndex]]:
-    """
-    Encode the object as an enumerated type or categorical variable.
-
+    """Encode the object as an enumerated type or categorical variable.
+    
     This method is useful for obtaining a numeric representation of an
     array when all that matters is identifying distinct values. `factorize`
     is available as both a top-level function :func:`pandas.factorize`,
@@ -543,13 +599,22 @@
 
     Parameters
     ----------
-    {values}{sort}
+    {values}{sort} :
+        
     na_sentinel : int or None, default -1
         Value to mark "not found". If None, will not drop the NaN
         from the uniques of the values.
-
         .. versionchanged:: 1.1.2
-    {size_hint}\
+    {size_hint}\ :
+        
+    values :
+        
+    sort: bool :
+         (Default value = False)
+    na_sentinel: Optional[int] :
+         (Default value = -1)
+    size_hint: Optional[int] :
+         (Default value = None)
 
     Returns
     -------
@@ -560,52 +625,62 @@
         The unique valid values. When `values` is Categorical, `uniques`
         is a Categorical. When `values` is some other pandas object, an
         `Index` is returned. Otherwise, a 1-D ndarray is returned.
-
         .. note ::
-
-           Even if there's a missing value in `values`, `uniques` will
-           *not* contain an entry for it.
+        Even if there's a missing value in `values`, `uniques` will
+        *not* contain an entry for it.
 
     See Also
     --------
     cut : Discretize continuous-valued array.
     unique : Find the unique value in an array.
-
     Examples
     --------
     These examples all show factorize as a top-level method like
     ``pd.factorize(values)``. The results are identical for methods like
     :meth:`Series.factorize`.
-
+    
+    
+    With ``sort=True``, the `uniques` will be sorted, and `codes` will be
+    shuffled so that the relationship is the maintained.
+    
+    
+    Missing values are indicated in `codes` with `na_sentinel`
+    (``-1`` by default). Note that missing values are never
+    included in `uniques`.
+    
+    
+    Thus far, we've only factorized lists (which are internally coerced to
+    NumPy arrays). When factorizing pandas objects, the type of `uniques`
+    will differ. For Categoricals, a `Categorical` is returned.
+    
+    
+    Notice that ``'b'`` is in ``uniques.categories``, despite not being
+    present in ``cat.values``.
+    
+    For all other pandas objects, an Index of the appropriate type is
+    returned.
+    
+    
+    If NaN is in the values, and we want to include NaN in the uniques of the
+    values, it can be achieved by setting ``na_sentinel=None``.
     >>> codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'])
     >>> codes
     array([0, 0, 1, 2, 0]...)
     >>> uniques
     array(['b', 'a', 'c'], dtype=object)
-
-    With ``sort=True``, the `uniques` will be sorted, and `codes` will be
-    shuffled so that the relationship is the maintained.
-
+    
     >>> codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'], sort=True)
     >>> codes
     array([1, 1, 0, 2, 1]...)
     >>> uniques
     array(['a', 'b', 'c'], dtype=object)
-
-    Missing values are indicated in `codes` with `na_sentinel`
-    (``-1`` by default). Note that missing values are never
-    included in `uniques`.
-
+    
     >>> codes, uniques = pd.factorize(['b', None, 'a', 'c', 'b'])
     >>> codes
     array([ 0, -1,  1,  2,  0]...)
     >>> uniques
     array(['b', 'a', 'c'], dtype=object)
-
-    Thus far, we've only factorized lists (which are internally coerced to
-    NumPy arrays). When factorizing pandas objects, the type of `uniques`
-    will differ. For Categoricals, a `Categorical` is returned.
-
+    
     >>> cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])
     >>> codes, uniques = pd.factorize(cat)
     >>> codes
@@ -613,30 +688,21 @@
     >>> uniques
     ['a', 'c']
     Categories (3, object): ['a', 'b', 'c']
-
-    Notice that ``'b'`` is in ``uniques.categories``, despite not being
-    present in ``cat.values``.
-
-    For all other pandas objects, an Index of the appropriate type is
-    returned.
-
+    
     >>> cat = pd.Series(['a', 'a', 'c'])
     >>> codes, uniques = pd.factorize(cat)
     >>> codes
     array([0, 0, 1]...)
     >>> uniques
     Index(['a', 'c'], dtype='object')
-
-    If NaN is in the values, and we want to include NaN in the uniques of the
-    values, it can be achieved by setting ``na_sentinel=None``.
-
+    
     >>> values = np.array([1, 2, 1, np.nan])
     >>> codes, uniques = pd.factorize(values)  # default: na_sentinel=-1
     >>> codes
     array([ 0,  1,  0, -1])
     >>> uniques
     array([1., 2.])
-
+    
     >>> codes, uniques = pd.factorize(values, na_sentinel=None)
     >>> codes
     array([0, 1, 0, 2])
@@ -712,27 +778,36 @@
     bins=None,
     dropna: bool = True,
 ) -> "Series":
-    """
-    Compute a histogram of the counts of non-null values.
+    """Compute a histogram of the counts of non-null values.
 
     Parameters
     ----------
     values : ndarray (1-d)
+        
     sort : bool, default True
         Sort by values
     ascending : bool, default False
         Sort in ascending order
-    normalize: bool, default False
+    normalize : bool, default False
         If True then compute a relative histogram
     bins : integer, optional
         Rather than count values, group them into half-open bins,
-        convenience for pd.cut, only works with numeric data
+        convenience for pd.cut, only works with numeric data (Default value = None)
     dropna : bool, default True
         Don't include counts of NaN
-
-    Returns
-    -------
-    Series
+    sort: bool :
+         (Default value = True)
+    ascending: bool :
+         (Default value = False)
+    normalize: bool :
+         (Default value = False)
+    dropna: bool :
+         (Default value = True)
+
+    Returns
+    -------
+
+    
     """
     from pandas.core.series import Series
 
@@ -786,15 +861,20 @@
 # Called once from SparseArray
 def _value_counts_arraylike(values, dropna: bool):
     """
+
     Parameters
     ----------
     values : arraylike
+        
     dropna : bool
-
-    Returns
-    -------
-    uniques : np.ndarray or ExtensionArray
-    counts : np.ndarray
+        
+    dropna: bool :
+        
+
+    Returns
+    -------
+
+    
     """
     values = _ensure_arraylike(values)
     original = values
@@ -829,8 +909,7 @@
 
 
 def duplicated(values, keep="first") -> np.ndarray:
-    """
-    Return boolean ndarray denoting duplicate values.
+    """Return boolean ndarray denoting duplicate values.
 
     Parameters
     ----------
@@ -838,14 +917,15 @@
         Array over which to check for duplicate values.
     keep : {'first', 'last', False}, default 'first'
         - ``first`` : Mark duplicates as ``True`` except for the first
-          occurrence.
+        occurrence.
         - ``last`` : Mark duplicates as ``True`` except for the last
-          occurrence.
-        - False : Mark all duplicates as ``True``.
-
-    Returns
-    -------
-    duplicated : ndarray
+        occurrence.
+        - False : Mark all duplicates as ``True``. (Default value = "first")
+
+    Returns
+    -------
+
+    
     """
     values, _ = _ensure_data(values)
     ndtype = values.dtype.name
@@ -854,8 +934,7 @@
 
 
 def mode(values, dropna: bool = True) -> "Series":
-    """
-    Returns the mode(s) of an array.
+    """Returns the mode(s) of an array.
 
     Parameters
     ----------
@@ -863,12 +942,14 @@
         Array over which to check for duplicate values.
     dropna : boolean, default True
         Don't consider counts of NaN/NaT.
-
         .. versionadded:: 0.24.0
-
-    Returns
-    -------
-    mode : Series
+    dropna: bool :
+         (Default value = True)
+
+    Returns
+    -------
+
+    
     """
     from pandas import Series
 
@@ -908,28 +989,27 @@
     ascending: bool = True,
     pct: bool = False,
 ):
-    """
-    Rank the values along a given axis.
-
-    Parameters
-    ----------
-    values : array-like
-        Array whose values will be ranked. The number of dimensions in this
-        array must not exceed 2.
-    axis : int, default 0
-        Axis over which to perform rankings.
-    method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'
-        The method by which tiebreaks are broken during the ranking.
-    na_option : {'keep', 'top'}, default 'keep'
-        The method by which NaNs are placed in the ranking.
-        - ``keep``: rank each NaN value with a NaN ranking
-        - ``top``: replace each NaN with either +/- inf so that they
-                   there are ranked at the top
-    ascending : boolean, default True
-        Whether or not the elements should be ranked in ascending order.
-    pct : boolean, default False
-        Whether or not to the display the returned rankings in integer form
-        (e.g. 1, 2, 3) or in percentile form (e.g. 0.333..., 0.666..., 1).
+    """Rank the values along a given axis.
+
+    Parameters
+    ----------
+    values :
+        
+    axis: int :
+         (Default value = 0)
+    method: str :
+         (Default value = "average")
+    na_option: str :
+         (Default value = "keep")
+    ascending: bool :
+         (Default value = True)
+    pct: bool :
+         (Default value = False)
+
+    Returns
+    -------
+
+    
     """
     if values.ndim == 1:
         values = _get_values_for_rank(values)
@@ -957,9 +1037,8 @@
 
 
 def checked_add_with_arr(arr, b, arr_mask=None, b_mask=None):
-    """
-    Perform array addition that checks for underflow and overflow.
-
+    """Perform array addition that checks for underflow and overflow.
+    
     Performs the addition of an int64 array and an int64 integer (or array)
     but checks that they do not result in overflow first. For elements that
     are indicated to be NaN, whether or not there is overflow for that element
@@ -968,21 +1047,21 @@
     Parameters
     ----------
     arr : array addend.
+        
     b : array or scalar addend.
+        
     arr_mask : boolean array or None
-        array indicating which elements to exclude from checking
+        array indicating which elements to exclude from checking (Default value = None)
     b_mask : boolean array or boolean or None
-        array or scalar indicating which element(s) to exclude from checking
+        array or scalar indicating which element(s) to exclude from checking (Default value = None)
 
     Returns
     -------
     sum : An array for elements x + b for each element x in arr if b is
-          a scalar or an array for elements x + y for each element pair
-          (x, y) in (arr, b).
-
-    Raises
-    ------
-    OverflowError if any x + y exceeds the maximum or minimum int64 value.
+        a scalar or an array for elements x + y for each element pair
+        (x, y) in (arr, b).
+
+    
     """
     # For performance reasons, we broadcast 'b' to the new array 'b2'
     # so that it has the same size as 'arr'.
@@ -1033,10 +1112,9 @@
 
 
 def quantile(x, q, interpolation_method="fraction"):
-    """
-    Compute sample quantile or quantiles of the input array. For example, q=0.5
+    """Compute sample quantile or quantiles of the input array. For example, q=0.5
     computes the median.
-
+    
     The `interpolation_method` parameter supports three values, namely
     `fraction` (default), `lower` and `higher`. Interpolation is done only,
     if the desired quantile lies between two data points `i` and `j`. For
@@ -1052,11 +1130,10 @@
     interpolation_method : {'fraction', 'lower', 'higher'}, optional
         This optional parameter specifies the interpolation method to use,
         when the desired quantile lies between two data points `i` and `j`:
-
         - fraction: `i + (j - i)*fraction`, where `fraction` is the
-                    fractional part of the index surrounded by `i` and `j`.
+        fractional part of the index surrounded by `i` and `j`.
         -lower: `i`.
-        - higher: `j`.
+        - higher: `j`. (Default value = "fraction")
 
     Returns
     -------
@@ -1069,7 +1146,6 @@
     >>> a = np.arange(100)
     >>> stats.scoreatpercentile(a, 50)
     49.5
-
     """
     x = np.asarray(x)
     mask = isna(x)
@@ -1079,13 +1155,36 @@
     values = np.sort(x)
 
     def _interpolate(a, b, fraction):
-        """
-        Returns the point at the given fraction between a and b, where
+        """Returns the point at the given fraction between a and b, where
         'fraction' must be between 0 and 1.
+
+        Parameters
+        ----------
+        a :
+            
+        b :
+            
+        fraction :
+            
+
+        Returns
+        -------
+
         """
         return a + (b - a) * fraction
 
     def _get_score(at):
+        """
+
+        Parameters
+        ----------
+        at :
+            
+
+        Returns
+        -------
+
+        """
         if len(values) == 0:
             return np.nan
 
@@ -1122,6 +1221,7 @@
 
 
 class SelectN:
+    """ """
     def __init__(self, obj, n: int, keep: str):
         self.obj = obj
         self.n = n
@@ -1131,16 +1231,26 @@
             raise ValueError('keep must be either "first", "last" or "all"')
 
     def nlargest(self):
+        """ """
         return self.compute("nlargest")
 
     def nsmallest(self):
+        """ """
         return self.compute("nsmallest")
 
     @staticmethod
     def is_valid_dtype_n_method(dtype: DtypeObj) -> bool:
-        """
-        Helper function to determine if dtype is valid for
+        """Helper function to determine if dtype is valid for
         nsmallest/nlargest methods
+
+        Parameters
+        ----------
+        dtype: DtypeObj :
+            
+
+        Returns
+        -------
+
         """
         return (
             is_numeric_dtype(dtype) and not is_complex_dtype(dtype)
@@ -1148,21 +1258,35 @@
 
 
 class SelectNSeries(SelectN):
-    """
-    Implement n largest/smallest for Series
+    """Implement n largest/smallest for Series
 
     Parameters
     ----------
     obj : Series
+        
     n : int
+        
     keep : {'first', 'last'}, default 'first'
-
-    Returns
-    -------
-    nordered : Series
+        
+
+    Returns
+    -------
+
+    
     """
 
     def compute(self, method):
+        """
+
+        Parameters
+        ----------
+        method :
+            
+
+        Returns
+        -------
+
+        """
 
         n = self.n
         dtype = self.obj.dtype
@@ -1214,19 +1338,23 @@
 
 
 class SelectNFrame(SelectN):
-    """
-    Implement n largest/smallest for DataFrame
+    """Implement n largest/smallest for DataFrame
 
     Parameters
     ----------
     obj : DataFrame
+        
     n : int
+        
     keep : {'first', 'last'}, default 'first'
+        
     columns : list or str
-
-    Returns
-    -------
-    nordered : DataFrame
+        
+
+    Returns
+    -------
+
+    
     """
 
     def __init__(self, obj, n: int, keep: str, columns):
@@ -1237,6 +1365,17 @@
         self.columns = columns
 
     def compute(self, method):
+        """
+
+        Parameters
+        ----------
+        method :
+            
+
+        Returns
+        -------
+
+        """
 
         from pandas import Int64Index
 
@@ -1253,9 +1392,19 @@
                 )
 
         def get_indexer(current_indexer, other_indexer):
-            """
-            Helper function to concat `current_indexer` and `other_indexer`
+            """Helper function to concat `current_indexer` and `other_indexer`
             depending on `method`
+
+            Parameters
+            ----------
+            current_indexer :
+                
+            other_indexer :
+                
+
+            Returns
+            -------
+
             """
             if method == "nsmallest":
                 return current_indexer.append(other_indexer)
@@ -1324,7 +1473,41 @@
 
 
 def _view_wrapper(f, arr_dtype=None, out_dtype=None, fill_wrap=None):
+    """
+
+    Parameters
+    ----------
+    f :
+        
+    arr_dtype :
+         (Default value = None)
+    out_dtype :
+         (Default value = None)
+    fill_wrap :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     def wrapper(arr, indexer, out, fill_value=np.nan):
+        """
+
+        Parameters
+        ----------
+        arr :
+            
+        indexer :
+            
+        out :
+            
+        fill_value :
+             (Default value = np.nan)
+
+        Returns
+        -------
+
+        """
         if arr_dtype is not None:
             arr = arr.view(arr_dtype)
         if out_dtype is not None:
@@ -1337,7 +1520,37 @@
 
 
 def _convert_wrapper(f, conv_dtype):
+    """
+
+    Parameters
+    ----------
+    f :
+        
+    conv_dtype :
+        
+
+    Returns
+    -------
+
+    """
     def wrapper(arr, indexer, out, fill_value=np.nan):
+        """
+
+        Parameters
+        ----------
+        arr :
+            
+        indexer :
+            
+        out :
+            
+        fill_value :
+             (Default value = np.nan)
+
+        Returns
+        -------
+
+        """
         arr = arr.astype(conv_dtype)
         f(arr, indexer, out, fill_value=fill_value)
 
@@ -1345,6 +1558,25 @@
 
 
 def _take_2d_multi_object(arr, indexer, out, fill_value, mask_info):
+    """
+
+    Parameters
+    ----------
+    arr :
+        
+    indexer :
+        
+    out :
+        
+    fill_value :
+        
+    mask_info :
+        
+
+    Returns
+    -------
+
+    """
     # this is not ideal, performance-wise, but it's better than raising
     # an exception (best to optimize in Cython to avoid getting here)
     row_idx, col_idx = indexer
@@ -1368,6 +1600,27 @@
 
 
 def _take_nd_object(arr, indexer, out, axis: int, fill_value, mask_info):
+    """
+
+    Parameters
+    ----------
+    arr :
+        
+    indexer :
+        
+    out :
+        
+    axis: int :
+        
+    fill_value :
+        
+    mask_info :
+        
+
+    Returns
+    -------
+
+    """
     if mask_info is not None:
         mask, needs_masking = mask_info
     else:
@@ -1487,6 +1740,25 @@
 def _get_take_nd_function(
     ndim: int, arr_dtype, out_dtype, axis: int = 0, mask_info=None
 ):
+    """
+
+    Parameters
+    ----------
+    ndim: int :
+        
+    arr_dtype :
+        
+    out_dtype :
+        
+    axis: int :
+         (Default value = 0)
+    mask_info :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     if ndim <= 2:
         tup = (arr_dtype.name, out_dtype.name)
         if ndim == 1:
@@ -1512,6 +1784,23 @@
             return func
 
     def func2(arr, indexer, out, fill_value=np.nan):
+        """
+
+        Parameters
+        ----------
+        arr :
+            
+        indexer :
+            
+        out :
+            
+        fill_value :
+             (Default value = np.nan)
+
+        Returns
+        -------
+
+        """
         indexer = ensure_int64(indexer)
         _take_nd_object(
             arr, indexer, out, axis=axis, fill_value=fill_value, mask_info=mask_info
@@ -1521,9 +1810,8 @@
 
 
 def take(arr, indices, axis: int = 0, allow_fill: bool = False, fill_value=None):
-    """
-    Take elements from an array.
-
+    """Take elements from an array.
+    
     .. versionadded:: 0.23.0
 
     Parameters
@@ -1537,21 +1825,21 @@
         The axis over which to select values.
     allow_fill : bool, default False
         How to handle negative values in `indices`.
-
         * False: negative values in `indices` indicate positional indices
-          from the right (the default). This is similar to :func:`numpy.take`.
-
+        from the right (the default). This is similar to :func:`numpy.take`.
         * True: negative values in `indices` indicate
-          missing values. These values are set to `fill_value`. Any other
-          other negative values raise a ``ValueError``.
-
+        missing values. These values are set to `fill_value`. Any other
+        other negative values raise a ``ValueError``.
     fill_value : any, optional
         Fill value to use for NA-indices when `allow_fill` is True.
         This may be ``None``, in which case the default NA value for
         the type (``self.dtype.na_value``) is used.
-
         For multi-dimensional `arr`, each *element* is filled with
         `fill_value`.
+    axis: int :
+         (Default value = 0)
+    allow_fill: bool :
+         (Default value = False)
 
     Returns
     -------
@@ -1570,28 +1858,27 @@
     -----
     When `allow_fill` is False, `indices` may be whatever dimensionality
     is accepted by NumPy for `arr`.
-
+    
     When `allow_fill` is True, `indices` should be 1-D.
-
     See Also
     --------
     numpy.take : Take elements from an array along an axis.
-
     Examples
     --------
-    >>> from pandas.api.extensions import take
-
+    
     With the default ``allow_fill=False``, negative numbers indicate
     positional indices from the right.
-
+    
+    
+    Setting ``allow_fill=True`` will place `fill_value` in those positions.
+    >>> from pandas.api.extensions import take
+    
     >>> take(np.array([10, 20, 30]), [0, 0, -1])
     array([10, 10, 30])
-
-    Setting ``allow_fill=True`` will place `fill_value` in those positions.
-
+    
     >>> take(np.array([10, 20, 30]), [0, 0, -1], allow_fill=True)
     array([10., 10., nan])
-
+    
     >>> take(np.array([10, 20, 30]), [0, 0, -1], allow_fill=True,
     ...      fill_value=-10)
     array([ 10,  10, -10])
@@ -1616,9 +1903,8 @@
 def take_nd(
     arr, indexer, axis: int = 0, out=None, fill_value=np.nan, allow_fill: bool = True
 ):
-    """
-    Specialized Cython take which sets NaN values in one pass
-
+    """Specialized Cython take which sets NaN values in one pass
+    
     This dispatches to ``take`` defined on ExtensionArrays. It does not
     currently dispatch to ``SparseArray.take`` for sparse ``arr``.
 
@@ -1634,18 +1920,22 @@
     out : ndarray or None, default None
         Optional output array, must be appropriate type to hold input and
         fill_value together, if indexer has any -1 value entries; call
-        maybe_promote to determine this type for any fill_value
+        maybe_promote to determine this type for any fill_value (Default value = None)
     fill_value : any, default np.nan
-        Fill value to replace -1 values with
+        Fill value to replace -1 values with (Default value = np.nan)
     allow_fill : boolean, default True
         If False, indexer is assumed to contain no -1 values so no filling
         will be done.  This short-circuits computation of a mask.  Result is
         undefined if allow_fill == False and -1 is present in indexer.
-
-    Returns
-    -------
-    subarray : array-like
-        May be the same type as the input, or cast to an ndarray.
+    axis: int :
+         (Default value = 0)
+    allow_fill: bool :
+         (Default value = True)
+
+    Returns
+    -------
+
+    
     """
     mask_info = None
 
@@ -1721,8 +2011,20 @@
 
 
 def take_2d_multi(arr, indexer, fill_value=np.nan):
-    """
-    Specialized Cython take which sets NaN values in one pass.
+    """Specialized Cython take which sets NaN values in one pass.
+
+    Parameters
+    ----------
+    arr :
+        
+    indexer :
+        
+    fill_value :
+         (Default value = np.nan)
+
+    Returns
+    -------
+
     """
     # This is only called from one place in DataFrame._reindex_multi,
     #  so we know indexer is well-behaved.
@@ -1767,6 +2069,23 @@
     if func is None:
 
         def func(arr, indexer, out, fill_value=np.nan):
+            """
+
+            Parameters
+            ----------
+            arr :
+                
+            indexer :
+                
+            out :
+                
+            fill_value :
+                 (Default value = np.nan)
+
+            Returns
+            -------
+
+            """
             _take_2d_multi_object(
                 arr, indexer, out, fill_value=fill_value, mask_info=mask_info
             )
@@ -1781,17 +2100,16 @@
 
 
 def searchsorted(arr, value, side="left", sorter=None):
-    """
-    Find indices where elements should be inserted to maintain order.
-
+    """Find indices where elements should be inserted to maintain order.
+    
     .. versionadded:: 0.25.0
-
+    
     Find the indices into a sorted array `arr` (a) such that, if the
     corresponding elements in `value` were inserted before the indices,
     the order of `arr` would be preserved.
-
+    
     Assuming that `arr` is sorted:
-
+    
     ======  ================================
     `side`  returned index `i` satisfies
     ======  ================================
@@ -1801,7 +2119,7 @@
 
     Parameters
     ----------
-    arr: array-like
+    arr : array-like
         Input array. If `sorter` is None, then it must be sorted in
         ascending order, otherwise `sorter` must be an array of indices
         that sort it.
@@ -1810,10 +2128,10 @@
     side : {'left', 'right'}, optional
         If 'left', the index of the first suitable location found is given.
         If 'right', return the last such index.  If there is no suitable
-        index, return either 0 or N (where N is the length of `self`).
+        index, return either 0 or N (where N is the length of `self`). (Default value = "left")
     sorter : 1-D array_like, optional
         Optional array of integer indices that sort array a into ascending
-        order. They are typically the result of argsort.
+        order. They are typically the result of argsort. (Default value = None)
 
     Returns
     -------
@@ -1871,23 +2189,28 @@
 
 
 def diff(arr, n: int, axis: int = 0, stacklevel=3):
-    """
-    difference of n between self,
+    """difference of n between self,
     analogous to s-s.shift(n)
 
     Parameters
     ----------
     arr : ndarray
+        
     n : int
         number of periods
     axis : int
         axis to shift on
     stacklevel : int
-        The stacklevel for the lost dtype warning.
-
-    Returns
-    -------
-    shifted
+        The stacklevel for the lost dtype warning. (Default value = 3)
+    n: int :
+        
+    axis: int :
+         (Default value = 0)
+
+    Returns
+    -------
+
+    
     """
     from pandas.core.arrays import PandasDtype
 
@@ -1995,9 +2318,8 @@
     assume_unique: bool = False,
     verify: bool = True,
 ) -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:
-    """
-    Sort ``values`` and reorder corresponding ``codes``.
-
+    """Sort ``values`` and reorder corresponding ``codes``.
+    
     ``values`` should be unique if ``codes`` is not None.
     Safe for use with mixed types (int, str), orders ints before strs.
 
@@ -2007,7 +2329,7 @@
         Sequence; must be unique if ``codes`` is not None.
     codes : list_like, optional
         Indices to ``values``. All out of bound indices are treated as
-        "not found" and will be masked with ``na_sentinel``.
+        "not found" and will be masked with ``na_sentinel``. (Default value = None)
     na_sentinel : int, default -1
         Value in ``codes`` to mark "not found".
         Ignored when ``codes`` is None.
@@ -2018,8 +2340,13 @@
         Check if codes are out of bound for the values and put out of bound
         codes equal to na_sentinel. If ``verify=False``, it is assumed there
         are no out of bound codes. Ignored when ``codes`` is None.
-
         .. versionadded:: 0.25.0
+    na_sentinel: int :
+         (Default value = -1)
+    assume_unique: bool :
+         (Default value = False)
+    verify: bool :
+         (Default value = True)
 
     Returns
     -------
@@ -2028,14 +2355,7 @@
     new_codes : ndarray
         Reordered ``codes``; returned when ``codes`` is not None.
 
-    Raises
-    ------
-    TypeError
-        * If ``values`` is not list-like or if ``codes`` is neither None
-        nor list-like
-        * If ``values`` cannot be sorted
-    ValueError
-        * If ``codes`` is not None and ``values`` contain duplicates.
+    
     """
     if not is_list_like(values):
         raise TypeError(
@@ -2048,6 +2368,17 @@
         values = np.asarray(values, dtype=dtype)
 
     def sort_mixed(values):
+        """
+
+        Parameters
+        ----------
+        values :
+            
+
+        Returns
+        -------
+
+        """
         # order ints before strings, safe in py3
         str_pos = np.array([isinstance(x, str) for x in values], dtype=bool)
         nums = np.sort(values[~str_pos])
