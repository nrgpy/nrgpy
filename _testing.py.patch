# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/_testing.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/_testing.py
@@ -112,6 +112,7 @@
 
 
 def set_testing_mode():
+    """ """
     # set the testing mode filters
     testing_mode = os.environ.get("PANDAS_TESTING_MODE", "None")
     if "deprecate" in testing_mode:
@@ -119,6 +120,7 @@
 
 
 def reset_testing_mode():
+    """ """
     # reset the testing mode filters
     testing_mode = os.environ.get("PANDAS_TESTING_MODE", "None")
     if "deprecate" in testing_mode:
@@ -129,17 +131,14 @@
 
 
 def reset_display_options():
-    """
-    Reset the display options for printing and representing objects.
-    """
+    """Reset the display options for printing and representing objects."""
     pd.reset_option("^display.", silent=True)
 
 
 def round_trip_pickle(
     obj: Any, path: Optional[FilePathOrBuffer] = None
 ) -> FrameOrSeries:
-    """
-    Pickle an object and then read it again.
+    """Pickle an object and then read it again.
 
     Parameters
     ----------
@@ -147,11 +146,15 @@
         The object to pickle and then re-read.
     path : str, path object or file-like object, default None
         The path where the pickled object is written and then read.
-
-    Returns
-    -------
-    pandas object
-        The original object that was pickled and then re-read.
+    obj: Any :
+        
+    path: Optional[FilePathOrBuffer] :
+         (Default value = None)
+
+    Returns
+    -------
+
+    
     """
     _path = path
     if _path is None:
@@ -162,8 +165,7 @@
 
 
 def round_trip_pathlib(writer, reader, path: Optional[str] = None):
-    """
-    Write an object to file specified by a pathlib.Path and read it back
+    """Write an object to file specified by a pathlib.Path and read it back
 
     Parameters
     ----------
@@ -173,11 +175,13 @@
         IO reading function (e.g. pd.read_csv )
     path : str, default None
         The path where the object is written and then read.
-
-    Returns
-    -------
-    pandas object
-        The original object that was serialized and then re-read.
+    path: Optional[str] :
+         (Default value = None)
+
+    Returns
+    -------
+
+    
     """
     import pytest
 
@@ -191,8 +195,7 @@
 
 
 def round_trip_localpath(writer, reader, path: Optional[str] = None):
-    """
-    Write an object to file specified by a py.path LocalPath and read it back.
+    """Write an object to file specified by a py.path LocalPath and read it back.
 
     Parameters
     ----------
@@ -202,11 +205,13 @@
         IO reading function (e.g. pd.read_csv )
     path : str, default None
         The path where the object is written and then read.
-
-    Returns
-    -------
-    pandas object
-        The original object that was serialized and then re-read.
+    path: Optional[str] :
+         (Default value = None)
+
+    Returns
+    -------
+
+    
     """
     import pytest
 
@@ -221,20 +226,19 @@
 
 @contextmanager
 def decompress_file(path, compression):
-    """
-    Open a compressed file and return a file object.
+    """Open a compressed file and return a file object.
 
     Parameters
     ----------
     path : str
         The path where the file is read from.
-
     compression : {'gzip', 'bz2', 'zip', 'xz', None}
         Name of the decompression to use
 
     Returns
     -------
-    file object
+
+    
     """
     if compression is None:
         f = open(path, "rb")
@@ -263,8 +267,7 @@
 
 
 def write_to_compressed(compression, path, data, dest="test"):
-    """
-    Write data to a compressed file.
+    """Write data to a compressed file.
 
     Parameters
     ----------
@@ -275,11 +278,12 @@
     data : str
         The data to write.
     dest : str, default "test"
-        The destination file (for ZIP only)
-
-    Raises
-    ------
-    ValueError : An invalid compression value was passed in.
+        The destination file (for ZIP only) (Default value = "test")
+
+    Returns
+    -------
+
+    
     """
     if compression == "zip":
         compress_method = zipfile.ZipFile
@@ -306,13 +310,17 @@
 
 
 def _get_tol_from_less_precise(check_less_precise: Union[bool, int]) -> float:
-    """
-    Return the tolerance equivalent to the deprecated `check_less_precise`
+    """Return the tolerance equivalent to the deprecated `check_less_precise`
     parameter.
 
     Parameters
     ----------
     check_less_precise : bool or int
+        
+    check_less_precise: Union[bool :
+        
+    int] :
+        
 
     Returns
     -------
@@ -332,7 +340,6 @@
     0.5e-2
     >>> _get_tol_from_less_precise(8)
     0.5e-8
-
     """
     if isinstance(check_less_precise, bool):
         if check_less_precise:
@@ -355,42 +362,36 @@
     atol: float = 1.0e-8,
     **kwargs,
 ):
-    """
-    Check that the left and right objects are approximately equal.
-
+    """Check that the left and right objects are approximately equal.
+    
     By approximately equal, we refer to objects that are numbers or that
     contain numbers which may be equivalent to specific levels of precision.
 
     Parameters
     ----------
-    left : object
-    right : object
-    check_dtype : bool or {'equiv'}, default 'equiv'
-        Check dtype if both a and b are the same type. If 'equiv' is passed in,
-        then `RangeIndex` and `Int64Index` are also considered equivalent
-        when doing type checking.
-    check_less_precise : bool or int, default False
-        Specify comparison precision. 5 digits (False) or 3 digits (True)
-        after decimal points are compared. If int, then specify the number
-        of digits to compare.
-
-        When comparing two numbers, if the first number has magnitude less
-        than 1e-5, we compare the two numbers directly and check whether
-        they are equivalent within the specified precision. Otherwise, we
-        compare the **ratio** of the second number to the first number and
-        check whether it is equivalent to 1 within the specified precision.
-
-        .. deprecated:: 1.1.0
-           Use `rtol` and `atol` instead to define relative/absolute
-           tolerance, respectively. Similar to :func:`math.isclose`.
-    rtol : float, default 1e-5
-        Relative tolerance.
-
-        .. versionadded:: 1.1.0
-    atol : float, default 1e-8
-        Absolute tolerance.
-
-        .. versionadded:: 1.1.0
+    left :
+        
+    right :
+        
+    check_dtype: Union[bool :
+        
+    str] :
+         (Default value = "equiv")
+    check_less_precise: Union[bool :
+        
+    int] :
+         (Default value = no_default)
+    rtol: float :
+         (Default value = 1.0e-5)
+    atol: float :
+         (Default value = 1.0e-8)
+    **kwargs :
+        
+
+    Returns
+    -------
+
+    
     """
     if check_less_precise is not no_default:
         warnings.warn(
@@ -456,20 +457,23 @@
 
 
 def _check_isinstance(left, right, cls):
-    """
-    Helper method for our assert_* methods that ensures that
+    """Helper method for our assert_* methods that ensures that
     the two objects being compared have the right type before
     proceeding with the comparison.
 
     Parameters
     ----------
     left : The first object being compared.
+        
     right : The second object being compared.
+        
     cls : The class type to check against.
-
-    Raises
-    ------
-    AssertionError : Either `left` or `right` is not an instance of `cls`.
+        
+
+    Returns
+    -------
+
+    
     """
     cls_name = cls.__name__
 
@@ -484,12 +488,40 @@
 
 
 def assert_dict_equal(left, right, compare_keys: bool = True):
+    """
+
+    Parameters
+    ----------
+    left :
+        
+    right :
+        
+    compare_keys: bool :
+         (Default value = True)
+
+    Returns
+    -------
+
+    """
 
     _check_isinstance(left, right, dict)
     _testing.assert_dict_equal(left, right, compare_keys=compare_keys)
 
 
 def randbool(size=(), p: float = 0.5):
+    """
+
+    Parameters
+    ----------
+    size :
+         (Default value = ())
+    p: float :
+         (Default value = 0.5)
+
+    Returns
+    -------
+
+    """
     return rand(*size) <= p
 
 
@@ -501,8 +533,20 @@
 
 
 def rands_array(nchars, size, dtype="O"):
-    """
-    Generate an array of byte strings.
+    """Generate an array of byte strings.
+
+    Parameters
+    ----------
+    nchars :
+        
+    size :
+        
+    dtype :
+         (Default value = "O")
+
+    Returns
+    -------
+
     """
     retval = (
         np.random.choice(RANDS_CHARS, size=nchars * np.prod(size))
@@ -513,8 +557,20 @@
 
 
 def randu_array(nchars, size, dtype="O"):
-    """
-    Generate an array of unicode strings.
+    """Generate an array of unicode strings.
+
+    Parameters
+    ----------
+    nchars :
+        
+    size :
+        
+    dtype :
+         (Default value = "O")
+
+    Returns
+    -------
+
     """
     retval = (
         np.random.choice(RANDU_CHARS, size=nchars * np.prod(size))
@@ -525,16 +581,34 @@
 
 
 def rands(nchars):
-    """
-    Generate one random byte string.
-
+    """Generate one random byte string.
+    
     See `rands_array` if you want to create an array of random strings.
 
+    Parameters
+    ----------
+    nchars :
+        
+
+    Returns
+    -------
+
     """
     return "".join(np.random.choice(RANDS_CHARS, nchars))
 
 
 def close(fignum=None):
+    """
+
+    Parameters
+    ----------
+    fignum :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     from matplotlib.pyplot import close as _close, get_fignums
 
     if fignum is None:
@@ -550,23 +624,25 @@
 
 @contextmanager
 def ensure_clean(filename=None, return_filelike=False, **kwargs):
-    """
-    Gets a temporary path and agrees to remove on close.
+    """Gets a temporary path and agrees to remove on close.
 
     Parameters
     ----------
     filename : str (optional)
         if None, creates a temporary file which is then removed when out of
-        scope. if passed, creates temporary file with filename as ending.
+        scope. if passed, creates temporary file with filename as ending. (Default value = None)
     return_filelike : bool (default False)
         if True, returns a file-like which is *always* cleaned. Necessary for
-        savefig and other functions which want to append extensions.
-    **kwargs
+        savefig and other functions which want to append extensions. (Default value = False)
+    **kwargs :
         Additional keywords passed in for creating a temporary file.
         :meth:`tempFile.TemporaryFile` is used when `return_filelike` is ``True``.
         :meth:`tempfile.mkstemp` is used when `return_filelike` is ``False``.
         Note that the `filename` parameter will be passed in as the `suffix`
         argument to either function.
+
+    Returns
+    -------
 
     See Also
     --------
@@ -613,12 +689,18 @@
 
 @contextmanager
 def ensure_clean_dir():
-    """
-    Get a temporary directory path and agrees to remove on close.
-
+    """Get a temporary directory path and agrees to remove on close.
+    
     Yields
     ------
     Temporary directory path
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
     directory_name = tempfile.mkdtemp(suffix="")
     try:
@@ -632,11 +714,17 @@
 
 @contextmanager
 def ensure_safe_environment_variables():
-    """
-    Get a context manager to safely set environment variables
-
+    """Get a context manager to safely set environment variables
+    
     All changes will be undone on close, hence environment variables set
     within this contextmanager will neither persist nor change global state.
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
     saved_environ = dict(os.environ)
     try:
@@ -651,8 +739,18 @@
 
 
 def equalContents(arr1, arr2) -> bool:
-    """
-    Checks if the set of unique elements of arr1 and arr2 are equivalent.
+    """Checks if the set of unique elements of arr1 and arr2 are equivalent.
+
+    Parameters
+    ----------
+    arr1 :
+        
+    arr2 :
+        
+
+    Returns
+    -------
+
     """
     return frozenset(arr1) == frozenset(arr2)
 
@@ -669,46 +767,58 @@
     atol: float = 1.0e-8,
     obj: str = "Index",
 ) -> None:
-    """
-    Check that left and right Index are equal.
-
-    Parameters
-    ----------
-    left : Index
-    right : Index
-    exact : bool or {'equiv'}, default 'equiv'
-        Whether to check the Index class, dtype and inferred_type
-        are identical. If 'equiv', then RangeIndex can be substituted for
-        Int64Index as well.
-    check_names : bool, default True
-        Whether to check the names attribute.
-    check_less_precise : bool or int, default False
-        Specify comparison precision. Only used when check_exact is False.
-        5 digits (False) or 3 digits (True) after decimal points are compared.
-        If int, then specify the digits to compare.
-
-        .. deprecated:: 1.1.0
-           Use `rtol` and `atol` instead to define relative/absolute
-           tolerance, respectively. Similar to :func:`math.isclose`.
-    check_exact : bool, default True
-        Whether to compare number exactly.
-    check_categorical : bool, default True
-        Whether to compare internal Categorical exactly.
-    rtol : float, default 1e-5
-        Relative tolerance. Only used when check_exact is False.
-
-        .. versionadded:: 1.1.0
-    atol : float, default 1e-8
-        Absolute tolerance. Only used when check_exact is False.
-
-        .. versionadded:: 1.1.0
-    obj : str, default 'Index'
-        Specify object name being compared, internally used to show appropriate
-        assertion message.
+    """Check that left and right Index are equal.
+
+    Parameters
+    ----------
+    left: Index :
+        
+    right: Index :
+        
+    exact: Union[bool :
+        
+    str] :
+         (Default value = "equiv")
+    check_names: bool :
+         (Default value = True)
+    check_less_precise: Union[bool :
+        
+    int] :
+         (Default value = no_default)
+    check_exact: bool :
+         (Default value = True)
+    check_categorical: bool :
+         (Default value = True)
+    rtol: float :
+         (Default value = 1.0e-5)
+    atol: float :
+         (Default value = 1.0e-8)
+    obj: str :
+         (Default value = "Index")
+
+    Returns
+    -------
+
+    
     """
     __tracebackhide__ = True
 
     def _check_types(l, r, obj="Index"):
+        """
+
+        Parameters
+        ----------
+        l :
+            
+        r :
+            
+        obj :
+             (Default value = "Index")
+
+        Returns
+        -------
+
+        """
         if exact:
             assert_class_equal(l, r, exact=exact, obj=obj)
 
@@ -723,6 +833,19 @@
                 assert_attr_equal("inferred_type", l, r, obj=obj)
 
     def _get_ilevel_values(index, level):
+        """
+
+        Parameters
+        ----------
+        index :
+            
+        level :
+            
+
+        Returns
+        -------
+
+        """
         # accept level number only
         unique = index.levels[level]
         level_codes = index.codes[level]
@@ -816,12 +939,39 @@
 
 
 def assert_class_equal(left, right, exact: Union[bool, str] = True, obj="Input"):
-    """
-    Checks classes are equal.
+    """Checks classes are equal.
+
+    Parameters
+    ----------
+    left :
+        
+    right :
+        
+    exact: Union[bool :
+        
+    str] :
+         (Default value = True)
+    obj :
+         (Default value = "Input")
+
+    Returns
+    -------
+
     """
     __tracebackhide__ = True
 
     def repr_class(x):
+        """
+
+        Parameters
+        ----------
+        x :
+            
+
+        Returns
+        -------
+
+        """
         if isinstance(x, Index):
             # return Index as it is to include values in the error message
             return x
@@ -842,18 +992,23 @@
 
 
 def assert_attr_equal(attr: str, left, right, obj: str = "Attributes"):
-    """
-    Check attributes are equal. Both objects must have attribute.
-
-    Parameters
-    ----------
-    attr : str
-        Attribute name being compared.
-    left : object
-    right : object
-    obj : str, default 'Attributes'
-        Specify object name being compared, internally used to show appropriate
-        assertion message
+    """Check attributes are equal. Both objects must have attribute.
+
+    Parameters
+    ----------
+    attr: str :
+        
+    left :
+        
+    right :
+        
+    obj: str :
+         (Default value = "Attributes")
+
+    Returns
+    -------
+
+    
     """
     __tracebackhide__ = True
 
@@ -887,6 +1042,17 @@
 
 
 def assert_is_valid_plot_return_object(objs):
+    """
+
+    Parameters
+    ----------
+    objs :
+        
+
+    Returns
+    -------
+
+    """
     import matplotlib.pyplot as plt
 
     if isinstance(objs, (pd.Series, np.ndarray)):
@@ -906,7 +1072,17 @@
 
 
 def assert_is_sorted(seq):
-    """Assert that the sequence is sorted."""
+    """Assert that the sequence is sorted.
+
+    Parameters
+    ----------
+    seq :
+        
+
+    Returns
+    -------
+
+    """
     if isinstance(seq, (Index, Series)):
         seq = seq.values
     # sorting does not change precisions
@@ -916,23 +1092,25 @@
 def assert_categorical_equal(
     left, right, check_dtype=True, check_category_order=True, obj="Categorical"
 ):
-    """
-    Test that Categoricals are equivalent.
-
-    Parameters
-    ----------
-    left : Categorical
-    right : Categorical
-    check_dtype : bool, default True
-        Check that integer dtype of the codes are the same
-    check_category_order : bool, default True
-        Whether the order of the categories should be compared, which
-        implies identical integer codes.  If False, only the resulting
-        values are compared.  The ordered attribute is
-        checked regardless.
-    obj : str, default 'Categorical'
-        Specify object name being compared, internally used to show appropriate
-        assertion message
+    """Test that Categoricals are equivalent.
+
+    Parameters
+    ----------
+    left :
+        
+    right :
+        
+    check_dtype :
+         (Default value = True)
+    check_category_order :
+         (Default value = True)
+    obj :
+         (Default value = "Categorical")
+
+    Returns
+    -------
+
+    
     """
     _check_isinstance(left, right, Categorical)
 
@@ -961,20 +1139,23 @@
 
 
 def assert_interval_array_equal(left, right, exact="equiv", obj="IntervalArray"):
-    """
-    Test that two IntervalArrays are equivalent.
-
-    Parameters
-    ----------
-    left, right : IntervalArray
-        The IntervalArrays to compare.
-    exact : bool or {'equiv'}, default 'equiv'
-        Whether to check the Index class, dtype and inferred_type
-        are identical. If 'equiv', then RangeIndex can be substituted for
-        Int64Index as well.
-    obj : str, default 'IntervalArray'
-        Specify object name being compared, internally used to show appropriate
-        assertion message
+    """Test that two IntervalArrays are equivalent.
+
+    Parameters
+    ----------
+    left :
+        
+    right :
+        
+    exact :
+         (Default value = "equiv")
+    obj :
+         (Default value = "IntervalArray")
+
+    Returns
+    -------
+
+    
     """
     _check_isinstance(left, right, IntervalArray)
 
@@ -984,6 +1165,21 @@
 
 
 def assert_period_array_equal(left, right, obj="PeriodArray"):
+    """
+
+    Parameters
+    ----------
+    left :
+        
+    right :
+        
+    obj :
+         (Default value = "PeriodArray")
+
+    Returns
+    -------
+
+    """
     _check_isinstance(left, right, PeriodArray)
 
     assert_numpy_array_equal(left._data, right._data, obj=f"{obj}._data")
@@ -991,6 +1187,21 @@
 
 
 def assert_datetime_array_equal(left, right, obj="DatetimeArray"):
+    """
+
+    Parameters
+    ----------
+    left :
+        
+    right :
+        
+    obj :
+         (Default value = "DatetimeArray")
+
+    Returns
+    -------
+
+    """
     __tracebackhide__ = True
     _check_isinstance(left, right, DatetimeArray)
 
@@ -1000,6 +1211,21 @@
 
 
 def assert_timedelta_array_equal(left, right, obj="TimedeltaArray"):
+    """
+
+    Parameters
+    ----------
+    left :
+        
+    right :
+        
+    obj :
+         (Default value = "TimedeltaArray")
+
+    Returns
+    -------
+
+    """
     __tracebackhide__ = True
     _check_isinstance(left, right, TimedeltaArray)
     assert_numpy_array_equal(left._data, right._data, obj=f"{obj}._data")
@@ -1007,6 +1233,27 @@
 
 
 def raise_assert_detail(obj, message, left, right, diff=None, index_values=None):
+    """
+
+    Parameters
+    ----------
+    obj :
+        
+    message :
+        
+    left :
+        
+    right :
+        
+    diff :
+         (Default value = None)
+    index_values :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     __tracebackhide__ = True
 
     msg = f"""{obj} are different
@@ -1046,26 +1293,31 @@
     obj="numpy array",
     index_values=None,
 ):
-    """
-    Check that 'np.ndarray' is equivalent.
-
-    Parameters
-    ----------
-    left, right : numpy.ndarray or iterable
-        The two arrays to be compared.
-    strict_nan : bool, default False
-        If True, consider NaN and None to be different.
-    check_dtype : bool, default True
-        Check dtype if both a and b are np.ndarray.
-    err_msg : str, default None
-        If provided, used as assertion message.
-    check_same : None|'copy'|'same', default None
-        Ensure left and right refer/do not refer to the same memory area.
-    obj : str, default 'numpy array'
-        Specify object name being compared, internally used to show appropriate
-        assertion message.
-    index_values : numpy.ndarray, default None
-        optional index (shared by both left and right), used in output.
+    """Check that 'np.ndarray' is equivalent.
+
+    Parameters
+    ----------
+    left :
+        
+    right :
+        
+    strict_nan :
+         (Default value = False)
+    check_dtype :
+         (Default value = True)
+    err_msg :
+         (Default value = None)
+    check_same :
+         (Default value = None)
+    obj :
+         (Default value = "numpy array")
+    index_values :
+         (Default value = None)
+
+    Returns
+    -------
+
+    
     """
     __tracebackhide__ = True
 
@@ -1076,6 +1328,17 @@
     _check_isinstance(left, right, np.ndarray)
 
     def _get_base(obj):
+        """
+
+        Parameters
+        ----------
+        obj :
+            
+
+        Returns
+        -------
+
+        """
         return obj.base if getattr(obj, "base", None) is not None else obj
 
     left_base = _get_base(left)
@@ -1089,6 +1352,21 @@
             raise AssertionError(f"{repr(left_base)} is {repr(right_base)}")
 
     def _raise(left, right, err_msg):
+        """
+
+        Parameters
+        ----------
+        left :
+            
+        right :
+            
+        err_msg :
+            
+
+        Returns
+        -------
+
+        """
         if err_msg is None:
             if left.shape != right.shape:
                 raise_assert_detail(
@@ -1126,35 +1404,42 @@
     rtol: float = 1.0e-5,
     atol: float = 1.0e-8,
 ):
-    """
-    Check that left and right ExtensionArrays are equal.
+    """Check that left and right ExtensionArrays are equal.
 
     Parameters
     ----------
     left, right : ExtensionArray
         The two arrays to compare.
     check_dtype : bool, default True
-        Whether to check if the ExtensionArray dtypes are identical.
+        Whether to check if the ExtensionArray dtypes are identical. (Default value = True)
     index_values : numpy.ndarray, default None
-        Optional index (shared by both left and right), used in output.
+        Optional index (shared by both left and right), used in output. (Default value = None)
     check_less_precise : bool or int, default False
         Specify comparison precision. Only used when check_exact is False.
         5 digits (False) or 3 digits (True) after decimal points are compared.
         If int, then specify the digits to compare.
-
         .. deprecated:: 1.1.0
-           Use `rtol` and `atol` instead to define relative/absolute
-           tolerance, respectively. Similar to :func:`math.isclose`.
+        Use `rtol` and `atol` instead to define relative/absolute
+        tolerance, respectively. Similar to :func:`math.isclose`. (Default value = no_default)
     check_exact : bool, default False
-        Whether to compare number exactly.
+        Whether to compare number exactly. (Default value = False)
     rtol : float, default 1e-5
         Relative tolerance. Only used when check_exact is False.
-
         .. versionadded:: 1.1.0
     atol : float, default 1e-8
         Absolute tolerance. Only used when check_exact is False.
-
         .. versionadded:: 1.1.0
+    left :
+        
+    right :
+        
+    rtol: float :
+         (Default value = 1.0e-5)
+    atol: float :
+         (Default value = 1.0e-8)
+
+    Returns
+    -------
 
     Notes
     -----
@@ -1231,59 +1516,45 @@
     atol=1.0e-8,
     obj="Series",
 ):
-    """
-    Check that left and right Series are equal.
-
-    Parameters
-    ----------
-    left : Series
-    right : Series
-    check_dtype : bool, default True
-        Whether to check the Series dtype is identical.
-    check_index_type : bool or {'equiv'}, default 'equiv'
-        Whether to check the Index class, dtype and inferred_type
-        are identical.
-    check_series_type : bool, default True
-         Whether to check the Series class is identical.
-    check_less_precise : bool or int, default False
-        Specify comparison precision. Only used when check_exact is False.
-        5 digits (False) or 3 digits (True) after decimal points are compared.
-        If int, then specify the digits to compare.
-
-        When comparing two numbers, if the first number has magnitude less
-        than 1e-5, we compare the two numbers directly and check whether
-        they are equivalent within the specified precision. Otherwise, we
-        compare the **ratio** of the second number to the first number and
-        check whether it is equivalent to 1 within the specified precision.
-
-        .. deprecated:: 1.1.0
-           Use `rtol` and `atol` instead to define relative/absolute
-           tolerance, respectively. Similar to :func:`math.isclose`.
-    check_names : bool, default True
-        Whether to check the Series and Index names attribute.
-    check_exact : bool, default False
-        Whether to compare number exactly.
-    check_datetimelike_compat : bool, default False
-        Compare datetime-like which is comparable ignoring dtype.
-    check_categorical : bool, default True
-        Whether to compare internal Categorical exactly.
-    check_category_order : bool, default True
-        Whether to compare category order of internal Categoricals.
-
-        .. versionadded:: 1.0.2
-    check_freq : bool, default True
-        Whether to check the `freq` attribute on a DatetimeIndex or TimedeltaIndex.
-    rtol : float, default 1e-5
-        Relative tolerance. Only used when check_exact is False.
-
-        .. versionadded:: 1.1.0
-    atol : float, default 1e-8
-        Absolute tolerance. Only used when check_exact is False.
-
-        .. versionadded:: 1.1.0
-    obj : str, default 'Series'
-        Specify object name being compared, internally used to show appropriate
-        assertion message.
+    """Check that left and right Series are equal.
+
+    Parameters
+    ----------
+    left :
+        
+    right :
+        
+    check_dtype :
+         (Default value = True)
+    check_index_type :
+         (Default value = "equiv")
+    check_series_type :
+         (Default value = True)
+    check_less_precise :
+         (Default value = no_default)
+    check_names :
+         (Default value = True)
+    check_exact :
+         (Default value = False)
+    check_datetimelike_compat :
+         (Default value = False)
+    check_categorical :
+         (Default value = True)
+    check_category_order :
+         (Default value = True)
+    check_freq :
+         (Default value = True)
+    rtol :
+         (Default value = 1.0e-5)
+    atol :
+         (Default value = 1.0e-8)
+    obj :
+         (Default value = "Series")
+
+    Returns
+    -------
+
+    
     """
     __tracebackhide__ = True
 
@@ -1435,9 +1706,8 @@
     atol=1.0e-8,
     obj="DataFrame",
 ):
-    """
-    Check that left and right DataFrame are equal.
-
+    """Check that left and right DataFrame are equal.
+    
     This function is intended to compare two DataFrames and output any
     differences. Is is mostly intended for use in unit tests.
     Additional parameters allow varying the strictness of the
@@ -1450,91 +1720,91 @@
     right : DataFrame
         Second DataFrame to compare.
     check_dtype : bool, default True
-        Whether to check the DataFrame dtype is identical.
+        Whether to check the DataFrame dtype is identical. (Default value = True)
     check_index_type : bool or {'equiv'}, default 'equiv'
         Whether to check the Index class, dtype and inferred_type
-        are identical.
+        are identical. (Default value = "equiv")
     check_column_type : bool or {'equiv'}, default 'equiv'
         Whether to check the columns class, dtype and inferred_type
         are identical. Is passed as the ``exact`` argument of
-        :func:`assert_index_equal`.
+        :func:`assert_index_equal`. (Default value = "equiv")
     check_frame_type : bool, default True
-        Whether to check the DataFrame class is identical.
+        Whether to check the DataFrame class is identical. (Default value = True)
     check_less_precise : bool or int, default False
         Specify comparison precision. Only used when check_exact is False.
         5 digits (False) or 3 digits (True) after decimal points are compared.
         If int, then specify the digits to compare.
-
         When comparing two numbers, if the first number has magnitude less
         than 1e-5, we compare the two numbers directly and check whether
         they are equivalent within the specified precision. Otherwise, we
         compare the **ratio** of the second number to the first number and
         check whether it is equivalent to 1 within the specified precision.
-
         .. deprecated:: 1.1.0
-           Use `rtol` and `atol` instead to define relative/absolute
-           tolerance, respectively. Similar to :func:`math.isclose`.
+        Use `rtol` and `atol` instead to define relative/absolute
+        tolerance, respectively. Similar to :func:`math.isclose`. (Default value = no_default)
     check_names : bool, default True
         Whether to check that the `names` attribute for both the `index`
-        and `column` attributes of the DataFrame is identical.
+        and `column` attributes of the DataFrame is identical. (Default value = True)
     by_blocks : bool, default False
         Specify how to compare internal data. If False, compare by columns.
-        If True, compare by blocks.
+        If True, compare by blocks. (Default value = False)
     check_exact : bool, default False
-        Whether to compare number exactly.
+        Whether to compare number exactly. (Default value = False)
     check_datetimelike_compat : bool, default False
-        Compare datetime-like which is comparable ignoring dtype.
+        Compare datetime-like which is comparable ignoring dtype. (Default value = False)
     check_categorical : bool, default True
-        Whether to compare internal Categorical exactly.
+        Whether to compare internal Categorical exactly. (Default value = True)
     check_like : bool, default False
         If True, ignore the order of index & columns.
         Note: index labels must match their respective rows
-        (same as in columns) - same labels must be with the same data.
+        (same as in columns) - same labels must be with the same data. (Default value = False)
     check_freq : bool, default True
-        Whether to check the `freq` attribute on a DatetimeIndex or TimedeltaIndex.
+        Whether to check the `freq` attribute on a DatetimeIndex or TimedeltaIndex. (Default value = True)
     rtol : float, default 1e-5
         Relative tolerance. Only used when check_exact is False.
-
-        .. versionadded:: 1.1.0
+        .. versionadded:: 1.1.0 (Default value = 1.0e-5)
     atol : float, default 1e-8
         Absolute tolerance. Only used when check_exact is False.
-
-        .. versionadded:: 1.1.0
+        .. versionadded:: 1.1.0 (Default value = 1.0e-8)
     obj : str, default 'DataFrame'
         Specify object name being compared, internally used to show appropriate
-        assertion message.
+        assertion message. (Default value = "DataFrame")
+
+    Returns
+    -------
 
     See Also
     --------
     assert_series_equal : Equivalent method for asserting Series equality.
     DataFrame.equals : Check DataFrame equality.
-
     Examples
     --------
     This example shows comparing two DataFrames that are equal
     but with columns of differing dtypes.
-
+    
+    
+    df1 equals itself.
+    
+    
+    df1 differs from df2 as column 'b' is of a different type.
+    
+    
+    Attribute "dtype" are different
+    [left]:  int64
+    [right]: float64
+    
+    Ignore differing dtypes in columns with check_dtype.
     >>> from pandas._testing import assert_frame_equal
     >>> df1 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})
     >>> df2 = pd.DataFrame({'a': [1, 2], 'b': [3.0, 4.0]})
-
-    df1 equals itself.
-
+    
     >>> assert_frame_equal(df1, df1)
-
-    df1 differs from df2 as column 'b' is of a different type.
-
+    
     >>> assert_frame_equal(df1, df2)
     Traceback (most recent call last):
     ...
     AssertionError: Attributes of DataFrame.iloc[:, 1] (column name="b") are different
-
-    Attribute "dtype" are different
-    [left]:  int64
-    [right]: float64
-
-    Ignore differing dtypes in columns with check_dtype.
-
+    
     >>> assert_frame_equal(df1, df2, check_dtype=False)
     """
     __tracebackhide__ = True
@@ -1625,15 +1895,21 @@
 
 
 def assert_equal(left, right, **kwargs):
-    """
-    Wrapper for tm.assert_*_equal to dispatch to the appropriate test function.
-
-    Parameters
-    ----------
-    left, right : Index, Series, DataFrame, ExtensionArray, or np.ndarray
-        The two items to be compared.
-    **kwargs
-        All keyword arguments are passed through to the underlying assert method.
+    """Wrapper for tm.assert_*_equal to dispatch to the appropriate test function.
+
+    Parameters
+    ----------
+    left :
+        
+    right :
+        
+    **kwargs :
+        
+
+    Returns
+    -------
+
+    
     """
     __tracebackhide__ = True
 
@@ -1665,17 +1941,21 @@
 
 
 def box_expected(expected, box_cls, transpose=True):
-    """
-    Helper function to wrap the expected output of a test in a given box_class.
+    """Helper function to wrap the expected output of a test in a given box_class.
 
     Parameters
     ----------
     expected : np.ndarray, Index, Series
+        
     box_cls : {Index, Series, DataFrame}
-
-    Returns
-    -------
-    subclass of box_cls
+        
+    transpose :
+         (Default value = True)
+
+    Returns
+    -------
+
+    
     """
     if box_cls is pd.array:
         expected = pd.array(expected)
@@ -1707,6 +1987,17 @@
 
 
 def to_array(obj):
+    """
+
+    Parameters
+    ----------
+    obj :
+        
+
+    Returns
+    -------
+
+    """
     # temporary implementation until we get pd.array in place
     dtype = getattr(obj, "dtype", None)
 
@@ -1725,13 +2016,19 @@
 
 
 def assert_sp_array_equal(left, right):
-    """
-    Check that the left and right SparseArray are equal.
-
-    Parameters
-    ----------
-    left : SparseArray
-    right : SparseArray
+    """Check that the left and right SparseArray are equal.
+
+    Parameters
+    ----------
+    left :
+        
+    right :
+        
+
+    Returns
+    -------
+
+    
     """
     _check_isinstance(left, right, pd.arrays.SparseArray)
 
@@ -1762,18 +2059,43 @@
 
 
 def assert_contains_all(iterable, dic):
+    """
+
+    Parameters
+    ----------
+    iterable :
+        
+    dic :
+        
+
+    Returns
+    -------
+
+    """
     for k in iterable:
         assert k in dic, f"Did not contain item: {repr(k)}"
 
 
 def assert_copy(iter1, iter2, **eql_kwargs):
-    """
-    iter1, iter2: iterables that produce elements
+    """iter1, iter2: iterables that produce elements
     comparable with assert_almost_equal
-
+    
     Checks that the elements are equal, but not
     the same object. (Does not check that items
     in sequences are also not the same object)
+
+    Parameters
+    ----------
+    iter1 :
+        
+    iter2 :
+        
+    **eql_kwargs :
+        
+
+    Returns
+    -------
+
     """
     for elem1, elem2 in zip(iter1, iter2):
         assert_almost_equal(elem1, elem2, **eql_kwargs)
@@ -1785,20 +2107,73 @@
 
 
 def getCols(k):
+    """
+
+    Parameters
+    ----------
+    k :
+        
+
+    Returns
+    -------
+
+    """
     return string.ascii_uppercase[:k]
 
 
 # make index
 def makeStringIndex(k=10, name=None):
+    """
+
+    Parameters
+    ----------
+    k :
+         (Default value = 10)
+    name :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     return Index(rands_array(nchars=10, size=k), name=name)
 
 
 def makeUnicodeIndex(k=10, name=None):
+    """
+
+    Parameters
+    ----------
+    k :
+         (Default value = 10)
+    name :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     return Index(randu_array(nchars=10, size=k), name=name)
 
 
 def makeCategoricalIndex(k=10, n=3, name=None, **kwargs):
-    """ make a length k index or n categories """
+    """make a length k index or n categories
+
+    Parameters
+    ----------
+    k :
+         (Default value = 10)
+    n :
+         (Default value = 3)
+    name :
+         (Default value = None)
+    **kwargs :
+        
+
+    Returns
+    -------
+
+    """
     x = rands_array(nchars=4, size=n)
     return CategoricalIndex(
         Categorical.from_codes(np.arange(k) % n, categories=x), name=name, **kwargs
@@ -1806,12 +2181,39 @@
 
 
 def makeIntervalIndex(k=10, name=None, **kwargs):
-    """ make a length k IntervalIndex """
+    """make a length k IntervalIndex
+
+    Parameters
+    ----------
+    k :
+         (Default value = 10)
+    name :
+         (Default value = None)
+    **kwargs :
+        
+
+    Returns
+    -------
+
+    """
     x = np.linspace(0, 100, num=(k + 1))
     return IntervalIndex.from_breaks(x, name=name, **kwargs)
 
 
 def makeBoolIndex(k=10, name=None):
+    """
+
+    Parameters
+    ----------
+    k :
+         (Default value = 10)
+    name :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     if k == 1:
         return Index([True], name=name)
     elif k == 2:
@@ -1820,39 +2222,157 @@
 
 
 def makeIntIndex(k=10, name=None):
+    """
+
+    Parameters
+    ----------
+    k :
+         (Default value = 10)
+    name :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     return Index(list(range(k)), name=name)
 
 
 def makeUIntIndex(k=10, name=None):
+    """
+
+    Parameters
+    ----------
+    k :
+         (Default value = 10)
+    name :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     return Index([2 ** 63 + i for i in range(k)], name=name)
 
 
 def makeRangeIndex(k=10, name=None, **kwargs):
+    """
+
+    Parameters
+    ----------
+    k :
+         (Default value = 10)
+    name :
+         (Default value = None)
+    **kwargs :
+        
+
+    Returns
+    -------
+
+    """
     return RangeIndex(0, k, 1, name=name, **kwargs)
 
 
 def makeFloatIndex(k=10, name=None):
+    """
+
+    Parameters
+    ----------
+    k :
+         (Default value = 10)
+    name :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     values = sorted(np.random.random_sample(k)) - np.random.random_sample(1)
     return Index(values * (10 ** np.random.randint(0, 9)), name=name)
 
 
 def makeDateIndex(k=10, freq="B", name=None, **kwargs):
+    """
+
+    Parameters
+    ----------
+    k :
+         (Default value = 10)
+    freq :
+         (Default value = "B")
+    name :
+         (Default value = None)
+    **kwargs :
+        
+
+    Returns
+    -------
+
+    """
     dt = datetime(2000, 1, 1)
     dr = bdate_range(dt, periods=k, freq=freq, name=name)
     return DatetimeIndex(dr, name=name, **kwargs)
 
 
 def makeTimedeltaIndex(k=10, freq="D", name=None, **kwargs):
+    """
+
+    Parameters
+    ----------
+    k :
+         (Default value = 10)
+    freq :
+         (Default value = "D")
+    name :
+         (Default value = None)
+    **kwargs :
+        
+
+    Returns
+    -------
+
+    """
     return pd.timedelta_range(start="1 day", periods=k, freq=freq, name=name, **kwargs)
 
 
 def makePeriodIndex(k=10, name=None, **kwargs):
+    """
+
+    Parameters
+    ----------
+    k :
+         (Default value = 10)
+    name :
+         (Default value = None)
+    **kwargs :
+        
+
+    Returns
+    -------
+
+    """
     dt = datetime(2000, 1, 1)
     dr = pd.period_range(start=dt, periods=k, freq="B", name=name, **kwargs)
     return dr
 
 
 def makeMultiIndex(k=10, names=None, **kwargs):
+    """
+
+    Parameters
+    ----------
+    k :
+         (Default value = 10)
+    names :
+         (Default value = None)
+    **kwargs :
+        
+
+    Returns
+    -------
+
+    """
     return MultiIndex.from_product((("foo", "bar"), (1, 2)), names=names, **kwargs)
 
 
@@ -1887,23 +2407,24 @@
 
 
 def _make_timeseries(start="2000-01-01", end="2000-12-31", freq="1D", seed=None):
-    """
-    Make a DataFrame with a DatetimeIndex
+    """Make a DataFrame with a DatetimeIndex
 
     Parameters
     ----------
     start : str or Timestamp, default "2000-01-01"
-        The start of the index. Passed to date_range with `freq`.
+        The start of the index. Passed to date_range with `freq`. (Default value = "2000-01-01")
     end : str or Timestamp, default "2000-12-31"
-        The end of the index. Passed to date_range with `freq`.
+        The end of the index. Passed to date_range with `freq`. (Default value = "2000-12-31")
     freq : str or Freq
-        The frequency to use for the DatetimeIndex
+        The frequency to use for the DatetimeIndex (Default value = "1D")
     seed : int, optional
         The random state seed.
-
         * name : object dtype with string names
         * id : int dtype with
-        * x, y : float dtype
+        * x, y : float dtype (Default value = None)
+
+    Returns
+    -------
 
     Examples
     --------
@@ -1938,6 +2459,7 @@
 
 
 def index_subclass_makers_generator():
+    """ """
     make_index_funcs = [
         makeDateIndex,
         makePeriodIndex,
@@ -1952,13 +2474,18 @@
 
 
 def all_timeseries_index_generator(k=10):
-    """
-    Generator which can be iterated over to get instances of all the classes
+    """Generator which can be iterated over to get instances of all the classes
     which represent time-series.
 
     Parameters
     ----------
-    k: length of each of the index instances
+    k :
+         (Default value = 10)
+
+    Returns
+    -------
+
+    
     """
     make_index_funcs = [makeDateIndex, makePeriodIndex, makeTimedeltaIndex]
     for make_index_func in make_index_funcs:
@@ -1967,16 +2494,49 @@
 
 # make series
 def makeFloatSeries(name=None):
+    """
+
+    Parameters
+    ----------
+    name :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     index = makeStringIndex(_N)
     return Series(randn(_N), index=index, name=name)
 
 
 def makeStringSeries(name=None):
+    """
+
+    Parameters
+    ----------
+    name :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     index = makeStringIndex(_N)
     return Series(randn(_N), index=index, name=name)
 
 
 def makeObjectSeries(name=None):
+    """
+
+    Parameters
+    ----------
+    name :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     data = makeStringIndex(_N)
     data = Index(data, dtype=object)
     index = makeStringIndex(_N)
@@ -1984,42 +2544,110 @@
 
 
 def getSeriesData():
+    """ """
     index = makeStringIndex(_N)
     return {c: Series(randn(_N), index=index) for c in getCols(_K)}
 
 
 def makeTimeSeries(nper=None, freq="B", name=None):
+    """
+
+    Parameters
+    ----------
+    nper :
+         (Default value = None)
+    freq :
+         (Default value = "B")
+    name :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     if nper is None:
         nper = _N
     return Series(randn(nper), index=makeDateIndex(nper, freq=freq), name=name)
 
 
 def makePeriodSeries(nper=None, name=None):
+    """
+
+    Parameters
+    ----------
+    nper :
+         (Default value = None)
+    name :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     if nper is None:
         nper = _N
     return Series(randn(nper), index=makePeriodIndex(nper), name=name)
 
 
 def getTimeSeriesData(nper=None, freq="B"):
+    """
+
+    Parameters
+    ----------
+    nper :
+         (Default value = None)
+    freq :
+         (Default value = "B")
+
+    Returns
+    -------
+
+    """
     return {c: makeTimeSeries(nper, freq) for c in getCols(_K)}
 
 
 def getPeriodData(nper=None):
+    """
+
+    Parameters
+    ----------
+    nper :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     return {c: makePeriodSeries(nper) for c in getCols(_K)}
 
 
 # make frame
 def makeTimeDataFrame(nper=None, freq="B"):
+    """
+
+    Parameters
+    ----------
+    nper :
+         (Default value = None)
+    freq :
+         (Default value = "B")
+
+    Returns
+    -------
+
+    """
     data = getTimeSeriesData(nper, freq)
     return DataFrame(data)
 
 
 def makeDataFrame():
+    """ """
     data = getSeriesData()
     return DataFrame(data)
 
 
 def getMixedTypeDict():
+    """ """
     index = Index(["a", "b", "c", "d", "e"])
 
     data = {
@@ -2033,10 +2661,22 @@
 
 
 def makeMixedDataFrame():
+    """ """
     return DataFrame(getMixedTypeDict()[1])
 
 
 def makePeriodFrame(nper=None):
+    """
+
+    Parameters
+    ----------
+    nper :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     data = getPeriodData(nper)
     return DataFrame(data)
 
@@ -2044,9 +2684,8 @@
 def makeCustomIndex(
     nentries, nlevels, prefix="#", names=False, ndupe_l=None, idx_type=None
 ):
-    """
-    Create an index/multindex with given dimensions, levels, names, etc'
-
+    """Create an index/multindex with given dimensions, levels, names, etc'
+    
     nentries - number of entries in index
     nlevels - number of levels (> 1 produces multindex)
     prefix - a string prefix for labels
@@ -2063,8 +2702,27 @@
        "s"/"u" creates a string/unicode index
        "dt" create a datetime index.
        "td" create a datetime index.
-
+    
         if unspecified, string labels will be generated.
+
+    Parameters
+    ----------
+    nentries :
+        
+    nlevels :
+        
+    prefix :
+         (Default value = "#")
+    names :
+         (Default value = False)
+    ndupe_l :
+         (Default value = None)
+    idx_type :
+         (Default value = None)
+
+    Returns
+    -------
+
     """
     if ndupe_l is None:
         ndupe_l = [1] * nlevels
@@ -2117,6 +2775,17 @@
     for i in range(nlevels):
 
         def keyfunc(x):
+            """
+
+            Parameters
+            ----------
+            x :
+                
+
+            Returns
+            -------
+
+            """
             import re
 
             numeric_tuple = re.sub(r"[^\d_]_?", "", x).split("_")
@@ -2160,62 +2829,90 @@
     c_idx_type=None,
     r_idx_type=None,
 ):
-    """
-    Create a DataFrame using supplied parameters.
-
-    Parameters
-    ----------
-    nrows,  ncols - number of data rows/cols
-    c_idx_names, idx_names  - False/True/list of strings,  yields No names ,
-            default names or uses the provided names for the levels of the
-            corresponding index. You can provide a single string when
-            c_idx_nlevels ==1.
-    c_idx_nlevels - number of levels in columns index. > 1 will yield MultiIndex
-    r_idx_nlevels - number of levels in rows index. > 1 will yield MultiIndex
-    data_gen_f - a function f(row,col) which return the data value
-            at that position, the default generator used yields values of the form
-            "RxCy" based on position.
-    c_ndupe_l, r_ndupe_l - list of integers, determines the number
-            of duplicates for each label at a given level of the corresponding
-            index. The default `None` value produces a multiplicity of 1 across
-            all levels, i.e. a unique index. Will accept a partial list of length
-            N < idx_nlevels, for just the first N levels. If ndupe doesn't divide
-            nrows/ncol, the last label might have lower multiplicity.
-    dtype - passed to the DataFrame constructor as is, in case you wish to
-            have more control in conjunction with a custom `data_gen_f`
-    r_idx_type, c_idx_type -  "i"/"f"/"s"/"u"/"dt"/"td".
+    """Create a DataFrame using supplied parameters.
+
+    Parameters
+    ----------
+    nrows,  ncols - number of data rows/cols :
+        
+    c_idx_names, idx_names  - False/True/list of strings,  yields No names , :
+        default names or uses the provided names for the levels of the
+        corresponding index. You can provide a single string when
+        c_idx_nlevels ==1.
+    c_idx_nlevels - number of levels in columns index. > 1 will yield MultiIndex :
+        
+    r_idx_nlevels - number of levels in rows index. > 1 will yield MultiIndex :
+        
+    data_gen_f - a function f(row,col) which return the data value :
+        at that position, the default generator used yields values of the form
+        "RxCy" based on position.
+    c_ndupe_l, r_ndupe_l - list of integers, determines the number :
+        of duplicates for each label at a given level of the corresponding
+        index. The default `None` value produces a multiplicity of 1 across
+        all levels, i.e. a unique index. Will accept a partial list of length
+        N < idx_nlevels, for just the first N levels. If ndupe doesn't divide
+        nrows/ncol, the last label might have lower multiplicity.
+    dtype - passed to the DataFrame constructor as is, in case you wish to :
+        have more control in conjunction with a custom `data_gen_f`
+    r_idx_type, c_idx_type -  "i"/"f"/"s"/"u"/"dt"/"td". :
         If idx_type is not None, `idx_nlevels` must be 1.
         "i"/"f" creates an integer/float index,
         "s"/"u" creates a string/unicode index
         "dt" create a datetime index.
         "td" create a timedelta index.
-
-            if unspecified, string labels will be generated.
+        if unspecified, string labels will be generated.
+    nrows :
+        
+    ncols :
+        
+    c_idx_names :
+         (Default value = True)
+    r_idx_names :
+         (Default value = True)
+    c_idx_nlevels :
+         (Default value = 1)
+    r_idx_nlevels :
+         (Default value = 1)
+    data_gen_f :
+         (Default value = None)
+    c_ndupe_l :
+         (Default value = None)
+    r_ndupe_l :
+         (Default value = None)
+    dtype :
+         (Default value = None)
+    c_idx_type :
+         (Default value = None)
+    r_idx_type :
+         (Default value = None)
+
+    Returns
+    -------
 
     Examples
     --------
     # 5 row, 3 columns, default names on both, single index on both axis
     >> makeCustomDataframe(5,3)
-
+    
     # make the data a random int between 1 and 100
     >> mkdf(5,3,data_gen_f=lambda r,c:randint(1,100))
-
+    
     # 2-level multiindex on rows with each label duplicated
     # twice on first level, default names on both axis, single
     # index on both axis
     >> a=makeCustomDataframe(5,3,r_idx_nlevels=2,r_ndupe_l=[2])
-
+    
     # DatetimeIndex on row, index with unicode labels on columns
     # no names on either axis
     >> a=makeCustomDataframe(5,3,c_idx_names=False,r_idx_names=False,
                              r_idx_type="dt",c_idx_type="u")
-
+    
     # 4-level multindex on rows with names provided, 2-level multindex
     # on columns with default labels and default names.
     >> a=makeCustomDataframe(5,3,r_idx_nlevels=4,
                              r_idx_names=["FEE","FI","FO","FAM"],
                              c_idx_nlevels=2)
-
+    
     >> a=mkdf(5,3,r_idx_nlevels=2,c_idx_nlevels=4)
     """
     assert c_idx_nlevels > 0
@@ -2254,6 +2951,23 @@
 
 
 def _create_missing_idx(nrows, ncols, density, random_state=None):
+    """
+
+    Parameters
+    ----------
+    nrows :
+        
+    ncols :
+        
+    density :
+        
+    random_state :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     if random_state is None:
         random_state = np.random
     else:
@@ -2267,6 +2981,19 @@
     extra_size = min(size + min_rows, fac * size)
 
     def _gen_unique_rand(rng, _extra_size):
+        """
+
+        Parameters
+        ----------
+        rng :
+            
+        _extra_size :
+            
+
+        Returns
+        -------
+
+        """
         ind = rng.rand(int(_extra_size))
         return np.unique(np.floor(ind * nrows * ncols))[:size]
 
@@ -2281,6 +3008,19 @@
 
 
 def makeMissingDataframe(density=0.9, random_state=None):
+    """
+
+    Parameters
+    ----------
+    density :
+         (Default value = 0.9)
+    random_state :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     df = makeDataFrame()
     i, j = _create_missing_idx(*df.shape, density=density, random_state=random_state)
     df.values[i, j] = np.nan
@@ -2288,20 +3028,52 @@
 
 
 def optional_args(decorator):
-    """
-    allows a decorator to take optional positional and keyword arguments.
+    """allows a decorator to take optional positional and keyword arguments.
     Assumes that taking a single, callable, positional argument means that
     it is decorating a function, i.e. something like this::
-
+    
         @my_decorator
         def function(): pass
-
+    
     Calls decorator with decorator(f, *args, **kwargs)
+
+    Parameters
+    ----------
+    decorator :
+        
+
+    Returns
+    -------
+
     """
 
     @wraps(decorator)
     def wrapper(*args, **kwargs):
+        """
+
+        Parameters
+        ----------
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         def dec(f):
+            """
+
+            Parameters
+            ----------
+            f :
+                
+
+            Returns
+            -------
+
+            """
             return decorator(f, *args, **kwargs)
 
         is_decorating = not kwargs and len(args) == 1 and callable(args[0])
@@ -2354,6 +3126,7 @@
 
 
 def _get_default_network_errors():
+    """ """
     # Lazy import for http.client because it imports many things from the stdlib
     import http.client
 
@@ -2361,20 +3134,20 @@
 
 
 def can_connect(url, error_classes=None):
-    """
-    Try to connect to the given url. True if succeeds, False if IOError
+    """Try to connect to the given url. True if succeeds, False if IOError
     raised
 
     Parameters
     ----------
     url : basestring
         The URL to try to connect to
-
-    Returns
-    -------
-    connectable : bool
-        Return True if no IOError (unable to connect) or URLError (bad url) was
-        raised
+    error_classes :
+         (Default value = None)
+
+    Returns
+    -------
+
+    
     """
     if error_classes is None:
         error_classes = _get_default_network_errors()
@@ -2398,14 +3171,13 @@
     skip_errnos=_network_errno_vals,
     _skip_on_messages=_network_error_messages,
 ):
-    """
-    Label a test as requiring network connection and, if an error is
+    """Label a test as requiring network connection and, if an error is
     encountered, only raise if it does not find a network connection.
-
+    
     In comparison to ``network``, this assumes an added contract to your test:
     you must assert that, under normal conditions, your test will ONLY fail if
     it does not have network connectivity.
-
+    
     You can call this in 3 ways: as a standard decorator, with keyword
     arguments, or with a positional argument that is the url to check.
 
@@ -2417,37 +3189,28 @@
         The url to test via ``pandas.io.common.urlopen`` to check
         for connectivity. Defaults to 'http://www.google.com'.
     raise_on_error : bool
-        If True, never catches errors.
+        If True, never catches errors. (Default value = _RAISE_NETWORK_ERROR_DEFAULT)
     check_before_test : bool
-        If True, checks connectivity before running the test case.
+        If True, checks connectivity before running the test case. (Default value = False)
     error_classes : tuple or Exception
         error classes to ignore. If not in ``error_classes``, raises the error.
         defaults to IOError. Be careful about changing the error classes here.
     skip_errnos : iterable of int
         Any exception that has .errno or .reason.erno set to one
         of these values will be skipped with an appropriate
-        message.
-    _skip_on_messages: iterable of string
+        message. (Default value = _network_errno_vals)
+    _skip_on_messages : iterable of string
         any exception e for which one of the strings is
         a substring of str(e) will be skipped with an appropriate
-        message. Intended to suppress errors where an errno isn't available.
+        message. Intended to suppress errors where an errno isn't available. (Default value = _network_error_messages)
+
+    Returns
+    -------
 
     Notes
     -----
     * ``raise_on_error`` supersedes ``check_before_test``
-
-    Returns
-    -------
-    t : callable
-        The decorated test ``t``, with checks for connectivity errors.
-
-    Example
-    -------
-
-    Tests decorated with @network will fail if it's possible to make a network
-    connection to another URL (defaults to google.com)::
-
-      >>> from pandas._testing import network
+    >>> from pandas._testing import network
       >>> from pandas.io.common import urlopen
       >>> @network
       ... def test_network():
@@ -2456,9 +3219,7 @@
       Traceback
          ...
       URLError: <urlopen error unknown url type: rabit>
-
-      You can specify alternative URLs::
-
+    
         >>> @network("http://www.yahoo.com")
         ... def test_something_with_yahoo():
         ...    raise IOError("Failure Message")
@@ -2466,10 +3227,7 @@
         Traceback (most recent call last):
             ...
         IOError: Failure Message
-
-    If you set check_before_test, it will check the url first and not run the
-    test on failure::
-
+    
         >>> @network("failing://url.blaher", check_before_test=True)
         ... def test_something():
         ...     print("I ran!")
@@ -2477,8 +3235,6 @@
         >>> test_something()
         Traceback (most recent call last):
             ...
-
-    Errors not related to networking will always be raised.
     """
     from pytest import skip
 
@@ -2489,6 +3245,19 @@
 
     @wraps(t)
     def wrapper(*args, **kwargs):
+        """
+
+        Parameters
+        ----------
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         if check_before_test and not raise_on_error:
             if not can_connect(url, error_classes):
                 skip()
@@ -2530,8 +3299,7 @@
     check_stacklevel=True,
     raise_on_extra_warnings=True,
 ):
-    """
-    Context manager for running code expected to either raise a specific
+    """Context manager for running code expected to either raise a specific
     warning, or not raise any warnings. Verifies that the code raises the
     expected warning, and that it does not raise any other unexpected
     warnings. It is basically a wrapper around ``warnings.catch_warnings``.
@@ -2541,31 +3309,34 @@
     expected_warning : {Warning, False, None}, default Warning
         The type of Exception raised. ``exception.Warning`` is the base
         class for all warnings. To check that no warning is returned,
-        specify ``False`` or ``None``.
+        specify ``False`` or ``None``. (Default value = Warning)
     filter_level : str or None, default "always"
         Specifies whether warnings are ignored, displayed, or turned
         into errors.
         Valid values are:
-
         * "error" - turns matching warnings into exceptions
         * "ignore" - discard the warning
         * "always" - always emit a warning
         * "default" - print the warning the first time it is generated
-          from each location
+        from each location
         * "module" - print the warning the first time it is generated
-          from each module
+        from each module
         * "once" - print the warning the first time it is generated
-
     check_stacklevel : bool, default True
         If True, displays the line that called the function containing
         the warning to show were the function is called. Otherwise, the
-        line that implements the function is displayed.
+        line that implements the function is displayed. (Default value = True)
     raise_on_extra_warnings : bool, default True
         Whether extra warnings not of the type `expected_warning` should
-        cause the test to fail.
+        cause the test to fail. (Default value = True)
+
+    Returns
+    -------
 
     Examples
     --------
+    
+    ..warn:: This is *not* thread-safe.
     >>> import warnings
     >>> with assert_produces_warning():
     ...     warnings.warn(UserWarning())
@@ -2581,8 +3352,6 @@
     Traceback (most recent call last):
         ...
     AssertionError: Did not see expected warning of class 'UserWarning'.
-
-    ..warn:: This is *not* thread-safe.
     """
     __tracebackhide__ = True
 
@@ -2633,14 +3402,16 @@
 
 
 class RNGContext:
-    """
-    Context manager to set the numpy random number generator speed. Returns
+    """Context manager to set the numpy random number generator speed. Returns
     to the original value upon exiting the context manager.
 
     Parameters
     ----------
     seed : int
         Seed for numpy.random.seed
+
+    Returns
+    -------
 
     Examples
     --------
@@ -2663,8 +3434,7 @@
 
 @contextmanager
 def with_csv_dialect(name, **kwargs):
-    """
-    Context manager to temporarily register a CSV dialect for parsing CSV.
+    """Context manager to temporarily register a CSV dialect for parsing CSV.
 
     Parameters
     ----------
@@ -2672,10 +3442,16 @@
         The name of the dialect.
     kwargs : mapping
         The parameters for the dialect.
+    **kwargs :
+        
+
+    Returns
+    -------
 
     Raises
     ------
-    ValueError : the name of the dialect conflicts with a builtin one.
+    ValueError
+        
 
     See Also
     --------
@@ -2695,6 +3471,19 @@
 
 @contextmanager
 def use_numexpr(use, min_elements=None):
+    """
+
+    Parameters
+    ----------
+    use :
+        
+    min_elements :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     from pandas.core.computation import expressions as expr
 
     if min_elements is None:
@@ -2710,25 +3499,26 @@
 
 
 def test_parallel(num_threads=2, kwargs_list=None):
-    """
-    Decorator to run the same function multiple times in parallel.
+    """Decorator to run the same function multiple times in parallel.
 
     Parameters
     ----------
     num_threads : int, optional
-        The number of times the function is run in parallel.
+        The number of times the function is run in parallel. (Default value = 2)
     kwargs_list : list of dicts, optional
         The list of kwargs to update original
-        function kwargs on different threads.
+        function kwargs on different threads. (Default value = None)
+
+    Returns
+    -------
 
     Notes
     -----
     This decorator does not pass the return value of the decorated function.
-
+    
     Original from scikit-image:
-
+    
     https://github.com/scikit-image/scikit-image/pull/1519
-
     """
     assert num_threads > 0
     has_kwargs_list = kwargs_list is not None
@@ -2737,8 +3527,32 @@
     import threading
 
     def wrapper(func):
+        """
+
+        Parameters
+        ----------
+        func :
+            
+
+        Returns
+        -------
+
+        """
         @wraps(func)
         def inner(*args, **kwargs):
+            """
+
+            Parameters
+            ----------
+            *args :
+                
+            **kwargs :
+                
+
+            Returns
+            -------
+
+            """
             if has_kwargs_list:
                 update_kwargs = lambda i: dict(kwargs, **kwargs_list[i])
             else:
@@ -2759,44 +3573,56 @@
 
 
 class SubclassedSeries(Series):
+    """ """
     _metadata = ["testattr", "name"]
 
     @property
     def _constructor(self):
+        """ """
         return SubclassedSeries
 
     @property
     def _constructor_expanddim(self):
+        """ """
         return SubclassedDataFrame
 
 
 class SubclassedDataFrame(DataFrame):
+    """ """
     _metadata = ["testattr"]
 
     @property
     def _constructor(self):
+        """ """
         return SubclassedDataFrame
 
     @property
     def _constructor_sliced(self):
+        """ """
         return SubclassedSeries
 
 
 class SubclassedCategorical(Categorical):
+    """ """
     @property
     def _constructor(self):
+        """ """
         return SubclassedCategorical
 
 
 @contextmanager
 def set_timezone(tz: str):
-    """
-    Context manager for temporarily setting a timezone.
+    """Context manager for temporarily setting a timezone.
 
     Parameters
     ----------
     tz : str
         A string representing a valid timezone.
+    tz: str :
+        
+
+    Returns
+    -------
 
     Examples
     --------
@@ -2804,7 +3630,7 @@
     >>> from dateutil.tz import tzlocal
     >>> tzlocal().tzname(datetime.now())
     'IST'
-
+    
     >>> with set_timezone('US/Eastern'):
     ...     tzlocal().tzname(datetime.now())
     ...
@@ -2814,6 +3640,17 @@
     import time
 
     def setTZ(tz):
+        """
+
+        Parameters
+        ----------
+        tz :
+            
+
+        Returns
+        -------
+
+        """
         if tz is None:
             try:
                 del os.environ["TZ"]
@@ -2832,8 +3669,7 @@
 
 
 def _make_skipna_wrapper(alternative, skipna_alternative=None):
-    """
-    Create a function for calling on an array.
+    """Create a function for calling on an array.
 
     Parameters
     ----------
@@ -2841,20 +3677,43 @@
         The function to be called on the array with no NaNs.
         Only used when 'skipna_alternative' is None.
     skipna_alternative : function
-        The function to be called on the original array
-
-    Returns
-    -------
-    function
+        The function to be called on the original array (Default value = None)
+
+    Returns
+    -------
+
+    
     """
     if skipna_alternative:
 
         def skipna_wrapper(x):
+            """
+
+            Parameters
+            ----------
+            x :
+                
+
+            Returns
+            -------
+
+            """
             return skipna_alternative(x.values)
 
     else:
 
         def skipna_wrapper(x):
+            """
+
+            Parameters
+            ----------
+            x :
+                
+
+            Returns
+            -------
+
+            """
             nona = x.dropna()
             if len(nona) == 0:
                 return np.nan
@@ -2864,20 +3723,21 @@
 
 
 def convert_rows_list_to_csv_str(rows_list: List[str]):
-    """
-    Convert list of CSV rows to single CSV-formatted string for current OS.
-
+    """Convert list of CSV rows to single CSV-formatted string for current OS.
+    
     This method is used for creating expected value of to_csv() method.
 
     Parameters
     ----------
     rows_list : List[str]
         Each element represents the row of csv.
-
-    Returns
-    -------
-    str
-        Expected output of to_csv() in current OS.
+    rows_list: List[str] :
+        
+
+    Returns
+    -------
+
+    
     """
     sep = os.linesep
     expected = sep.join(rows_list) + sep
@@ -2885,18 +3745,19 @@
 
 
 def external_error_raised(expected_exception: Type[Exception],) -> ContextManager:
-    """
-    Helper function to mark pytest.raises that have an external error message.
+    """Helper function to mark pytest.raises that have an external error message.
 
     Parameters
     ----------
     expected_exception : Exception
         Expected error to raise.
-
-    Returns
-    -------
-    Callable
-        Regular `pytest.raises` function with `match` equal to `None`.
+    expected_exception: Type[Exception] :
+        
+
+    Returns
+    -------
+
+    
     """
     import pytest
 
@@ -2907,21 +3768,21 @@
 
 
 def get_cython_table_params(ndframe, func_names_and_expected):
-    """
-    Combine frame, functions from SelectionMixin._cython_table
+    """Combine frame, functions from SelectionMixin._cython_table
     keys and expected result.
 
     Parameters
     ----------
     ndframe : DataFrame or Series
+        
     func_names_and_expected : Sequence of two items
         The first item is a name of a NDFrame method ('sum', 'prod') etc.
         The second item is the expected return value.
 
     Returns
     -------
-    list
-        List of three items (DataFrame, function, expected result)
+
+    
     """
     results = []
     for func_name, expected in func_names_and_expected:
@@ -2935,18 +3796,19 @@
 
 
 def get_op_from_name(op_name: str) -> Callable:
-    """
-    The operator function for a given op name.
+    """The operator function for a given op name.
 
     Parameters
     ----------
     op_name : string
         The op name, in form of "add" or "__add__".
-
-    Returns
-    -------
-    function
-        A function performing the operation.
+    op_name: str :
+        
+
+    Returns
+    -------
+
+    
     """
     short_opname = op_name.strip("_")
     try:
