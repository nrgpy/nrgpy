# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/io/parsers.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/io/parsers.py
@@ -367,20 +367,24 @@
 
 
 def _validate_integer(name, val, min_val=0):
-    """
-    Checks whether the 'name' parameter for parsing is either
+    """Checks whether the 'name' parameter for parsing is either
     an integer OR float that can SAFELY be cast to an integer
     without losing accuracy. Raises a ValueError if that is
     not the case.
 
     Parameters
     ----------
-    name : string
-        Parameter name (used for error reporting)
-    val : int or float
-        The value to check
-    min_val : int
-        Minimum allowed value (val < min_val will result in a ValueError)
+    name :
+        
+    val :
+        
+    min_val :
+         (Default value = 0)
+
+    Returns
+    -------
+
+    
     """
     msg = f"'{name:s}' must be an integer >={min_val:d}"
 
@@ -396,8 +400,7 @@
 
 
 def _validate_names(names):
-    """
-    Raise ValueError if the `names` parameter contains duplicates or has an
+    """Raise ValueError if the `names` parameter contains duplicates or has an
     invalid data type.
 
     Parameters
@@ -405,10 +408,10 @@
     names : array-like or None
         An array containing a list of the names used for the output DataFrame.
 
-    Raises
-    ------
-    ValueError
-        If names are not unique or are not ordered (e.g. set).
+    Returns
+    -------
+
+    
     """
     if names is not None:
         if len(names) != len(set(names)):
@@ -420,7 +423,19 @@
 
 
 def _read(filepath_or_buffer: FilePathOrBuffer, kwds):
-    """Generic reader of line files."""
+    """Generic reader of line files.
+
+    Parameters
+    ----------
+    filepath_or_buffer: FilePathOrBuffer :
+        
+    kwds :
+        
+
+    Returns
+    -------
+
+    """
     encoding = kwds.get("encoding", None)
     if encoding is not None:
         encoding = re.sub("_", "-", encoding).lower()
@@ -598,6 +613,119 @@
     memory_map=False,
     float_precision=None,
 ):
+    """
+
+    Parameters
+    ----------
+    filepath_or_buffer: FilePathOrBuffer :
+        
+    sep :
+         (Default value = ")
+    " :
+        
+    delimiter :
+         (Default value = None)
+    # Column and Index Locations and Namesheader :
+         (Default value = "infer")
+    names :
+         (Default value = None)
+    index_col :
+         (Default value = None)
+    usecols :
+         (Default value = None)
+    squeeze :
+         (Default value = False)
+    prefix :
+         (Default value = None)
+    mangle_dupe_cols :
+         (Default value = True)
+    # General Parsing Configurationdtype :
+         (Default value = None)
+    engine :
+         (Default value = None)
+    converters :
+         (Default value = None)
+    true_values :
+         (Default value = None)
+    false_values :
+         (Default value = None)
+    skipinitialspace :
+         (Default value = False)
+    skiprows :
+         (Default value = None)
+    skipfooter :
+         (Default value = 0)
+    nrows :
+         (Default value = None)
+    # NA and Missing Data Handlingna_values :
+         (Default value = None)
+    keep_default_na :
+         (Default value = True)
+    na_filter :
+         (Default value = True)
+    verbose :
+         (Default value = False)
+    skip_blank_lines :
+         (Default value = True)
+    # Datetime Handlingparse_dates :
+         (Default value = False)
+    infer_datetime_format :
+         (Default value = False)
+    keep_date_col :
+         (Default value = False)
+    date_parser :
+         (Default value = None)
+    dayfirst :
+         (Default value = False)
+    cache_dates :
+         (Default value = True)
+    # Iterationiterator :
+         (Default value = False)
+    chunksize :
+         (Default value = None)
+    # Quoting :
+        
+    Compression :
+        
+    and File Formatcompression :
+         (Default value = "infer")
+    thousands :
+         (Default value = None)
+    decimal: str :
+         (Default value = ".")
+    lineterminator :
+         (Default value = None)
+    quotechar :
+         (Default value = '"')
+    quoting :
+         (Default value = csv.QUOTE_MINIMAL)
+    doublequote :
+         (Default value = True)
+    escapechar :
+         (Default value = None)
+    comment :
+         (Default value = None)
+    encoding :
+         (Default value = None)
+    dialect :
+         (Default value = None)
+    # Error Handlingerror_bad_lines :
+         (Default value = True)
+    warn_bad_lines :
+         (Default value = True)
+    # Internaldelim_whitespace :
+         (Default value = False)
+    low_memory :
+         (Default value = _c_parser_defaults["low_memory"])
+    memory_map :
+         (Default value = False)
+    float_precision :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     # gh-23761
     #
     # When a dialect is passed, it overrides any of the overlapping
@@ -754,6 +882,117 @@
     memory_map=False,
     float_precision=None,
 ):
+    """
+
+    Parameters
+    ----------
+    filepath_or_buffer: FilePathOrBuffer :
+        
+    sep :
+         (Default value = "\t")
+    delimiter :
+         (Default value = None)
+    # Column and Index Locations and Namesheader :
+         (Default value = "infer")
+    names :
+         (Default value = None)
+    index_col :
+         (Default value = None)
+    usecols :
+         (Default value = None)
+    squeeze :
+         (Default value = False)
+    prefix :
+         (Default value = None)
+    mangle_dupe_cols :
+         (Default value = True)
+    # General Parsing Configurationdtype :
+         (Default value = None)
+    engine :
+         (Default value = None)
+    converters :
+         (Default value = None)
+    true_values :
+         (Default value = None)
+    false_values :
+         (Default value = None)
+    skipinitialspace :
+         (Default value = False)
+    skiprows :
+         (Default value = None)
+    skipfooter :
+         (Default value = 0)
+    nrows :
+         (Default value = None)
+    # NA and Missing Data Handlingna_values :
+         (Default value = None)
+    keep_default_na :
+         (Default value = True)
+    na_filter :
+         (Default value = True)
+    verbose :
+         (Default value = False)
+    skip_blank_lines :
+         (Default value = True)
+    # Datetime Handlingparse_dates :
+         (Default value = False)
+    infer_datetime_format :
+         (Default value = False)
+    keep_date_col :
+         (Default value = False)
+    date_parser :
+         (Default value = None)
+    dayfirst :
+         (Default value = False)
+    cache_dates :
+         (Default value = True)
+    # Iterationiterator :
+         (Default value = False)
+    chunksize :
+         (Default value = None)
+    # Quoting :
+        
+    Compression :
+        
+    and File Formatcompression :
+         (Default value = "infer")
+    thousands :
+         (Default value = None)
+    decimal: str :
+         (Default value = ".")
+    lineterminator :
+         (Default value = None)
+    quotechar :
+         (Default value = '"')
+    quoting :
+         (Default value = csv.QUOTE_MINIMAL)
+    doublequote :
+         (Default value = True)
+    escapechar :
+         (Default value = None)
+    comment :
+         (Default value = None)
+    encoding :
+         (Default value = None)
+    dialect :
+         (Default value = None)
+    # Error Handlingerror_bad_lines :
+         (Default value = True)
+    warn_bad_lines :
+         (Default value = True)
+    # Internaldelim_whitespace :
+         (Default value = False)
+    low_memory :
+         (Default value = _c_parser_defaults["low_memory"])
+    memory_map :
+         (Default value = False)
+    float_precision :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     # TODO: validation duplicated in read_csv
     if delim_whitespace and (delimiter is not None or sep != "\t"):
         raise ValueError(
@@ -774,12 +1013,12 @@
     infer_nrows=100,
     **kwds,
 ):
-    r"""
+    """r"""
     Read a table of fixed-width formatted lines into DataFrame.
-
+    
     Also supports optionally iterating or breaking of the file
     into chunks.
-
+    
     Additional help can be found in the `online docs for IO Tools
     <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.
 
@@ -790,10 +1029,8 @@
         URL schemes include http, ftp, s3, and file. For file URLs, a host is
         expected. A local file could be:
         ``file://localhost/path/to/table.csv``.
-
         If you want to pass in a path object, pandas accepts any
         ``os.PathLike``.
-
         By file-like object, we refer to objects with a ``read()`` method,
         such as a file handler (e.g. via builtin ``open`` function)
         or ``StringIO``.
@@ -805,14 +1042,15 @@
         the data which are not being skipped via skiprows (default='infer').
     widths : list of int, optional
         A list of field widths which can be used instead of 'colspecs' if
-        the intervals are contiguous.
+        the intervals are contiguous. (Default value = None)
     infer_nrows : int, default 100
         The number of rows to consider when letting the parser determine the
         `colspecs`.
-
-        .. versionadded:: 0.24.0
+        .. versionadded:: 0.24.0 (Default value = 100)
     **kwds : optional
         Optional keyword arguments can be passed to ``TextFileReader``.
+    filepath_or_buffer: FilePathOrBuffer :
+        
 
     Returns
     -------
@@ -824,11 +1062,9 @@
     --------
     DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.
     read_csv : Read a comma-separated values (csv) file into DataFrame.
-
     Examples
     --------
     >>> pd.read_fwf('data.csv')  # doctest: +SKIP
-    """
     # Check input arguments.
     if colspecs is None and widths is None:
         raise ValueError("Must specify either colspecs or widths")
@@ -849,11 +1085,7 @@
 
 
 class TextFileReader(abc.Iterator):
-    """
-
-    Passed dialect overrides any of the related parser options
-
-    """
+    """Passed dialect overrides any of the related parser options"""
 
     def __init__(self, f, engine=None, **kwds):
 
@@ -948,9 +1180,21 @@
         self._make_engine(self.engine)
 
     def close(self):
+        """ """
         self._engine.close()
 
     def _get_options_with_defaults(self, engine):
+        """
+
+        Parameters
+        ----------
+        engine :
+            
+
+        Returns
+        -------
+
+        """
         kwds = self.orig_options
 
         options = {}
@@ -989,6 +1233,19 @@
         return options
 
     def _check_file_or_buffer(self, f, engine):
+        """
+
+        Parameters
+        ----------
+        f :
+            
+        engine :
+            
+
+        Returns
+        -------
+
+        """
         # see gh-16530
         if is_file_like(f):
             next_attr = "__next__"
@@ -1005,6 +1262,19 @@
         return engine
 
     def _clean_options(self, options, engine):
+        """
+
+        Parameters
+        ----------
+        options :
+            
+        engine :
+            
+
+        Returns
+        -------
+
+        """
         result = options.copy()
 
         engine_specified = self._engine_specified
@@ -1176,6 +1446,17 @@
             raise
 
     def _make_engine(self, engine="c"):
+        """
+
+        Parameters
+        ----------
+        engine :
+             (Default value = "c")
+
+        Returns
+        -------
+
+        """
         if engine == "c":
             self._engine = CParserWrapper(self.f, **self.options)
         else:
@@ -1191,9 +1472,21 @@
             self._engine = klass(self.f, **self.options)
 
     def _failover_to_python(self):
+        """ """
         raise AbstractMethodError(self)
 
     def read(self, nrows=None):
+        """
+
+        Parameters
+        ----------
+        nrows :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         nrows = _validate_integer("nrows", nrows)
         ret = self._engine.read(nrows)
 
@@ -1219,10 +1512,32 @@
         return df
 
     def _create_index(self, ret):
+        """
+
+        Parameters
+        ----------
+        ret :
+            
+
+        Returns
+        -------
+
+        """
         index, columns, col_dict = ret
         return index, columns, col_dict
 
     def get_chunk(self, size=None):
+        """
+
+        Parameters
+        ----------
+        size :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         if size is None:
             size = self.chunksize
         if self.nrows is not None:
@@ -1233,14 +1548,24 @@
 
 
 def _is_index_col(col):
+    """
+
+    Parameters
+    ----------
+    col :
+        
+
+    Returns
+    -------
+
+    """
     return col is not None and col is not False
 
 
 def _is_potential_multi_index(
     columns, index_col: Optional[Union[bool, Sequence[int]]] = None
 ):
-    """
-    Check whether or not the `columns` parameter
+    """Check whether or not the `columns` parameter
     could be converted into a MultiIndex.
 
     Parameters
@@ -1249,10 +1574,15 @@
         Object which may or may not be convertible into a MultiIndex
     index_col : None, bool or list, optional
         Column or columns to use as the (possibly hierarchical) index
+    index_col: Optional[Union[bool :
+        
+    Sequence[int]]] :
+         (Default value = None)
 
     Returns
     -------
-    boolean : Whether or not columns could become a MultiIndex
+
+    
     """
     if index_col is None or isinstance(index_col, bool):
         index_col = []
@@ -1265,12 +1595,22 @@
 
 
 def _evaluate_usecols(usecols, names):
-    """
-    Check whether or not the 'usecols' parameter
+    """Check whether or not the 'usecols' parameter
     is a callable.  If so, enumerates the 'names'
     parameter and returns a set of indices for
     each entry in 'names' that evaluates to True.
     If not a callable, returns 'usecols'.
+
+    Parameters
+    ----------
+    usecols :
+        
+    names :
+        
+
+    Returns
+    -------
+
     """
     if callable(usecols):
         return {i for i, name in enumerate(names) if usecols(name)}
@@ -1278,8 +1618,7 @@
 
 
 def _validate_usecols_names(usecols, names):
-    """
-    Validates that all usecols are present in a given
+    """Validates that all usecols are present in a given
     list of names. If not, raise a ValueError that
     shows what usecols are missing.
 
@@ -1295,9 +1634,7 @@
     usecols : iterable of usecols
         The `usecols` parameter if the validation succeeds.
 
-    Raises
-    ------
-    ValueError : Columns were missing. Error message will list them.
+    
     """
     missing = [c for c in usecols if c not in names]
     if len(missing) > 0:
@@ -1309,9 +1646,8 @@
 
 
 def _validate_skipfooter_arg(skipfooter):
-    """
-    Validate the 'skipfooter' parameter.
-
+    """Validate the 'skipfooter' parameter.
+    
     Checks whether 'skipfooter' is a non-negative integer.
     Raises a ValueError if that is not the case.
 
@@ -1325,9 +1661,7 @@
     validated_skipfooter : non-negative integer
         The original input if the validation succeeds.
 
-    Raises
-    ------
-    ValueError : 'skipfooter' was not a non-negative integer.
+    
     """
     if not is_integer(skipfooter):
         raise ValueError("skipfooter must be an integer")
@@ -1339,9 +1673,8 @@
 
 
 def _validate_usecols_arg(usecols):
-    """
-    Validate the 'usecols' parameter.
-
+    """Validate the 'usecols' parameter.
+    
     Checks whether or not the 'usecols' parameter contains all integers
     (column selection by index), strings (column by name) or is a callable.
     Raises a ValueError if that is not the case.
@@ -1354,14 +1687,8 @@
 
     Returns
     -------
-    usecols_tuple : tuple
-        A tuple of (verified_usecols, usecols_dtype).
-
-        'verified_usecols' is either a set if an array-like is passed in or
-        'usecols' if a callable or None is passed in.
-
-        'usecols_dtype` is the inferred dtype of 'usecols' if an array-like
-        is passed in or None if a callable or None is passed in.
+
+    
     """
     msg = (
         "'usecols' must either be list-like of all strings, all unicode, "
@@ -1389,10 +1716,18 @@
 
 
 def _validate_parse_dates_arg(parse_dates):
-    """
-    Check whether or not the 'parse_dates' parameter
+    """Check whether or not the 'parse_dates' parameter
     is a non-boolean scalar. Raises a ValueError if
     that is the case.
+
+    Parameters
+    ----------
+    parse_dates :
+        
+
+    Returns
+    -------
+
     """
     msg = (
         "Only booleans, lists, and dictionaries are accepted "
@@ -1411,6 +1746,7 @@
 
 
 class ParserBase:
+    """ """
     def __init__(self, kwds):
         self.names = kwds.get("names")
         self.orig_names = None
@@ -1499,9 +1835,8 @@
         self.handles = []
 
     def _validate_parse_dates_presence(self, columns: List[str]) -> None:
-        """
-        Check if parse_dates are in columns.
-
+        """Check if parse_dates are in columns.
+        
         If user has provided names for parse_dates, check if those columns
         are available.
 
@@ -1509,12 +1844,13 @@
         ----------
         columns : list
             List of names of the dataframe.
-
-        Raises
-        ------
-        ValueError
-            If column to parse_date is not in dataframe.
-
+        columns: List[str] :
+            
+
+        Returns
+        -------
+
+        
         """
         cols_needed: Iterable
         if is_dict_like(self.parse_dates):
@@ -1547,11 +1883,13 @@
             )
 
     def close(self):
+        """ """
         for f in self.handles:
             f.close()
 
     @property
     def _has_complex_date_col(self):
+        """ """
         return isinstance(self.parse_dates, dict) or (
             isinstance(self.parse_dates, list)
             and len(self.parse_dates) > 0
@@ -1559,6 +1897,17 @@
         )
 
     def _should_parse_dates(self, i):
+        """
+
+        Parameters
+        ----------
+        i :
+            
+
+        Returns
+        -------
+
+        """
         if isinstance(self.parse_dates, bool):
             return self.parse_dates
         else:
@@ -1580,9 +1929,23 @@
     def _extract_multi_indexer_columns(
         self, header, index_names, col_names, passed_names=False
     ):
-        """
-        extract and return the names, index_names, col_names
+        """extract and return the names, index_names, col_names
         header is a list-of-lists returned from the parsers
+
+        Parameters
+        ----------
+        header :
+            
+        index_names :
+            
+        col_names :
+            
+        passed_names :
+             (Default value = False)
+
+        Returns
+        -------
+
         """
         if len(header) < 2:
             return header[0], index_names, col_names, passed_names
@@ -1608,6 +1971,17 @@
         field_count = len(header[0])
 
         def extract(r):
+            """
+
+            Parameters
+            ----------
+            r :
+                
+
+            Returns
+            -------
+
+            """
             return tuple(r[i] for i in range(field_count) if i not in sic)
 
         columns = list(zip(*(extract(r) for r in header)))
@@ -1637,6 +2011,17 @@
         return names, index_names, col_names, passed_names
 
     def _maybe_dedup_names(self, names):
+        """
+
+        Parameters
+        ----------
+        names :
+            
+
+        Returns
+        -------
+
+        """
         # see gh-7160 and gh-9424: this helps to provide
         # immediate alleviation of the duplicate names
         # issue and appears to be satisfactory to users,
@@ -1665,12 +2050,42 @@
         return names
 
     def _maybe_make_multi_index_columns(self, columns, col_names=None):
+        """
+
+        Parameters
+        ----------
+        columns :
+            
+        col_names :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         # possibly create a column mi here
         if _is_potential_multi_index(columns):
             columns = MultiIndex.from_tuples(columns, names=col_names)
         return columns
 
     def _make_index(self, data, alldata, columns, indexnamerow=False):
+        """
+
+        Parameters
+        ----------
+        data :
+            
+        alldata :
+            
+        columns :
+            
+        indexnamerow :
+             (Default value = False)
+
+        Returns
+        -------
+
+        """
         if not _is_index_col(self.index_col) or not self.index_col:
             index = None
 
@@ -1699,7 +2114,31 @@
     _implicit_index = False
 
     def _get_simple_index(self, data, columns):
+        """
+
+        Parameters
+        ----------
+        data :
+            
+        columns :
+            
+
+        Returns
+        -------
+
+        """
         def ix(col):
+            """
+
+            Parameters
+            ----------
+            col :
+                
+
+            Returns
+            -------
+
+            """
             if not isinstance(col, str):
                 return col
             raise ValueError(f"Index {col} invalid")
@@ -1721,7 +2160,31 @@
         return index
 
     def _get_complex_date_index(self, data, col_names):
+        """
+
+        Parameters
+        ----------
+        data :
+            
+        col_names :
+            
+
+        Returns
+        -------
+
+        """
         def _get_name(icol):
+            """
+
+            Parameters
+            ----------
+            icol :
+                
+
+            Returns
+            -------
+
+            """
             if isinstance(icol, str):
                 return icol
 
@@ -1748,6 +2211,19 @@
         return index
 
     def _agg_index(self, index, try_parse_dates=True):
+        """
+
+        Parameters
+        ----------
+        index :
+            
+        try_parse_dates :
+             (Default value = True)
+
+        Returns
+        -------
+
+        """
         arrays = []
 
         for i, arr in enumerate(index):
@@ -1780,6 +2256,27 @@
     def _convert_to_ndarrays(
         self, dct, na_values, na_fvalues, verbose=False, converters=None, dtypes=None
     ):
+        """
+
+        Parameters
+        ----------
+        dct :
+            
+        na_values :
+            
+        na_fvalues :
+            
+        verbose :
+             (Default value = False)
+        converters :
+             (Default value = None)
+        dtypes :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         result = {}
         for c, values in dct.items():
             conv_f = None if converters is None else converters.get(c, None)
@@ -1853,20 +2350,21 @@
         return result
 
     def _infer_types(self, values, na_values, try_num_bool=True):
-        """
-        Infer types of values, possibly casting
+        """Infer types of values, possibly casting
 
         Parameters
         ----------
         values : ndarray
+            
         na_values : set
+            
         try_num_bool : bool, default try
-           try to cast values to numeric (first preference) or boolean
+            try to cast values to numeric (first preference) or boolean (Default value = True)
 
         Returns
         -------
-        converted : ndarray
-        na_count : int
+
+        
         """
         na_count = 0
         if issubclass(values.dtype.type, (np.number, np.bool_)):
@@ -1904,20 +2402,21 @@
         return result, na_count
 
     def _cast_types(self, values, cast_type, column):
-        """
-        Cast values to specified type
+        """Cast values to specified type
 
         Parameters
         ----------
         values : ndarray
+            
         cast_type : string or np.dtype
-           dtype to cast values to
+            dtype to cast values to
         column : string
             column name - used only for error reporting
 
         Returns
         -------
-        converted : ndarray
+
+        
         """
         if is_categorical_dtype(cast_type):
             known_cats = (
@@ -1959,6 +2458,19 @@
         return values
 
     def _do_date_conversions(self, names, data):
+        """
+
+        Parameters
+        ----------
+        names :
+            
+        data :
+            
+
+        Returns
+        -------
+
+        """
         # returns data, columns
 
         if self.parse_dates is not None:
@@ -1976,9 +2488,7 @@
 
 
 class CParserWrapper(ParserBase):
-    """
-
-    """
+    """ """
 
     def __init__(self, src, **kwds):
         self.kwds = kwds
@@ -2087,6 +2597,7 @@
         self._implicit_index = self._reader.leading_cols > 0
 
     def close(self):
+        """ """
         for f in self.handles:
             f.close()
 
@@ -2097,11 +2608,17 @@
             pass
 
     def _set_noconvert_columns(self):
-        """
-        Set the columns that should not undergo dtype conversions.
-
+        """Set the columns that should not undergo dtype conversions.
+        
         Currently, any column that is involved with date parsing will not
         undergo such conversions.
+
+        Parameters
+        ----------
+
+        Returns
+        -------
+
         """
         names = self.orig_names
         if self.usecols_dtype == "integer":
@@ -2118,6 +2635,17 @@
             usecols = None
 
         def _set(x):
+            """
+
+            Parameters
+            ----------
+            x :
+                
+
+            Returns
+            -------
+
+            """
             if usecols is not None and is_integer(x):
                 x = usecols[x]
 
@@ -2150,9 +2678,31 @@
                 _set(self.index_col)
 
     def set_error_bad_lines(self, status):
+        """
+
+        Parameters
+        ----------
+        status :
+            
+
+        Returns
+        -------
+
+        """
         self._reader.set_error_bad_lines(int(status))
 
     def read(self, nrows=None):
+        """
+
+        Parameters
+        ----------
+        nrows :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         try:
             data = self._reader.read(nrows)
         except StopIteration:
@@ -2238,6 +2788,17 @@
         return index, names, data
 
     def _filter_usecols(self, names):
+        """
+
+        Parameters
+        ----------
+        names :
+            
+
+        Returns
+        -------
+
+        """
         # hackish
         usecols = _evaluate_usecols(self.usecols, names)
         if usecols is not None and len(names) != len(usecols):
@@ -2247,6 +2808,7 @@
         return names
 
     def _get_index_names(self):
+        """ """
         names = list(self._reader.header[0])
         idx_names = None
 
@@ -2258,78 +2820,65 @@
         return names, idx_names
 
     def _maybe_parse_dates(self, values, index, try_parse_dates=True):
+        """
+
+        Parameters
+        ----------
+        values :
+            
+        index :
+            
+        try_parse_dates :
+             (Default value = True)
+
+        Returns
+        -------
+
+        """
         if try_parse_dates and self._should_parse_dates(index):
             values = self._date_conv(values)
         return values
 
 
 def TextParser(*args, **kwds):
-    """
-    Converts lists of lists/tuples into DataFrames with proper type inference
+    """Converts lists of lists/tuples into DataFrames with proper type inference
     and optional (e.g. string to datetime) conversion. Also enables iterating
     lazily over chunks of large files
 
     Parameters
     ----------
-    data : file-like object or list
-    delimiter : separator character to use
-    dialect : str or csv.Dialect instance, optional
-        Ignored if delimiter is longer than 1 character
-    names : sequence, default
-    header : int, default 0
-        Row to use to parse column labels. Defaults to the first row. Prior
-        rows will be discarded
-    index_col : int or list, optional
-        Column or columns to use as the (possibly hierarchical) index
-    has_index_names: bool, default False
-        True if the cols defined in index_col have an index name and are
-        not in the header.
-    na_values : scalar, str, list-like, or dict, optional
-        Additional strings to recognize as NA/NaN.
-    keep_default_na : bool, default True
-    thousands : str, optional
-        Thousands separator
-    comment : str, optional
-        Comment out remainder of line
-    parse_dates : bool, default False
-    keep_date_col : bool, default False
-    date_parser : function, optional
-    skiprows : list of integers
-        Row numbers to skip
-    skipfooter : int
-        Number of line at bottom of file to skip
-    converters : dict, optional
-        Dict of functions for converting values in certain columns. Keys can
-        either be integers or column labels, values are functions that take one
-        input argument, the cell (not column) content, and return the
-        transformed content.
-    encoding : str, optional
-        Encoding to use for UTF when reading/writing (ex. 'utf-8')
-    squeeze : bool, default False
-        returns Series if only one column.
-    infer_datetime_format: bool, default False
-        If True and `parse_dates` is True for a column, try to infer the
-        datetime format based on the first datetime string. If the format
-        can be inferred, there often will be a large parsing speed-up.
-    float_precision : str, optional
-        Specifies which converter the C engine should use for floating-point
-        values. The options are None for the ordinary converter,
-        'high' for the high-precision converter, and 'round_trip' for the
-        round-trip converter.
+    *args :
+        
+    **kwds :
+        
+
+    Returns
+    -------
+
+    
     """
     kwds["engine"] = "python"
     return TextFileReader(*args, **kwds)
 
 
 def count_empty_vals(vals):
+    """
+
+    Parameters
+    ----------
+    vals :
+        
+
+    Returns
+    -------
+
+    """
     return sum(1 for v in vals if v == "" or v is None)
 
 
 class PythonParser(ParserBase):
     def __init__(self, f, **kwds):
-        """
-        Workhorse function for processing nested list into DataFrame
-        """
+    """Workhorse function for processing nested list into DataFrame"""
         ParserBase.__init__(self, kwds)
 
         self.data = None
@@ -2455,11 +3004,23 @@
             self.nonnum = re.compile(fr"[^-^0-9^{self.thousands}^{self.decimal}]+")
 
     def _set_no_thousands_columns(self):
+        """ """
         # Create a set of column ids that are not to be stripped of thousands
         # operators.
         noconvert_columns = set()
 
         def _set(x):
+            """
+
+            Parameters
+            ----------
+            x :
+                
+
+            Returns
+            -------
+
+            """
             if is_integer(x):
                 noconvert_columns.add(x)
             else:
@@ -2491,6 +3052,17 @@
         return noconvert_columns
 
     def _make_reader(self, f):
+        """
+
+        Parameters
+        ----------
+        f :
+            
+
+        Returns
+        -------
+
+        """
         sep = self.delimiter
 
         if sep is None or len(sep) == 1:
@@ -2500,6 +3072,7 @@
                 )
 
             class MyDialect(csv.Dialect):
+                """ """
                 delimiter = self.delimiter
                 quotechar = self.quotechar
                 escapechar = self.escapechar
@@ -2541,6 +3114,7 @@
         else:
 
             def _read():
+                """ """
                 line = f.readline()
                 pat = re.compile(sep)
 
@@ -2554,6 +3128,17 @@
         self.data = reader
 
     def read(self, rows=None):
+        """
+
+        Parameters
+        ----------
+        rows :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         try:
             content = self._get_lines(rows)
         except StopIteration:
@@ -2594,6 +3179,17 @@
         return index, columns, data
 
     def _exclude_implicit_index(self, alldata):
+        """
+
+        Parameters
+        ----------
+        alldata :
+            
+
+        Returns
+        -------
+
+        """
         names = self._maybe_dedup_names(self.orig_names)
 
         if self._implicit_index:
@@ -2612,14 +3208,46 @@
 
     # legacy
     def get_chunk(self, size=None):
+        """
+
+        Parameters
+        ----------
+        size :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         if size is None:
             size = self.chunksize
         return self.read(rows=size)
 
     def _convert_data(self, data):
+        """
+
+        Parameters
+        ----------
+        data :
+            
+
+        Returns
+        -------
+
+        """
         # apply converters
         def _clean_mapping(mapping):
-            """converts col numbers to names"""
+            """converts col numbers to names
+
+            Parameters
+            ----------
+            mapping :
+                
+
+            Returns
+            -------
+
+            """
             clean = {}
             for col, v in mapping.items():
                 if isinstance(col, int) and col not in self.orig_names:
@@ -2662,6 +3290,7 @@
         )
 
     def _infer_columns(self):
+        """ """
         names = self.names
         num_original_columns = 0
         clear_buffer = True
@@ -2818,10 +3447,20 @@
         return columns, num_original_columns, unnamed_cols
 
     def _handle_usecols(self, columns, usecols_key):
-        """
-        Sets self._col_indices
-
+        """Sets self._col_indices
+        
         usecols_key is used if there are string usecols.
+
+        Parameters
+        ----------
+        columns :
+            
+        usecols_key :
+            
+
+        Returns
+        -------
+
         """
         if self.usecols is not None:
             if callable(self.usecols):
@@ -2852,21 +3491,27 @@
         return columns
 
     def _buffered_line(self):
-        """
-        Return a line from buffer, filling buffer if required.
-        """
+        """ """
         if len(self.buf) > 0:
             return self.buf[0]
         else:
             return self._next_line()
 
     def _check_for_bom(self, first_row):
-        """
-        Checks whether the file begins with the BOM character.
+        """Checks whether the file begins with the BOM character.
         If it does, remove it. In addition, if there is quoting
         in the field subsequent to the BOM, remove it as well
         because it technically takes place at the beginning of
         the name, not the middle of it.
+
+        Parameters
+        ----------
+        first_row :
+            
+
+        Returns
+        -------
+
         """
         # first_row will be a list, so we need to check
         # that that list is not empty before proceeding.
@@ -2914,8 +3559,7 @@
             return [""]
 
     def _is_line_empty(self, line):
-        """
-        Check if a line is empty or not.
+        """Check if a line is empty or not.
 
         Parameters
         ----------
@@ -2924,11 +3568,13 @@
 
         Returns
         -------
-        boolean : Whether or not the line is empty.
+
+        
         """
         return not line or all(not x for x in line)
 
     def _next_line(self):
+        """ """
         if isinstance(self.data, list):
             while self.skipfunc(self.pos):
                 self.pos += 1
@@ -2981,18 +3627,22 @@
         return line
 
     def _alert_malformed(self, msg, row_num):
-        """
-        Alert a user about a malformed row.
-
+        """Alert a user about a malformed row.
+        
         If `self.error_bad_lines` is True, the alert will be `ParserError`.
         If `self.warn_bad_lines` is True, the alert will be printed out.
 
         Parameters
         ----------
-        msg : The error message to display.
-        row_num : The row number where the parsing error occurred.
-                  Because this row number is displayed, we 1-index,
-                  even though we 0-index internally.
+        msg :
+            
+        row_num :
+            
+
+        Returns
+        -------
+
+        
         """
         if self.error_bad_lines:
             raise ParserError(msg)
@@ -3001,16 +3651,21 @@
             sys.stderr.write(base + msg + "\n")
 
     def _next_iter_line(self, row_num):
-        """
-        Wrapper around iterating through `self.data` (CSV source).
-
+        """Wrapper around iterating through `self.data` (CSV source).
+        
         When a CSV error is raised, we check for specific
         error messages that allow us to customize the
         error message displayed to the user.
 
         Parameters
         ----------
-        row_num : The row number of the line being parsed.
+        row_num :
+            
+
+        Returns
+        -------
+
+        
         """
         try:
             return next(self.data)
@@ -3040,6 +3695,17 @@
             return None
 
     def _check_comments(self, lines):
+        """
+
+        Parameters
+        ----------
+        lines :
+            
+
+        Returns
+        -------
+
+        """
         if self.comment is None:
             return lines
         ret = []
@@ -3057,8 +3723,7 @@
         return ret
 
     def _remove_empty_lines(self, lines):
-        """
-        Iterate through the lines and remove any that are
+        """Iterate through the lines and remove any that are
         either empty or contain only one whitespace value
 
         Parameters
@@ -3068,8 +3733,8 @@
 
         Returns
         -------
-        filtered_lines : array-like
-            The same array of lines with the "empty" ones removed.
+
+        
         """
         ret = []
         for l in lines:
@@ -3083,6 +3748,17 @@
         return ret
 
     def _check_thousands(self, lines):
+        """
+
+        Parameters
+        ----------
+        lines :
+            
+
+        Returns
+        -------
+
+        """
         if self.thousands is None:
             return lines
 
@@ -3091,6 +3767,21 @@
         )
 
     def _search_replace_num_columns(self, lines, search, replace):
+        """
+
+        Parameters
+        ----------
+        lines :
+            
+        search :
+            
+        replace :
+            
+
+        Returns
+        -------
+
+        """
         ret = []
         for l in lines:
             rl = []
@@ -3108,6 +3799,17 @@
         return ret
 
     def _check_decimal(self, lines):
+        """
+
+        Parameters
+        ----------
+        lines :
+            
+
+        Returns
+        -------
+
+        """
         if self.decimal == _parser_defaults["decimal"]:
             return lines
 
@@ -3116,14 +3818,14 @@
         )
 
     def _clear_buffer(self):
+        """ """
         self.buf = []
 
     _implicit_index = False
 
     def _get_index_name(self, columns):
-        """
-        Try several cases to get lines:
-
+        """Try several cases to get lines:
+        
         0) There are headers on row 0 and row 1 and their
         total summed lengths equals the length of the next line.
         Treat row 0 as columns and row 1 as indices
@@ -3131,6 +3833,15 @@
         on row 1 than row 0. If this is true, assume that row
         1 lists index columns and row 0 lists normal columns.
         2) Get index from the columns if it was listed.
+
+        Parameters
+        ----------
+        columns :
+            
+
+        Returns
+        -------
+
         """
         orig_names = list(columns)
         columns = list(columns)
@@ -3185,6 +3896,17 @@
         return index_name, orig_names, columns
 
     def _rows_to_cols(self, content):
+        """
+
+        Parameters
+        ----------
+        content :
+            
+
+        Returns
+        -------
+
+        """
         col_len = self.num_original_columns
 
         if self._implicit_index:
@@ -3256,6 +3978,17 @@
         return zipped_content
 
     def _get_lines(self, rows=None):
+        """
+
+        Parameters
+        ----------
+        rows :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         lines = self.buf
         new_rows = None
 
@@ -3337,7 +4070,35 @@
 def _make_date_converter(
     date_parser=None, dayfirst=False, infer_datetime_format=False, cache_dates=True
 ):
+    """
+
+    Parameters
+    ----------
+    date_parser :
+         (Default value = None)
+    dayfirst :
+         (Default value = False)
+    infer_datetime_format :
+         (Default value = False)
+    cache_dates :
+         (Default value = True)
+
+    Returns
+    -------
+
+    """
     def converter(*date_cols):
+        """
+
+        Parameters
+        ----------
+        *date_cols :
+            
+
+        Returns
+        -------
+
+        """
         if date_parser is None:
             strs = parsing.concat_date_cols(date_cols)
 
@@ -3388,7 +4149,41 @@
     columns,
     keep_date_col=False,
 ):
+    """
+
+    Parameters
+    ----------
+    data_dict :
+        
+    converter :
+        
+    parse_spec :
+        
+    index_col :
+        
+    index_names :
+        
+    columns :
+        
+    keep_date_col :
+         (Default value = False)
+
+    Returns
+    -------
+
+    """
     def _isindex(colspec):
+        """
+
+        Parameters
+        ----------
+        colspec :
+            
+
+        Returns
+        -------
+
+        """
         return (isinstance(index_col, list) and colspec in index_col) or (
             isinstance(index_names, list) and colspec in index_names
         )
@@ -3449,6 +4244,23 @@
 
 
 def _try_convert_dates(parser, colspec, data_dict, columns):
+    """
+
+    Parameters
+    ----------
+    parser :
+        
+    colspec :
+        
+    data_dict :
+        
+    columns :
+        
+
+    Returns
+    -------
+
+    """
     colset = set(columns)
     colnames = []
 
@@ -3468,6 +4280,19 @@
 
 
 def _clean_na_values(na_values, keep_default_na=True):
+    """
+
+    Parameters
+    ----------
+    na_values :
+        
+    keep_default_na :
+         (Default value = True)
+
+    Returns
+    -------
+
+    """
 
     if na_values is None:
         if keep_default_na:
@@ -3505,6 +4330,21 @@
 
 
 def _clean_index_names(columns, index_col, unnamed_cols):
+    """
+
+    Parameters
+    ----------
+    columns :
+        
+    index_col :
+        
+    unnamed_cols :
+        
+
+    Returns
+    -------
+
+    """
     if not _is_index_col(index_col):
         return None, columns, index_col
 
@@ -3538,6 +4378,23 @@
 
 
 def _get_empty_meta(columns, index_col, index_names, dtype=None):
+    """
+
+    Parameters
+    ----------
+    columns :
+        
+    index_col :
+        
+    index_names :
+        
+    dtype :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     columns = list(columns)
 
     # Convert `dtype` to a defaultdict of some kind.
@@ -3582,6 +4439,17 @@
 
 
 def _floatify_na_values(na_values):
+    """
+
+    Parameters
+    ----------
+    na_values :
+        
+
+    Returns
+    -------
+
+    """
     # create float versions of the na_values
     result = set()
     for v in na_values:
@@ -3595,7 +4463,19 @@
 
 
 def _stringify_na_values(na_values):
-    """ return a stringified and numeric for these values """
+    """
+
+    Parameters
+    ----------
+    na_values :
+        
+
+    Returns
+    -------
+    type
+        
+
+    """
     result = []
     for x in na_values:
         result.append(str(x))
@@ -3620,8 +4500,7 @@
 
 
 def _get_na_values(col, na_values, na_fvalues, keep_default_na):
-    """
-    Get the NaN values for a given column.
+    """Get the NaN values for a given column.
 
     Parameters
     ----------
@@ -3637,10 +4516,8 @@
 
     Returns
     -------
-    nan_tuple : A length-two tuple composed of
-
-        1) na_values : the string NaN values for that column.
-        2) na_fvalues : the float NaN values for that column.
+
+    
     """
     if isinstance(na_values, dict):
         if col in na_values:
@@ -3655,6 +4532,19 @@
 
 
 def _get_col_names(colspec, columns):
+    """
+
+    Parameters
+    ----------
+    colspec :
+        
+    columns :
+        
+
+    Returns
+    -------
+
+    """
     colset = set(columns)
     colnames = []
     for c in colspec:
@@ -3666,9 +4556,7 @@
 
 
 class FixedWidthReader(abc.Iterator):
-    """
-    A reader of fixed-width lines.
-    """
+    """A reader of fixed-width lines."""
 
     def __init__(self, f, colspecs, delimiter, comment, skiprows=None, infer_nrows=100):
         self.f = f
@@ -3701,9 +4589,8 @@
                 )
 
     def get_rows(self, infer_nrows, skiprows=None):
-        """
-        Read rows from self.f, skipping as specified.
-
+        """Read rows from self.f, skipping as specified.
+        
         We distinguish buffer_rows (the first <= infer_nrows
         lines) from the rows returned to detect_colspecs
         because it's simpler to leave the other locations
@@ -3716,14 +4603,13 @@
         infer_nrows : int
             Number of rows to read from self.f, not counting
             rows that are skipped.
-        skiprows: set, optional
-            Indices of rows to skip.
+        skiprows : set, optional
+            Indices of rows to skip. (Default value = None)
 
         Returns
         -------
-        detect_rows : list of str
-            A list containing the rows to read.
-
+
+        
         """
         if skiprows is None:
             skiprows = set()
@@ -3739,6 +4625,19 @@
         return detect_rows
 
     def detect_colspecs(self, infer_nrows=100, skiprows=None):
+        """
+
+        Parameters
+        ----------
+        infer_nrows :
+             (Default value = 100)
+        skiprows :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         # Regex escape the delimiters
         delimiters = "".join(fr"\{x}" for x in self.delimiter)
         pattern = re.compile(f"([^{delimiters}]+)")
@@ -3772,9 +4671,15 @@
 
 
 class FixedWidthFieldParser(PythonParser):
-    """
-    Specialization that Converts fixed-width fields into DataFrames.
+    """Specialization that Converts fixed-width fields into DataFrames.
     See PythonParser for details.
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
 
     def __init__(self, f, **kwds):
@@ -3784,6 +4689,17 @@
         PythonParser.__init__(self, f, **kwds)
 
     def _make_reader(self, f):
+        """
+
+        Parameters
+        ----------
+        f :
+            
+
+        Returns
+        -------
+
+        """
         self.data = FixedWidthReader(
             f,
             self.colspecs,
