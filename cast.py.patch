# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/core/dtypes/cast.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/core/dtypes/cast.py
@@ -86,7 +86,17 @@
 
 
 def maybe_convert_platform(values):
-    """ try to do platform conversion, allow ndarray or list here """
+    """try to do platform conversion, allow ndarray or list here
+
+    Parameters
+    ----------
+    values :
+        
+
+    Returns
+    -------
+
+    """
     if isinstance(values, (list, tuple, range)):
         values = construct_1d_object_array_from_listlike(values)
     if getattr(values, "dtype", None) == np.object_:
@@ -99,10 +109,18 @@
 
 def is_nested_object(obj) -> bool:
     """
-    return a boolean if we have a nested object, e.g. a Series with 1 or
-    more Series elements
-
-    This may not be necessarily be performant.
+
+    Parameters
+    ----------
+    obj :
+        
+
+    Returns
+    -------
+    type
+        more Series elements
+        
+        This may not be necessarily be performant.
 
     """
     if isinstance(obj, ABCSeries) and is_object_dtype(obj.dtype):
@@ -114,9 +132,19 @@
 
 
 def maybe_downcast_to_dtype(result, dtype):
-    """
-    try to cast to the specified dtype (e.g. convert back to bool/int
+    """try to cast to the specified dtype (e.g. convert back to bool/int
     or could be an astype of float64->float32
+
+    Parameters
+    ----------
+    result :
+        
+    dtype :
+        
+
+    Returns
+    -------
+
     """
     do_round = False
 
@@ -182,18 +210,23 @@
 
 
 def maybe_downcast_numeric(result, dtype, do_round: bool = False):
-    """
-    Subset of maybe_downcast_to_dtype restricted to numeric dtypes.
+    """Subset of maybe_downcast_to_dtype restricted to numeric dtypes.
 
     Parameters
     ----------
     result : ndarray or ExtensionArray
+        
     dtype : np.dtype or ExtensionDtype
+        
     do_round : bool
-
-    Returns
-    -------
-    ndarray or ExtensionArray
+        
+    do_round: bool :
+         (Default value = False)
+
+    Returns
+    -------
+
+    
     """
     if not isinstance(dtype, np.dtype):
         # e.g. SparseDtype has no itemsize attr
@@ -204,6 +237,17 @@
         result = np.array(result)
 
     def trans(x):
+        """
+
+        Parameters
+        ----------
+        x :
+            
+
+        Returns
+        -------
+
+        """
         if do_round:
             return x.round()
         return x
@@ -255,8 +299,7 @@
 
 
 def maybe_cast_result(result, obj: "Series", numeric_only: bool = False, how: str = ""):
-    """
-    Try casting result to a different type if appropriate
+    """Try casting result to a different type if appropriate
 
     Parameters
     ----------
@@ -268,11 +311,17 @@
         Whether to cast only numerics or datetimes as well.
     how : str, default ""
         How the result was computed.
-
-    Returns
-    -------
-    result : array-like
-        result maybe casted to the dtype.
+    obj: "Series" :
+        
+    numeric_only: bool :
+         (Default value = False)
+    how: str :
+         (Default value = "")
+
+    Returns
+    -------
+
+    
     """
     if obj.ndim > 1:
         dtype = obj._values.dtype
@@ -298,8 +347,7 @@
 
 
 def maybe_cast_result_dtype(dtype: DtypeObj, how: str) -> DtypeObj:
-    """
-    Get the desired dtype of a result based on the
+    """Get the desired dtype of a result based on the
     input dtype and how it was computed.
 
     Parameters
@@ -308,11 +356,15 @@
         Input dtype.
     how : str
         How the result was computed.
-
-    Returns
-    -------
-    DtypeObj
-        The desired dtype of the result.
+    dtype: DtypeObj :
+        
+    how: str :
+        
+
+    Returns
+    -------
+
+    
     """
     from pandas.core.arrays.boolean import BooleanDtype
     from pandas.core.arrays.integer import Int64Dtype
@@ -325,19 +377,23 @@
 
 
 def maybe_cast_to_extension_array(cls: Type["ExtensionArray"], obj, dtype=None):
-    """
-    Call to `_from_sequence` that returns the object unchanged on Exception.
+    """Call to `_from_sequence` that returns the object unchanged on Exception.
 
     Parameters
     ----------
     cls : class, subclass of ExtensionArray
+        
     obj : arraylike
         Values to pass to cls._from_sequence
     dtype : ExtensionDtype, optional
-
-    Returns
-    -------
-    ExtensionArray or obj
+         (Default value = None)
+    cls: Type["ExtensionArray"] :
+        
+
+    Returns
+    -------
+
+    
     """
     from pandas.core.arrays.string_ import StringArray
 
@@ -358,9 +414,8 @@
 
 
 def maybe_upcast_putmask(result: np.ndarray, mask: np.ndarray, other):
-    """
-    A safe version of putmask that potentially upcasts the result.
-
+    """A safe version of putmask that potentially upcasts the result.
+    
     The result is replaced with the first N elements of other,
     where N is the number of True values in mask.
     If the length of other is shorter than N, other will be repeated.
@@ -371,12 +426,18 @@
         The destination array. This will be mutated in-place if no upcasting is
         necessary.
     mask : boolean ndarray
+        
     other : scalar
         The source value.
+    result: np.ndarray :
+        
+    mask: np.ndarray :
+        
 
     Returns
     -------
     result : ndarray
+        
     changed : bool
         Set to true if the result array was upcasted.
 
@@ -410,6 +471,7 @@
                 other = np.array(other, dtype=result.dtype)
 
         def changeit():
+            """ """
             # we are forced to change the dtype of the result as the input
             # isn't compatible
             r, _ = maybe_upcast(result, fill_value=other, copy=True)
@@ -440,20 +502,19 @@
 
 
 def maybe_promote(dtype, fill_value=np.nan):
-    """
-    Find the minimal dtype that can hold both the given dtype and fill_value.
+    """Find the minimal dtype that can hold both the given dtype and fill_value.
 
     Parameters
     ----------
     dtype : np.dtype or ExtensionDtype
+        
     fill_value : scalar, default np.nan
-
-    Returns
-    -------
-    dtype
-        Upcasted from dtype argument if necessary.
-    fill_value
-        Upcasted from fill_value argument if necessary.
+         (Default value = np.nan)
+
+    Returns
+    -------
+
+    
     """
     if not is_scalar(fill_value) and not is_object_dtype(dtype):
         # with object dtype there is nothing to promote, and the user can
@@ -596,20 +657,22 @@
 
 
 def _ensure_dtype_type(value, dtype):
-    """
-    Ensure that the given value is an instance of the given dtype.
-
+    """Ensure that the given value is an instance of the given dtype.
+    
     e.g. if out dtype is np.complex64_, we should have an instance of that
     as opposed to a python complex object.
 
     Parameters
     ----------
     value : object
+        
     dtype : np.dtype or ExtensionDtype
-
-    Returns
-    -------
-    object
+        
+
+    Returns
+    -------
+
+    
     """
     # Start with exceptions in which we do _not_ cast to numpy types
     if is_extension_array_dtype(dtype):
@@ -624,16 +687,19 @@
 
 
 def infer_dtype_from(val, pandas_dtype: bool = False) -> Tuple[DtypeObj, Any]:
-    """
-    Interpret the dtype from a scalar or array.
-
-    Parameters
-    ----------
-    val : object
-    pandas_dtype : bool, default False
-        whether to infer dtype including pandas extension types.
-        If False, scalar/array belongs to pandas extension types is inferred as
-        object
+    """Interpret the dtype from a scalar or array.
+
+    Parameters
+    ----------
+    val :
+        
+    pandas_dtype: bool :
+         (Default value = False)
+
+    Returns
+    -------
+
+    
     """
     if is_scalar(val):
         return infer_dtype_from_scalar(val, pandas_dtype=pandas_dtype)
@@ -641,15 +707,19 @@
 
 
 def infer_dtype_from_scalar(val, pandas_dtype: bool = False) -> Tuple[DtypeObj, Any]:
-    """
-    Interpret the dtype from a scalar.
-
-    Parameters
-    ----------
-    pandas_dtype : bool, default False
-        whether to infer dtype including pandas extension types.
-        If False, scalar belongs to pandas extension types is inferred as
-        object
+    """Interpret the dtype from a scalar.
+
+    Parameters
+    ----------
+    val :
+        
+    pandas_dtype: bool :
+         (Default value = False)
+
+    Returns
+    -------
+
+    
     """
     dtype = np.dtype(object)
 
@@ -724,35 +794,37 @@
 
 # TODO: try to make the Any in the return annotation more specific
 def infer_dtype_from_array(arr, pandas_dtype: bool = False) -> Tuple[DtypeObj, Any]:
-    """
-    Infer the dtype from an array.
+    """Infer the dtype from an array.
 
     Parameters
     ----------
     arr : array
+        
     pandas_dtype : bool, default False
         whether to infer dtype including pandas extension types.
         If False, array belongs to pandas extension types
         is inferred as object
+    pandas_dtype: bool :
+         (Default value = False)
 
     Returns
     -------
     tuple (numpy-compat/pandas-compat dtype, array)
+        
 
     Notes
     -----
     if pandas_dtype=False. these infer to numpy dtypes
     exactly with the exception that mixed / object dtypes
     are not coerced by stringifying or conversion
-
+    
     if pandas_dtype=True. datetime64tz-aware/categorical
     types will retain there character.
-
     Examples
     --------
     >>> np.asarray([1, '1'])
     array(['1', '1'], dtype='<U21')
-
+    
     >>> infer_dtype_from_array([1, '1'])
     (dtype('O'), [1, '1'])
     """
@@ -778,9 +850,8 @@
 
 
 def maybe_infer_dtype_type(element):
-    """
-    Try to infer an object's dtype, for use in arithmetic ops.
-
+    """Try to infer an object's dtype, for use in arithmetic ops.
+    
     Uses `element.dtype` if that's available.
     Objects implementing the iterator protocol are cast to a NumPy array,
     and from there the array's type is used.
@@ -794,6 +865,7 @@
     Returns
     -------
     tipo : type
+        
 
     Examples
     --------
@@ -812,17 +884,23 @@
 
 
 def maybe_upcast(values, fill_value=np.nan, dtype=None, copy: bool = False):
-    """
-    Provide explicit type promotion and coercion.
-
-    Parameters
-    ----------
-    values : ndarray or ExtensionArray
-        The array that we want to maybe upcast.
-    fill_value : what we want to fill with
-    dtype : if None, then use the dtype of the values, else coerce to this type
-    copy : bool, default True
-        If True always make a copy even if no upcast is required.
+    """Provide explicit type promotion and coercion.
+
+    Parameters
+    ----------
+    values :
+        
+    fill_value :
+         (Default value = np.nan)
+    dtype :
+         (Default value = None)
+    copy: bool :
+         (Default value = False)
+
+    Returns
+    -------
+
+    
     """
     if not is_scalar(fill_value) and not is_object_dtype(values.dtype):
         # We allow arbitrary fill values for object dtype
@@ -844,9 +922,17 @@
 
 
 def invalidate_string_dtypes(dtype_set):
-    """
-    Change string like dtypes to object for
+    """Change string like dtypes to object for
     ``DataFrame.select_dtypes()``.
+
+    Parameters
+    ----------
+    dtype_set :
+        
+
+    Returns
+    -------
+
     """
     non_string_dtypes = dtype_set - {np.dtype("S").type, np.dtype("<U").type}
     if non_string_dtypes != dtype_set:
@@ -854,7 +940,19 @@
 
 
 def coerce_indexer_dtype(indexer, categories):
-    """ coerce the indexer input array to the smallest dtype possible """
+    """coerce the indexer input array to the smallest dtype possible
+
+    Parameters
+    ----------
+    indexer :
+        
+    categories :
+        
+
+    Returns
+    -------
+
+    """
     length = len(categories)
     if length < _int8_max:
         return ensure_int8(indexer)
@@ -866,14 +964,37 @@
 
 
 def coerce_to_dtypes(result, dtypes):
-    """
-    given a dtypes and a result set, coerce the result elements to the
+    """given a dtypes and a result set, coerce the result elements to the
     dtypes
+
+    Parameters
+    ----------
+    result :
+        
+    dtypes :
+        
+
+    Returns
+    -------
+
     """
     if len(result) != len(dtypes):
         raise AssertionError("_coerce_to_dtypes requires equal len arrays")
 
     def conv(r, dtype):
+        """
+
+        Parameters
+        ----------
+        r :
+            
+        dtype :
+            
+
+        Returns
+        -------
+
+        """
         if np.any(isna(r)):
             pass
         elif dtype == DT64NS_DTYPE:
@@ -896,23 +1017,28 @@
 
 
 def astype_nansafe(arr, dtype, copy: bool = True, skipna: bool = False):
-    """
-    Cast the elements of an array to a given dtype a nan-safe manner.
+    """Cast the elements of an array to a given dtype a nan-safe manner.
 
     Parameters
     ----------
     arr : ndarray
+        
     dtype : np.dtype
+        
     copy : bool, default True
         If False, a view will be attempted but may fail, if
         e.g. the item sizes don't align.
-    skipna: bool, default False
+    skipna : bool, default False
         Whether or not we should skip NaN when casting as a string-type.
-
-    Raises
-    ------
-    ValueError
-        The dtype was a datetime64/timedelta64 dtype, but it had no unit.
+    copy: bool :
+         (Default value = True)
+    skipna: bool :
+         (Default value = False)
+
+    Returns
+    -------
+
+    
     """
     # dispatch on extension dtype if needed
     if is_extension_array_dtype(dtype):
@@ -1000,17 +1126,23 @@
 
 
 def maybe_convert_objects(values: np.ndarray, convert_numeric: bool = True):
-    """
-    If we have an object dtype array, try to coerce dates and/or numbers.
+    """If we have an object dtype array, try to coerce dates and/or numbers.
 
     Parameters
     ----------
     values : ndarray
+        
     convert_numeric : bool, default True
-
-    Returns
-    -------
-    ndarray or DatetimeIndex
+        
+    values: np.ndarray :
+        
+    convert_numeric: bool :
+         (Default value = True)
+
+    Returns
+    -------
+
+    
     """
     validate_bool_kwarg(convert_numeric, "convert_numeric")
 
@@ -1056,7 +1188,27 @@
     coerce: bool = False,
     copy: bool = True,
 ):
-    """ if we have an object dtype, try to coerce dates and/or numbers """
+    """if we have an object dtype, try to coerce dates and/or numbers
+
+    Parameters
+    ----------
+    values: np.ndarray :
+        
+    datetime: bool :
+         (Default value = True)
+    numeric: bool :
+         (Default value = True)
+    timedelta: bool :
+         (Default value = True)
+    coerce: bool :
+         (Default value = False)
+    copy: bool :
+         (Default value = True)
+
+    Returns
+    -------
+
+    """
     validate_bool_kwarg(datetime, "datetime")
     validate_bool_kwarg(numeric, "numeric")
     validate_bool_kwarg(timedelta, "timedelta")
@@ -1125,24 +1277,30 @@
     convert_integer: bool = True,
     convert_boolean: bool = True,
 ) -> Dtype:
-    """
-    Convert objects to best possible type, and optionally,
+    """Convert objects to best possible type, and optionally,
     to types supporting ``pd.NA``.
 
     Parameters
     ----------
     input_array : ExtensionArray or PandasArray
+        
     convert_string : bool, default True
         Whether object dtypes should be converted to ``StringDtype()``.
     convert_integer : bool, default True
         Whether, if possible, conversion can be done to integer extension types.
     convert_boolean : bool, defaults True
         Whether object dtypes should be converted to ``BooleanDtypes()``.
-
-    Returns
-    -------
-    dtype
-        new dtype
+    convert_string: bool :
+         (Default value = True)
+    convert_integer: bool :
+         (Default value = True)
+    convert_boolean: bool :
+         (Default value = True)
+
+    Returns
+    -------
+
+    
     """
     is_extension = is_extension_array_dtype(input_array.dtype)
     if (convert_string or convert_integer or convert_boolean) and not is_extension:
@@ -1185,6 +1343,17 @@
 
 
 def maybe_castable(arr) -> bool:
+    """
+
+    Parameters
+    ----------
+    arr :
+        
+
+    Returns
+    -------
+
+    """
     # return False to force a non-fastpath
 
     # check datetime64[ns]/timedelta64[ns] are valid
@@ -1199,21 +1368,24 @@
 
 
 def maybe_infer_to_datetimelike(value, convert_dates: bool = False):
-    """
-    we might have a array (or single object) that is datetime like,
+    """we might have a array (or single object) that is datetime like,
     and no dtype is passed don't change the value unless we find a
     datetime/timedelta set
-
+    
     this is pretty strict in that a datetime/timedelta is REQUIRED
     in addition to possible nulls/string likes
 
     Parameters
     ----------
-    value : np.array / Series / Index / list-like
-    convert_dates : bool, default False
-       if True try really hard to convert dates (such as datetime.date), other
-       leave inferred dtype 'date' alone
-
+    value :
+        
+    convert_dates: bool :
+         (Default value = False)
+
+    Returns
+    -------
+
+    
     """
     # TODO: why not timedelta?
     if isinstance(
@@ -1242,6 +1414,17 @@
         return value
 
     def try_datetime(v):
+        """
+
+        Parameters
+        ----------
+        v :
+            
+
+        Returns
+        -------
+
+        """
         # safe coerce to datetime64
         try:
             # GH19671
@@ -1268,6 +1451,17 @@
         return v.reshape(shape)
 
     def try_timedelta(v):
+        """
+
+        Parameters
+        ----------
+        v :
+            
+
+        Returns
+        -------
+
+        """
         # safe coerce to timedelta64
 
         # will try first with a string & object conversion
@@ -1308,9 +1502,21 @@
 
 
 def maybe_cast_to_datetime(value, dtype, errors: str = "raise"):
-    """
-    try to cast the array/value to a datetimelike dtype, converting float
+    """try to cast the array/value to a datetimelike dtype, converting float
     nan to iNaT
+
+    Parameters
+    ----------
+    value :
+        
+    dtype :
+        
+    errors: str :
+         (Default value = "raise")
+
+    Returns
+    -------
+
     """
     from pandas.core.tools.datetimes import to_datetime
     from pandas.core.tools.timedeltas import to_timedelta
@@ -1446,21 +1652,23 @@
 
 
 def find_common_type(types: List[DtypeObj]) -> DtypeObj:
-    """
-    Find a common data type among the given dtypes.
+    """Find a common data type among the given dtypes.
 
     Parameters
     ----------
     types : list of dtypes
+        
+    types: List[DtypeObj] :
+        
 
     Returns
     -------
     pandas extension or numpy dtype
+        
 
     See Also
     --------
     numpy.find_common_type
-
     """
     if len(types) == 0:
         raise ValueError("no types given")
@@ -1501,20 +1709,23 @@
 
 
 def cast_scalar_to_array(shape, value, dtype: Optional[DtypeObj] = None) -> np.ndarray:
-    """
-    Create np.ndarray of specified shape and dtype, filled with values.
+    """Create np.ndarray of specified shape and dtype, filled with values.
 
     Parameters
     ----------
     shape : tuple
+        
     value : scalar value
+        
     dtype : np.dtype, optional
         dtype to coerce
-
-    Returns
-    -------
-    ndarray of shape, filled with value, of specified / inferred dtype
-
+    dtype: Optional[DtypeObj] :
+         (Default value = None)
+
+    Returns
+    -------
+
+    
     """
     if dtype is None:
         dtype, fill_value = infer_dtype_from_scalar(value)
@@ -1530,20 +1741,26 @@
 def construct_1d_arraylike_from_scalar(
     value, length: int, dtype: DtypeObj
 ) -> ArrayLike:
-    """
-    create a np.ndarray / pandas type of specified shape and dtype
+    """create a np.ndarray / pandas type of specified shape and dtype
     filled with values
 
     Parameters
     ----------
     value : scalar value
+        
     length : int
+        
     dtype : pandas_dtype or np.dtype
-
-    Returns
-    -------
-    np.ndarray / pandas type of length, filled with value
-
+        
+    length: int :
+        
+    dtype: DtypeObj :
+        
+
+    Returns
+    -------
+
+    
     """
     if is_extension_array_dtype(dtype):
         cls = dtype.construct_array_type()
@@ -1568,22 +1785,23 @@
 
 
 def construct_1d_object_array_from_listlike(values) -> np.ndarray:
-    """
-    Transform any list-like object in a 1-dimensional numpy array of object
+    """Transform any list-like object in a 1-dimensional numpy array of object
     dtype.
 
     Parameters
     ----------
     values : any iterable which has a len()
+        
+
+    Returns
+    -------
 
     Raises
     ------
     TypeError
         * If `values` does not have a len()
 
-    Returns
-    -------
-    1-dimensional numpy array of dtype object
+    
     """
     # numpy will try to interpret nested lists as further dimensions, hence
     # making a 1D array that contains list-likes is a bit tricky:
@@ -1595,26 +1813,32 @@
 def construct_1d_ndarray_preserving_na(
     values, dtype: Optional[DtypeObj] = None, copy: bool = False
 ) -> np.ndarray:
-    """
-    Construct a new ndarray, coercing `values` to `dtype`, preserving NA.
+    """Construct a new ndarray, coercing `values` to `dtype`, preserving NA.
 
     Parameters
     ----------
     values : Sequence
+        
     dtype : numpy.dtype, optional
+        
     copy : bool, default False
         Note that copies may still be made with ``copy=False`` if casting
         is required.
+    dtype: Optional[DtypeObj] :
+         (Default value = None)
+    copy: bool :
+         (Default value = False)
 
     Returns
     -------
     arr : ndarray[dtype]
+        
 
     Examples
     --------
     >>> np.array([1.0, 2.0, None], dtype='str')
     array(['1.0', '2.0', 'None'], dtype='<U4')
-
+    
     >>> construct_1d_ndarray_preserving_na([1.0, 2.0, None], dtype=np.dtype('str'))
     array(['1.0', '2.0', None], dtype=object)
     """
@@ -1628,10 +1852,9 @@
 
 
 def maybe_cast_to_integer_array(arr, dtype, copy: bool = False):
-    """
-    Takes any dtype and returns the casted version, raising for when data is
+    """Takes any dtype and returns the casted version, raising for when data is
     incompatible with integer/unsigned integer dtypes.
-
+    
     .. versionadded:: 0.24.0
 
     Parameters
@@ -1640,8 +1863,10 @@
         The array to cast.
     dtype : str, np.dtype
         The integer dtype to cast the array to.
-    copy: bool, default False
+    copy : bool, default False
         Whether to make a copy of the array before returning.
+    copy: bool :
+         (Default value = False)
 
     Returns
     -------
@@ -1650,20 +1875,22 @@
 
     Raises
     ------
-    OverflowError : the dtype is incompatible with the data
-    ValueError : loss of precision has occurred during casting
+    OverflowError
+        
+    ValueError
+        
 
     Examples
     --------
     If you try to coerce negative values to unsigned integers, it raises:
-
+    
+    
+    Also, if you try to coerce float values to integers, it raises:
     >>> pd.Series([-1], dtype="uint64")
     Traceback (most recent call last):
         ...
     OverflowError: Trying to coerce negative values to unsigned integers
-
-    Also, if you try to coerce float values to integers, it raises:
-
+    
     >>> pd.Series([1, 2, 3.5], dtype="int64")
     Traceback (most recent call last):
         ...
@@ -1698,18 +1925,22 @@
 
 
 def convert_scalar_for_putitemlike(scalar, dtype: np.dtype):
-    """
-    Convert datetimelike scalar if we are setting into a datetime64
+    """Convert datetimelike scalar if we are setting into a datetime64
     or timedelta64 ndarray.
 
     Parameters
     ----------
     scalar : scalar
+        
     dtype : np.dtype
-
-    Returns
-    -------
-    scalar
+        
+    dtype: np.dtype :
+        
+
+    Returns
+    -------
+
+    
     """
     if dtype.kind == "m":
         if isinstance(scalar, (timedelta, np.timedelta64)):
@@ -1729,18 +1960,22 @@
 
 
 def validate_numeric_casting(dtype: np.dtype, value):
-    """
-    Check that we can losslessly insert the given value into an array
+    """Check that we can losslessly insert the given value into an array
     with the given dtype.
 
     Parameters
     ----------
     dtype : np.dtype
+        
     value : scalar
-
-    Raises
-    ------
-    ValueError
+        
+    dtype: np.dtype :
+        
+
+    Returns
+    -------
+
+    
     """
     if issubclass(dtype.type, (np.integer, np.bool_)):
         if is_float(value) and np.isnan(value):
