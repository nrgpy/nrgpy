# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pygments/lexers/webmisc.py
+++ b/..//venv/lib/python3.8/site-packages/pygments/lexers/webmisc.py
@@ -25,12 +25,18 @@
 
 
 class DuelLexer(RegexLexer):
-    """
-    Lexer for Duel Views Engine (formerly JBST) markup with JavaScript code blocks.
+    """Lexer for Duel Views Engine (formerly JBST) markup with JavaScript code blocks.
     See http://duelengine.org/.
     See http://jsonml.org/jbst/.
-
+    
     .. versionadded:: 1.4
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
 
     name = 'Duel'
@@ -58,11 +64,17 @@
 
 
 class XQueryLexer(ExtendedRegexLexer):
-    """
-    An XQuery lexer, parsing a stream and outputting the tokens needed to
+    """An XQuery lexer, parsing a stream and outputting the tokens needed to
     highlight xquery code.
-
+    
     .. versionadded:: 1.4
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
     name = 'XQuery'
     aliases = ['xquery', 'xqy', 'xq', 'xql', 'xqm']
@@ -115,28 +127,103 @@
     flags = re.DOTALL | re.MULTILINE | re.UNICODE
 
     def punctuation_root_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Punctuation, match.group(1)
         # transition to root always - don't pop off stack
         ctx.stack = ['root']
         ctx.pos = match.end()
 
     def operator_root_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Operator, match.group(1)
         # transition to root always - don't pop off stack
         ctx.stack = ['root']
         ctx.pos = match.end()
 
     def popstate_tag_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Name.Tag, match.group(1)
         ctx.stack.append(lexer.xquery_parse_state.pop())
         ctx.pos = match.end()
 
     def popstate_xmlcomment_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), String.Doc, match.group(1)
         ctx.stack.append(lexer.xquery_parse_state.pop())
         ctx.pos = match.end()
 
     def popstate_kindtest_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Punctuation, match.group(1)
         next_state = lexer.xquery_parse_state.pop()
         if next_state == 'occurrenceindicator':
@@ -152,6 +239,21 @@
             ctx.pos = match.end(1)
 
     def popstate_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Punctuation, match.group(1)
         # if we have run out of our state stack, pop whatever is on the pygments
         # state stack
@@ -168,24 +270,84 @@
         ctx.pos = match.end()
 
     def pushstate_element_content_starttag_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Name.Tag, match.group(1)
         lexer.xquery_parse_state.append('element_content')
         ctx.stack.append('start_tag')
         ctx.pos = match.end()
 
     def pushstate_cdata_section_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), String.Doc, match.group(1)
         ctx.stack.append('cdata_section')
         lexer.xquery_parse_state.append(ctx.state.pop)
         ctx.pos = match.end()
 
     def pushstate_starttag_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Name.Tag, match.group(1)
         lexer.xquery_parse_state.append(ctx.state.pop)
         ctx.stack.append('start_tag')
         ctx.pos = match.end()
 
     def pushstate_operator_order_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Keyword, match.group(1)
         yield match.start(), Text, match.group(2)
         yield match.start(), Punctuation, match.group(3)
@@ -194,6 +356,21 @@
         ctx.pos = match.end()
 
     def pushstate_operator_map_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Keyword, match.group(1)
         yield match.start(), Text, match.group(2)
         yield match.start(), Punctuation, match.group(3)
@@ -202,6 +379,21 @@
         ctx.pos = match.end()
 
     def pushstate_operator_root_validate(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Keyword, match.group(1)
         yield match.start(), Text, match.group(2)
         yield match.start(), Punctuation, match.group(3)
@@ -210,6 +402,21 @@
         ctx.pos = match.end()
 
     def pushstate_operator_root_validate_withmode(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Keyword, match.group(1)
         yield match.start(), Text, match.group(2)
         yield match.start(), Keyword, match.group(3)
@@ -218,42 +425,147 @@
         ctx.pos = match.end()
 
     def pushstate_operator_processing_instruction_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), String.Doc, match.group(1)
         ctx.stack.append('processing_instruction')
         lexer.xquery_parse_state.append('operator')
         ctx.pos = match.end()
 
     def pushstate_element_content_processing_instruction_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), String.Doc, match.group(1)
         ctx.stack.append('processing_instruction')
         lexer.xquery_parse_state.append('element_content')
         ctx.pos = match.end()
 
     def pushstate_element_content_cdata_section_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), String.Doc, match.group(1)
         ctx.stack.append('cdata_section')
         lexer.xquery_parse_state.append('element_content')
         ctx.pos = match.end()
 
     def pushstate_operator_cdata_section_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), String.Doc, match.group(1)
         ctx.stack.append('cdata_section')
         lexer.xquery_parse_state.append('operator')
         ctx.pos = match.end()
 
     def pushstate_element_content_xmlcomment_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), String.Doc, match.group(1)
         ctx.stack.append('xml_comment')
         lexer.xquery_parse_state.append('element_content')
         ctx.pos = match.end()
 
     def pushstate_operator_xmlcomment_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), String.Doc, match.group(1)
         ctx.stack.append('xml_comment')
         lexer.xquery_parse_state.append('operator')
         ctx.pos = match.end()
 
     def pushstate_kindtest_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Keyword, match.group(1)
         yield match.start(), Text, match.group(2)
         yield match.start(), Punctuation, match.group(3)
@@ -262,6 +574,21 @@
         ctx.pos = match.end()
 
     def pushstate_operator_kindtestforpi_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Keyword, match.group(1)
         yield match.start(), Text, match.group(2)
         yield match.start(), Punctuation, match.group(3)
@@ -270,6 +597,21 @@
         ctx.pos = match.end()
 
     def pushstate_operator_kindtest_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Keyword, match.group(1)
         yield match.start(), Text, match.group(2)
         yield match.start(), Punctuation, match.group(3)
@@ -278,6 +620,21 @@
         ctx.pos = match.end()
 
     def pushstate_occurrenceindicator_kindtest_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Name.Tag, match.group(1)
         yield match.start(), Text, match.group(2)
         yield match.start(), Punctuation, match.group(3)
@@ -286,18 +643,63 @@
         ctx.pos = match.end()
 
     def pushstate_operator_starttag_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Name.Tag, match.group(1)
         lexer.xquery_parse_state.append('operator')
         ctx.stack.append('start_tag')
         ctx.pos = match.end()
 
     def pushstate_operator_root_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Punctuation, match.group(1)
         lexer.xquery_parse_state.append('operator')
         ctx.stack = ['root']
         ctx.pos = match.end()
 
     def pushstate_operator_root_construct_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Keyword, match.group(1)
         yield match.start(), Text, match.group(2)
         yield match.start(), Punctuation, match.group(3)
@@ -306,6 +708,21 @@
         ctx.pos = match.end()
 
     def pushstate_root_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Punctuation, match.group(1)
         cur_state = ctx.stack.pop()
         lexer.xquery_parse_state.append(cur_state)
@@ -313,11 +730,41 @@
         ctx.pos = match.end()
 
     def pushstate_operator_attribute_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Name.Attribute, match.group(1)
         ctx.stack.append('operator')
         ctx.pos = match.end()
 
     def pushstate_operator_callback(lexer, match, ctx):
+        """
+
+        Parameters
+        ----------
+        lexer :
+            
+        match :
+            
+        ctx :
+            
+
+        Returns
+        -------
+
+        """
         yield match.start(), Keyword, match.group(1)
         yield match.start(), Text, match.group(2)
         yield match.start(), Punctuation, match.group(3)
@@ -791,10 +1238,16 @@
 
 
 class QmlLexer(RegexLexer):
-    """
-    For QML files. See http://doc.qt.digia.com/4.7/qdeclarativeintroduction.html.
-
+    """For QML files. See http://doc.qt.digia.com/4.7/qdeclarativeintroduction.html.
+    
     .. versionadded:: 1.6
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
 
     # QML is based on javascript, so much of this is taken from the
@@ -864,18 +1317,23 @@
 
 
 class CirruLexer(RegexLexer):
-    r"""
+    """r"""
     Syntax rules of Cirru can be found at:
     http://cirru.org/
-
+    
     * using ``()`` for expressions, but restricted in a same line
     * using ``""`` for strings, with ``\`` for escaping chars
     * using ``$`` as folding operator
     * using ``,`` as unfolding operator
     * using indentations for nested blocks
-
+    
     .. versionadded:: 2.0
-    """
+
+    Parameters
+    ----------
+
+    Returns
+    -------
 
     name = 'Cirru'
     aliases = ['cirru']
@@ -919,10 +1377,16 @@
 
 
 class SlimLexer(ExtendedRegexLexer):
-    """
-    For Slim markup.
-
+    """For Slim markup.
+    
     .. versionadded:: 2.0
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
 
     name = 'Slim'
