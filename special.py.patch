# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pygments/lexers/special.py
+++ b/..//venv/lib/python3.8/site-packages/pygments/lexers/special.py
@@ -21,9 +21,7 @@
 
 
 class TextLexer(Lexer):
-    """
-    "Null" lexer, doesn't highlight anything.
-    """
+    """"Null" lexer, doesn't highlight anything."""
     name = 'Text only'
     aliases = ['text']
     filenames = ['*.txt']
@@ -31,9 +29,31 @@
     priority = 0.01
 
     def get_tokens_unprocessed(self, text):
+        """
+
+        Parameters
+        ----------
+        text :
+            
+
+        Returns
+        -------
+
+        """
         yield 0, Text, text
 
     def analyse_text(text):
+        """
+
+        Parameters
+        ----------
+        text :
+            
+
+        Returns
+        -------
+
+        """
         return TextLexer.priority
 
 
@@ -43,16 +63,22 @@
 
 
 class RawTokenLexer(Lexer):
-    """
-    Recreate a token stream formatted with the `RawTokenFormatter`.  This
+    """Recreate a token stream formatted with the `RawTokenFormatter`.  This
     lexer raises exceptions during parsing if the token stream in the
     file is malformed.
-
+    
     Additional options accepted:
-
+    
     `compress`
         If set to ``"gz"`` or ``"bz2"``, decompress the token stream with
         the given compression algorithm before lexing (default: ``""``).
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
     name = 'Raw token data'
     aliases = ['raw']
@@ -65,6 +91,17 @@
         Lexer.__init__(self, **options)
 
     def get_tokens(self, text):
+        """
+
+        Parameters
+        ----------
+        text :
+            
+
+        Returns
+        -------
+
+        """
         if isinstance(text, str):
             # raw token stream never has any non-ASCII characters
             text = text.encode('ascii')
@@ -83,6 +120,17 @@
             yield t, v
 
     def get_tokens_unprocessed(self, text):
+        """
+
+        Parameters
+        ----------
+        text :
+            
+
+        Returns
+        -------
+
+        """
         length = 0
         for match in line_re.finditer(text):
             try:
