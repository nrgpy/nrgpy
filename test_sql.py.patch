# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/tests/io/test_sql.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/tests/io/test_sql.py
@@ -209,7 +209,19 @@
 
 
 class MixInBase:
+    """ """
     def teardown_method(self, method):
+        """
+
+        Parameters
+        ----------
+        method :
+            
+
+        Returns
+        -------
+
+        """
         # if setup fails, there may not be a connection to close.
         if hasattr(self, "conn"):
             for tbl in self._get_all_tables():
@@ -218,17 +230,31 @@
 
 
 class MySQLMixIn(MixInBase):
+    """ """
     def drop_table(self, table_name):
+        """
+
+        Parameters
+        ----------
+        table_name :
+            
+
+        Returns
+        -------
+
+        """
         cur = self.conn.cursor()
         cur.execute(f"DROP TABLE IF EXISTS {sql._get_valid_mysql_name(table_name)}")
         self.conn.commit()
 
     def _get_all_tables(self):
+        """ """
         cur = self.conn.cursor()
         cur.execute("SHOW TABLES")
         return [table[0] for table in cur.fetchall()]
 
     def _close_conn(self):
+        """ """
         from pymysql.err import Error
 
         try:
@@ -238,41 +264,67 @@
 
 
 class SQLiteMixIn(MixInBase):
+    """ """
     def drop_table(self, table_name):
+        """
+
+        Parameters
+        ----------
+        table_name :
+            
+
+        Returns
+        -------
+
+        """
         self.conn.execute(
             f"DROP TABLE IF EXISTS {sql._get_valid_sqlite_name(table_name)}"
         )
         self.conn.commit()
 
     def _get_all_tables(self):
+        """ """
         c = self.conn.execute("SELECT name FROM sqlite_master WHERE type='table'")
         return [table[0] for table in c.fetchall()]
 
     def _close_conn(self):
+        """ """
         self.conn.close()
 
 
 class SQLAlchemyMixIn(MixInBase):
+    """ """
     def drop_table(self, table_name):
+        """
+
+        Parameters
+        ----------
+        table_name :
+            
+
+        Returns
+        -------
+
+        """
         sql.SQLDatabase(self.conn).drop_table(table_name)
 
     def _get_all_tables(self):
+        """ """
         meta = sqlalchemy.schema.MetaData(bind=self.conn)
         meta.reflect()
         table_list = meta.tables.keys()
         return table_list
 
     def _close_conn(self):
+        """ """
         pass
 
 
 class PandasSQLTest:
-    """
-    Base class with common private methods for SQLAlchemy and fallback cases.
-
-    """
+    """Base class with common private methods for SQLAlchemy and fallback cases."""
 
     def _get_exec(self):
+        """ """
         if hasattr(self.conn, "execute"):
             return self.conn
         else:
@@ -280,6 +332,19 @@
 
     @pytest.fixture(params=[("io", "data", "csv", "iris.csv")])
     def load_iris_data(self, datapath, request):
+        """
+
+        Parameters
+        ----------
+        datapath :
+            
+        request :
+            
+
+        Returns
+        -------
+
+        """
         import io
 
         iris_csv_file = datapath(*request.param)
@@ -299,10 +364,22 @@
                 self._get_exec().execute(ins, row)
 
     def _load_iris_view(self):
+        """ """
         self.drop_table("iris_view")
         self._get_exec().execute(SQL_STRINGS["create_view"][self.flavor])
 
     def _check_iris_loaded_frame(self, iris_frame):
+        """
+
+        Parameters
+        ----------
+        iris_frame :
+            
+
+        Returns
+        -------
+
+        """
         pytype = iris_frame.dtypes[0].type
         row = iris_frame.iloc[0]
 
@@ -310,6 +387,7 @@
         tm.equalContents(row.values, [5.1, 3.5, 1.4, 0.2, "Iris-setosa"])
 
     def _load_test1_data(self):
+        """ """
         columns = ["index", "A", "B", "C", "D"]
         data = [
             (
@@ -345,6 +423,7 @@
         self.test_frame1 = DataFrame(data, columns=columns)
 
     def _load_test2_data(self):
+        """ """
         df = DataFrame(
             dict(
                 A=[4, 1, 3, 6],
@@ -359,6 +438,7 @@
         self.test_frame2 = df
 
     def _load_test3_data(self):
+        """ """
         columns = ["index", "A", "B"]
         data = [
             ("2000-01-03 00:00:00", 2 ** 31 - 1, -1.987670),
@@ -370,6 +450,7 @@
         self.test_frame3 = DataFrame(data, columns=columns)
 
     def _load_raw_sql(self):
+        """ """
         self.drop_table("types_test_data")
         self._get_exec().execute(SQL_STRINGS["create_test_types"][self.flavor])
         ins = SQL_STRINGS["insert_test_types"][self.flavor]
@@ -406,6 +487,17 @@
             )
 
     def _count_rows(self, table_name):
+        """
+
+        Parameters
+        ----------
+        table_name :
+            
+
+        Returns
+        -------
+
+        """
         result = (
             self._get_exec()
             .execute(f"SELECT count(*) AS count_1 FROM {table_name}")
@@ -414,27 +506,42 @@
         return result[0]
 
     def _read_sql_iris(self):
+        """ """
         iris_frame = self.pandasSQL.read_query("SELECT * FROM iris")
         self._check_iris_loaded_frame(iris_frame)
 
     def _read_sql_iris_parameter(self):
+        """ """
         query = SQL_STRINGS["read_parameters"][self.flavor]
         params = ["Iris-setosa", 5.1]
         iris_frame = self.pandasSQL.read_query(query, params=params)
         self._check_iris_loaded_frame(iris_frame)
 
     def _read_sql_iris_named_parameter(self):
+        """ """
         query = SQL_STRINGS["read_named_parameters"][self.flavor]
         params = {"name": "Iris-setosa", "length": 5.1}
         iris_frame = self.pandasSQL.read_query(query, params=params)
         self._check_iris_loaded_frame(iris_frame)
 
     def _read_sql_iris_no_parameter_with_percent(self):
+        """ """
         query = SQL_STRINGS["read_no_parameters_with_percent"][self.flavor]
         iris_frame = self.pandasSQL.read_query(query, params=None)
         self._check_iris_loaded_frame(iris_frame)
 
     def _to_sql(self, method=None):
+        """
+
+        Parameters
+        ----------
+        method :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         self.drop_table("test_frame1")
 
         self.pandasSQL.to_sql(self.test_frame1, "test_frame1", method=method)
@@ -448,10 +555,12 @@
         self.drop_table("test_frame1")
 
     def _to_sql_empty(self):
+        """ """
         self.drop_table("test_frame1")
         self.pandasSQL.to_sql(self.test_frame1.iloc[:0], "test_frame1")
 
     def _to_sql_fail(self):
+        """ """
         self.drop_table("test_frame1")
 
         self.pandasSQL.to_sql(self.test_frame1, "test_frame1", if_exists="fail")
@@ -464,6 +573,7 @@
         self.drop_table("test_frame1")
 
     def _to_sql_replace(self):
+        """ """
         self.drop_table("test_frame1")
 
         self.pandasSQL.to_sql(self.test_frame1, "test_frame1", if_exists="fail")
@@ -478,6 +588,7 @@
         self.drop_table("test_frame1")
 
     def _to_sql_append(self):
+        """ """
         # Nuke table just in case
         self.drop_table("test_frame1")
 
@@ -494,9 +605,27 @@
         self.drop_table("test_frame1")
 
     def _to_sql_method_callable(self):
+        """ """
         check = []  # used to double check function below is really being used
 
         def sample(pd_table, conn, keys, data_iter):
+            """
+
+            Parameters
+            ----------
+            pd_table :
+                
+            conn :
+                
+            keys :
+                
+            data_iter :
+                
+
+            Returns
+            -------
+
+            """
             check.append(1)
             data = [dict(zip(keys, row)) for row in data_iter]
             conn.execute(pd_table.table.insert(), data)
@@ -514,6 +643,7 @@
         self.drop_table("test_frame1")
 
     def _roundtrip(self):
+        """ """
         self.drop_table("test_frame_roundtrip")
         self.pandasSQL.to_sql(self.test_frame1, "test_frame_roundtrip")
         result = self.pandasSQL.read_query("SELECT * FROM test_frame_roundtrip")
@@ -526,12 +656,14 @@
         tm.assert_frame_equal(result, self.test_frame1)
 
     def _execute_sql(self):
+        """ """
         # drop_sql = "DROP TABLE IF EXISTS test"  # should already be done
         iris_results = self.pandasSQL.execute("SELECT * FROM iris")
         row = iris_results.fetchone()
         tm.equalContents(row, [5.1, 3.5, 1.4, 0.2, "Iris-setosa"])
 
     def _to_sql_save_index(self):
+        """ """
         df = DataFrame.from_records(
             [(1, 2.1, "line1"), (2, 1.5, "line2")], columns=["A", "B", "C"], index=["A"]
         )
@@ -540,10 +672,12 @@
         assert ix_cols == [["A"]]
 
     def _transaction_test(self):
+        """ """
         with self.pandasSQL.run_transaction() as trans:
             trans.execute("CREATE TABLE test_trans (A INT, B TEXT)")
 
         class DummyException(Exception):
+            """ """
             pass
 
         # Make sure when transaction is rolled back, no rows get inserted
@@ -570,19 +704,24 @@
 
 
 class _TestSQLApi(PandasSQLTest):
-    """
-    Base class to test the public API.
-
+    """Base class to test the public API.
+    
     From this two classes are derived to run these tests for both the
     sqlalchemy mode (`TestSQLApi`) and the fallback mode
     (`TestSQLiteFallbackApi`).  These tests are run with sqlite3. Specific
     tests for the different sql flavours are included in `_TestSQLAlchemy`.
-
+    
     Notes:
     flavor can always be passed even in SQLAlchemy mode,
     should be correctly ignored.
-
+    
     we don't use drop_table because that isn't part of the public api
+
+    Parameters
+    ----------
+
+    Returns
+    -------
 
     """
 
@@ -590,13 +729,26 @@
     mode: str
 
     def setup_connect(self):
+        """ """
         self.conn = self.connect()
 
     @pytest.fixture(autouse=True)
     def setup_method(self, load_iris_data):
+        """
+
+        Parameters
+        ----------
+        load_iris_data :
+            
+
+        Returns
+        -------
+
+        """
         self.load_test_data_and_sql()
 
     def load_test_data_and_sql(self):
+        """ """
         self._load_iris_view()
         self._load_test1_data()
         self._load_test2_data()
@@ -604,18 +756,22 @@
         self._load_raw_sql()
 
     def test_read_sql_iris(self):
+        """ """
         iris_frame = sql.read_sql_query("SELECT * FROM iris", self.conn)
         self._check_iris_loaded_frame(iris_frame)
 
     def test_read_sql_view(self):
+        """ """
         iris_frame = sql.read_sql_query("SELECT * FROM iris_view", self.conn)
         self._check_iris_loaded_frame(iris_frame)
 
     def test_to_sql(self):
+        """ """
         sql.to_sql(self.test_frame1, "test_frame1", self.conn)
         assert sql.has_table("test_frame1", self.conn)
 
     def test_to_sql_fail(self):
+        """ """
         sql.to_sql(self.test_frame1, "test_frame2", self.conn, if_exists="fail")
         assert sql.has_table("test_frame2", self.conn)
 
@@ -624,6 +780,7 @@
             sql.to_sql(self.test_frame1, "test_frame2", self.conn, if_exists="fail")
 
     def test_to_sql_replace(self):
+        """ """
         sql.to_sql(self.test_frame1, "test_frame3", self.conn, if_exists="fail")
         # Add to table again
         sql.to_sql(self.test_frame1, "test_frame3", self.conn, if_exists="replace")
@@ -635,6 +792,7 @@
         assert num_rows == num_entries
 
     def test_to_sql_append(self):
+        """ """
         sql.to_sql(self.test_frame1, "test_frame4", self.conn, if_exists="fail")
 
         # Add to table again
@@ -647,18 +805,21 @@
         assert num_rows == num_entries
 
     def test_to_sql_type_mapping(self):
+        """ """
         sql.to_sql(self.test_frame3, "test_frame5", self.conn, index=False)
         result = sql.read_sql("SELECT * FROM test_frame5", self.conn)
 
         tm.assert_frame_equal(self.test_frame3, result)
 
     def test_to_sql_series(self):
+        """ """
         s = Series(np.arange(5, dtype="int64"), name="series")
         sql.to_sql(s, "test_series", self.conn, index=False)
         s2 = sql.read_sql_query("SELECT * FROM test_series", self.conn)
         tm.assert_frame_equal(s.to_frame(), s2)
 
     def test_roundtrip(self):
+        """ """
         sql.to_sql(self.test_frame1, "test_frame_roundtrip", con=self.conn)
         result = sql.read_sql_query("SELECT * FROM test_frame_roundtrip", con=self.conn)
 
@@ -670,6 +831,7 @@
         tm.assert_frame_equal(result, self.test_frame1)
 
     def test_roundtrip_chunksize(self):
+        """ """
         sql.to_sql(
             self.test_frame1,
             "test_frame_roundtrip",
@@ -681,12 +843,14 @@
         tm.assert_frame_equal(result, self.test_frame1)
 
     def test_execute_sql(self):
+        """ """
         # drop_sql = "DROP TABLE IF EXISTS test"  # should already be done
         iris_results = sql.execute("SELECT * FROM iris", con=self.conn)
         row = iris_results.fetchone()
         tm.equalContents(row, [5.1, 3.5, 1.4, 0.2, "Iris-setosa"])
 
     def test_date_parsing(self):
+        """ """
         # Test date parsing in read_sql
         # No Parsing
         df = sql.read_sql_query("SELECT * FROM types_test_data", self.conn)
@@ -742,6 +906,7 @@
         ]
 
     def test_date_and_index(self):
+        """ """
         # Test case where same column appears in parse_date and index_col
 
         df = sql.read_sql_query(
@@ -755,6 +920,7 @@
         assert issubclass(df.IntDateCol.dtype.type, np.datetime64)
 
     def test_timedelta(self):
+        """ """
 
         # see #6921
         df = to_timedelta(Series(["00:00:01", "00:00:03"], name="foo")).to_frame()
@@ -764,6 +930,7 @@
         tm.assert_series_equal(result["foo"], df["foo"].astype("int64"))
 
     def test_complex_raises(self):
+        """ """
         df = DataFrame({"a": [1 + 1j, 2j]})
         msg = "Complex datatypes not supported"
         with pytest.raises(ValueError, match=msg):
@@ -787,6 +954,21 @@
         ],
     )
     def test_to_sql_index_label(self, index_name, index_label, expected):
+        """
+
+        Parameters
+        ----------
+        index_name :
+            
+        index_label :
+            
+        expected :
+            
+
+        Returns
+        -------
+
+        """
         temp_frame = DataFrame({"col1": range(4)})
         temp_frame.index.name = index_name
         query = "SELECT * FROM test_index_label"
@@ -795,6 +977,7 @@
         assert frame.columns[0] == expected
 
     def test_to_sql_index_label_multiindex(self):
+        """ """
         temp_frame = DataFrame(
             {"col1": range(4)},
             index=MultiIndex.from_product([("A0", "A1"), ("B0", "B1")]),
@@ -845,6 +1028,7 @@
             )
 
     def test_multiindex_roundtrip(self):
+        """ """
         df = DataFrame.from_records(
             [(1, 2.1, "line1"), (2, 1.5, "line2")],
             columns=["A", "B", "C"],
@@ -858,14 +1042,17 @@
         tm.assert_frame_equal(df, result, check_index_type=True)
 
     def test_integer_col_names(self):
+        """ """
         df = DataFrame([[1, 2], [3, 4]], columns=[0, 1])
         sql.to_sql(df, "test_frame_integer_col_names", self.conn, if_exists="replace")
 
     def test_get_schema(self):
+        """ """
         create_sql = sql.get_schema(self.test_frame1, "test", con=self.conn)
         assert "CREATE" in create_sql
 
     def test_get_schema_dtypes(self):
+        """ """
         float_frame = DataFrame({"a": [1.1, 1.2], "b": [2.1, 2.2]})
         dtype = sqlalchemy.Integer if self.mode == "sqlalchemy" else "INTEGER"
         create_sql = sql.get_schema(
@@ -875,6 +1062,7 @@
         assert "INTEGER" in create_sql
 
     def test_get_schema_keys(self):
+        """ """
         frame = DataFrame({"Col1": [1.1, 1.2], "Col2": [2.1, 2.2]})
         create_sql = sql.get_schema(frame, "test", con=self.conn, keys="Col1")
         constraint_sentence = 'CONSTRAINT test_pk PRIMARY KEY ("Col1")'
@@ -888,6 +1076,7 @@
         assert constraint_sentence in create_sql
 
     def test_chunksize_read(self):
+        """ """
         df = DataFrame(np.random.randn(22, 5), columns=list("abcde"))
         df.to_sql("test_chunksize", self.conn, index=False)
 
@@ -922,6 +1111,7 @@
             tm.assert_frame_equal(res1, res3)
 
     def test_categorical(self):
+        """ """
         # GH8624
         # test that categorical gets written correctly as dense column
         df = DataFrame(
@@ -939,11 +1129,13 @@
         tm.assert_frame_equal(res, df)
 
     def test_unicode_column_name(self):
+        """ """
         # GH 11431
         df = DataFrame([[1, 2], [3, 4]], columns=["\xe9", "b"])
         df.to_sql("test_unicode", self.conn, index=False)
 
     def test_escaped_table_name(self):
+        """ """
         # GH 13206
         df = DataFrame({"A": [0, 1, 2], "B": [0.2, np.nan, 5.6]})
         df.to_sql("d1187b08-4943-4c8d-a7f6", self.conn, index=False)
@@ -956,21 +1148,28 @@
 @pytest.mark.single
 @pytest.mark.skipif(not SQLALCHEMY_INSTALLED, reason="SQLAlchemy not installed")
 class TestSQLApi(SQLAlchemyMixIn, _TestSQLApi):
-    """
-    Test the public API as it would be used directly
-
+    """Test the public API as it would be used directly
+    
     Tests for `read_sql_table` are included here, as this is specific for the
     sqlalchemy mode.
 
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
 
     flavor = "sqlite"
     mode = "sqlalchemy"
 
     def connect(self):
+        """ """
         return sqlalchemy.create_engine("sqlite:///:memory:")
 
     def test_read_table_columns(self):
+        """ """
         # test columns argument in read_table
         sql.to_sql(self.test_frame1, "test_frame", self.conn)
 
@@ -979,6 +1178,7 @@
         assert result.columns.tolist() == cols
 
     def test_read_table_index_col(self):
+        """ """
         # test columns argument in read_table
         sql.to_sql(self.test_frame1, "test_frame", self.conn)
 
@@ -995,6 +1195,7 @@
         assert result.columns.tolist() == ["C", "D"]
 
     def test_read_sql_delegate(self):
+        """ """
         iris_frame1 = sql.read_sql_query("SELECT * FROM iris", self.conn)
         iris_frame2 = sql.read_sql("SELECT * FROM iris", self.conn)
         tm.assert_frame_equal(iris_frame1, iris_frame2)
@@ -1004,6 +1205,7 @@
         tm.assert_frame_equal(iris_frame1, iris_frame2)
 
     def test_not_reflect_all_tables(self):
+        """ """
         # create invalid table
         qry = """CREATE TABLE invalid (x INTEGER, y UNKNOWN);"""
         self.conn.execute(qry)
@@ -1020,6 +1222,7 @@
             assert len(w) == 0
 
     def test_warning_case_insensitive_table_name(self):
+        """ """
         # see gh-7815
         #
         # We can't test that this warning is triggered, a the database
@@ -1034,6 +1237,17 @@
             assert len(w) == 0
 
     def _get_index_columns(self, tbl_name):
+        """
+
+        Parameters
+        ----------
+        tbl_name :
+            
+
+        Returns
+        -------
+
+        """
         from sqlalchemy.engine import reflection
 
         insp = reflection.Inspector.from_engine(self.conn)
@@ -1042,6 +1256,7 @@
         return ixs
 
     def test_sqlalchemy_type_mapping(self):
+        """ """
 
         # Test Timestamp objects (no datetime64 because of timezone) (GH9085)
         df = DataFrame(
@@ -1053,6 +1268,7 @@
         assert isinstance(table.table.c["time"].type, sqltypes.TIMESTAMP)
 
     def test_database_uri_string(self):
+        """ """
 
         # Test read_sql and .to_sql method with a database URI (GH10654)
         test_frame1 = self.test_frame1
@@ -1086,6 +1302,7 @@
             sql.read_sql("select * from table", db_uri)
 
     def _make_iris_table_metadata(self):
+        """ """
         sa = sqlalchemy
         metadata = sa.MetaData()
         iris = sa.Table(
@@ -1101,6 +1318,7 @@
         return iris
 
     def test_query_by_text_obj(self):
+        """ """
         # WIP : GH10846
         name_text = sqlalchemy.text("select * from iris where name=:name")
         iris_df = sql.read_sql(name_text, self.conn, params={"name": "Iris-versicolor"})
@@ -1108,6 +1326,7 @@
         assert all_names == {"Iris-versicolor"}
 
     def test_query_by_select_obj(self):
+        """ """
         # WIP : GH10846
         iris = self._make_iris_table_metadata()
 
@@ -1120,12 +1339,21 @@
 
 
 class _EngineToConnMixin:
-    """
-    A mixin that causes setup_connect to create a conn rather than an engine.
-    """
+    """A mixin that causes setup_connect to create a conn rather than an engine."""
 
     @pytest.fixture(autouse=True)
     def setup_method(self, load_iris_data):
+        """
+
+        Parameters
+        ----------
+        load_iris_data :
+            
+
+        Returns
+        -------
+
+        """
         super().load_test_data_and_sql()
         engine = self.conn
         conn = engine.connect()
@@ -1144,23 +1372,33 @@
 
 @pytest.mark.single
 class TestSQLApiConn(_EngineToConnMixin, TestSQLApi):
+    """ """
     pass
 
 
 @pytest.mark.single
 class TestSQLiteFallbackApi(SQLiteMixIn, _TestSQLApi):
-    """
-    Test the public sqlite connection fallback API
-
-    """
+    """Test the public sqlite connection fallback API"""
 
     flavor = "sqlite"
     mode = "fallback"
 
     def connect(self, database=":memory:"):
+        """
+
+        Parameters
+        ----------
+        database :
+             (Default value = ":memory:")
+
+        Returns
+        -------
+
+        """
         return sqlite3.connect(database)
 
     def test_sql_open_close(self):
+        """ """
         # Test if the IO in the database still work if the connection closed
         # between the writing and reading (as in many real situations).
 
@@ -1178,12 +1416,14 @@
 
     @pytest.mark.skipif(SQLALCHEMY_INSTALLED, reason="SQLAlchemy is installed")
     def test_con_string_import_error(self):
+        """ """
         conn = "mysql://root@localhost/pandas_nosetest"
         msg = "Using URI string without sqlalchemy installed"
         with pytest.raises(ImportError, match=msg):
             sql.read_sql("SELECT * FROM iris", conn)
 
     def test_read_sql_delegate(self):
+        """ """
         iris_frame1 = sql.read_sql_query("SELECT * FROM iris", self.conn)
         iris_frame2 = sql.read_sql("SELECT * FROM iris", self.conn)
         tm.assert_frame_equal(iris_frame1, iris_frame2)
@@ -1193,6 +1433,7 @@
             sql.read_sql("iris", self.conn)
 
     def test_safe_names_warning(self):
+        """ """
         # GH 6798
         df = DataFrame([[1, 2], [3, 4]], columns=["a", "b "])  # has a space
         # warns on create table with spaces in names
@@ -1200,11 +1441,25 @@
             sql.to_sql(df, "test_frame3_legacy", self.conn, index=False)
 
     def test_get_schema2(self):
+        """ """
         # without providing a connection object (available for backwards comp)
         create_sql = sql.get_schema(self.test_frame1, "test")
         assert "CREATE" in create_sql
 
     def _get_sqlite_column_type(self, schema, column):
+        """
+
+        Parameters
+        ----------
+        schema :
+            
+        column :
+            
+
+        Returns
+        -------
+
+        """
 
         for col in schema.split("\n"):
             if col.split()[0].strip('""') == column:
@@ -1212,6 +1467,7 @@
         raise ValueError(f"Column {column} not found")
 
     def test_sqlite_type_mapping(self):
+        """ """
 
         # Test Timestamp objects (no datetime64 because of timezone) (GH9085)
         df = DataFrame(
@@ -1228,46 +1484,68 @@
 
 
 class _TestSQLAlchemy(SQLAlchemyMixIn, PandasSQLTest):
-    """
-    Base class for testing the sqlalchemy backend.
-
+    """Base class for testing the sqlalchemy backend.
+    
     Subclasses for specific database types are created below. Tests that
     deviate for each flavor are overwritten there.
 
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
 
     flavor: str
 
     @pytest.fixture(autouse=True, scope="class")
     def setup_class(cls):
+        """ """
         cls.setup_import()
         cls.setup_driver()
         conn = cls.connect()
         conn.connect()
 
     def load_test_data_and_sql(self):
+        """ """
         self._load_raw_sql()
         self._load_test1_data()
 
     @pytest.fixture(autouse=True)
     def setup_method(self, load_iris_data):
+        """
+
+        Parameters
+        ----------
+        load_iris_data :
+            
+
+        Returns
+        -------
+
+        """
         self.load_test_data_and_sql()
 
     @classmethod
     def setup_import(cls):
+        """ """
         # Skip this test if SQLAlchemy not available
         if not SQLALCHEMY_INSTALLED:
             pytest.skip("SQLAlchemy not installed")
 
     @classmethod
     def setup_driver(cls):
+        """ """
         raise NotImplementedError()
 
     @classmethod
     def connect(cls):
+        """ """
         raise NotImplementedError()
 
     def setup_connect(self):
+        """ """
         try:
             self.conn = self.connect()
             self.pandasSQL = sql.SQLDatabase(self.conn)
@@ -1277,36 +1555,47 @@
             pytest.skip(f"Can't connect to {self.flavor} server")
 
     def test_read_sql(self):
+        """ """
         self._read_sql_iris()
 
     def test_read_sql_parameter(self):
+        """ """
         self._read_sql_iris_parameter()
 
     def test_read_sql_named_parameter(self):
+        """ """
         self._read_sql_iris_named_parameter()
 
     def test_to_sql(self):
+        """ """
         self._to_sql()
 
     def test_to_sql_empty(self):
+        """ """
         self._to_sql_empty()
 
     def test_to_sql_fail(self):
+        """ """
         self._to_sql_fail()
 
     def test_to_sql_replace(self):
+        """ """
         self._to_sql_replace()
 
     def test_to_sql_append(self):
+        """ """
         self._to_sql_append()
 
     def test_to_sql_method_multi(self):
+        """ """
         self._to_sql(method="multi")
 
     def test_to_sql_method_callable(self):
+        """ """
         self._to_sql_method_callable()
 
     def test_create_table(self):
+        """ """
         temp_conn = self.connect()
         temp_frame = DataFrame(
             {"one": [1.0, 2.0, 3.0, 4.0], "two": [4.0, 3.0, 2.0, 1.0]}
@@ -1318,6 +1607,7 @@
         assert temp_conn.has_table("temp_frame")
 
     def test_drop_table(self):
+        """ """
         temp_conn = self.connect()
 
         temp_frame = DataFrame(
@@ -1334,27 +1624,33 @@
         assert not temp_conn.has_table("temp_frame")
 
     def test_roundtrip(self):
+        """ """
         self._roundtrip()
 
     def test_execute_sql(self):
+        """ """
         self._execute_sql()
 
     def test_read_table(self):
+        """ """
         iris_frame = sql.read_sql_table("iris", con=self.conn)
         self._check_iris_loaded_frame(iris_frame)
 
     def test_read_table_columns(self):
+        """ """
         iris_frame = sql.read_sql_table(
             "iris", con=self.conn, columns=["SepalLength", "SepalLength"]
         )
         tm.equalContents(iris_frame.columns.values, ["SepalLength", "SepalLength"])
 
     def test_read_table_absent_raises(self):
+        """ """
         msg = "Table this_doesnt_exist not found"
         with pytest.raises(ValueError, match=msg):
             sql.read_sql_table("this_doesnt_exist", con=self.conn)
 
     def test_default_type_conversion(self):
+        """ """
         df = sql.read_sql_table("types_test_data", self.conn)
 
         assert issubclass(df.FloatCol.dtype.type, np.floating)
@@ -1367,6 +1663,7 @@
         assert issubclass(df.BoolColWithNull.dtype.type, object)
 
     def test_bigint(self):
+        """ """
         # int64 should be converted to BigInteger, GH7433
         df = DataFrame(data={"i64": [2 ** 62]})
         df.to_sql("test_bigint", self.conn, index=False)
@@ -1375,6 +1672,7 @@
         tm.assert_frame_equal(df, result)
 
     def test_default_date_load(self):
+        """ """
         df = sql.read_sql_table("types_test_data", self.conn)
 
         # IMPORTANT - sqlite has no native date type, so shouldn't parse, but
@@ -1382,11 +1680,23 @@
         assert issubclass(df.DateCol.dtype.type, np.datetime64)
 
     def test_datetime_with_timezone(self):
+        """ """
         # edge case that converts postgresql datetime with time zone types
         # to datetime64[ns,psycopg2.tz.FixedOffsetTimezone..], which is ok
         # but should be more natural, so coerce to datetime64[ns] for now
 
         def check(col):
+            """
+
+            Parameters
+            ----------
+            col :
+                
+
+            Returns
+            -------
+
+            """
             # check that a column is either datetime64[ns]
             # or datetime64[ns, UTC]
             if is_datetime64_dtype(col.dtype):
@@ -1462,6 +1772,7 @@
         check(df.DateColWithTz)
 
     def test_datetime_with_timezone_roundtrip(self):
+        """ """
         # GH 9086
         # Write datetimetz data to a db and read it back
         # For dbs that support timestamps with timezones, should get back UTC
@@ -1489,6 +1800,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_out_of_bounds_datetime(self):
+        """ """
         # GH 26761
         data = pd.DataFrame({"date": datetime(9999, 1, 1)}, index=[0])
         data.to_sql("test_datetime_obb", self.conn, index=False)
@@ -1497,6 +1809,7 @@
         tm.assert_frame_equal(result, expected)
 
     def test_naive_datetimeindex_roundtrip(self):
+        """ """
         # GH 23510
         # Ensure that a naive DatetimeIndex isn't converted to UTC
         dates = date_range("2018-01-01", periods=5, freq="6H")._with_freq(None)
@@ -1507,6 +1820,7 @@
         tm.assert_frame_equal(result, expected, check_names=False)
 
     def test_date_parsing(self):
+        """ """
         # No Parsing
         df = sql.read_sql_table("types_test_data", self.conn)
         expected_type = object if self.flavor == "sqlite" else np.datetime64
@@ -1543,6 +1857,7 @@
         assert issubclass(df.IntDateCol.dtype.type, np.datetime64)
 
     def test_datetime(self):
+        """ """
         df = DataFrame(
             {"A": date_range("2013-01-01 09:00:00", periods=3), "B": np.arange(3.0)}
         )
@@ -1564,6 +1879,7 @@
             tm.assert_frame_equal(result, df)
 
     def test_datetime_NaT(self):
+        """ """
         df = DataFrame(
             {"A": date_range("2013-01-01 09:00:00", periods=3), "B": np.arange(3.0)}
         )
@@ -1584,6 +1900,7 @@
             tm.assert_frame_equal(result, df)
 
     def test_datetime_date(self):
+        """ """
         # test support for datetime.date
         df = DataFrame([date(2014, 1, 1), date(2014, 1, 2)], columns=["a"])
         df.to_sql("test_date", self.conn, index=False)
@@ -1594,6 +1911,7 @@
         tm.assert_series_equal(result, expected)
 
     def test_datetime_time(self):
+        """ """
         # test support for datetime.time
         df = DataFrame([time(9, 0, 0), time(9, 1, 30)], columns=["a"])
         df.to_sql("test_time", self.conn, index=False)
@@ -1617,6 +1935,7 @@
         tm.assert_frame_equal(df, res)
 
     def test_mixed_dtype_insert(self):
+        """ """
         # see GH6509
         s1 = Series(2 ** 25 + 1, dtype=np.int32)
         s2 = Series(0.0, dtype=np.float32)
@@ -1629,6 +1948,7 @@
         tm.assert_frame_equal(df, df2, check_dtype=False, check_exact=True)
 
     def test_nan_numeric(self):
+        """ """
         # NaNs in numeric float column
         df = DataFrame({"A": [0, 1, 2], "B": [0.2, np.nan, 5.6]})
         df.to_sql("test_nan", self.conn, index=False)
@@ -1642,6 +1962,7 @@
         tm.assert_frame_equal(result, df)
 
     def test_nan_fullcolumn(self):
+        """ """
         # full NaN column (numeric float column)
         df = DataFrame({"A": [0, 1, 2], "B": [np.nan, np.nan, np.nan]})
         df.to_sql("test_nan", self.conn, index=False)
@@ -1657,6 +1978,7 @@
         tm.assert_frame_equal(result, df)
 
     def test_nan_string(self):
+        """ """
         # NaNs in string column
         df = DataFrame({"A": [0, 1, 2], "B": ["a", "b", np.nan]})
         df.to_sql("test_nan", self.conn, index=False)
@@ -1673,6 +1995,17 @@
         tm.assert_frame_equal(result, df)
 
     def _get_index_columns(self, tbl_name):
+        """
+
+        Parameters
+        ----------
+        tbl_name :
+            
+
+        Returns
+        -------
+
+        """
         from sqlalchemy.engine import reflection
 
         insp = reflection.Inspector.from_engine(self.conn)
@@ -1681,12 +2014,15 @@
         return ixs
 
     def test_to_sql_save_index(self):
+        """ """
         self._to_sql_save_index()
 
     def test_transactions(self):
+        """ """
         self._transaction_test()
 
     def test_get_schema_create_table(self):
+        """ """
         # Use a dataframe without a bool column, since MySQL converts bool to
         # TINYINT (which read_sql_table returns as an int and causes a dtype
         # mismatch)
@@ -1703,6 +2039,7 @@
         self.drop_table(tbl)
 
     def test_dtype(self):
+        """ """
         cols = ["A", "B"]
         data = [(0.8, True), (0.9, None)]
         df = DataFrame(data, columns=cols)
@@ -1733,6 +2070,7 @@
         assert isinstance(sqltypeb, sqlalchemy.TEXT)
 
     def test_notna_dtype(self):
+        """ """
         cols = {
             "Bool": Series([True, None]),
             "Date": Series([datetime(2012, 5, 1), None]),
@@ -1759,6 +2097,7 @@
         assert isinstance(col_dict["Float"].type, sqltypes.Float)
 
     def test_double_precision(self):
+        """ """
         V = 1.23456789101112131415
 
         df = DataFrame(
@@ -1794,17 +2133,53 @@
         assert isinstance(col_dict["i64"].type, sqltypes.BigInteger)
 
     def test_connectable_issue_example(self):
+        """ """
         # This tests the example raised in issue
         # https://github.com/pandas-dev/pandas/issues/10104
 
         def foo(connection):
+            """
+
+            Parameters
+            ----------
+            connection :
+                
+
+            Returns
+            -------
+
+            """
             query = "SELECT test_foo_data FROM test_foo_data"
             return sql.read_sql_query(query, con=connection)
 
         def bar(connection, data):
+            """
+
+            Parameters
+            ----------
+            connection :
+                
+            data :
+                
+
+            Returns
+            -------
+
+            """
             data.to_sql(name="test_foo_data", con=connection, if_exists="append")
 
         def main(connectable):
+            """
+
+            Parameters
+            ----------
+            connectable :
+                
+
+            Returns
+            -------
+
+            """
             with connectable.connect() as conn:
                 with conn.begin():
                     foo_data = conn.run_callable(foo)
@@ -1818,6 +2193,17 @@
         [{"foo": [np.inf]}, {"foo": [-np.inf]}, {"foo": [-np.inf], "infe0": ["bar"]}],
     )
     def test_to_sql_with_negative_npinf(self, input):
+        """
+
+        Parameters
+        ----------
+        input :
+            
+
+        Returns
+        -------
+
+        """
         # GH 34431
 
         df = pd.DataFrame(input)
@@ -1832,11 +2218,13 @@
             tm.assert_equal(df, res)
 
     def test_temporary_table(self):
+        """ """
         test_data = "Hello, World!"
         expected = DataFrame({"spam": [test_data]})
         Base = declarative.declarative_base()
 
         class Temporary(Base):
+            """ """
             __tablename__ = "temp_test"
             __table_args__ = {"prefixes": ["TEMPORARY"]}
             id = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True)
@@ -1855,28 +2243,30 @@
 
 
 class _TestSQLAlchemyConn(_EngineToConnMixin, _TestSQLAlchemy):
+    """ """
     def test_transactions(self):
+        """ """
         pytest.skip("Nested transactions rollbacks don't work with Pandas")
 
 
 class _TestSQLiteAlchemy:
-    """
-    Test the sqlalchemy backend against an in-memory sqlite database.
-
-    """
+    """Test the sqlalchemy backend against an in-memory sqlite database."""
 
     flavor = "sqlite"
 
     @classmethod
     def connect(cls):
+        """ """
         return sqlalchemy.create_engine("sqlite:///:memory:")
 
     @classmethod
     def setup_driver(cls):
+        """ """
         # sqlite3 is built-in
         cls.driver = None
 
     def test_default_type_conversion(self):
+        """ """
         df = sql.read_sql_table("types_test_data", self.conn)
 
         assert issubclass(df.FloatCol.dtype.type, np.floating)
@@ -1892,12 +2282,14 @@
         assert issubclass(df.BoolColWithNull.dtype.type, np.floating)
 
     def test_default_date_load(self):
+        """ """
         df = sql.read_sql_table("types_test_data", self.conn)
 
         # IMPORTANT - sqlite has no native date type, so shouldn't parse, but
         assert not issubclass(df.DateCol.dtype.type, np.datetime64)
 
     def test_bigint_warning(self):
+        """ """
         # test no warning for BIGINT (to support int64) is raised (GH7433)
         df = DataFrame({"a": [1, 2]}, dtype="int64")
         df.to_sql("test_bigintwarning", self.conn, index=False)
@@ -1909,15 +2301,13 @@
 
 
 class _TestMySQLAlchemy:
-    """
-    Test the sqlalchemy backend against an MySQL database.
-
-    """
+    """Test the sqlalchemy backend against an MySQL database."""
 
     flavor = "mysql"
 
     @classmethod
     def connect(cls):
+        """ """
         return sqlalchemy.create_engine(
             f"mysql+{cls.driver}://root@localhost/pandas_nosetest",
             connect_args=cls.connect_args,
@@ -1925,11 +2315,13 @@
 
     @classmethod
     def setup_driver(cls):
+        """ """
         pymysql = pytest.importorskip("pymysql")
         cls.driver = "pymysql"
         cls.connect_args = {"client_flag": pymysql.constants.CLIENT.MULTI_STATEMENTS}
 
     def test_default_type_conversion(self):
+        """ """
         df = sql.read_sql_table("types_test_data", self.conn)
 
         assert issubclass(df.FloatCol.dtype.type, np.floating)
@@ -1945,6 +2337,7 @@
         assert issubclass(df.BoolColWithNull.dtype.type, np.floating)
 
     def test_read_procedure(self):
+        """ """
         import pymysql
 
         # see GH7324. Although it is more an api test, it is added to the
@@ -1978,25 +2371,25 @@
 
 
 class _TestPostgreSQLAlchemy:
-    """
-    Test the sqlalchemy backend against an PostgreSQL database.
-
-    """
+    """Test the sqlalchemy backend against an PostgreSQL database."""
 
     flavor = "postgresql"
 
     @classmethod
     def connect(cls):
+        """ """
         return sqlalchemy.create_engine(
             f"postgresql+{cls.driver}://postgres@localhost/pandas_nosetest"
         )
 
     @classmethod
     def setup_driver(cls):
+        """ """
         pytest.importorskip("psycopg2")
         cls.driver = "psycopg2"
 
     def test_schema_support(self):
+        """ """
         # only test this for postgresql (schema's not supported in
         # mysql/sqlite)
         df = DataFrame({"col1": [1, 2], "col2": [0.1, 0.2], "col3": ["a", "n"]})
@@ -2068,10 +2461,28 @@
             tm.assert_frame_equal(res1, res2)
 
     def test_copy_from_callable_insertion_method(self):
+        """ """
         # GH 8953
         # Example in io.rst found under _io.sql.method
         # not available in sqlite, mysql
         def psql_insert_copy(table, conn, keys, data_iter):
+            """
+
+            Parameters
+            ----------
+            table :
+                
+            conn :
+                
+            keys :
+                
+            data_iter :
+                
+
+            Returns
+            -------
+
+            """
             # gets a DBAPI connection that can provide a cursor
             dbapi_conn = conn.connection
             with dbapi_conn.cursor() as cur:
@@ -2100,34 +2511,40 @@
 @pytest.mark.single
 @pytest.mark.db
 class TestMySQLAlchemy(_TestMySQLAlchemy, _TestSQLAlchemy):
+    """ """
     pass
 
 
 @pytest.mark.single
 @pytest.mark.db
 class TestMySQLAlchemyConn(_TestMySQLAlchemy, _TestSQLAlchemyConn):
+    """ """
     pass
 
 
 @pytest.mark.single
 @pytest.mark.db
 class TestPostgreSQLAlchemy(_TestPostgreSQLAlchemy, _TestSQLAlchemy):
+    """ """
     pass
 
 
 @pytest.mark.single
 @pytest.mark.db
 class TestPostgreSQLAlchemyConn(_TestPostgreSQLAlchemy, _TestSQLAlchemyConn):
+    """ """
     pass
 
 
 @pytest.mark.single
 class TestSQLiteAlchemy(_TestSQLiteAlchemy, _TestSQLAlchemy):
+    """ """
     pass
 
 
 @pytest.mark.single
 class TestSQLiteAlchemyConn(_TestSQLiteAlchemy, _TestSQLAlchemyConn):
+    """ """
     pass
 
 
@@ -2137,57 +2554,78 @@
 
 @pytest.mark.single
 class TestSQLiteFallback(SQLiteMixIn, PandasSQLTest):
-    """
-    Test the fallback mode against an in-memory sqlite database.
-
-    """
+    """Test the fallback mode against an in-memory sqlite database."""
 
     flavor = "sqlite"
 
     @classmethod
     def connect(cls):
+        """ """
         return sqlite3.connect(":memory:")
 
     def setup_connect(self):
+        """ """
         self.conn = self.connect()
 
     def load_test_data_and_sql(self):
+        """ """
         self.pandasSQL = sql.SQLiteDatabase(self.conn)
         self._load_test1_data()
 
     @pytest.fixture(autouse=True)
     def setup_method(self, load_iris_data):
+        """
+
+        Parameters
+        ----------
+        load_iris_data :
+            
+
+        Returns
+        -------
+
+        """
         self.load_test_data_and_sql()
 
     def test_read_sql(self):
+        """ """
         self._read_sql_iris()
 
     def test_read_sql_parameter(self):
+        """ """
         self._read_sql_iris_parameter()
 
     def test_read_sql_named_parameter(self):
+        """ """
         self._read_sql_iris_named_parameter()
 
     def test_to_sql(self):
+        """ """
         self._to_sql()
 
     def test_to_sql_empty(self):
+        """ """
         self._to_sql_empty()
 
     def test_to_sql_fail(self):
+        """ """
         self._to_sql_fail()
 
     def test_to_sql_replace(self):
+        """ """
         self._to_sql_replace()
 
     def test_to_sql_append(self):
+        """ """
         self._to_sql_append()
 
     def test_to_sql_method_multi(self):
+        """ """
         # GH 29921
         self._to_sql(method="multi")
 
     def test_create_and_drop_table(self):
+        """ """
         temp_frame = DataFrame(
             {"one": [1.0, 2.0, 3.0, 4.0], "two": [4.0, 3.0, 2.0, 1.0]}
         )
@@ -2201,12 +2639,15 @@
         assert not self.pandasSQL.has_table("drop_test_frame")
 
     def test_roundtrip(self):
+        """ """
         self._roundtrip()
 
     def test_execute_sql(self):
+        """ """
         self._execute_sql()
 
     def test_datetime_date(self):
+        """ """
         # test support for datetime.date
         df = DataFrame([date(2014, 1, 1), date(2014, 1, 2)], columns=["a"])
         df.to_sql("test_date", self.conn, index=False)
@@ -2218,6 +2659,7 @@
             tm.assert_frame_equal(res, df)
 
     def test_datetime_time(self):
+        """ """
         # test support for datetime.time, GH #8341
         df = DataFrame([time(9, 0, 0), time(9, 1, 30)], columns=["a"])
         df.to_sql("test_time", self.conn, index=False)
@@ -2228,6 +2670,17 @@
             tm.assert_frame_equal(res, expected)
 
     def _get_index_columns(self, tbl_name):
+        """
+
+        Parameters
+        ----------
+        tbl_name :
+            
+
+        Returns
+        -------
+
+        """
         ixs = sql.read_sql_query(
             "SELECT * FROM sqlite_master WHERE type = 'index' "
             + f"AND tbl_name = '{tbl_name}'",
@@ -2240,12 +2693,27 @@
         return ix_cols
 
     def test_to_sql_save_index(self):
+        """ """
         self._to_sql_save_index()
 
     def test_transactions(self):
+        """ """
         self._transaction_test()
 
     def _get_sqlite_column_type(self, table, column):
+        """
+
+        Parameters
+        ----------
+        table :
+            
+        column :
+            
+
+        Returns
+        -------
+
+        """
         recs = self.conn.execute(f"PRAGMA table_info({table})")
         for cid, name, ctype, not_null, default, pk in recs:
             if name == column:
@@ -2253,6 +2721,7 @@
         raise ValueError(f"Table {table}, column {column} not found")
 
     def test_dtype(self):
+        """ """
         if self.flavor == "mysql":
             pytest.skip("Not applicable to MySQL legacy")
         cols = ["A", "B"]
@@ -2275,6 +2744,7 @@
         assert self._get_sqlite_column_type("single_dtype_test", "B") == "STRING"
 
     def test_notna_dtype(self):
+        """ """
         if self.flavor == "mysql":
             pytest.skip("Not applicable to MySQL legacy")
 
@@ -2295,6 +2765,7 @@
         assert self._get_sqlite_column_type(tbl, "Float") == "REAL"
 
     def test_illegal_names(self):
+        """ """
         # For sqlite, these should work fine
         df = DataFrame([[1, 2], [3, 4]], columns=["a", "b"])
 
@@ -2330,7 +2801,17 @@
 
 
 def date_format(dt):
-    """Returns date in YYYYMMDD format."""
+    """Returns date in YYYYMMDD format.
+
+    Parameters
+    ----------
+    dt :
+        
+
+    Returns
+    -------
+
+    """
     return dt.strftime("%Y%m%d")
 
 
@@ -2350,6 +2831,16 @@
 def format_query(sql, *args):
     """
 
+    Parameters
+    ----------
+    sql :
+        
+    *args :
+        
+
+    Returns
+    -------
+
     """
     processed_args = []
     for arg in args:
@@ -2363,7 +2854,21 @@
 
 
 def tquery(query, con=None, cur=None):
-    """Replace removed sql.tquery function"""
+    """Replace removed sql.tquery function
+
+    Parameters
+    ----------
+    query :
+        
+    con :
+         (Default value = None)
+    cur :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     res = sql.execute(query, con=con, cur=cur).fetchall()
     if res is None:
         return None
@@ -2373,8 +2878,22 @@
 
 @pytest.mark.single
 class TestXSQLite(SQLiteMixIn):
+    """ """
     @pytest.fixture(autouse=True)
     def setup_method(self, request, datapath):
+        """
+
+        Parameters
+        ----------
+        request :
+            
+        datapath :
+            
+
+        Returns
+        -------
+
+        """
         self.method = request.function
         self.conn = sqlite3.connect(":memory:")
 
@@ -2385,10 +2904,12 @@
         self.conn = sqlite3.connect(":memory:")
 
     def test_basic(self):
+        """ """
         frame = tm.makeTimeDataFrame()
         self._check_roundtrip(frame)
 
     def test_write_row_by_row(self):
+        """ """
 
         frame = tm.makeTimeDataFrame()
         frame.iloc[0, 0] = np.nan
@@ -2410,6 +2931,7 @@
         tm.assert_frame_equal(result, frame, rtol=1e-3)
 
     def test_execute(self):
+        """ """
         frame = tm.makeTimeDataFrame()
         create_sql = sql.get_schema(frame, "test")
         cur = self.conn.cursor()
@@ -2425,6 +2947,7 @@
         tm.assert_frame_equal(result, frame[:1])
 
     def test_schema(self):
+        """ """
         frame = tm.makeTimeDataFrame()
         create_sql = sql.get_schema(frame, "test")
         lines = create_sql.splitlines()
@@ -2441,7 +2964,7 @@
         cur.execute(create_sql)
 
     def test_execute_fail(self):
-        create_sql = """
+        """create_sql = """
         CREATE TABLE test
         (
         a TEXT,
@@ -2449,7 +2972,12 @@
         c REAL,
         PRIMARY KEY (a, b)
         );
-        """
+
+        Parameters
+        ----------
+
+        Returns
+        -------
         cur = self.conn.cursor()
         cur.execute(create_sql)
 
@@ -2460,7 +2988,7 @@
             sql.execute('INSERT INTO test VALUES("foo", "bar", 7)', self.conn)
 
     def test_execute_closed_connection(self):
-        create_sql = """
+        """create_sql = """
         CREATE TABLE test
         (
         a TEXT,
@@ -2468,7 +2996,12 @@
         c REAL,
         PRIMARY KEY (a, b)
         );
-        """
+
+        Parameters
+        ----------
+
+        Returns
+        -------
         cur = self.conn.cursor()
         cur.execute(create_sql)
 
@@ -2479,9 +3012,21 @@
             tquery("select * from test", con=self.conn)
 
     def test_na_roundtrip(self):
+        """ """
         pass
 
     def _check_roundtrip(self, frame):
+        """
+
+        Parameters
+        ----------
+        frame :
+            
+
+        Returns
+        -------
+
+        """
         sql.to_sql(frame, name="test_table", con=self.conn, index=False)
         result = sql.read_sql("select * from test_table", self.conn)
 
@@ -2503,10 +3048,12 @@
         tm.assert_frame_equal(expected, result)
 
     def test_keyword_as_column_names(self):
+        """ """
         df = DataFrame({"From": np.ones(5)})
         sql.to_sql(df, con=self.conn, name="testkeywords", index=False)
 
     def test_onecolumn_of_integer(self):
+        """ """
         # GH 3628
         # a column_of_integers dataframe should transfer well to sql
 
@@ -2522,15 +3069,24 @@
         tm.assert_frame_equal(result, mono_df)
 
     def test_if_exists(self):
+        """ """
         df_if_exists_1 = DataFrame({"col1": [1, 2], "col2": ["A", "B"]})
         df_if_exists_2 = DataFrame({"col1": [3, 4, 5], "col2": ["C", "D", "E"]})
         table_name = "table_if_exists"
         sql_select = f"SELECT * FROM {table_name}"
 
         def clean_up(test_table_to_drop):
-            """
-            Drops tables created from individual tests
+            """Drops tables created from individual tests
             so no dependencies arise from sequential tests
+
+            Parameters
+            ----------
+            test_table_to_drop :
+                
+
+            Returns
+            -------
+
             """
             self.drop_table(test_table_to_drop)
 
@@ -2604,8 +3160,10 @@
     reason="gh-13611: there is no support for MySQL if SQLAlchemy is not installed"
 )
 class TestXMySQL(MySQLMixIn):
+    """ """
     @pytest.fixture(autouse=True, scope="class")
     def setup_class(cls):
+        """ """
         pymysql = pytest.importorskip("pymysql")
         pymysql.connect(host="localhost", user="root", passwd="", db="pandas_nosetest")
         try:
@@ -2626,6 +3184,19 @@
 
     @pytest.fixture(autouse=True)
     def setup_method(self, request, datapath):
+        """
+
+        Parameters
+        ----------
+        request :
+            
+        datapath :
+            
+
+        Returns
+        -------
+
+        """
         pymysql = pytest.importorskip("pymysql")
         pymysql.connect(host="localhost", user="root", passwd="", db="pandas_nosetest")
         try:
@@ -2647,10 +3218,12 @@
         self.method = request.function
 
     def test_basic(self):
+        """ """
         frame = tm.makeTimeDataFrame()
         self._check_roundtrip(frame)
 
     def test_write_row_by_row(self):
+        """ """
         frame = tm.makeTimeDataFrame()
         frame.iloc[0, 0] = np.nan
         drop_sql = "DROP TABLE IF EXISTS test"
@@ -2672,6 +3245,7 @@
         #  no obvious pattern
 
     def test_chunksize_read_type(self):
+        """ """
         frame = tm.makeTimeDataFrame()
         frame.index.name = "index"
         drop_sql = "DROP TABLE IF EXISTS test"
@@ -2687,6 +3261,7 @@
         tm.assert_frame_equal(frame[:chunksize], chunk_df)
 
     def test_execute(self):
+        """ """
         frame = tm.makeTimeDataFrame()
         drop_sql = "DROP TABLE IF EXISTS test"
         create_sql = sql.get_schema(frame, "test")
@@ -2706,6 +3281,7 @@
         tm.assert_frame_equal(result, frame[:1])
 
     def test_schema(self):
+        """ """
         frame = tm.makeTimeDataFrame()
         create_sql = sql.get_schema(frame, "test")
         lines = create_sql.splitlines()
@@ -2724,6 +3300,7 @@
         cur.execute(create_sql)
 
     def test_execute_fail(self):
+        """ """
         drop_sql = "DROP TABLE IF EXISTS test"
         create_sql = """
         CREATE TABLE test
@@ -2745,6 +3322,19 @@
             sql.execute('INSERT INTO test VALUES("foo", "bar", 7)', self.conn)
 
     def test_execute_closed_connection(self, request, datapath):
+        """
+
+        Parameters
+        ----------
+        request :
+            
+        datapath :
+            
+
+        Returns
+        -------
+
+        """
         drop_sql = "DROP TABLE IF EXISTS test"
         create_sql = """
         CREATE TABLE test
@@ -2769,9 +3359,21 @@
         self.setup_method(request, datapath)
 
     def test_na_roundtrip(self):
+        """ """
         pass
 
     def _check_roundtrip(self, frame):
+        """
+
+        Parameters
+        ----------
+        frame :
+            
+
+        Returns
+        -------
+
+        """
         drop_sql = "DROP TABLE IF EXISTS test_table"
         cur = self.conn.cursor()
         with warnings.catch_warnings():
@@ -2806,21 +3408,31 @@
         tm.assert_frame_equal(expected, result)
 
     def test_keyword_as_column_names(self):
+        """ """
         df = DataFrame({"From": np.ones(5)})
         sql.to_sql(
             df, con=self.conn, name="testkeywords", if_exists="replace", index=False
         )
 
     def test_if_exists(self):
+        """ """
         df_if_exists_1 = DataFrame({"col1": [1, 2], "col2": ["A", "B"]})
         df_if_exists_2 = DataFrame({"col1": [3, 4, 5], "col2": ["C", "D", "E"]})
         table_name = "table_if_exists"
         sql_select = f"SELECT * FROM {table_name}"
 
         def clean_up(test_table_to_drop):
-            """
-            Drops tables created from individual tests
+            """Drops tables created from individual tests
             so no dependencies arise from sequential tests
+
+            Parameters
+            ----------
+            test_table_to_drop :
+                
+
+            Returns
+            -------
+
             """
             self.drop_table(test_table_to_drop)
 
