# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/bleach/linkifier.py
+++ b/..//venv/lib/python3.8/site-packages/bleach/linkifier.py
@@ -31,15 +31,25 @@
 
 def build_url_re(tlds=TLDS, protocols=html5lib_shim.allowed_protocols):
     """Builds the url regex used by linkifier
-
+    
     If you want a different set of tlds or allowed protocols, pass those in
     and stomp on the existing ``url_re``::
-
+    
         from bleach import linkifier
-
+    
         my_url_re = linkifier.build_url_re(my_tlds_list, my_protocols)
-
+    
         linker = LinkifyFilter(url_re=my_url_re)
+
+    Parameters
+    ----------
+    tlds :
+         (Default value = TLDS)
+    protocols :
+         (Default value = html5lib_shim.allowed_protocols)
+
+    Returns
+    -------
 
     """
     return re.compile(
@@ -64,14 +74,22 @@
 
 def build_email_re(tlds=TLDS):
     """Builds the email regex used by linkifier
-
+    
     If you want a different set of tlds, pass those in and stomp on the existing ``email_re``::
-
+    
         from bleach import linkifier
-
+    
         my_email_re = linkifier.build_email_re(my_tlds_list)
-
+    
         linker = LinkifyFilter(email_re=my_url_re)
+
+    Parameters
+    ----------
+    tlds :
+         (Default value = TLDS)
+
+    Returns
+    -------
 
     """
     # open and closing braces doubled below for format string
@@ -94,16 +112,22 @@
 
 class Linker(object):
     """Convert URL-like strings in an HTML fragment to links
-
+    
     This function converts strings that look like URLs, domain names and email
     addresses in text that may be an HTML fragment to links, while preserving:
-
+    
     1. links already in the string
     2. urls found in attributes
     3. email addresses
-
+    
     linkify does a best-effort approach and tries to recover from bad
     situations due to crazy text.
+
+    Parameters
+    ----------
+
+    Returns
+    -------
 
     """
 
@@ -163,12 +187,23 @@
 
     def linkify(self, text):
         """Linkify specified text
-
+        
         :arg str text: the text to add links to
 
-        :returns: linkified text as unicode
-
-        :raises TypeError: if ``text`` is not a text type
+        Parameters
+        ----------
+        text :
+            
+
+        Returns
+        -------
+        type
+            linkified text as unicode
+
+        Raises
+        ------
+        TypeError
+            if ``text`` is not a text type
 
         """
         if not isinstance(text, six.string_types):
@@ -193,15 +228,21 @@
 
 class LinkifyFilter(html5lib_shim.Filter):
     """html5lib filter that linkifies text
-
+    
     This will do the following:
-
+    
     * convert email addresses into links
     * convert urls into links
     * edit existing links by running them through callbacks--the default is to
       add a ``rel="nofollow"``
-
+    
     This filter can be used anywhere html5lib filters can be used.
+
+    Parameters
+    ----------
+
+    Returns
+    -------
 
     """
 
@@ -243,16 +284,26 @@
 
     def apply_callbacks(self, attrs, is_new):
         """Given an attrs dict and an is_new bool, runs through callbacks
-
+        
         Callbacks can return an adjusted attrs dict or ``None``. In the case of
         ``None``, we stop going through callbacks and return that and the link
         gets dropped.
-
+        
         :arg dict attrs: map of ``(namespace, name)`` -> ``value``
-
+        
         :arg bool is_new: whether or not this link was added by linkify
 
-        :returns: adjusted attrs dict or ``None``
+        Parameters
+        ----------
+        attrs :
+            
+        is_new :
+            
+
+        Returns
+        -------
+        type
+            adjusted attrs dict or ``None``
 
         """
         for cb in self.callbacks:
@@ -262,7 +313,17 @@
         return attrs
 
     def extract_character_data(self, token_list):
-        """Extracts and squashes character sequences in a token stream"""
+        """Extracts and squashes character sequences in a token stream
+
+        Parameters
+        ----------
+        token_list :
+            
+
+        Returns
+        -------
+
+        """
         # FIXME(willkg): This is a terrible idea. What it does is drop all the
         # tags from the token list and merge the Characters and SpaceCharacters
         # tokens into a single text.
@@ -289,7 +350,17 @@
         return "".join(out)
 
     def handle_email_addresses(self, src_iter):
-        """Handle email addresses in character tokens"""
+        """Handle email addresses in character tokens
+
+        Parameters
+        ----------
+        src_iter :
+            
+
+        Returns
+        -------
+
+        """
         for token in src_iter:
             if token["type"] == "Characters":
                 text = token["data"]
@@ -345,8 +416,16 @@
 
     def strip_non_url_bits(self, fragment):
         """Strips non-url bits from the url
-
+        
         This accounts for over-eager matching by the regex.
+
+        Parameters
+        ----------
+        fragment :
+            
+
+        Returns
+        -------
 
         """
         prefix = suffix = ""
@@ -392,7 +471,17 @@
         return fragment, prefix, suffix
 
     def handle_links(self, src_iter):
-        """Handle links in character tokens"""
+        """Handle links in character tokens
+
+        Parameters
+        ----------
+        src_iter :
+            
+
+        Returns
+        -------
+
+        """
         in_a = False  # happens, if parse_email=True and if a mail was found
         for token in src_iter:
             if in_a:
@@ -473,11 +562,19 @@
 
     def handle_a_tag(self, token_buffer):
         """Handle the "a" tag
-
+        
         This could adjust the link or drop it altogether depending on what the
         callbacks return.
-
+        
         This yields the new set of tokens.
+
+        Parameters
+        ----------
+        token_buffer :
+            
+
+        Returns
+        -------
 
         """
         a_token = token_buffer[0]
