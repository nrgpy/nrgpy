# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pycparser/ply/lex.py
+++ b/..//venv/lib/python3.8/site-packages/pycparser/ply/lex.py
@@ -55,6 +55,7 @@
 # Exception thrown when invalid token encountered and no default error
 # handler is defined.
 class LexError(Exception):
+    """ """
     def __init__(self, message, s):
         self.args = (message,)
         self.text = s
@@ -62,6 +63,7 @@
 
 # Token class.  This class is used to represent the tokens produced.
 class LexToken(object):
+    """ """
     def __str__(self):
         return 'LexToken(%s,%r,%d,%d)' % (self.type, self.value, self.lineno, self.lexpos)
 
@@ -73,16 +75,62 @@
 # logging module.
 
 class PlyLogger(object):
+    """ """
     def __init__(self, f):
         self.f = f
 
     def critical(self, msg, *args, **kwargs):
+        """
+
+        Parameters
+        ----------
+        msg :
+            
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         self.f.write((msg % args) + '\n')
 
     def warning(self, msg, *args, **kwargs):
+        """
+
+        Parameters
+        ----------
+        msg :
+            
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         self.f.write('WARNING: ' + (msg % args) + '\n')
 
     def error(self, msg, *args, **kwargs):
+        """
+
+        Parameters
+        ----------
+        msg :
+            
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         self.f.write('ERROR: ' + (msg % args) + '\n')
 
     info = critical
@@ -91,6 +139,7 @@
 
 # Null logger is used when no output is generated. Does nothing.
 class NullLogger(object):
+    """ """
     def __getattribute__(self, name):
         return self
 
@@ -113,6 +162,7 @@
 # -----------------------------------------------------------------------------
 
 class Lexer:
+    """ """
     def __init__(self):
         self.lexre = None             # Master regular expression. This is a list of
                                       # tuples (re, findex) where re is a compiled
@@ -142,6 +192,17 @@
         self.lexoptimize = False      # Optimized mode
 
     def clone(self, object=None):
+        """
+
+        Parameters
+        ----------
+        object :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         c = copy.copy(self)
 
         # If the object parameter has been supplied, it means we are attaching the
@@ -172,6 +233,19 @@
     # writetab() - Write lexer information to a table file
     # ------------------------------------------------------------
     def writetab(self, lextab, outputdir=''):
+        """
+
+        Parameters
+        ----------
+        lextab :
+            
+        outputdir :
+             (Default value = '')
+
+        Returns
+        -------
+
+        """
         if isinstance(lextab, types.ModuleType):
             raise IOError("Won't overwrite existing lextab module")
         basetabmodule = lextab.split('.')[-1]
@@ -209,6 +283,19 @@
     # readtab() - Read lexer information from a tab file
     # ------------------------------------------------------------
     def readtab(self, tabfile, fdict):
+        """
+
+        Parameters
+        ----------
+        tabfile :
+            
+        fdict :
+            
+
+        Returns
+        -------
+
+        """
         if isinstance(tabfile, types.ModuleType):
             lextab = tabfile
         else:
@@ -249,6 +336,17 @@
     # input() - Push a new string into the lexer
     # ------------------------------------------------------------
     def input(self, s):
+        """
+
+        Parameters
+        ----------
+        s :
+            
+
+        Returns
+        -------
+
+        """
         # Pull off the first character to see if s looks like a string
         c = s[:1]
         if not isinstance(c, StringTypes):
@@ -261,6 +359,17 @@
     # begin() - Changes the lexing state
     # ------------------------------------------------------------
     def begin(self, state):
+        """
+
+        Parameters
+        ----------
+        state :
+            
+
+        Returns
+        -------
+
+        """
         if state not in self.lexstatere:
             raise ValueError('Undefined state')
         self.lexre = self.lexstatere[state]
@@ -274,6 +383,17 @@
     # push_state() - Changes the lexing state and saves old on stack
     # ------------------------------------------------------------
     def push_state(self, state):
+        """
+
+        Parameters
+        ----------
+        state :
+            
+
+        Returns
+        -------
+
+        """
         self.lexstatestack.append(self.lexstate)
         self.begin(state)
 
@@ -281,18 +401,31 @@
     # pop_state() - Restores the previous state
     # ------------------------------------------------------------
     def pop_state(self):
+        """ """
         self.begin(self.lexstatestack.pop())
 
     # ------------------------------------------------------------
     # current_state() - Returns the current lexing state
     # ------------------------------------------------------------
     def current_state(self):
+        """ """
         return self.lexstate
 
     # ------------------------------------------------------------
     # skip() - Skip ahead n characters
     # ------------------------------------------------------------
     def skip(self, n):
+        """
+
+        Parameters
+        ----------
+        n :
+            
+
+        Returns
+        -------
+
+        """
         self.lexpos += n
 
     # ------------------------------------------------------------
@@ -303,6 +436,7 @@
     # you are doing
     # ------------------------------------------------------------
     def token(self):
+        """ """
         # Make local copies of frequently referenced attributes
         lexpos    = self.lexpos
         lexlen    = self.lexlen
@@ -416,6 +550,7 @@
         return self
 
     def next(self):
+        """ """
         t = self.token()
         if t is None:
             raise StopIteration
@@ -437,6 +572,17 @@
 # or as a .regex attribute attached by the @TOKEN decorator.
 # -----------------------------------------------------------------------------
 def _get_regex(func):
+    """
+
+    Parameters
+    ----------
+    func :
+        
+
+    Returns
+    -------
+
+    """
     return getattr(func, 'regex', func.__doc__)
 
 # -----------------------------------------------------------------------------
@@ -447,6 +593,17 @@
 # associated with the yacc() call if none was provided.
 # -----------------------------------------------------------------------------
 def get_caller_module_dict(levels):
+    """
+
+    Parameters
+    ----------
+    levels :
+        
+
+    Returns
+    -------
+
+    """
     f = sys._getframe(levels)
     ldict = f.f_globals.copy()
     if f.f_globals != f.f_locals:
@@ -460,6 +617,19 @@
 # suitable for output to a table file
 # -----------------------------------------------------------------------------
 def _funcs_to_names(funclist, namelist):
+    """
+
+    Parameters
+    ----------
+    funclist :
+        
+    namelist :
+        
+
+    Returns
+    -------
+
+    """
     result = []
     for f, name in zip(funclist, namelist):
         if f and f[0]:
@@ -475,6 +645,19 @@
 # functions.
 # -----------------------------------------------------------------------------
 def _names_to_funcs(namelist, fdict):
+    """
+
+    Parameters
+    ----------
+    namelist :
+        
+    fdict :
+        
+
+    Returns
+    -------
+
+    """
     result = []
     for n in namelist:
         if n and n[0]:
@@ -491,6 +674,23 @@
 # module, it may be necessary to break the master regex into separate expressions.
 # -----------------------------------------------------------------------------
 def _form_master_re(relist, reflags, ldict, toknames):
+    """
+
+    Parameters
+    ----------
+    relist :
+        
+    reflags :
+        
+    ldict :
+        
+    toknames :
+        
+
+    Returns
+    -------
+
+    """
     if not relist:
         return []
     regex = '|'.join(relist)
@@ -531,6 +731,19 @@
 # calling this with s = "t_foo_bar_SPAM" might return (('foo','bar'),'SPAM')
 # -----------------------------------------------------------------------------
 def _statetoken(s, names):
+    """
+
+    Parameters
+    ----------
+    s :
+        
+    names :
+        
+
+    Returns
+    -------
+
+    """
     nonstate = 1
     parts = s.split('_')
     for i, part in enumerate(parts[1:], 1):
@@ -556,6 +769,7 @@
 # user's input file.
 # -----------------------------------------------------------------------------
 class LexerReflect(object):
+    """ """
     def __init__(self, ldict, log=None, reflags=0):
         self.ldict      = ldict
         self.error_func = None
@@ -568,6 +782,7 @@
 
     # Get all of the basic information
     def get_all(self):
+        """ """
         self.get_tokens()
         self.get_literals()
         self.get_states()
@@ -575,6 +790,7 @@
 
     # Validate all of the information
     def validate_all(self):
+        """ """
         self.validate_tokens()
         self.validate_literals()
         self.validate_rules()
@@ -582,6 +798,7 @@
 
     # Get the tokens map
     def get_tokens(self):
+        """ """
         tokens = self.ldict.get('tokens', None)
         if not tokens:
             self.log.error('No token list is defined')
@@ -602,6 +819,7 @@
 
     # Validate the tokens
     def validate_tokens(self):
+        """ """
         terminals = {}
         for n in self.tokens:
             if not _is_identifier.match(n):
@@ -613,12 +831,14 @@
 
     # Get the literals specifier
     def get_literals(self):
+        """ """
         self.literals = self.ldict.get('literals', '')
         if not self.literals:
             self.literals = ''
 
     # Validate literals
     def validate_literals(self):
+        """ """
         try:
             for c in self.literals:
                 if not isinstance(c, StringTypes) or len(c) > 1:
@@ -630,6 +850,7 @@
             self.error = True
 
     def get_states(self):
+        """ """
         self.states = self.ldict.get('states', None)
         # Build statemap
         if self.states:
@@ -661,6 +882,7 @@
     # categories (functions, strings, error functions, and ignore characters)
 
     def get_rules(self):
+        """ """
         tsymbols = [f for f in self.ldict if f[:2] == 't_']
 
         # Now build up a list of functions and a list of strings
@@ -727,6 +949,7 @@
 
     # Validate all of the t_rules collected
     def validate_rules(self):
+        """ """
         for state in self.stateinfo:
             # Validate all rules defined by functions
 
@@ -830,6 +1053,17 @@
     # -----------------------------------------------------------------------------
 
     def validate_module(self, module):
+        """
+
+        Parameters
+        ----------
+        module :
+            
+
+        Returns
+        -------
+
+        """
         try:
             lines, linen = inspect.getsourcelines(module)
         except IOError:
@@ -862,6 +1096,35 @@
 # -----------------------------------------------------------------------------
 def lex(module=None, object=None, debug=False, optimize=False, lextab='lextab',
         reflags=int(re.VERBOSE), nowarn=False, outputdir=None, debuglog=None, errorlog=None):
+    """
+
+    Parameters
+    ----------
+    module :
+         (Default value = None)
+    object :
+         (Default value = None)
+    debug :
+         (Default value = False)
+    optimize :
+         (Default value = False)
+    lextab :
+         (Default value = 'lextab')
+    reflags :
+         (Default value = int(re.VERBOSE))
+    nowarn :
+         (Default value = False)
+    outputdir :
+         (Default value = None)
+    debuglog :
+         (Default value = None)
+    errorlog :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
 
     if lextab is None:
         lextab = 'lextab'
@@ -1053,6 +1316,19 @@
 # -----------------------------------------------------------------------------
 
 def runmain(lexer=None, data=None):
+    """
+
+    Parameters
+    ----------
+    lexer :
+         (Default value = None)
+    data :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     if not data:
         try:
             filename = sys.argv[1]
@@ -1087,7 +1363,29 @@
 # -----------------------------------------------------------------------------
 
 def TOKEN(r):
+    """
+
+    Parameters
+    ----------
+    r :
+        
+
+    Returns
+    -------
+
+    """
     def set_regex(f):
+        """
+
+        Parameters
+        ----------
+        f :
+            
+
+        Returns
+        -------
+
+        """
         if hasattr(r, '__call__'):
             f.regex = _get_regex(r)
         else:
