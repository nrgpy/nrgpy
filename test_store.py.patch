# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/tests/io/pytables/test_store.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/tests/io/pytables/test_store.py
@@ -64,7 +64,19 @@
 
 @pytest.mark.single
 class TestHDFStore:
+    """ """
     def test_format_type(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = pd.DataFrame({"A": [1, 2]})
         with ensure_clean_path(setup_path) as path:
             with HDFStore(path) as store:
@@ -75,6 +87,17 @@
                 assert store.get_storer("b").format_type == "table"
 
     def test_format_kwarg_in_constructor(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 13291
 
         msg = "format is not a defined argument for HDFStore"
@@ -84,6 +107,17 @@
                 HDFStore(path, format="table")
 
     def test_context(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         path = create_tempfile(setup_path)
         try:
             with HDFStore(path) as tbl:
@@ -104,10 +138,36 @@
             safe_remove(path)
 
     def test_conv_read_write(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         path = create_tempfile(setup_path)
         try:
 
             def roundtrip(key, obj, **kwargs):
+                """
+
+                Parameters
+                ----------
+                key :
+                    
+                obj :
+                    
+                **kwargs :
+                    
+
+                Returns
+                -------
+
+                """
                 obj.to_hdf(path, key, **kwargs)
                 return read_hdf(path, key)
 
@@ -130,6 +190,17 @@
             safe_remove(path)
 
     def test_long_strings(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH6166
         df = DataFrame(
@@ -143,6 +214,17 @@
             tm.assert_frame_equal(df, result)
 
     def test_api(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH4584
         # API issue when to_hdf doesn't accept append AND format args
@@ -240,6 +322,17 @@
             read_hdf(path, "df")
 
     def test_api_default_format(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # default_format option
         with ensure_clean_store(setup_path) as store:
@@ -287,6 +380,17 @@
             pd.set_option("io.hdf.default_format", None)
 
     def test_keys(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             store["a"] = tm.makeTimeSeries()
@@ -299,11 +403,37 @@
             assert set(store) == expected
 
     def test_no_track_times(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH 32682
         # enables to set track_times (see `pytables` `create_table` documentation)
 
         def checksum(filename, hash_factory=hashlib.md5, chunk_num_blocks=128):
+            """
+
+            Parameters
+            ----------
+            filename :
+                
+            hash_factory :
+                 (Default value = hashlib.md5)
+            chunk_num_blocks :
+                 (Default value = 128)
+
+            Returns
+            -------
+
+            """
             h = hash_factory()
             with open(filename, "rb") as f:
                 for chunk in iter(lambda: f.read(chunk_num_blocks * h.block_size), b""):
@@ -311,6 +441,17 @@
             return h.digest()
 
         def create_h5_and_return_checksum(track_times):
+            """
+
+            Parameters
+            ----------
+            track_times :
+                
+
+            Returns
+            -------
+
+            """
             with ensure_clean_path(setup_path) as path:
                 df = pd.DataFrame({"a": [1]})
 
@@ -342,13 +483,27 @@
         assert checksum_0_tt_true != checksum_1_tt_true
 
     def test_non_pandas_keys(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         class Table1(tables.IsDescription):
+            """ """
             value1 = tables.Float32Col()
 
         class Table2(tables.IsDescription):
+            """ """
             value2 = tables.Float32Col()
 
         class Table3(tables.IsDescription):
+            """ """
             value3 = tables.Float32Col()
 
         with ensure_clean_path(setup_path) as path:
@@ -367,6 +522,17 @@
                     assert len(df.columns) == 1
 
     def test_keys_illegal_include_keyword_value(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         with ensure_clean_store(setup_path) as store:
             with pytest.raises(
                 ValueError,
@@ -376,6 +542,17 @@
                 store.keys(include="illegal")
 
     def test_keys_ignore_hdf_softlink(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH 20523
         # Puts a softlink into HDF file and rereads
@@ -393,12 +570,34 @@
             assert store.keys() == ["/df"]
 
     def test_iter_empty(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             # GH 12221
             assert list(store) == []
 
     def test_repr(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             repr(store)
@@ -445,6 +644,17 @@
 
     @ignore_natural_naming_warning
     def test_contains(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             store["a"] = tm.makeTimeSeries()
@@ -464,6 +674,17 @@
             assert "node())" in store
 
     def test_versioning(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             store["a"] = tm.makeTimeSeries()
@@ -490,10 +711,32 @@
                 store.select("df2")
 
     def test_mode(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         df = tm.makeTimeDataFrame()
 
         def check(mode):
+            """
+
+            Parameters
+            ----------
+            mode :
+                
+
+            Returns
+            -------
+
+            """
 
             with ensure_clean_path(setup_path) as path:
 
@@ -541,6 +784,7 @@
                     tm.assert_frame_equal(result, df)
 
         def check_default_mode():
+            """ """
 
             # read_hdf uses default mode
             with ensure_clean_path(setup_path) as path:
@@ -555,6 +799,17 @@
         check_default_mode()
 
     def test_reopen_handle(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_path(setup_path) as path:
 
@@ -603,6 +858,17 @@
             assert not store.is_open
 
     def test_open_args(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_path(setup_path) as path:
 
@@ -624,6 +890,17 @@
             assert not os.path.exists(path)
 
     def test_flush(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             store["a"] = tm.makeTimeSeries()
@@ -631,6 +908,17 @@
             store.flush(fsync=True)
 
     def test_get(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             store["a"] = tm.makeTimeSeries()
@@ -667,6 +955,21 @@
         ],
     )
     def test_walk(self, where, expected, setup_path):
+        """
+
+        Parameters
+        ----------
+        where :
+            
+        expected :
+            
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH10143
         objs = {
             "df1": pd.DataFrame([1, 2, 3]),
@@ -706,6 +1009,17 @@
                         tm.assert_series_equal(obj, objs[leaf])
 
     def test_getattr(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -733,6 +1047,17 @@
                 getattr(store, f"_{x}")
 
     def test_put(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -764,6 +1089,17 @@
             tm.assert_frame_equal(df[:10], store["c"])
 
     def test_put_string_index(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -791,6 +1127,17 @@
             tm.assert_frame_equal(store["b"], df)
 
     def test_put_compression(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             df = tm.makeTimeDataFrame()
@@ -804,6 +1151,17 @@
 
     @td.skip_if_windows_python_3
     def test_put_compression_blosc(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = tm.makeTimeDataFrame()
 
         with ensure_clean_store(setup_path) as store:
@@ -816,6 +1174,17 @@
             tm.assert_frame_equal(store["c"], df)
 
     def test_complibs_default_settings(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH15943
         df = tm.makeDataFrame()
 
@@ -869,6 +1238,17 @@
                     assert node.filters.complib == "blosc"
 
     def test_complibs(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH14478
         df = tm.makeDataFrame()
 
@@ -905,12 +1285,34 @@
                 h5table.close()
 
     def test_put_integer(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # non-date, non-string index
         df = DataFrame(np.random.randn(50, 100))
         self._check_roundtrip(df, tm.assert_frame_equal, setup_path)
 
     @td.xfail_non_writeable
     def test_put_mixed_type(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = tm.makeTimeDataFrame()
         df["obj1"] = "foo"
         df["obj2"] = "bar"
@@ -941,6 +1343,17 @@
         "ignore:object name:tables.exceptions.NaturalNameWarning"
     )
     def test_append(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -1009,6 +1422,17 @@
                 tm.assert_frame_equal(store["uints"], uint_data)
 
     def test_append_series(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -1055,12 +1479,36 @@
             tm.assert_series_equal(store["mi"], s)
 
     def test_store_index_types(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH5386
         # test storing various index types
 
         with ensure_clean_store(setup_path) as store:
 
             def check(format, index):
+                """
+
+                Parameters
+                ----------
+                format :
+                    
+                index :
+                    
+
+                Returns
+                -------
+
+                """
                 df = DataFrame(np.random.randn(10, 2), columns=list("AB"))
                 df.index = index(len(df))
 
@@ -1092,6 +1540,17 @@
         not is_platform_little_endian(), reason="reason platform is not little endian"
     )
     def test_encoding(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             df = DataFrame(dict(A="foo", B="bar"), index=range(5))
@@ -1121,6 +1580,21 @@
     )
     @pytest.mark.parametrize("dtype", ["category", object])
     def test_latin_encoding(self, setup_path, dtype, val):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+        dtype :
+            
+        val :
+            
+
+        Returns
+        -------
+
+        """
         enc = "latin-1"
         nan_rep = ""
         key = "data"
@@ -1137,6 +1611,17 @@
         tm.assert_series_equal(s_nan, retr)
 
     def test_append_some_nans(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             df = DataFrame(
@@ -1183,6 +1668,17 @@
             tm.assert_frame_equal(store["df3"], df3)
 
     def test_append_all_nans(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -1278,6 +1774,17 @@
             tm.assert_frame_equal(df_with_missing, reloaded)
 
     def test_read_missing_key_close_store(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 25766
         with ensure_clean_path(setup_path) as path:
             df = pd.DataFrame({"a": range(2), "b": range(2)})
@@ -1291,6 +1798,17 @@
             df.to_hdf(path, "k2")
 
     def test_read_missing_key_opened_store(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 28699
         with ensure_clean_path(setup_path) as path:
             df = pd.DataFrame({"a": range(2), "b": range(2)})
@@ -1306,6 +1824,17 @@
                 pd.read_hdf(store, "k1")
 
     def test_append_frame_column_oriented(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         with ensure_clean_store(setup_path) as store:
 
             # column oriented
@@ -1331,6 +1860,17 @@
                 store.select("df1", "columns=A and index>df.index[4]")
 
     def test_append_with_different_block_ordering(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH 4096; using same frames, but different block orderings
         with ensure_clean_store(setup_path) as store:
@@ -1374,11 +1914,37 @@
                 store.append("df", df)
 
     def test_append_with_strings(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             with catch_warnings(record=True):
 
                 def check_col(key, name, size):
+                    """
+
+                    Parameters
+                    ----------
+                    key :
+                        
+                    name :
+                        
+                    size :
+                        
+
+                    Returns
+                    -------
+
+                    """
                     assert (
                         getattr(store.get_storer(key).table.description, name).itemsize
                         == size
@@ -1452,6 +2018,21 @@
         with ensure_clean_store(setup_path) as store:
 
             def check_col(key, name, size):
+                """
+
+                Parameters
+                ----------
+                key :
+                    
+                name :
+                    
+                size :
+                    
+
+                Returns
+                -------
+
+                """
                 assert getattr(
                     store.get_storer(key).table.description, name
                 ).itemsize, size
@@ -1490,6 +2071,17 @@
                 store.append("df", df, min_itemsize={"foo": 20, "foobar": 20})
 
     def test_append_with_empty_string(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -1500,6 +2092,17 @@
             tm.assert_frame_equal(store.select("df"), df)
 
     def test_to_hdf_with_min_itemsize(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_path(setup_path) as path:
 
@@ -1522,6 +2125,19 @@
         "format", [pytest.param("fixed", marks=td.xfail_non_writeable), "table"]
     )
     def test_to_hdf_errors(self, format, setup_path):
+        """
+
+        Parameters
+        ----------
+        format :
+            
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         data = ["\ud800foo"]
         ser = pd.Series(data, index=pd.Index(data))
@@ -1533,6 +2149,17 @@
             tm.assert_series_equal(result, ser)
 
     def test_append_with_data_columns(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             df = tm.makeTimeDataFrame()
@@ -1570,6 +2197,21 @@
 
             # using min_itemsize and a data column
             def check_col(key, name, size):
+                """
+
+                Parameters
+                ----------
+                key :
+                    
+                name :
+                    
+                size :
+                    
+
+                Returns
+                -------
+
+                """
                 assert (
                     getattr(store.get_storer(key).table.description, name).itemsize
                     == size
@@ -1696,12 +2338,36 @@
             tm.assert_frame_equal(result, expected)
 
     def test_create_table_index(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
             with catch_warnings(record=True):
 
                 def col(t, column):
+                    """
+
+                    Parameters
+                    ----------
+                    t :
+                        
+                    column :
+                        
+
+                    Returns
+                    -------
+
+                    """
                     return getattr(store.get_storer(t).table.cols, column)
 
                 # data columns
@@ -1728,6 +2394,17 @@
                     store.create_table_index("f2")
 
     def test_create_table_index_data_columns_argument(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 28156
 
         with ensure_clean_store(setup_path) as store:
@@ -1735,6 +2412,19 @@
             with catch_warnings(record=True):
 
                 def col(t, column):
+                    """
+
+                    Parameters
+                    ----------
+                    t :
+                        
+                    column :
+                        
+
+                    Returns
+                    -------
+
+                    """
                     return getattr(store.get_storer(t).table.cols, column)
 
                 # data columns
@@ -1759,6 +2449,17 @@
                     store.create_table_index("f", columns=["string2"])
 
     def test_append_hierarchical(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         index = MultiIndex(
             levels=[["foo", "bar", "baz", "qux"], ["one", "two", "three"]],
             codes=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3], [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
@@ -1783,6 +2484,17 @@
             tm.assert_frame_equal(result, expected)
 
     def test_column_multiindex(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 4710
         # recreate multi-indexes properly
 
@@ -1834,12 +2546,34 @@
             )
 
     def test_store_multiindex(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # validate multi-index names
         # GH 5527
         with ensure_clean_store(setup_path) as store:
 
             def make_index(names=None):
+                """
+
+                Parameters
+                ----------
+                names :
+                     (Default value = None)
+
+                Returns
+                -------
+
+                """
                 return MultiIndex.from_tuples(
                     [
                         (datetime.datetime(2013, 12, d), s, t)
@@ -1904,6 +2638,17 @@
             tm.assert_frame_equal(store.select("df"), df)
 
     def test_select_columns_in_where(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH 6169
         # recreate multi-indexes when columns is passed
@@ -1932,6 +2677,17 @@
             tm.assert_series_equal(store.select("s", where="columns=['A']"), s)
 
     def test_mi_data_columns(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 14435
         idx = pd.MultiIndex.from_arrays(
             [date_range("2000-01-01", periods=5), range(5)], names=["date", "id"]
@@ -1946,6 +2702,17 @@
             tm.assert_frame_equal(actual, expected)
 
     def test_pass_spec_to_storer(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         df = tm.makeDataFrame()
 
@@ -1958,6 +2725,17 @@
 
     @td.xfail_non_writeable
     def test_append_misc(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             df = tm.makeDataFrame()
@@ -1971,6 +2749,19 @@
 
         # more chunksize in append tests
         def check(obj, comparator):
+            """
+
+            Parameters
+            ----------
+            obj :
+                
+            comparator :
+                
+
+            Returns
+            -------
+
+            """
             for c in [10, 200, 1000]:
                 with ensure_clean_store(setup_path, mode="w") as store:
                     store.append("obj", obj, chunksize=c)
@@ -2008,6 +2799,17 @@
             tm.assert_frame_equal(store.select("df2"), df)
 
     def test_append_raise(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -2053,6 +2855,17 @@
                 store.append("df", df)
 
     def test_table_index_incompatible_dtypes(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df1 = DataFrame({"a": [1, 2, 3]})
         df2 = DataFrame({"a": [4, 5, 6]}, index=date_range("1/1/2000", periods=3))
 
@@ -2062,6 +2875,17 @@
                 store.put("frame", df2, format="table", append=True)
 
     def test_table_values_dtypes_roundtrip(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             df1 = DataFrame({"a": [1, 2, 3]}, dtype="f8")
@@ -2118,6 +2942,17 @@
             tm.assert_series_equal(result, expected)
 
     def test_table_mixed_dtypes(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # frame
         df = tm.makeDataFrame()
@@ -2140,6 +2975,17 @@
             tm.assert_frame_equal(store.select("df1_mixed"), df)
 
     def test_unimplemented_dtypes_table_columns(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -2173,6 +3019,17 @@
         ),
     )
     def test_calendar_roundtrip_issue(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # 8591
         # doc example from tseries holiday section
@@ -2201,6 +3058,17 @@
             tm.assert_series_equal(result, s)
 
     def test_roundtrip_tz_aware_index(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 17618
         time = pd.Timestamp("2000-01-01 01:00:00", tz="US/Eastern")
         df = pd.DataFrame(data=[0], index=[time])
@@ -2212,6 +3080,17 @@
             assert recons.index[0].value == 946706400000000000
 
     def test_append_with_timedelta(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 3577
         # append timedelta
 
@@ -2261,6 +3140,17 @@
             tm.assert_frame_equal(result, df)
 
     def test_remove(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -2301,6 +3191,17 @@
             assert len(store) == 0
 
     def test_invalid_terms(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -2351,6 +3252,17 @@
                 read_hdf(path, "dfq", where="A>0 or C>0")
 
     def test_same_name_scoping(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -2377,6 +3289,17 @@
             tm.assert_frame_equal(result, expected)
 
     def test_series(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         s = tm.makeStringSeries()
         self._check_roundtrip(s, tm.assert_series_equal, path=setup_path)
@@ -2393,6 +3316,17 @@
         )
 
     def test_float_index(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH #454
         index = np.random.randn(10)
@@ -2401,6 +3335,17 @@
 
     @td.xfail_non_writeable
     def test_tuple_index(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH #492
         col = np.arange(10)
@@ -2415,6 +3360,17 @@
     @td.xfail_non_writeable
     @pytest.mark.filterwarnings("ignore::pandas.errors.PerformanceWarning")
     def test_index_types(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with catch_warnings(record=True):
             values = np.random.randn(2)
@@ -2466,6 +3422,17 @@
             self._check_roundtrip(ser, func, path=setup_path)
 
     def test_timeseries_preepoch(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         dr = bdate_range("1/1/1940", "1/1/1960")
         ts = Series(np.random.randn(len(dr)), index=dr)
@@ -2479,6 +3446,19 @@
         "compression", [False, pytest.param(True, marks=td.skip_if_windows_python_3)]
     )
     def test_frame(self, compression, setup_path):
+        """
+
+        Parameters
+        ----------
+        compression :
+            
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         df = tm.makeDataFrame()
 
@@ -2510,6 +3490,17 @@
 
     @td.xfail_non_writeable
     def test_empty_series_frame(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         s0 = Series(dtype=object)
         s1 = Series(name="myseries", dtype=object)
         df0 = DataFrame()
@@ -2527,10 +3518,34 @@
         "dtype", [np.int64, np.float64, object, "m8[ns]", "M8[ns]"]
     )
     def test_empty_series(self, dtype, setup_path):
+        """
+
+        Parameters
+        ----------
+        dtype :
+            
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         s = Series(dtype=dtype)
         self._check_roundtrip(s, tm.assert_series_equal, path=setup_path)
 
     def test_can_serialize_dates(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         rng = [x.date() for x in bdate_range("1/1/2000", "1/30/2000")]
         frame = DataFrame(np.random.randn(len(rng), 4), index=rng)
@@ -2538,6 +3553,17 @@
         self._check_roundtrip(frame, tm.assert_frame_equal, path=setup_path)
 
     def test_store_hierarchical(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         index = MultiIndex(
             levels=[["foo", "bar", "baz", "qux"], ["one", "two", "three"]],
             codes=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3], [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
@@ -2556,6 +3582,17 @@
             tm.assert_frame_equal(recons, frame)
 
     def test_store_index_name(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = tm.makeDataFrame()
         df.index.name = "foo"
 
@@ -2565,6 +3602,17 @@
             tm.assert_frame_equal(recons, df)
 
     def test_store_index_name_with_tz(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 13884
         df = pd.DataFrame({"A": [1, 2]})
         df.index = pd.DatetimeIndex([1234567890123456787, 1234567890123456788])
@@ -2578,6 +3626,19 @@
 
     @pytest.mark.parametrize("table_format", ["table", "fixed"])
     def test_store_index_name_numpy_str(self, table_format, setup_path):
+        """
+
+        Parameters
+        ----------
+        table_format :
+            
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH #13492
         idx = pd.Index(
             pd.to_datetime([datetime.date(2000, 1, 1), datetime.date(2000, 1, 2)]),
@@ -2600,6 +3661,17 @@
             assert type(df2.columns.name) == str
 
     def test_store_series_name(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = tm.makeDataFrame()
         series = df["A"]
 
@@ -2613,7 +3685,21 @@
         "compression", [False, pytest.param(True, marks=td.skip_if_windows_python_3)]
     )
     def test_store_mixed(self, compression, setup_path):
+        """
+
+        Parameters
+        ----------
+        compression :
+            
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         def _make_one():
+            """ """
             df = tm.makeDataFrame()
             df["obj1"] = "foo"
             df["obj2"] = "bar"
@@ -2659,6 +3745,17 @@
         "ignore:\\nduplicate:pandas.io.pytables.DuplicateWarning"
     )
     def test_select_with_dups(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # single dtypes
         df = DataFrame(np.random.randn(10, 4), columns=["A", "A", "B", "B"])
@@ -2721,6 +3818,17 @@
             tm.assert_frame_equal(result, expected, by_blocks=True)
 
     def test_overwrite_node(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             store["a"] = tm.makeTimeDataFrame()
@@ -2730,6 +3838,17 @@
             tm.assert_series_equal(store["a"], ts)
 
     def test_select(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -2770,6 +3889,17 @@
                 tm.assert_frame_equal(expected, result)
 
     def test_select_dtypes(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             # with a Timestamp data column (GH #2637)
@@ -2873,6 +4003,17 @@
             tm.assert_frame_equal(expected, result)
 
     def test_select_with_many_inputs(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -2926,6 +4067,17 @@
             assert len(result) == 100
 
     def test_select_iterator(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # single table
         with ensure_clean_store(setup_path) as store:
@@ -2993,6 +4145,17 @@
             tm.assert_frame_equal(expected, result)
 
     def test_select_iterator_complete_8014(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH 8014
         # using iterator and where clause
@@ -3064,6 +4227,17 @@
             tm.assert_frame_equal(expected, result)
 
     def test_select_iterator_non_complete_8014(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH 8014
         # using iterator and where clause
@@ -3117,6 +4291,17 @@
             assert 0 == len(results)
 
     def test_select_iterator_many_empty_frames(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH 8014
         # using iterator and where clause can return many empty
@@ -3178,6 +4363,17 @@
         "ignore:\\nthe :pandas.io.pytables.AttributeConflictWarning"
     )
     def test_retain_index_attributes(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH 3499, losing frequency info on index recreation
         df = DataFrame(
@@ -3238,6 +4434,17 @@
         "ignore:\\nthe :pandas.io.pytables.AttributeConflictWarning"
     )
     def test_retain_index_attributes2(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         with ensure_clean_path(setup_path) as path:
 
             with catch_warnings(record=True):
@@ -3276,6 +4483,17 @@
             assert read_hdf(path, "data").index.name is None
 
     def test_frame_select(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         df = tm.makeTimeDataFrame()
 
@@ -3309,6 +4527,17 @@
             #     store.select('frame', [crit1, crit2])
 
     def test_frame_select_complex(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # select via complex criteria
 
         df = tm.makeTimeDataFrame()
@@ -3361,6 +4590,17 @@
             tm.assert_frame_equal(result, expected)
 
     def test_frame_select_complex2(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_path(["parms.hdf", "hist.hdf"]) as paths:
 
@@ -3425,6 +4665,17 @@
             store.close()
 
     def test_invalid_filtering(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # can't use more than one filter (atm)
 
@@ -3442,6 +4693,17 @@
                 store.select("df", "columns=['A','B'] & columns=['C']")
 
     def test_string_select(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 2973
         with ensure_clean_store(setup_path) as store:
 
@@ -3484,6 +4746,17 @@
             tm.assert_frame_equal(result, expected)
 
     def test_read_column(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         df = tm.makeTimeDataFrame()
 
@@ -3557,6 +4830,17 @@
             tm.assert_series_equal(result, expected)
 
     def test_coordinates(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = tm.makeTimeDataFrame()
 
         with ensure_clean_store(setup_path) as store:
@@ -3661,6 +4945,17 @@
             tm.assert_frame_equal(result, expected)
 
     def test_append_to_multiple(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df1 = tm.makeTimeDataFrame()
         df2 = tm.makeTimeDataFrame().rename(columns="{}_2".format)
         df2["foo"] = "bar"
@@ -3691,6 +4986,17 @@
             tm.assert_frame_equal(result, expected)
 
     def test_append_to_multiple_dropna(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df1 = tm.makeTimeDataFrame()
         df2 = tm.makeTimeDataFrame().rename(columns="{}_2".format)
         df1.iloc[1, df1.columns.get_indexer(["A", "B"])] = np.nan
@@ -3711,6 +5017,17 @@
         run=False, reason="append_to_multiple_dropna_false is not raising as failed"
     )
     def test_append_to_multiple_dropna_false(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df1 = tm.makeTimeDataFrame()
         df2 = tm.makeTimeDataFrame().rename(columns="{}_2".format)
         df1.iloc[1, df1.columns.get_indexer(["A", "B"])] = np.nan
@@ -3729,6 +5046,17 @@
             assert not store.select("df1a").index.equals(store.select("df2a").index)
 
     def test_append_to_multiple_min_itemsize(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 11238
         df = pd.DataFrame(
             {
@@ -3756,6 +5084,17 @@
             tm.assert_frame_equal(result, expected)
 
     def test_select_as_multiple(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         df1 = tm.makeTimeDataFrame()
         df2 = tm.makeTimeDataFrame().rename(columns="{}_2".format)
@@ -3830,6 +5169,17 @@
         reason=("tables version does not support fix for nan selection bug: GH 4858"),
     )
     def test_nan_selection_bug_4858(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -3848,6 +5198,17 @@
             tm.assert_frame_equal(result, expected)
 
     def test_start_stop_table(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -3866,6 +5227,17 @@
             tm.assert_frame_equal(result, expected)
 
     def test_start_stop_multiple(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH 16209
         with ensure_clean_store(setup_path) as store:
@@ -3882,6 +5254,17 @@
             tm.assert_frame_equal(result, expected)
 
     def test_start_stop_fixed(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -3922,6 +5305,17 @@
             df.iloc[8:10, -2] = np.nan
 
     def test_select_filter_corner(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         df = DataFrame(np.random.randn(50, 100))
         df.index = [f"{c:3d}" for c in df.index]
@@ -3939,6 +5333,17 @@
             tm.assert_frame_equal(result, df.loc[:, df.columns[:75:2]])
 
     def test_path_pathlib(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = tm.makeDataFrame()
 
         result = tm.round_trip_pathlib(
@@ -3948,6 +5353,21 @@
 
     @pytest.mark.parametrize("start, stop", [(0, 2), (1, 2), (None, None)])
     def test_contiguous_mixed_data_table(self, start, stop, setup_path):
+        """
+
+        Parameters
+        ----------
+        start :
+            
+        stop :
+            
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 17021
         # ValueError when reading a contiguous mixed-data table ft. VLArray
         df = DataFrame(
@@ -3964,13 +5384,46 @@
             tm.assert_frame_equal(df[start:stop], result)
 
     def test_path_pathlib_hdfstore(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = tm.makeDataFrame()
 
         def writer(path):
+            """
+
+            Parameters
+            ----------
+            path :
+                
+
+            Returns
+            -------
+
+            """
             with pd.HDFStore(path) as store:
                 df.to_hdf(store, "df")
 
         def reader(path):
+            """
+
+            Parameters
+            ----------
+            path :
+                
+
+            Returns
+            -------
+
+            """
             with pd.HDFStore(path) as store:
                 return pd.read_hdf(store, "df")
 
@@ -3978,6 +5431,17 @@
         tm.assert_frame_equal(df, result)
 
     def test_pickle_path_localpath(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = tm.makeDataFrame()
         result = tm.round_trip_pathlib(
             lambda p: df.to_hdf(p, "df"), lambda p: pd.read_hdf(p, "df")
@@ -3985,13 +5449,46 @@
         tm.assert_frame_equal(df, result)
 
     def test_path_localpath_hdfstore(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = tm.makeDataFrame()
 
         def writer(path):
+            """
+
+            Parameters
+            ----------
+            path :
+                
+
+            Returns
+            -------
+
+            """
             with pd.HDFStore(path) as store:
                 df.to_hdf(store, "df")
 
         def reader(path):
+            """
+
+            Parameters
+            ----------
+            path :
+                
+
+            Returns
+            -------
+
+            """
             with pd.HDFStore(path) as store:
                 return pd.read_hdf(store, "df")
 
@@ -3999,6 +5496,25 @@
         tm.assert_frame_equal(df, result)
 
     def _check_roundtrip(self, obj, comparator, path, compression=False, **kwargs):
+        """
+
+        Parameters
+        ----------
+        obj :
+            
+        comparator :
+            
+        path :
+            
+        compression :
+             (Default value = False)
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
 
         options = {}
         if compression:
@@ -4012,6 +5528,25 @@
     def _check_double_roundtrip(
         self, obj, comparator, path, compression=False, **kwargs
     ):
+        """
+
+        Parameters
+        ----------
+        obj :
+            
+        comparator :
+            
+        path :
+            
+        compression :
+             (Default value = False)
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         options = {}
         if compression:
             options["complib"] = compression or _default_compressor
@@ -4025,6 +5560,23 @@
             comparator(again, obj, **kwargs)
 
     def _check_roundtrip_table(self, obj, comparator, path, compression=False):
+        """
+
+        Parameters
+        ----------
+        obj :
+            
+        comparator :
+            
+        path :
+            
+        compression :
+             (Default value = False)
+
+        Returns
+        -------
+
+        """
         options = {}
         if compression:
             options["complib"] = _default_compressor
@@ -4036,6 +5588,17 @@
             comparator(retrieved, obj)
 
     def test_multiple_open_close(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # gh-4409: open & close multiple times
 
         with ensure_clean_path(setup_path) as path:
@@ -4159,6 +5722,19 @@
                 store.select("df")
 
     def test_pytables_native_read(self, datapath, setup_path):
+        """
+
+        Parameters
+        ----------
+        datapath :
+            
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         with ensure_clean_store(
             datapath("io", "data", "legacy_hdf/pytables_native.h5"), mode="r"
         ) as store:
@@ -4169,6 +5745,19 @@
         is_platform_windows(), reason="native2 read fails oddly on windows"
     )
     def test_pytables_native2_read(self, datapath, setup_path):
+        """
+
+        Parameters
+        ----------
+        datapath :
+            
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         with ensure_clean_store(
             datapath("io", "data", "legacy_hdf", "pytables_native2.h5"), mode="r"
         ) as store:
@@ -4178,6 +5767,19 @@
 
     @td.xfail_non_writeable
     def test_legacy_table_fixed_format_read_py2(self, datapath, setup_path):
+        """
+
+        Parameters
+        ----------
+        datapath :
+            
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 24510
         # legacy table with fixed format written in Python 2
         with ensure_clean_store(
@@ -4192,6 +5794,19 @@
             tm.assert_frame_equal(expected, result)
 
     def test_legacy_table_fixed_format_read_datetime_py2(self, datapath, setup_path):
+        """
+
+        Parameters
+        ----------
+        datapath :
+            
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 31750
         # legacy table with fixed format and datetime64 column written in Python 2
         with ensure_clean_store(
@@ -4207,6 +5822,19 @@
             tm.assert_frame_equal(expected, result)
 
     def test_legacy_table_read_py2(self, datapath, setup_path):
+        """
+
+        Parameters
+        ----------
+        datapath :
+            
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # issue: 24925
         # legacy table written in Python 2
         with ensure_clean_store(
@@ -4218,10 +5846,40 @@
         tm.assert_frame_equal(expected, result)
 
     def test_copy(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with catch_warnings(record=True):
 
             def do_copy(f, new_f=None, keys=None, propindexes=True, **kwargs):
+                """
+
+                Parameters
+                ----------
+                f :
+                    
+                new_f :
+                     (Default value = None)
+                keys :
+                     (Default value = None)
+                propindexes :
+                     (Default value = True)
+                **kwargs :
+                    
+
+                Returns
+                -------
+
+                """
                 try:
                     store = HDFStore(f, "r")
 
@@ -4276,6 +5934,17 @@
                 safe_remove(path)
 
     def test_store_datetime_fractional_secs(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             dt = datetime.datetime(2012, 1, 2, 3, 4, 5, 123456)
@@ -4284,6 +5953,17 @@
             assert store["a"].index[0] == dt
 
     def test_tseries_indices_series(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             idx = tm.makeDateIndex(10)
@@ -4305,6 +5985,17 @@
             tm.assert_class_equal(result.index, ser.index, obj="series index")
 
     def test_tseries_indices_frame(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
             idx = tm.makeDateIndex(10)
@@ -4326,6 +6017,17 @@
             tm.assert_class_equal(result.index, df.index, obj="dataframe index")
 
     def test_unicode_index(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         unicode_values = ["\u03c3", "\u03c3\u03c3"]
 
@@ -4336,6 +6038,17 @@
             self._check_roundtrip(s, tm.assert_series_equal, path=setup_path)
 
     def test_unicode_longer_encoded(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 11234
         char = "\u0394"
         df = pd.DataFrame({"A": [char]})
@@ -4352,6 +6065,17 @@
 
     @td.xfail_non_writeable
     def test_store_datetime_mixed(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         df = DataFrame({"a": [1, 2, 3], "b": [1.0, 2.0, 3.0], "c": ["a", "b", "c"]})
         ts = tm.makeTimeSeries()
@@ -4369,6 +6093,17 @@
     #         store.put('foo', df, format='table')
 
     def test_append_with_diff_col_name_types_raises_value_error(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame(np.random.randn(10, 1))
         df2 = DataFrame({"a": np.random.randn(10)})
         df3 = DataFrame({(1, 2): np.random.randn(10)})
@@ -4384,6 +6119,17 @@
                     store.append(name, d)
 
     def test_query_with_nested_special_character(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame(
             {
                 "a": ["a", "a", "c", "b", "test & test", "c", "b", "e"],
@@ -4397,6 +6143,17 @@
         tm.assert_frame_equal(expected, result)
 
     def test_categorical(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         with ensure_clean_store(setup_path) as store:
 
@@ -4517,6 +6274,17 @@
                 store.select("df3/meta/s/meta")
 
     def test_categorical_conversion(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH13322
         # Check that read_hdf with categorical columns doesn't return rows if
@@ -4547,6 +6315,17 @@
             tm.assert_frame_equal(result, expected)
 
     def test_categorical_nan_only_columns(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH18413
         # Check that read_hdf with categorical columns with NaN-only values can
         # be read back.
@@ -4568,6 +6347,17 @@
             tm.assert_frame_equal(result, expected)
 
     def test_duplicate_column_name(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame(columns=["a", "a"], data=[[0, 0]])
 
         with ensure_clean_path(setup_path) as path:
@@ -4582,6 +6372,17 @@
             assert other.equals(df)
 
     def test_round_trip_equals(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 9330
         df = DataFrame({"B": [1, 2], "A": ["x", "y"]})
 
@@ -4593,6 +6394,17 @@
             assert other.equals(df)
 
     def test_preserve_timedeltaindex_type(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH9635
         # Storing TimedeltaIndexed DataFrames in fixed stores did not preserve
         # the type of the index.
@@ -4605,6 +6417,17 @@
             tm.assert_frame_equal(store["df"], df)
 
     def test_columns_multiindex_modified(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # BUG: 7212
         # read_hdf store.select modified the passed columns parameters
         # when multi-indexed.
@@ -4630,6 +6453,17 @@
 
     @ignore_natural_naming_warning
     def test_to_hdf_with_object_column_names(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH9057
         # Writing HDF5 table format should only work for string-like
         # column types
@@ -4664,6 +6498,17 @@
                     assert len(result)
 
     def test_read_hdf_open_store(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH10330
         # No check for non-string path_or-buf, and no test of open store
         df = DataFrame(np.random.rand(4, 5), index=list("abcd"), columns=list("ABCDE"))
@@ -4680,6 +6525,17 @@
             store.close()
 
     def test_read_hdf_iterator(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame(np.random.rand(4, 5), index=list("abcd"), columns=list("ABCDE"))
         df.index.name = "letters"
         df = df.set_index(keys="E", append=True)
@@ -4694,6 +6550,17 @@
             iterator.store.close()
 
     def test_read_hdf_errors(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame(np.random.rand(4, 5), index=list("abcd"), columns=list("ABCDE"))
 
         with ensure_clean_path(setup_path) as path:
@@ -4708,10 +6575,22 @@
                 read_hdf(store, "df")
 
     def test_read_hdf_generic_buffer_errors(self):
+        """ """
         with pytest.raises(NotImplementedError):
             read_hdf(BytesIO(b""), "df")
 
     def test_invalid_complib(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame(np.random.rand(4, 5), index=list("abcd"), columns=list("ABCDE"))
         with ensure_clean_path(setup_path) as path:
             with pytest.raises(ValueError):
@@ -4720,6 +6599,17 @@
     # GH10443
 
     def test_read_nokey(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         df = DataFrame(np.random.rand(4, 5), index=list("abcd"), columns=list("ABCDE"))
 
         # Categorical dtype not supported for "fixed" format. So no need
@@ -4734,6 +6624,17 @@
                 read_hdf(path)
 
     def test_read_nokey_table(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH13231
         df = DataFrame({"i": range(5), "c": Series(list("abacd"), dtype="category")})
 
@@ -4747,6 +6648,17 @@
                 read_hdf(path)
 
     def test_read_nokey_empty(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         with ensure_clean_path(setup_path) as path:
             store = HDFStore(path)
             store.close()
@@ -4755,6 +6667,17 @@
                 read_hdf(path)
 
     def test_read_from_pathlib_path(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH11773
         expected = DataFrame(
@@ -4770,6 +6693,17 @@
 
     @td.skip_if_no("py.path")
     def test_read_from_py_localpath(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
 
         # GH11773
         from py.path import local as LocalPath
@@ -4786,6 +6720,17 @@
         tm.assert_frame_equal(expected, actual)
 
     def test_query_long_float_literal(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 14241
         df = pd.DataFrame({"A": [1000000000.0009, 1000000000.0011, 1000000000.0015]})
 
@@ -4807,6 +6752,17 @@
             tm.assert_frame_equal(expected, result)
 
     def test_query_compare_column_type(self, setup_path):
+        """
+
+        Parameters
+        ----------
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 15492
         df = pd.DataFrame(
             {
@@ -4856,6 +6812,19 @@
 
     @pytest.mark.parametrize("format", ["fixed", "table"])
     def test_read_hdf_series_mode_r(self, format, setup_path):
+        """
+
+        Parameters
+        ----------
+        format :
+            
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 16583
         # Tests that reading a Series saved to an HDF file
         # still works if a mode='r' argument is supplied
@@ -4866,11 +6835,23 @@
         tm.assert_series_equal(result, series)
 
     def test_fspath(self):
+        """ """
         with tm.ensure_clean("foo.h5") as path:
             with pd.HDFStore(path) as store:
                 assert os.fspath(store) == str(path)
 
     def test_read_py2_hdf_file_in_py3(self, datapath):
+        """
+
+        Parameters
+        ----------
+        datapath :
+            
+
+        Returns
+        -------
+
+        """
         # GH 16781
 
         # tests reading a PeriodIndex DataFrame written in Python2 in Python3
@@ -4897,6 +6878,17 @@
 
     @pytest.mark.parametrize("where", ["", (), (None,), [], [None]])
     def test_select_empty_where(self, where):
+        """
+
+        Parameters
+        ----------
+        where :
+            
+
+        Returns
+        -------
+
+        """
         # GH26610
 
         # Using keyword `where` as '' or (), or [None], etc
@@ -4918,6 +6910,19 @@
         ],
     )
     def test_to_hdf_multiindex_extension_dtype(self, idx, setup_path):
+        """
+
+        Parameters
+        ----------
+        idx :
+            
+        setup_path :
+            
+
+        Returns
+        -------
+
+        """
         # GH 7775
         mi = MultiIndex.from_arrays([idx, idx])
         df = pd.DataFrame(0, index=mi, columns=["a"])
@@ -4926,6 +6931,17 @@
                 df.to_hdf(path, "df")
 
     def test_unsuppored_hdf_file_error(self, datapath):
+        """
+
+        Parameters
+        ----------
+        datapath :
+            
+
+        Returns
+        -------
+
+        """
         # GH 9539
         data_path = datapath("io", "data", "legacy_hdf/incompatible_dataset.h5")
         message = (
