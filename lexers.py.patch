# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/IPython/lib/lexers.py
+++ b/..//venv/lib/python3.8/site-packages/IPython/lib/lexers.py
@@ -56,16 +56,20 @@
 
 def build_ipy_lexer(python3):
     """Builds IPython lexers depending on the value of `python3`.
-
+    
     The lexer inherits from an appropriate Python lexer and then adds
     information about IPython specific keywords (i.e. magic commands,
     shell commands, etc.)
 
     Parameters
     ----------
-    python3 : bool
-        If `True`, then build an IPython lexer from a Python 3 lexer.
-
+    python3 :
+        
+
+    Returns
+    -------
+
+    
     """
     # It would be nice to have a single IPython lexer class which takes
     # a boolean `python3`.  But since there are two Python lexer classes,
@@ -126,10 +130,15 @@
 
 
 class IPythonPartialTracebackLexer(RegexLexer):
-    """
-    Partial lexer for IPython tracebacks.
-
+    """Partial lexer for IPython tracebacks.
+    
     Handles all the non-python output.
+
+    Parameters
+    ----------
+
+    Returns
+    -------
 
     """
     name = 'IPython Partial Traceback'
@@ -175,13 +184,22 @@
 
 
 class IPythonTracebackLexer(DelegatingLexer):
-    """
-    IPython traceback lexer.
-
+    """IPython traceback lexer.
+    
     For doctests, the tracebacks can be snipped as much as desired with the
-    exception to the lines that designate a traceback. For non-syntax error
-    tracebacks, this is the line of hyphens. For syntax error tracebacks,
-    this is the line which lists the File and line number.
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
+    Raises
+    ------
+    tracebacks
+        this is the line of hyphens
+    this
+        is the line which lists the File and line number
 
     """
     # The lexer inherits from DelegatingLexer.  The "root" lexer is an
@@ -209,38 +227,41 @@
                                  IPythonPartialTracebackLexer, **options)
 
 class IPythonConsoleLexer(Lexer):
-    """
-    An IPython console lexer for IPython code-blocks and doctests, such as:
-
+    """An IPython console lexer for IPython code-blocks and doctests, such as:
+    
     .. code-block:: rst
-
+    
         .. code-block:: ipythonconsole
-
+    
             In [1]: a = 'foo'
-
+    
             In [2]: a
             Out[2]: 'foo'
-
+    
             In [3]: print a
             foo
-
+    
             In [4]: 1 / 0
-
-
+    
+    
     Support is also provided for IPython exceptions:
-
+    
     .. code-block:: rst
-
+    
         .. code-block:: ipythonconsole
-
+    
             In [1]: raise Exception
-
+    
             ---------------------------------------------------------------------------
             Exception                                 Traceback (most recent call last)
             <ipython-input-1-fca2ab0ca76b> in <module>
             ----> 1 raise Exception
 
-            Exception:
+    Parameters
+    ----------
+
+    Returns
+    -------
 
     """
     name = 'IPython console session'
@@ -330,15 +351,21 @@
         self.reset()
 
     def reset(self):
+        """ """
         self.mode = 'output'
         self.index = 0
         self.buffer = u''
         self.insertions = []
 
     def buffered_tokens(self):
-        """
-        Generator of unprocessed tokens after doing insertions and before
+        """Generator of unprocessed tokens after doing insertions and before
         changing to a new state.
+
+        Parameters
+        ----------
+
+        Returns
+        -------
 
         """
         if self.mode == 'output':
@@ -358,23 +385,30 @@
         self.insertions = []
 
     def get_mci(self, line):
-        """
-        Parses the line and returns a 3-tuple: (mode, code, insertion).
-
+        """Parses the line and returns a 3-tuple: (mode, code, insertion).
+        
         `mode` is the next mode (or state) of the lexer, and is always equal
         to 'input', 'output', or 'tb'.
-
+        
         `code` is a portion of the line that should be added to the buffer
         corresponding to the next mode and eventually lexed by another lexer.
         For example, `code` could be Python code if `mode` were 'input'.
-
+        
         `insertion` is a 3-tuple (index, token, text) representing an
         unprocessed "token" that will be inserted into the stream of tokens
         that are created from the buffer once we change modes. This is usually
         the input or output prompt.
-
+        
         In general, the next mode depends on current mode and on the contents
         of `line`.
+
+        Parameters
+        ----------
+        line :
+            
+
+        Returns
+        -------
 
         """
         # To reduce the number of regex match checks, we have multiple
@@ -475,6 +509,17 @@
         return mode, code, insertion
 
     def get_tokens_unprocessed(self, text):
+        """
+
+        Parameters
+        ----------
+        text :
+            
+
+        Returns
+        -------
+
+        """
         self.reset()
         for match in line_re.finditer(text):
             line = match.group()
@@ -494,17 +539,21 @@
             yield token
 
 class IPyLexer(Lexer):
-    r"""
+    """r"""
     Primary lexer for all IPython-like code.
-
+    
     This is a simple helper lexer.  If the first line of the text begins with
     "In \[[0-9]+\]:", then the entire text is parsed with an IPython console
     lexer. If not, then the entire text is parsed with an IPython lexer.
-
+    
     The goal is to reduce the number of lexers that are registered
     with Pygments.
 
-    """
+    Parameters
+    ----------
+
+    Returns
+    -------
     name = 'IPy session'
     aliases = ['ipy']
 
@@ -521,6 +570,17 @@
         self.IPythonConsoleLexer = IPythonConsoleLexer(**options)
 
     def get_tokens_unprocessed(self, text):
+        """
+
+        Parameters
+        ----------
+        text :
+            
+
+        Returns
+        -------
+
+        """
         # Search for the input prompt anywhere...this allows code blocks to
         # begin with comments as well.
         if re.match(r'.*(In \[[0-9]+\]:)', text.strip(), re.DOTALL):
