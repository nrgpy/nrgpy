# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/numpy/core/einsumfunc.py
+++ b/..//venv/lib/python3.8/site-packages/numpy/core/einsumfunc.py
@@ -16,8 +16,7 @@
 
 
 def _flop_count(idx_contraction, inner, num_terms, size_dictionary):
-    """
-    Computes the number of FLOPS in the contraction.
+    """Computes the number of FLOPS in the contraction.
 
     Parameters
     ----------
@@ -37,13 +36,11 @@
 
     Examples
     --------
-
     >>> _flop_count('abc', False, 1, {'a': 2, 'b':3, 'c':5})
     30
-
+    
     >>> _flop_count('abc', True, 2, {'a': 2, 'b':3, 'c':5})
     60
-
     """
 
     overall_size = _compute_size_by_dict(idx_contraction, size_dictionary)
@@ -54,8 +51,7 @@
     return overall_size * op_factor
 
 def _compute_size_by_dict(indices, idx_dict):
-    """
-    Computes the product of the elements in indices based on the dictionary
+    """Computes the product of the elements in indices based on the dictionary
     idx_dict.
 
     Parameters
@@ -74,7 +70,6 @@
     --------
     >>> _compute_size_by_dict('abbc', {'a': 2, 'b':3, 'c':5})
     90
-
     """
     ret = 1
     for i in indices:
@@ -83,8 +78,7 @@
 
 
 def _find_contraction(positions, input_sets, output_set):
-    """
-    Finds the contraction for a given set of input and output sets.
+    """Finds the contraction for a given set of input and output sets.
 
     Parameters
     ----------
@@ -109,15 +103,16 @@
 
     Examples
     --------
-
+    
     # A simple dot product test case
+    
+    # A more complex case with additional terms in the contraction
     >>> pos = (0, 1)
     >>> isets = [set('ab'), set('bc')]
     >>> oset = set('ac')
     >>> _find_contraction(pos, isets, oset)
     ({'a', 'c'}, [{'a', 'c'}], {'b'}, {'a', 'b', 'c'})
-
-    # A more complex case with additional terms in the contraction
+    
     >>> pos = (0, 2)
     >>> isets = [set('abd'), set('ac'), set('bdc')]
     >>> oset = set('ac')
@@ -143,8 +138,7 @@
 
 
 def _optimal_path(input_sets, output_set, idx_dict, memory_limit):
-    """
-    Computes all possible pair contractions, sieves the results based
+    """Computes all possible pair contractions, sieves the results based
     on ``memory_limit`` and returns the lowest cost path. This algorithm
     scales factorial with respect to the elements in the list ``input_sets``.
 
@@ -235,13 +229,8 @@
 
     Returns
     -------
-    cost : (int, int)
-        A tuple containing the size of any indices removed, and the flop cost.
-    positions : tuple of int
-        The locations of the proposed tensors to contract.
-    new_input_sets : list of sets
-        The resulting new list of indices if this proposed contraction is performed.
-
+
+    
     """
 
     # Find the contraction
@@ -284,8 +273,8 @@
 
     Returns
     -------
-    mod_results : list
-        The list of modified results, updated with outcome of ``best`` contraction.
+
+    
     """
 
     best_con = best[1]
@@ -310,8 +299,7 @@
     return mod_results
 
 def _greedy_path(input_sets, output_set, idx_dict, memory_limit):
-    """
-    Finds the path by contracting the best pair until the input list is
+    """Finds the path by contracting the best pair until the input list is
     exhausted. The best pair is found by minimizing the tuple
     ``(-prod(indices_removed), cost)``.  What this amounts to is prioritizing
     matrix multiplication or inner product operations, then Hadamard like
@@ -329,6 +317,8 @@
         Dictionary of index sizes
     memory_limit_limit : int
         The maximum number of elements in a temporary array
+    memory_limit :
+        
 
     Returns
     -------
@@ -411,8 +401,7 @@
 
 
 def _can_dot(inputs, result, idx_removed):
-    """
-    Checks if we can use BLAS (np.tensordot) call and its beneficial to do so.
+    """Checks if we can use BLAS (np.tensordot) call and its beneficial to do so.
 
     Parameters
     ----------
@@ -423,7 +412,6 @@
     idx_removed : set
         Indices that are removed in the summation
 
-
     Returns
     -------
     type : bool
@@ -434,23 +422,23 @@
     If the operations is BLAS level 1 or 2 and is not already aligned
     we default back to einsum as the memory movement to copy is more
     costly than the operation itself.
-
-
+    
     Examples
     --------
-
+    
     # Standard GEMM operation
+    
+    # Can use the standard BLAS, but requires odd data movement
+    
+    # DDOT where the memory is not aligned
     >>> _can_dot(['ij', 'jk'], 'ik', set('j'))
     True
-
-    # Can use the standard BLAS, but requires odd data movement
+    
     >>> _can_dot(['ijj', 'jk'], 'ik', set('j'))
     False
-
-    # DDOT where the memory is not aligned
+    
     >>> _can_dot(['ijk', 'ikj'], '', set('ijk'))
     False
-
     """
 
     # All `dot` calls remove indices
@@ -521,8 +509,12 @@
 
 
 def _parse_einsum_input(operands):
-    """
-    A reproduction of einsum c side einsum parsing in python.
+    """A reproduction of einsum c side einsum parsing in python.
+
+    Parameters
+    ----------
+    operands :
+        
 
     Returns
     -------
@@ -536,13 +528,12 @@
     Examples
     --------
     The operand list is simplified to reduce printing:
-
     >>> np.random.seed(123)
     >>> a = np.random.rand(4, 4)
     >>> b = np.random.rand(4, 4, 4)
     >>> _parse_einsum_input(('...a,...a->...', a, b))
     ('za,xza', 'xz', [a, b]) # may vary
-
+    
     >>> _parse_einsum_input((a, [Ellipsis, 0], b, [Ellipsis, 0]))
     ('za,xza', 'xz', [a, b]) # may vary
     """
@@ -694,6 +685,21 @@
 
 
 def _einsum_path_dispatcher(*operands, optimize=None, einsum_call=None):
+    """
+
+    Parameters
+    ----------
+    *operands :
+        
+    optimize :
+         (Default value = None)
+    einsum_call :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     # NOTE: technically, we should only dispatch on array-like arguments, not
     # subscripts (given as strings). But separating operands into
     # arrays/subscripts is a little tricky/slow (given einsum's two supported
@@ -705,9 +711,8 @@
 
 @array_function_dispatch(_einsum_path_dispatcher, module='numpy')
 def einsum_path(*operands, optimize='greedy', einsum_call=False):
-    """
-    einsum_path(subscripts, *operands, optimize='greedy')
-
+    """einsum_path(subscripts, *operands, optimize='greedy')
+    
     Evaluates the lowest cost contraction order for an einsum expression by
     considering the creation of intermediate arrays.
 
@@ -722,22 +727,22 @@
         assumed to be the maximum intermediate size created. If only a single
         argument is provided the largest input or output array size is used
         as a maximum intermediate size.
-
         * if a list is given that starts with ``einsum_path``, uses this as the
-          contraction path
+        contraction path
         * if False no optimization is taken
         * if True defaults to the 'greedy' algorithm
         * 'optimal' An algorithm that combinatorially explores all possible
-          ways of contracting the listed tensors and choosest the least costly
-          path. Scales exponentially with the number of terms in the
-          contraction.
+        ways of contracting the listed tensors and choosest the least costly
+        path. Scales exponentially with the number of terms in the
+        contraction.
         * 'greedy' An algorithm that chooses the best pair contraction
-          at each step. Effectively, this algorithm searches the largest inner,
-          Hadamard, and then outer products at each step. Scales cubically with
-          the number of terms in the contraction. Equivalent to the 'optimal'
-          path for most contractions.
-
+        at each step. Effectively, this algorithm searches the largest inner,
+        Hadamard, and then outer products at each step. Scales cubically with
+        the number of terms in the contraction. Equivalent to the 'optimal'
+        path for most contractions.
         Default is 'greedy'.
+    einsum_call :
+         (Default value = False)
 
     Returns
     -------
@@ -752,20 +757,21 @@
     contracted first, the result of this contraction is then appended to the
     end of the contraction list. This list can then be iterated over until all
     intermediate contractions are complete.
-
     See Also
     --------
     einsum, linalg.multi_dot
-
     Examples
     --------
-
+    
     We can begin with a chain dot example. In this case, it is optimal to
     contract the ``b`` and ``c`` tensors first as represented by the first
     element of the path ``(1, 2)``. The resulting tensor is added to the end
     of the contraction and the remaining contraction ``(0, 1)`` is then
     completed.
-
+    
+    
+    
+    A more complex index transformation example.
     >>> np.random.seed(123)
     >>> a = np.random.rand(2, 2)
     >>> b = np.random.rand(2, 5)
@@ -786,18 +792,15 @@
     -------------------------------------------------------------------------
        3                   kl,jk->jl                                ij,jl->il
        3                   jl,ij->il                                   il->il
-
-
-    A more complex index transformation example.
-
+    
     >>> I = np.random.rand(10, 10, 10, 10)
     >>> C = np.random.rand(10, 10)
     >>> path_info = np.einsum_path('ea,fb,abcd,gc,hd->efgh', C, C, I, C, C,
     ...                            optimize='greedy')
-
+    
     >>> print(path_info[0])
     ['einsum_path', (0, 2), (0, 3), (0, 2), (0, 1)]
-    >>> print(path_info[1]) 
+    >>> print(path_info[1])
       Complete contraction:  ea,fb,abcd,gc,hd->efgh # may vary
              Naive scaling:  8
          Optimized scaling:  5
@@ -987,6 +990,23 @@
 
 
 def _einsum_dispatcher(*operands, out=None, optimize=None, **kwargs):
+    """
+
+    Parameters
+    ----------
+    *operands :
+        
+    out :
+         (Default value = None)
+    optimize :
+         (Default value = None)
+    **kwargs :
+        
+
+    Returns
+    -------
+
+    """
     # Arguably we dispatch on more arguments that we really should; see note in
     # _einsum_path_dispatcher for why.
     yield from operands
@@ -996,21 +1016,20 @@
 # Rewrite einsum to handle different cases
 @array_function_dispatch(_einsum_dispatcher, module='numpy')
 def einsum(*operands, out=None, optimize=False, **kwargs):
-    """
-    einsum(subscripts, *operands, out=None, dtype=None, order='K',
+    """einsum(subscripts, *operands, out=None, dtype=None, order='K',
            casting='safe', optimize=False)
-
+    
     Evaluates the Einstein summation convention on the operands.
-
+    
     Using the Einstein summation convention, many common multi-dimensional,
     linear algebraic array operations can be represented in a simple fashion.
     In *implicit* mode `einsum` computes these values.
-
+    
     In *explicit* mode, `einsum` provides further flexibility to compute
     other array operations that might not be considered classical Einstein
     summation operations, by disabling, or forcing summation over specified
     subscript labels.
-
+    
     See the notes and examples for clarification.
 
     Parameters
@@ -1023,7 +1042,7 @@
     operands : list of array_like
         These are the arrays for the operation.
     out : ndarray, optional
-        If provided, the calculation is done into this array.
+        If provided, the calculation is done into this array. (Default value = None)
     dtype : {data-type, None}, optional
         If provided, forces the calculation to use the data type specified.
         Note that you may have to also give a more liberal `casting`
@@ -1038,20 +1057,22 @@
     casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
         Controls what kind of data casting may occur.  Setting this to
         'unsafe' is not recommended, as it can adversely affect accumulations.
-
-          * 'no' means the data types should not be cast at all.
-          * 'equiv' means only byte-order changes are allowed.
-          * 'safe' means only casts which can preserve values are allowed.
-          * 'same_kind' means only safe casts or casts within a kind,
-            like float64 to float32, are allowed.
-          * 'unsafe' means any data conversions may be done.
-
+        * 'no' means the data types should not be cast at all.
+        * 'equiv' means only byte-order changes are allowed.
+        * 'safe' means only casts which can preserve values are allowed.
+        * 'same_kind' means only safe casts or casts within a kind,
+        like float64 to float32, are allowed.
+        * 'unsafe' means any data conversions may be done.
         Default is 'safe'.
     optimize : {False, True, 'greedy', 'optimal'}, optional
         Controls if intermediate optimization should occur. No optimization
         will occur if False and True will default to the 'greedy' algorithm.
         Also accepts an explicit contraction list from the ``np.einsum_path``
         function. See ``np.einsum_path`` for more details. Defaults to False.
+    *operands :
+        
+    **kwargs :
+        
 
     Returns
     -------
@@ -1061,18 +1082,17 @@
     See Also
     --------
     einsum_path, dot, inner, outer, tensordot, linalg.multi_dot
-
     Notes
     -----
     .. versionadded:: 1.6.0
-
+    
     The Einstein summation convention can be used to compute
     many multi-dimensional, linear algebraic array operations. `einsum`
     provides a succinct way of representing these.
-
+    
     A non-exhaustive list of these operations,
     which can be computed by `einsum`, is shown below along with examples:
-
+    
     * Trace of an array, :py:func:`numpy.trace`.
     * Return a diagonal, :py:func:`numpy.diag`.
     * Array axis summations, :py:func:`numpy.sum`.
@@ -1082,7 +1102,7 @@
     * Broadcasting, element-wise and scalar multiplication, :py:func:`numpy.multiply`.
     * Tensor contractions, :py:func:`numpy.tensordot`.
     * Chained array operations, in efficient calculation order, :py:func:`numpy.einsum_path`.
-
+    
     The subscripts string is a comma-separated list of subscript labels,
     where each label refers to a dimension of the corresponding operand.
     Whenever a label is repeated it is summed, so ``np.einsum('i,i', a, b)``
@@ -1093,7 +1113,7 @@
     :py:func:`np.matmul(a,b) <numpy.matmul>`. Repeated subscript labels in one
     operand take the diagonal. For example, ``np.einsum('ii', a)`` is equivalent
     to :py:func:`np.trace(a) <numpy.trace>`.
-
+    
     In *implicit mode*, the chosen subscripts are important
     since the axes of the output are reordered alphabetically.  This
     means that ``np.einsum('ij', a)`` doesn't affect a 2D array, while
@@ -1101,7 +1121,7 @@
     ``np.einsum('ij,jk', a, b)`` returns a matrix multiplication, while,
     ``np.einsum('ij,jh', a, b)`` returns the transpose of the
     multiplication since subscript 'h' precedes subscript 'i'.
-
+    
     In *explicit mode* the output can be directly controlled by
     specifying output subscript labels.  This requires the
     identifier '->' as well as the list of output subscript labels.
@@ -1113,7 +1133,7 @@
     Additionally ``np.einsum('ij,jh->ih', a, b)`` directly specifies the
     order of the output subscript labels and therefore returns matrix
     multiplication, unlike the example above in implicit mode.
-
+    
     To enable and control broadcasting, use an ellipsis.  Default
     NumPy-style broadcasting is done by adding an ellipsis
     to the left of each term, like ``np.einsum('...ii->...i', a)``.
@@ -1121,85 +1141,128 @@
     you can do ``np.einsum('i...i', a)``, or to do a matrix-matrix
     product with the left-most indices instead of rightmost, one can do
     ``np.einsum('ij...,jk...->ik...', a, b)``.
-
+    
     When there is only one operand, no axes are summed, and no output
     parameter is provided, a view into the operand is returned instead
     of a new array.  Thus, taking the diagonal as ``np.einsum('ii->i', a)``
     produces a view (changed in version 1.10.0).
-
+    
     `einsum` also provides an alternative way to provide the subscripts
     and operands as ``einsum(op0, sublist0, op1, sublist1, ..., [sublistout])``.
     If the output shape is not provided in this format `einsum` will be
     calculated in implicit mode, otherwise it will be performed explicitly.
     The examples below have corresponding `einsum` calls with the two
     parameter methods.
-
+    
     .. versionadded:: 1.10.0
-
+    
     Views returned from einsum are now writeable whenever the input array
     is writeable. For example, ``np.einsum('ijk...->kji...', a)`` will now
     have the same effect as :py:func:`np.swapaxes(a, 0, 2) <numpy.swapaxes>`
     and ``np.einsum('ii->i', a)`` will return a writeable view of the diagonal
     of a 2D array.
-
+    
     .. versionadded:: 1.12.0
-
+    
     Added the ``optimize`` argument which will optimize the contraction order
     of an einsum expression. For a contraction with three or more operands this
     can greatly increase the computational efficiency at the cost of a larger
     memory footprint during computation.
-
+    
     Typically a 'greedy' algorithm is applied which empirical tests have shown
     returns the optimal path in the majority of cases. In some cases 'optimal'
     will return the superlative path through a more expensive, exhaustive search.
     For iterative calculations it may be advisable to calculate the optimal path
     once and reuse that path by supplying it as an argument. An example is given
     below.
-
+    
     See :py:func:`numpy.einsum_path` for more details.
-
     Examples
     --------
+    
+    Trace of a matrix:
+    
+    
+    Extract the diagonal (requires explicit form):
+    
+    
+    Sum over an axis (requires explicit form):
+    
+    
+    For higher dimensional arrays summing a single axis can be done with ellipsis:
+    
+    
+    Compute a matrix transpose, or reorder any number of axes:
+    
+    
+    Vector inner products:
+    
+    
+    Matrix vector multiplication:
+    
+    
+    Broadcasting and scalar multiplication:
+    
+    
+    Vector outer product:
+    
+    
+    Tensor contraction:
+    
+    
+    Writeable returned arrays (since version 1.10.0):
+    
+    
+    Example of ellipsis use:
+    
+    
+    Chained array operations. For more complicated contractions, speed ups
+    might be achieved by repeatedly computing a 'greedy' path or pre-computing the
+    'optimal' path and repeatedly applying it, using an
+    `einsum_path` insertion (since version 1.12.0). Performance improvements can be
+    particularly significant with larger arrays:
+    
+    
+    Basic `einsum`: ~1520ms  (benchmarked on 3.1GHz Intel i5.)
+    
+    
+    Sub-optimal `einsum` (due to repeated path calculation time): ~330ms
+    
+    
+    Greedy `einsum` (faster optimal path approximation): ~160ms
+    
+    
+    Optimal `einsum` (best usage pattern in some use cases): ~110ms
     >>> a = np.arange(25).reshape(5,5)
     >>> b = np.arange(5)
     >>> c = np.arange(6).reshape(2,3)
-
-    Trace of a matrix:
-
+    
     >>> np.einsum('ii', a)
     60
     >>> np.einsum(a, [0,0])
     60
     >>> np.trace(a)
     60
-
-    Extract the diagonal (requires explicit form):
-
+    
     >>> np.einsum('ii->i', a)
     array([ 0,  6, 12, 18, 24])
     >>> np.einsum(a, [0,0], [0])
     array([ 0,  6, 12, 18, 24])
     >>> np.diag(a)
     array([ 0,  6, 12, 18, 24])
-
-    Sum over an axis (requires explicit form):
-
+    
     >>> np.einsum('ij->i', a)
     array([ 10,  35,  60,  85, 110])
     >>> np.einsum(a, [0,1], [0])
     array([ 10,  35,  60,  85, 110])
     >>> np.sum(a, axis=1)
     array([ 10,  35,  60,  85, 110])
-
-    For higher dimensional arrays summing a single axis can be done with ellipsis:
-
+    
     >>> np.einsum('...j->...', a)
     array([ 10,  35,  60,  85, 110])
     >>> np.einsum(a, [Ellipsis,1], [Ellipsis])
     array([ 10,  35,  60,  85, 110])
-
-    Compute a matrix transpose, or reorder any number of axes:
-
+    
     >>> np.einsum('ji', c)
     array([[0, 3],
            [1, 4],
@@ -1216,18 +1279,14 @@
     array([[0, 3],
            [1, 4],
            [2, 5]])
-
-    Vector inner products:
-
+    
     >>> np.einsum('i,i', b, b)
     30
     >>> np.einsum(b, [0], b, [0])
     30
     >>> np.inner(b,b)
     30
-
-    Matrix vector multiplication:
-
+    
     >>> np.einsum('ij,j', a, b)
     array([ 30,  80, 130, 180, 230])
     >>> np.einsum(a, [0,1], b, [1])
@@ -1236,9 +1295,7 @@
     array([ 30,  80, 130, 180, 230])
     >>> np.einsum('...j,j', a, b)
     array([ 30,  80, 130, 180, 230])
-
-    Broadcasting and scalar multiplication:
-
+    
     >>> np.einsum('..., ...', 3, c)
     array([[ 0,  3,  6],
            [ 9, 12, 15]])
@@ -1251,9 +1308,7 @@
     >>> np.multiply(3, c)
     array([[ 0,  3,  6],
            [ 9, 12, 15]])
-
-    Vector outer product:
-
+    
     >>> np.einsum('i,j', np.arange(2)+1, b)
     array([[0, 1, 2, 3, 4],
            [0, 2, 4, 6, 8]])
@@ -1263,9 +1318,7 @@
     >>> np.outer(np.arange(2)+1, b)
     array([[0, 1, 2, 3, 4],
            [0, 2, 4, 6, 8]])
-
-    Tensor contraction:
-
+    
     >>> a = np.arange(60.).reshape(3,4,5)
     >>> b = np.arange(24.).reshape(4,3,2)
     >>> np.einsum('ijk,jil->kl', a, b)
@@ -1286,18 +1339,14 @@
            [4664., 5018.],
            [4796., 5162.],
            [4928., 5306.]])
-
-    Writeable returned arrays (since version 1.10.0):
-
+    
     >>> a = np.zeros((3, 3))
     >>> np.einsum('ii->i', a)[:] = 1
     >>> a
     array([[1., 0., 0.],
            [0., 1., 0.],
            [0., 0., 1.]])
-
-    Example of ellipsis use:
-
+    
     >>> a = np.arange(6).reshape((3,2))
     >>> b = np.arange(12).reshape((4,3))
     >>> np.einsum('ki,jk->ij', a, b)
@@ -1309,36 +1358,21 @@
     >>> np.einsum('k...,jk', a, b)
     array([[10, 28, 46, 64],
            [13, 40, 67, 94]])
-
-    Chained array operations. For more complicated contractions, speed ups
-    might be achieved by repeatedly computing a 'greedy' path or pre-computing the
-    'optimal' path and repeatedly applying it, using an
-    `einsum_path` insertion (since version 1.12.0). Performance improvements can be
-    particularly significant with larger arrays:
-
+    
     >>> a = np.ones(64).reshape(2,4,8)
-
-    Basic `einsum`: ~1520ms  (benchmarked on 3.1GHz Intel i5.)
-
+    
     >>> for iteration in range(500):
     ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a)
-
-    Sub-optimal `einsum` (due to repeated path calculation time): ~330ms
-
+    
     >>> for iteration in range(500):
     ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='optimal')
-
-    Greedy `einsum` (faster optimal path approximation): ~160ms
-
+    
     >>> for iteration in range(500):
     ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='greedy')
-
-    Optimal `einsum` (best usage pattern in some use cases): ~110ms
-
+    
     >>> path = np.einsum_path('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='optimal')[0]
     >>> for iteration in range(500):
     ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize=path)
-
     """
     # Special handling if out is specified
     specified_out = out is not None
