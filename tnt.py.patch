# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pygments/lexers/tnt.py
+++ b/..//venv/lib/python3.8/site-packages/pygments/lexers/tnt.py
@@ -19,13 +19,19 @@
 
 
 class TNTLexer(Lexer):
-    """
-    Lexer for Typographic Number Theory, as described in the book
+    """Lexer for Typographic Number Theory, as described in the book
     GÃ¶del, Escher, Bach, by Douglas R. Hofstadter,
     or as summarized here:
     https://github.com/Kenny2github/language-tnt/blob/master/README.md#summary-of-tnt
-
+    
     .. versionadded:: 2.7
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
 
     name = 'Typographic Number Theory'
@@ -60,7 +66,21 @@
         self.cur = []
 
     def whitespace(self, start, text, required=False):
-        """Tokenize whitespace."""
+        """Tokenize whitespace.
+
+        Parameters
+        ----------
+        start :
+            
+        text :
+            
+        required :
+             (Default value = False)
+
+        Returns
+        -------
+
+        """
         end = start
         try:
             while text[end] in self.WHITESPACE:
@@ -74,7 +94,19 @@
         return end
 
     def variable(self, start, text):
-        """Tokenize a variable."""
+        """Tokenize a variable.
+
+        Parameters
+        ----------
+        start :
+            
+        text :
+            
+
+        Returns
+        -------
+
+        """
         assert text[start] in self.VARIABLES
         end = start+1
         while text[end] in self.PRIMES:
@@ -83,7 +115,19 @@
         return end
 
     def term(self, start, text):
-        """Tokenize a term."""
+        """Tokenize a term.
+
+        Parameters
+        ----------
+        start :
+            
+        text :
+            
+
+        Returns
+        -------
+
+        """
         if text[start] == 'S':  # S...S(...) or S...0
             end = start+1
             while text[end] == 'S':
@@ -107,7 +151,19 @@
         raise AssertionError  # no matches
 
     def formula(self, start, text):
-        """Tokenize a formula."""
+        """Tokenize a formula.
+
+        Parameters
+        ----------
+        start :
+            
+        text :
+            
+
+        Returns
+        -------
+
+        """
         if text[start] in self.NEGATORS:  # ~<...>
             end = start+1
             while text[end] in self.NEGATORS:
@@ -137,7 +193,19 @@
         return start
 
     def rule(self, start, text):
-        """Tokenize a rule."""
+        """Tokenize a rule.
+
+        Parameters
+        ----------
+        start :
+            
+        text :
+            
+
+        Returns
+        -------
+
+        """
         match = self.RULES.match(text, start)
         assert match is not None
         groups = sorted(match.regs[1:])  # exclude whole match
@@ -155,7 +223,19 @@
         return match.end()
 
     def lineno(self, start, text):
-        """Tokenize a line referral."""
+        """Tokenize a line referral.
+
+        Parameters
+        ----------
+        start :
+            
+        text :
+            
+
+        Returns
+        -------
+
+        """
         end = start
         while text[end] not in self.NUMBERS:
             end += 1
@@ -170,7 +250,19 @@
         return match.end() + 1
 
     def error_till_line_end(self, start, text):
-        """Mark everything from ``start`` to the end of the line as Error."""
+        """Mark everything from ``start`` to the end of the line as Error.
+
+        Parameters
+        ----------
+        start :
+            
+        text :
+            
+
+        Returns
+        -------
+
+        """
         end = start
         try:
             while text[end] != '\n':  # there's whitespace in rules
@@ -183,7 +275,17 @@
         return end
 
     def get_tokens_unprocessed(self, text):
-        """Returns a list of TNT tokens."""
+        """Returns a list of TNT tokens.
+
+        Parameters
+        ----------
+        text :
+            
+
+        Returns
+        -------
+
+        """
         self.cur = []
         start = end = self.whitespace(0, text)
         while start <= end < len(text):
