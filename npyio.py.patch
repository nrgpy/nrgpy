# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/numpy/lib/npyio.py
+++ b/..//venv/lib/python3.8/site-packages/numpy/lib/npyio.py
@@ -30,6 +30,19 @@
 
 @set_module('numpy')
 def loads(*args, **kwargs):
+    """
+
+    Parameters
+    ----------
+    *args :
+        
+    **kwargs :
+        
+
+    Returns
+    -------
+
+    """
     # NumPy 1.15.0, 2017-12-10
     warnings.warn(
         "np.loads is deprecated, use pickle.loads instead",
@@ -49,15 +62,17 @@
 
 
 class BagObj:
-    """
-    BagObj(obj)
-
+    """BagObj(obj)
+    
     Convert attribute look-ups to getitems on the object passed in.
 
     Parameters
     ----------
     obj : class instance
         Object on which attribute look-up is performed.
+
+    Returns
+    -------
 
     Examples
     --------
@@ -75,7 +90,6 @@
     "Doesn't matter what you want, you're gonna get this"
     >>> bagobj.I_can_be_anything
     "Doesn't matter what you want, you're gonna get this"
-
     """
 
     def __init__(self, obj):
@@ -98,12 +112,24 @@
 
 
 def zipfile_factory(file, *args, **kwargs):
-    """
-    Create a ZipFile.
-
+    """Create a ZipFile.
+    
     Allows for Zip64, and the `file` argument can accept file, str, or
     pathlib.Path objects. `args` and `kwargs` are passed to the zipfile.ZipFile
     constructor.
+
+    Parameters
+    ----------
+    file :
+        
+    *args :
+        
+    **kwargs :
+        
+
+    Returns
+    -------
+
     """
     if not hasattr(file, 'read'):
         file = os_fspath(file)
@@ -113,21 +139,32 @@
 
 
 class NpzFile(Mapping):
-    """
-    NpzFile(fid)
-
+    """NpzFile(fid)
+    
     A dictionary-like object with lazy-loading of files in the zipped
     archive provided on construction.
-
+    
     `NpzFile` is used to load files in the NumPy ``.npz`` data archive
     format. It assumes that files in the archive have a ``.npy`` extension,
     other files are ignored.
-
+    
     The arrays and file strings are lazily loaded on either
     getitem access using ``obj['key']`` or attribute lookup using
     ``obj.f.key``. A list of all files (without ``.npy`` extensions) can
     be obtained with ``obj.files`` and the ZipFile object itself using
     ``obj.zip``.
+
+    Parameters
+    ----------
+    fid : file or str
+        The zipped archive to open. This is either a file-like object
+        or a string containing the path to the archive.
+    own_fid : bool, optional
+        Whether NpzFile should close the file handle.
+        Requires that `fid` is a file-like object.
+
+    Returns
+    -------
 
     Attributes
     ----------
@@ -140,24 +177,14 @@
         to getitem access on the `NpzFile` instance itself.
     allow_pickle : bool, optional
         Allow loading pickled data. Default: False
-
+    
         .. versionchanged:: 1.16.3
             Made default False in response to CVE-2019-6446.
-
+    
     pickle_kwargs : dict, optional
         Additional keyword arguments to pass on to pickle.load.
         These are only useful when loading object arrays saved on
         Python 2 when using Python 3.
-
-    Parameters
-    ----------
-    fid : file or str
-        The zipped archive to open. This is either a file-like object
-        or a string containing the path to the archive.
-    own_fid : bool, optional
-        Whether NpzFile should close the file handle.
-        Requires that `fid` is a file-like object.
-
     Examples
     --------
     >>> from tempfile import TemporaryFile
@@ -166,7 +193,7 @@
     >>> y = np.sin(x)
     >>> np.savez(outfile, x=x, y=y)
     >>> _ = outfile.seek(0)
-
+    
     >>> npz = np.load(outfile)
     >>> isinstance(npz, np.lib.io.NpzFile)
     True
@@ -176,7 +203,6 @@
     array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
     >>> npz.f.x  # attribute lookup
     array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
-
     """
 
     def __init__(self, fid, own_fid=False, allow_pickle=False,
@@ -207,10 +233,7 @@
         self.close()
 
     def close(self):
-        """
-        Close the file.
-
-        """
+        """Close the file."""
         if self.zip is not None:
             self.zip.close()
             self.zip = None
@@ -264,6 +287,7 @@
     # versions of numpy, so no need to deprecated it here.
 
     def iteritems(self):
+        """ """
         # Numpy 1.15, 2018-02-20
         warnings.warn(
             "NpzFile.iteritems is deprecated in python 3, to match the "
@@ -272,6 +296,7 @@
         return self.items()
 
     def iterkeys(self):
+        """ """
         # Numpy 1.15, 2018-02-20
         warnings.warn(
             "NpzFile.iterkeys is deprecated in python 3, to match the "
@@ -283,9 +308,8 @@
 @set_module('numpy')
 def load(file, mmap_mode=None, allow_pickle=False, fix_imports=True,
          encoding='ASCII'):
-    """
-    Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.
-
+    """Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.
+    
     .. warning:: Loading files that contain object arrays uses the ``pickle``
                  module, which is not secure against erroneous or maliciously
                  constructed data. Consider passing ``allow_pickle=False`` to
@@ -304,21 +328,19 @@
         memory-mapped array is kept on disk. However, it can be accessed
         and sliced like any ndarray.  Memory mapping is especially useful
         for accessing small fragments of large files without reading the
-        entire file into memory.
+        entire file into memory. (Default value = None)
     allow_pickle : bool, optional
         Allow loading pickled object arrays stored in npy files. Reasons for
         disallowing pickles include security, as loading pickled data can
         execute arbitrary code. If pickles are disallowed, loading object
         arrays will fail. Default: False
-
         .. versionchanged:: 1.16.3
-            Made default False in response to CVE-2019-6446.
-
+        Made default False in response to CVE-2019-6446.
     fix_imports : bool, optional
         Only useful when loading Python 2 generated pickled files on Python 3,
         which includes npy/npz files containing object arrays. If `fix_imports`
         is True, pickle will try to map the old Python 2 names to the new names
-        used in Python 3.
+        used in Python 3. (Default value = True)
     encoding : str, optional
         What encoding to use when reading Python 2 strings. Only useful when
         loading Python 2 generated pickled files in Python 3, which includes
@@ -344,7 +366,6 @@
     save, savez, savez_compressed, loadtxt
     memmap : Create a memory-map to an array stored in a file on disk.
     lib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.
-
     Notes
     -----
     - If the file contains pickle data, then whatever object is stored
@@ -355,24 +376,27 @@
       each file in the archive.
     - If the file is a ``.npz`` file, the returned value supports the
       context manager protocol in a similar fashion to the open function::
-
+    
         with load('foo.npz') as data:
             a = data['a']
-
+    
       The underlying file descriptor is closed when exiting the 'with'
       block.
-
     Examples
     --------
     Store data to disk, and load it again:
-
+    
+    
+    Store compressed data to disk, and load it again:
+    
+    
+    Mem-map the stored array, and then access the second row
+    directly from disk:
     >>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))
     >>> np.load('/tmp/123.npy')
     array([[1, 2, 3],
            [4, 5, 6]])
-
-    Store compressed data to disk, and load it again:
-
+    
     >>> a=np.array([[1, 2, 3], [4, 5, 6]])
     >>> b=np.array([1, 2])
     >>> np.savez('/tmp/123.npz', a=a, b=b)
@@ -383,14 +407,10 @@
     >>> data['b']
     array([1, 2])
     >>> data.close()
-
-    Mem-map the stored array, and then access the second row
-    directly from disk:
-
+    
     >>> X = np.load('/tmp/123.npy', mmap_mode='r')
     >>> X[1, :]
     memmap([4, 5, 6])
-
     """
     if encoding not in ('ASCII', 'latin1', 'bytes'):
         # The 'encoding' value for pickle also affects what encoding
@@ -451,13 +471,29 @@
 
 
 def _save_dispatcher(file, arr, allow_pickle=None, fix_imports=None):
+    """
+
+    Parameters
+    ----------
+    file :
+        
+    arr :
+        
+    allow_pickle :
+         (Default value = None)
+    fix_imports :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     return (arr,)
 
 
 @array_function_dispatch(_save_dispatcher)
 def save(file, arr, allow_pickle=True, fix_imports=True):
-    """
-    Save an array to a binary file in NumPy ``.npy`` format.
+    """Save an array to a binary file in NumPy ``.npy`` format.
 
     Parameters
     ----------
@@ -480,32 +516,32 @@
         Only useful in forcing objects in object arrays on Python 3 to be
         pickled in a Python 2 compatible way. If `fix_imports` is True, pickle
         will try to map the new Python 3 names to the old module names used in
-        Python 2, so that the pickle data stream is readable with Python 2.
+        Python 2, so that the pickle data stream is readable with Python 2. (Default value = True)
+
+    Returns
+    -------
 
     See Also
     --------
     savez : Save several arrays into a ``.npz`` archive
     savetxt, load
-
     Notes
     -----
     For a description of the ``.npy`` format, see :py:mod:`numpy.lib.format`.
-
+    
     Any data saved to the file is appended to the end of the file.
-
     Examples
     --------
     >>> from tempfile import TemporaryFile
     >>> outfile = TemporaryFile()
-
+    
     >>> x = np.arange(10)
     >>> np.save(outfile, x)
-
+    
     >>> _ = outfile.seek(0) # Only needed here to simulate closing & reopening file
     >>> np.load(outfile)
     array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
-
-
+    
     >>> with open('test.npy', 'wb') as f:
     ...     np.save(f, np.array([1, 2]))
     ...     np.save(f, np.array([1, 3]))
@@ -530,6 +566,21 @@
 
 
 def _savez_dispatcher(file, *args, **kwds):
+    """
+
+    Parameters
+    ----------
+    file :
+        
+    *args :
+        
+    **kwds :
+        
+
+    Returns
+    -------
+
+    """
     yield from args
     yield from kwds.values()
 
@@ -537,7 +588,7 @@
 @array_function_dispatch(_savez_dispatcher)
 def savez(file, *args, **kwds):
     """Save several arrays into a single file in uncompressed ``.npz`` format.
-
+    
     If arguments are passed in with no keywords, the corresponding variable
     names, in the ``.npz`` file, are 'arr_0', 'arr_1', etc. If keyword
     arguments are given, the corresponding variable names, in the ``.npz``
@@ -558,42 +609,48 @@
     kwds : Keyword arguments, optional
         Arrays to save to the file. Arrays will be saved in the file with the
         keyword names.
+    *args :
+        
+    **kwds :
+        
 
     Returns
     -------
     None
+        
 
     See Also
     --------
     save : Save a single array to a binary file in NumPy format.
     savetxt : Save an array to a file as plain text.
     savez_compressed : Save several arrays into a compressed ``.npz`` archive
-
     Notes
     -----
     The ``.npz`` file format is a zipped archive of files named after the
     variables they contain.  The archive is not compressed and each file
     in the archive contains one variable in ``.npy`` format. For a
     description of the ``.npy`` format, see :py:mod:`numpy.lib.format`.
-
+    
     When opening the saved ``.npz`` file with `load` a `NpzFile` object is
     returned. This is a dictionary-like object which can be queried for
     its list of arrays (with the ``.files`` attribute), and for the arrays
     themselves.
-
+    
     When saving dictionaries, the dictionary keys become filenames
     inside the ZIP archive. Therefore, keys should be valid filenames.
     E.g., avoid keys that begin with ``/`` or contain ``.``.
-
     Examples
     --------
+    
+    Using `savez` with \\*args, the arrays are saved with default names.
+    
+    
+    Using `savez` with \\**kwds, the arrays are saved with the keyword names.
     >>> from tempfile import TemporaryFile
     >>> outfile = TemporaryFile()
     >>> x = np.arange(10)
     >>> y = np.sin(x)
-
-    Using `savez` with \\*args, the arrays are saved with default names.
-
+    
     >>> np.savez(outfile, x, y)
     >>> _ = outfile.seek(0) # Only needed here to simulate closing & reopening file
     >>> npzfile = np.load(outfile)
@@ -601,9 +658,7 @@
     ['arr_0', 'arr_1']
     >>> npzfile['arr_0']
     array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
-
-    Using `savez` with \\**kwds, the arrays are saved with the keyword names.
-
+    
     >>> outfile = TemporaryFile()
     >>> np.savez(outfile, x=x, y=y)
     >>> _ = outfile.seek(0)
@@ -617,15 +672,29 @@
 
 
 def _savez_compressed_dispatcher(file, *args, **kwds):
+    """
+
+    Parameters
+    ----------
+    file :
+        
+    *args :
+        
+    **kwds :
+        
+
+    Returns
+    -------
+
+    """
     yield from args
     yield from kwds.values()
 
 
 @array_function_dispatch(_savez_compressed_dispatcher)
 def savez_compressed(file, *args, **kwds):
-    """
-    Save several arrays into a single file in compressed ``.npz`` format.
-
+    """Save several arrays into a single file in compressed ``.npz`` format.
+    
     If keyword arguments are given, then filenames are taken from the keywords.
     If arguments are passed in with no keywords, then stored filenames are
     arr_0, arr_1, etc.
@@ -645,10 +714,15 @@
     kwds : Keyword arguments, optional
         Arrays to save to the file. Arrays will be saved in the file with the
         keyword names.
+    *args :
+        
+    **kwds :
+        
 
     Returns
     -------
     None
+        
 
     See Also
     --------
@@ -656,7 +730,6 @@
     numpy.savetxt : Save an array to a file as plain text.
     numpy.savez : Save several arrays into an uncompressed ``.npz`` file format
     numpy.load : Load the files created by savez_compressed.
-
     Notes
     -----
     The ``.npz`` file format is a zipped archive of files named after the
@@ -664,13 +737,12 @@
     ``zipfile.ZIP_DEFLATED`` and each file in the archive contains one variable
     in ``.npy`` format. For a description of the ``.npy`` format, see
     :py:mod:`numpy.lib.format`.
-
-
+    
+    
     When opening the saved ``.npz`` file with `load` a `NpzFile` object is
     returned. This is a dictionary-like object which can be queried for
     its list of arrays (with the ``.files`` attribute), and for the arrays
     themselves.
-
     Examples
     --------
     >>> test_array = np.random.rand(3, 2)
@@ -681,12 +753,32 @@
     True
     >>> print(np.array_equal(test_vector, loaded['b']))
     True
-
     """
     _savez(file, args, kwds, True)
 
 
 def _savez(file, args, kwds, compress, allow_pickle=True, pickle_kwargs=None):
+    """
+
+    Parameters
+    ----------
+    file :
+        
+    args :
+        
+    kwds :
+        
+    compress :
+        
+    allow_pickle :
+         (Default value = True)
+    pickle_kwargs :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     # Import is postponed to here since zipfile depends on gzip, an optional
     # component of the so-called standard library.
     import zipfile
@@ -754,9 +846,30 @@
 
 
 def _getconv(dtype):
-    """ Find the correct dtype converter. Adapted from matplotlib """
+    """Find the correct dtype converter. Adapted from matplotlib
+
+    Parameters
+    ----------
+    dtype :
+        
+
+    Returns
+    -------
+
+    """
 
     def floatconv(x):
+        """
+
+        Parameters
+        ----------
+        x :
+            
+
+        Returns
+        -------
+
+        """
         x.lower()
         if '0x' in x:
             return float.fromhex(x)
@@ -792,9 +905,9 @@
 def loadtxt(fname, dtype=float, comments='#', delimiter=None,
             converters=None, skiprows=0, usecols=None, unpack=False,
             ndmin=0, encoding='bytes', max_rows=None):
-    r"""
+    """r"""
     Load data from a text file.
-
+    
     Each row in the text file must have the same number of values.
 
     Parameters
@@ -829,11 +942,10 @@
         Which columns to read, with 0 being the first. For example,
         ``usecols = (1,4,5)`` will extract the 2nd, 5th and 6th columns.
         The default, None, results in all columns being read.
-
         .. versionchanged:: 1.11.0
-            When a single column has to be read it is possible to use
-            an integer instead of a tuple. E.g ``usecols = 3`` reads the
-            fourth column the same way as ``usecols = (3,)`` would.
+        When a single column has to be read it is possible to use
+        an integer instead of a tuple. E.g ``usecols = 3`` reads the
+        fourth column the same way as ``usecols = (3,)`` would.
     unpack : bool, optional
         If True, the returned array is transposed, so that arguments may be
         unpacked using ``x, y, z = loadtxt(...)``.  When used with a structured
@@ -842,7 +954,6 @@
         The returned array will have at least `ndmin` dimensions.
         Otherwise mono-dimensional axes will be squeezed.
         Legal values: 0 (default), 1 or 2.
-
         .. versionadded:: 1.6.0
     encoding : str, optional
         Encoding used to decode the inputfile. Does not apply to input streams.
@@ -851,12 +962,10 @@
         'latin1' encoded strings to converters. Override this value to receive
         unicode arrays and pass strings as input to converters.  If set to None
         the system default is used. The default value is 'bytes'.
-
         .. versionadded:: 1.14.0
     max_rows : int, optional
         Read `max_rows` lines of content after `skiprows` lines. The default
         is to read all the lines.
-
         .. versionadded:: 1.16.0
 
     Returns
@@ -869,42 +978,42 @@
     load, fromstring, fromregex
     genfromtxt : Load data with missing values handled as specified.
     scipy.io.loadmat : reads MATLAB data files
-
     Notes
     -----
     This function aims to be a fast reader for simply formatted files.  The
     `genfromtxt` function provides more sophisticated handling of, e.g.,
     lines with missing values.
-
+    
     .. versionadded:: 1.10.0
-
+    
     The strings produced by the Python float.hex method can be used as
     input for floats.
-
     Examples
     --------
+    
+    
+    
+    This example shows how `converters` can be used to convert a field
+    with a trailing minus sign into a negative number.
     >>> from io import StringIO   # StringIO behaves like a file object
     >>> c = StringIO("0 1\n2 3")
     >>> np.loadtxt(c)
     array([[0., 1.],
            [2., 3.]])
-
+    
     >>> d = StringIO("M 21 72\nF 35 58")
     >>> np.loadtxt(d, dtype={'names': ('gender', 'age', 'weight'),
     ...                      'formats': ('S1', 'i4', 'f4')})
     array([(b'M', 21, 72.), (b'F', 35, 58.)],
           dtype=[('gender', 'S1'), ('age', '<i4'), ('weight', '<f4')])
-
+    
     >>> c = StringIO("1,0,2\n3,0,4")
     >>> x, y = np.loadtxt(c, delimiter=',', usecols=(0, 2), unpack=True)
     >>> x
     array([1., 3.])
     >>> y
     array([2., 4.])
-
-    This example shows how `converters` can be used to convert a field
-    with a trailing minus sign into a negative number.
-
+    
     >>> s = StringIO('10.01 31.25-\n19.22 64.31\n17.57- 63.94')
     >>> def conv(fld):
     ...     return -float(fld[:-1]) if fld.endswith(b'-') else float(fld)
@@ -913,7 +1022,6 @@
     array([[ 10.01, -31.25],
            [ 19.22,  64.31],
            [-17.57,  63.94]])
-    """
     # Type conversions for Py3 convenience
     if comments is not None:
         if isinstance(comments, (str, bytes)):
@@ -980,7 +1088,17 @@
     # not to be confused with the flatten_dtype we import...
     @recursive
     def flatten_dtype_internal(self, dt):
-        """Unpack a structured data-type, and produce re-packing info."""
+        """Unpack a structured data-type, and produce re-packing info.
+
+        Parameters
+        ----------
+        dt :
+            
+
+        Returns
+        -------
+
+        """
         if dt.names is None:
             # If the dtype is flattened, return.
             # If the dtype has a shape, the dtype occurs
@@ -1010,7 +1128,19 @@
 
     @recursive
     def pack_items(self, items, packing):
-        """Pack items into nested lists based on re-packing info."""
+        """Pack items into nested lists based on re-packing info.
+
+        Parameters
+        ----------
+        items :
+            
+        packing :
+            
+
+        Returns
+        -------
+
+        """
         if packing is None:
             return items[0]
         elif packing is tuple:
@@ -1026,7 +1156,17 @@
             return tuple(ret)
 
     def split_line(line):
-        """Chop off comments, strip, and split at delimiter. """
+        """Chop off comments, strip, and split at delimiter.
+
+        Parameters
+        ----------
+        line :
+            
+
+        Returns
+        -------
+
+        """
         line = _decode_line(line, encoding=encoding)
 
         if comments is not None:
@@ -1039,15 +1179,18 @@
 
     def read_data(chunk_size):
         """Parse each line, including the first.
-
+        
         The file read, `fh`, is a global defined above.
 
         Parameters
         ----------
-        chunk_size : int
-            At most `chunk_size` lines are read at a time, with iteration
-            until all lines are read.
-
+        chunk_size :
+            
+
+        Returns
+        -------
+
+        
         """
         X = []
         line_iter = itertools.chain([first_line], fh)
@@ -1121,6 +1264,19 @@
                 # converters may use decode to workaround numpy's old behaviour,
                 # so encode the string again before passing to the user converter
                 def tobytes_first(x, conv):
+                    """
+
+                    Parameters
+                    ----------
+                    x :
+                        
+                    conv :
+                        
+
+                    Returns
+                    -------
+
+                    """
                     if type(x) is bytes:
                         return conv(x)
                     return conv(x.encode("latin1"))
@@ -1185,14 +1341,40 @@
 def _savetxt_dispatcher(fname, X, fmt=None, delimiter=None, newline=None,
                         header=None, footer=None, comments=None,
                         encoding=None):
+    """
+
+    Parameters
+    ----------
+    fname :
+        
+    X :
+        
+    fmt :
+         (Default value = None)
+    delimiter :
+         (Default value = None)
+    newline :
+         (Default value = None)
+    header :
+         (Default value = None)
+    footer :
+         (Default value = None)
+    comments :
+         (Default value = None)
+    encoding :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     return (X,)
 
 
 @array_function_dispatch(_savetxt_dispatcher)
 def savetxt(fname, X, fmt='%.18e', delimiter=' ', newline='\n', header='',
             footer='', comments='# ', encoding=None):
-    """
-    Save an array to a text file.
+    """Save an array to a text file.
 
     Parameters
     ----------
@@ -1207,65 +1389,60 @@
         multi-format string, e.g. 'Iteration %d -- %10.5f', in which
         case `delimiter` is ignored. For complex `X`, the legal options
         for `fmt` are:
-
         * a single specifier, `fmt='%.4e'`, resulting in numbers formatted
-          like `' (%s+%sj)' % (fmt, fmt)`
+        like `' (%s+%sj)' % (fmt, fmt)`
         * a full string specifying every real and imaginary part, e.g.
-          `' %.4e %+.4ej %.4e %+.4ej %.4e %+.4ej'` for 3 columns
+        `' %.4e %+.4ej %.4e %+.4ej %.4e %+.4ej'` for 3 columns
         * a list of specifiers, one per column - in this case, the real
-          and imaginary part must have separate specifiers,
-          e.g. `['%.3e + %.3ej', '(%.15e%+.15ej)']` for 2 columns
+        and imaginary part must have separate specifiers,
+        e.g. `['%.3e + %.3ej', '(%.15e%+.15ej)']` for 2 columns (Default value = '%.18e')
     delimiter : str, optional
-        String or character separating columns.
+        String or character separating columns. (Default value = ' ')
     newline : str, optional
         String or character separating lines.
-
-        .. versionadded:: 1.5.0
+        .. versionadded:: 1.5.0 (Default value = '\n')
     header : str, optional
         String that will be written at the beginning of the file.
-
-        .. versionadded:: 1.7.0
+        .. versionadded:: 1.7.0 (Default value = '')
     footer : str, optional
         String that will be written at the end of the file.
-
-        .. versionadded:: 1.7.0
+        .. versionadded:: 1.7.0 (Default value = '')
     comments : str, optional
         String that will be prepended to the ``header`` and ``footer`` strings,
         to mark them as comments. Default: '# ',  as expected by e.g.
         ``numpy.loadtxt``.
-
         .. versionadded:: 1.7.0
     encoding : {None, str}, optional
         Encoding used to encode the outputfile. Does not apply to output
         streams. If the encoding is something other than 'bytes' or 'latin1'
         you will not be able to load the file in NumPy versions < 1.14. Default
         is 'latin1'.
-
         .. versionadded:: 1.14.0
 
+    Returns
+    -------
 
     See Also
     --------
     save : Save an array to a binary file in NumPy ``.npy`` format
     savez : Save several arrays into an uncompressed ``.npz`` archive
     savez_compressed : Save several arrays into a compressed ``.npz`` archive
-
     Notes
     -----
     Further explanation of the `fmt` parameter
     (``%[flag]width[.precision]specifier``):
-
+    
     flags:
         ``-`` : left justify
-
+    
         ``+`` : Forces to precede result with + or -.
-
+    
         ``0`` : Left pad the number with zeros instead of space (see width).
-
+    
     width:
         Minimum number of characters to be printed. The value is not truncated
         if it has more characters.
-
+    
     precision:
         - For integer specifiers (eg. ``d,i,o,x``), the minimum number of
           digits.
@@ -1273,42 +1450,39 @@
           after the decimal point.
         - For ``g`` and ``G``, the maximum number of significant digits.
         - For ``s``, the maximum number of characters.
-
+    
     specifiers:
         ``c`` : character
-
+    
         ``d`` or ``i`` : signed decimal integer
-
+    
         ``e`` or ``E`` : scientific notation with ``e`` or ``E``.
-
+    
         ``f`` : decimal floating point
-
+    
         ``g,G`` : use the shorter of ``e,E`` or ``f``
-
+    
         ``o`` : signed octal
-
+    
         ``s`` : string of characters
-
+    
         ``u`` : unsigned decimal integer
-
+    
         ``x,X`` : unsigned hexadecimal integer
-
+    
     This explanation of ``fmt`` is not complete, for an exhaustive
     specification see [1]_.
-
     References
     ----------
     .. [1] `Format Specification Mini-Language
            <https://docs.python.org/library/string.html#format-specification-mini-language>`_,
            Python Documentation.
-
     Examples
     --------
     >>> x = y = z = np.arange(0.0,5.0,1.0)
     >>> np.savetxt('test.out', x, delimiter=',')   # X is an array
     >>> np.savetxt('test.out', (x,y,z))   # x,y,z equal sized 1D arrays
     >>> np.savetxt('test.out', x, fmt='%1.4e')   # use exponential notation
-
     """
 
     # Py3 conversions first
@@ -1317,30 +1491,73 @@
     delimiter = asstr(delimiter)
 
     class WriteWrap:
-        """Convert to bytes on bytestream inputs.
-
-        """
+        """Convert to bytes on bytestream inputs."""
         def __init__(self, fh, encoding):
             self.fh = fh
             self.encoding = encoding
             self.do_write = self.first_write
 
         def close(self):
+            """ """
             self.fh.close()
 
         def write(self, v):
+            """
+
+            Parameters
+            ----------
+            v :
+                
+
+            Returns
+            -------
+
+            """
             self.do_write(v)
 
         def write_bytes(self, v):
+            """
+
+            Parameters
+            ----------
+            v :
+                
+
+            Returns
+            -------
+
+            """
             if isinstance(v, bytes):
                 self.fh.write(v)
             else:
                 self.fh.write(v.encode(self.encoding))
 
         def write_normal(self, v):
+            """
+
+            Parameters
+            ----------
+            v :
+                
+
+            Returns
+            -------
+
+            """
             self.fh.write(asunicode(v))
 
         def first_write(self, v):
+            """
+
+            Parameters
+            ----------
+            v :
+                
+
+            Returns
+            -------
+
+            """
             try:
                 self.write_normal(v)
                 self.write = self.write_normal
@@ -1438,9 +1655,8 @@
 
 @set_module('numpy')
 def fromregex(file, regexp, dtype, encoding=None):
-    """
-    Construct an array from a text file, using regular expression parsing.
-
+    """Construct an array from a text file, using regular expression parsing.
+    
     The returned array is always a structured array, and is constructed from
     all matches of the regular expression in the file. Groups in the regular
     expression are converted to fields of the structured array.
@@ -1456,8 +1672,7 @@
         Dtype for the structured array.
     encoding : str, optional
         Encoding used to decode the inputfile. Does not apply to input streams.
-
-        .. versionadded:: 1.14.0
+        .. versionadded:: 1.14.0 (Default value = None)
 
     Returns
     -------
@@ -1473,19 +1688,17 @@
     See Also
     --------
     fromstring, loadtxt
-
     Notes
     -----
     Dtypes for structured arrays can be specified in several forms, but all
     forms specify at least the data type and field name. For details see
     `doc.structured_arrays`.
-
     Examples
     --------
     >>> f = open('test.dat', 'w')
     >>> _ = f.write("1312 foo\\n1534  bar\\n444   qux")
     >>> f.close()
-
+    
     >>> regexp = r"(\\d+)\\s+(...)"  # match [digits, whitespace, anything]
     >>> output = np.fromregex('test.dat', regexp,
     ...                       [('num', np.int64), ('key', 'S3')])
@@ -1494,7 +1707,6 @@
           dtype=[('num', '<i8'), ('key', 'S3')])
     >>> output['num']
     array([1312, 1534,  444])
-
     """
     own_fh = False
     if not hasattr(file, "read"):
@@ -1544,9 +1756,8 @@
                replace_space='_', autostrip=False, case_sensitive=True,
                defaultfmt="f%i", unpack=None, usemask=False, loose=True,
                invalid_raise=True, max_rows=None, encoding='bytes'):
-    """
-    Load data from a text file, with missing values handled as specified.
-
+    """Load data from a text file, with missing values handled as specified.
+    
     Each line past the first `skip_header` lines is split at the `delimiter`
     character, and characters following the `comments` character are discarded.
 
@@ -1560,10 +1771,10 @@
     dtype : dtype, optional
         Data type of the resulting array.
         If None, the dtypes will be determined by the contents of each
-        column, individually.
+        column, individually. (Default value = float)
     comments : str, optional
         The character used to indicate the start of a comment.
-        All the characters occurring on a line after a comment are discarded
+        All the characters occurring on a line after a comment are discarded (Default value = '#')
     delimiter : str, int, or sequence, optional
         The string used to separate values.  By default, any consecutive
         whitespaces act as delimiter.  An integer or sequence of integers
@@ -1571,9 +1782,9 @@
     skiprows : int, optional
         `skiprows` was removed in numpy 1.10. Please use `skip_header` instead.
     skip_header : int, optional
-        The number of lines to skip at the beginning of the file.
+        The number of lines to skip at the beginning of the file. (Default value = 0)
     skip_footer : int, optional
-        The number of lines to skip at the end of the file.
+        The number of lines to skip at the end of the file. (Default value = 0)
     converters : variable, optional
         The set of functions that convert the data of a column to a value.
         The converters can also be used to provide a default value
@@ -1582,54 +1793,53 @@
         `missing` was removed in numpy 1.10. Please use `missing_values`
         instead.
     missing_values : variable, optional
-        The set of strings corresponding to missing data.
+        The set of strings corresponding to missing data. (Default value = None)
     filling_values : variable, optional
         The set of values to be used as default when the data are missing.
     usecols : sequence, optional
         Which columns to read, with 0 being the first.  For example,
-        ``usecols = (1, 4, 5)`` will extract the 2nd, 5th and 6th columns.
+        ``usecols = (1, 4, 5)`` will extract the 2nd, 5th and 6th columns. (Default value = None)
     names : {None, True, str, sequence}, optional
         If `names` is True, the field names are read from the first line after
         the first `skip_header` lines.  This line can optionally be proceeded
         by a comment delimiter. If `names` is a sequence or a single-string of
         comma-separated names, the names will be used to define the field names
         in a structured dtype. If `names` is None, the names of the dtype
-        fields will be used, if any.
+        fields will be used, if any. (Default value = None)
     excludelist : sequence, optional
         A list of names to exclude. This list is appended to the default list
         ['return','file','print']. Excluded names are appended an underscore:
         for example, `file` would become `file_`.
     deletechars : str, optional
         A string combining invalid characters that must be deleted from the
-        names.
+        names. (Default value = ''.join(sorted(NameValidator.defaultdeletechars)))
     defaultfmt : str, optional
         A format used to define default field names, such as "f%i" or "f_%02i".
     autostrip : bool, optional
-        Whether to automatically strip white spaces from the variables.
+        Whether to automatically strip white spaces from the variables. (Default value = False)
     replace_space : char, optional
         Character(s) used in replacement of white spaces in the variables
         names. By default, use a '_'.
     case_sensitive : {True, False, 'upper', 'lower'}, optional
         If True, field names are case sensitive.
         If False or 'upper', field names are converted to upper case.
-        If 'lower', field names are converted to lower case.
+        If 'lower', field names are converted to lower case. (Default value = True)
     unpack : bool, optional
         If True, the returned array is transposed, so that arguments may be
-        unpacked using ``x, y, z = loadtxt(...)``
+        unpacked using ``x, y, z = loadtxt(...)`` (Default value = None)
     usemask : bool, optional
         If True, return a masked array.
-        If False, return a regular array.
+        If False, return a regular array. (Default value = False)
     loose : bool, optional
-        If True, do not raise errors for invalid values.
+        If True, do not raise errors for invalid values. (Default value = True)
     invalid_raise : bool, optional
         If True, an exception is raised if an inconsistency is detected in the
         number of columns.
-        If False, a warning is emitted and the offending lines are skipped.
+        If False, a warning is emitted and the offending lines are skipped. (Default value = True)
     max_rows : int,  optional
         The maximum number of rows to read. Must not be used with skip_footer
         at the same time.  If given, the value must be at least 1. Default is
         to read the entire file.
-
         .. versionadded:: 1.10.0
     encoding : str, optional
         Encoding used to decode the inputfile. Does not apply when `fname` is
@@ -1638,7 +1848,6 @@
         and passes latin1 encoded strings to converters. Override this value to
         receive unicode arrays and pass strings as input to converters.  If set
         to None the system default is used. The default value is 'bytes'.
-
         .. versionadded:: 1.14.0
 
     Returns
@@ -1650,7 +1859,6 @@
     See Also
     --------
     numpy.loadtxt : equivalent function when no data is missing.
-
     Notes
     -----
     * When spaces are used as delimiters, or when no delimiter has been given
@@ -1660,55 +1868,57 @@
       exception is raised).
     * Individual values are not stripped of spaces by default.
       When using a custom converter, make sure the function does remove spaces.
-
     References
     ----------
     .. [1] NumPy User Guide, section `I/O with NumPy
            <https://docs.scipy.org/doc/numpy/user/basics.io.genfromtxt.html>`_.
-
     Examples
     ---------
+    
+    Comma delimited file with mixed dtype
+    
+    
+    Using dtype = None
+    
+    
+    Specifying dtype and names
+    
+    
+    An example with fixed-width columns
+    
+    
+    An example to show comments
     >>> from io import StringIO
     >>> import numpy as np
-
-    Comma delimited file with mixed dtype
-
+    
     >>> s = StringIO(u"1,1.3,abcde")
     >>> data = np.genfromtxt(s, dtype=[('myint','i8'),('myfloat','f8'),
     ... ('mystring','S5')], delimiter=",")
     >>> data
     array((1, 1.3, b'abcde'),
           dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])
-
-    Using dtype = None
-
+    
     >>> _ = s.seek(0) # needed for StringIO example only
     >>> data = np.genfromtxt(s, dtype=None,
     ... names = ['myint','myfloat','mystring'], delimiter=",")
     >>> data
     array((1, 1.3, b'abcde'),
           dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])
-
-    Specifying dtype and names
-
+    
     >>> _ = s.seek(0)
     >>> data = np.genfromtxt(s, dtype="i8,f8,S5",
     ... names=['myint','myfloat','mystring'], delimiter=",")
     >>> data
     array((1, 1.3, b'abcde'),
           dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])
-
-    An example with fixed-width columns
-
+    
     >>> s = StringIO(u"11.3abcde")
     >>> data = np.genfromtxt(s, dtype=None, names=['intvar','fltvar','strvar'],
     ...     delimiter=[1,3,5])
     >>> data
     array((1, 1.3, b'abcde'),
           dtype=[('intvar', '<i8'), ('fltvar', '<f8'), ('strvar', 'S5')])
-
-    An example to show comments
-
+    
     >>> f = StringIO('''
     ... text,# of chars
     ... hello world,11
@@ -1716,7 +1926,6 @@
     >>> np.genfromtxt(f, dtype='S12,S12', delimiter=',')
     array([(b'text', b''), (b'hello world', b'11'), (b'numpy', b'5')],
       dtype=[('f0', 'S12'), ('f1', 'S12')])
-
     """
     if max_rows is not None:
         if skip_footer:
@@ -1982,6 +2191,19 @@
                 # converters may use decode to workaround numpy's old behaviour,
                 # so encode the string again before passing to the user converter
                 def tobytes_first(x, conv):
+                    """
+
+                    Parameters
+                    ----------
+                    x :
+                        
+                    conv :
+                        
+
+                    Returns
+                    -------
+
+                    """
                     if type(x) is bytes:
                         return conv(x)
                     return conv(x.encode("latin1"))
@@ -2116,6 +2338,17 @@
                 "system default.",
                 np.VisibleDeprecationWarning, stacklevel=2)
             def encode_unicode_cols(row_tup):
+                """
+
+                Parameters
+                ----------
+                row_tup :
+                    
+
+                Returns
+                -------
+
+                """
                 row = list(row_tup)
                 for i in strcolidx:
                     row[i] = row[i].encode('latin1')
@@ -2232,9 +2465,8 @@
 
 
 def ndfromtxt(fname, **kwargs):
-    """
-    Load ASCII data stored in a file and return it as a single array.
-
+    """Load ASCII data stored in a file and return it as a single array.
+    
     .. deprecated:: 1.17
         ndfromtxt` is a deprecated alias of `genfromtxt` which
         overwrites the ``usemask`` argument with `False` even when
@@ -2244,11 +2476,18 @@
     Parameters
     ----------
     fname, kwargs : For a description of input parameters, see `genfromtxt`.
+        
+    fname :
+        
+    **kwargs :
+        
+
+    Returns
+    -------
 
     See Also
     --------
     numpy.genfromtxt : generic function.
-
     """
     kwargs['usemask'] = False
     # Numpy 1.17
@@ -2260,9 +2499,8 @@
 
 
 def mafromtxt(fname, **kwargs):
-    """
-    Load ASCII data stored in a text file and return a masked array.
-
+    """Load ASCII data stored in a text file and return a masked array.
+    
     .. deprecated:: 1.17
         np.mafromtxt is a deprecated alias of `genfromtxt` which
         overwrites the ``usemask`` argument with `True` even when
@@ -2272,11 +2510,18 @@
     Parameters
     ----------
     fname, kwargs : For a description of input parameters, see `genfromtxt`.
+        
+    fname :
+        
+    **kwargs :
+        
+
+    Returns
+    -------
 
     See Also
     --------
     numpy.genfromtxt : generic function to load ASCII data.
-
     """
     kwargs['usemask'] = True
     # Numpy 1.17
@@ -2288,25 +2533,30 @@
 
 
 def recfromtxt(fname, **kwargs):
-    """
-    Load ASCII data from a file and return it in a record array.
-
+    """Load ASCII data from a file and return it in a record array.
+    
     If ``usemask=False`` a standard `recarray` is returned,
     if ``usemask=True`` a MaskedRecords array is returned.
 
     Parameters
     ----------
     fname, kwargs : For a description of input parameters, see `genfromtxt`.
+        
+    fname :
+        
+    **kwargs :
+        
+
+    Returns
+    -------
 
     See Also
     --------
     numpy.genfromtxt : generic function
-
     Notes
     -----
     By default, `dtype` is None, which means that the data-type of the output
     array will be determined from the data.
-
     """
     kwargs.setdefault("dtype", None)
     usemask = kwargs.get('usemask', False)
@@ -2320,9 +2570,8 @@
 
 
 def recfromcsv(fname, **kwargs):
-    """
-    Load ASCII data stored in a comma-separated file.
-
+    """Load ASCII data stored in a comma-separated file.
+    
     The returned array is a record array (if ``usemask=False``, see
     `recarray`) or a masked record array (if ``usemask=True``,
     see `ma.mrecords.MaskedRecords`).
@@ -2330,16 +2579,22 @@
     Parameters
     ----------
     fname, kwargs : For a description of input parameters, see `genfromtxt`.
+        
+    fname :
+        
+    **kwargs :
+        
+
+    Returns
+    -------
 
     See Also
     --------
     numpy.genfromtxt : generic function to load ASCII data.
-
     Notes
     -----
     By default, `dtype` is None, which means that the data-type of the output
     array will be determined from the data.
-
     """
     # Set default kwargs for genfromtxt as relevant to csv import.
     kwargs.setdefault("case_sensitive", "lower")
