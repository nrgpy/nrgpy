# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/tests/groupby/test_groupby.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/tests/groupby/test_groupby.py
@@ -15,6 +15,7 @@
 
 
 def test_repr():
+    """ """
     # GH18203
     result = repr(pd.Grouper(key="A", level="B"))
     expected = "Grouper(key='A', level='B', axis=0, sort=False)"
@@ -23,6 +24,17 @@
 
 @pytest.mark.parametrize("dtype", ["int64", "int32", "float64", "float32"])
 def test_basic(dtype):
+    """
+
+    Parameters
+    ----------
+    dtype :
+        
+
+    Returns
+    -------
+
+    """
 
     data = Series(np.arange(9) // 3, index=np.arange(9), dtype=dtype)
 
@@ -71,6 +83,19 @@
 
 
 def test_groupby_nonobject_dtype(mframe, df_mixed_floats):
+    """
+
+    Parameters
+    ----------
+    mframe :
+        
+    df_mixed_floats :
+        
+
+    Returns
+    -------
+
+    """
     key = mframe.index.codes[0]
     grouped = mframe.groupby(key)
     result = grouped.sum()
@@ -83,6 +108,17 @@
     df["value"] = range(len(df))
 
     def max_value(group):
+        """
+
+        Parameters
+        ----------
+        group :
+            
+
+        Returns
+        -------
+
+        """
         return group.loc[group["value"].idxmax()]
 
     applied = df.groupby("A").apply(max_value)
@@ -95,6 +131,7 @@
 
 
 def test_groupby_return_type():
+    """ """
 
     # GH2893, return a reduced type
     df1 = DataFrame(
@@ -107,6 +144,17 @@
     )
 
     def func(dataf):
+        """
+
+        Parameters
+        ----------
+        dataf :
+            
+
+        Returns
+        -------
+
+        """
         return dataf["val2"] - dataf["val2"].mean()
 
     with tm.assert_produces_warning(FutureWarning):
@@ -123,6 +171,17 @@
     )
 
     def func(dataf):
+        """
+
+        Parameters
+        ----------
+        dataf :
+            
+
+        Returns
+        -------
+
+        """
         return dataf["val2"] - dataf["val2"].mean()
 
     with tm.assert_produces_warning(FutureWarning):
@@ -137,6 +196,7 @@
 
 
 def test_inconsistent_return_type():
+    """ """
     # GH5592
     # inconsistent return type
     df = DataFrame(
@@ -148,6 +208,17 @@
     )
 
     def f(grp):
+        """
+
+        Parameters
+        ----------
+        grp :
+            
+
+        Returns
+        -------
+
+        """
         return grp.iloc[0]
 
     expected = df.groupby("A").first()[["B"]]
@@ -155,6 +226,17 @@
     tm.assert_frame_equal(result, expected)
 
     def f(grp):
+        """
+
+        Parameters
+        ----------
+        grp :
+            
+
+        Returns
+        -------
+
+        """
         if grp.name == "Tiger":
             return None
         return grp.iloc[0]
@@ -165,6 +247,17 @@
     tm.assert_frame_equal(result, e)
 
     def f(grp):
+        """
+
+        Parameters
+        ----------
+        grp :
+            
+
+        Returns
+        -------
+
+        """
         if grp.name == "Pony":
             return None
         return grp.iloc[0]
@@ -176,6 +269,17 @@
 
     # 5592 revisited, with datetimes
     def f(grp):
+        """
+
+        Parameters
+        ----------
+        grp :
+            
+
+        Returns
+        -------
+
+        """
         if grp.name == "Pony":
             return None
         return grp.iloc[0]
@@ -187,6 +291,17 @@
 
     # scalar outputs
     def f(grp):
+        """
+
+        Parameters
+        ----------
+        grp :
+            
+
+        Returns
+        -------
+
+        """
         if grp.name == "Pony":
             return None
         return grp.iloc[0].loc["C"]
@@ -199,7 +314,35 @@
 
 
 def test_pass_args_kwargs(ts, tsframe):
+    """
+
+    Parameters
+    ----------
+    ts :
+        
+    tsframe :
+        
+
+    Returns
+    -------
+
+    """
     def f(x, q=None, axis=0):
+        """
+
+        Parameters
+        ----------
+        x :
+            
+        q :
+             (Default value = None)
+        axis :
+             (Default value = 0)
+
+        Returns
+        -------
+
+        """
         return np.percentile(x, q, axis=axis)
 
     g = lambda x: np.percentile(x, 80, axis=0)
@@ -239,6 +382,7 @@
 
 
 def test_len():
+    """ """
     df = tm.makeTimeDataFrame()
     grouped = df.groupby([lambda x: x.year, lambda x: x.month, lambda x: x.day])
     assert len(grouped) == len(df)
@@ -255,6 +399,7 @@
 
 
 def test_basic_regression():
+    """ """
     # regression
     result = Series([1.0 * x for x in list(range(1, 10)) * 10])
 
@@ -269,6 +414,17 @@
     "dtype", ["float64", "float32", "int64", "int32", "int16", "int8"]
 )
 def test_with_na_groups(dtype):
+    """
+
+    Parameters
+    ----------
+    dtype :
+        
+
+    Returns
+    -------
+
+    """
     index = Index(np.arange(10))
     values = Series(np.ones(10), index, dtype=dtype)
     labels = Series(
@@ -287,6 +443,17 @@
 
     # explicitly return a float from my function
     def f(x):
+        """
+
+        Parameters
+        ----------
+        x :
+            
+
+        Returns
+        -------
+
+        """
         return float(len(x))
 
     agged = grouped.agg(f)
@@ -297,10 +464,22 @@
 
 
 def test_indices_concatenation_order():
+    """ """
 
     # GH 2808
 
     def f1(x):
+        """
+
+        Parameters
+        ----------
+        x :
+            
+
+        Returns
+        -------
+
+        """
         y = x[(x.b % 2) == 1] ** 2
         if y.empty:
             multiindex = MultiIndex(levels=[[]] * 2, codes=[[]] * 2, names=["b", "c"])
@@ -311,6 +490,17 @@
             return y
 
     def f2(x):
+        """
+
+        Parameters
+        ----------
+        x :
+            
+
+        Returns
+        -------
+
+        """
         y = x[(x.b % 2) == 1] ** 2
         if y.empty:
             return DataFrame()
@@ -319,6 +509,17 @@
             return y
 
     def f3(x):
+        """
+
+        Parameters
+        ----------
+        x :
+            
+
+        Returns
+        -------
+
+        """
         y = x[(x.b % 2) == 1] ** 2
         if y.empty:
             multiindex = MultiIndex(
@@ -353,6 +554,17 @@
 
 
 def test_attr_wrapper(ts):
+    """
+
+    Parameters
+    ----------
+    ts :
+        
+
+    Returns
+    -------
+
+    """
     grouped = ts.groupby(lambda x: x.weekday())
 
     result = grouped.std()
@@ -376,6 +588,17 @@
 
 
 def test_frame_groupby(tsframe):
+    """
+
+    Parameters
+    ----------
+    tsframe :
+        
+
+    Returns
+    -------
+
+    """
     grouped = tsframe.groupby(lambda x: x.weekday())
 
     # aggregate
@@ -416,6 +639,17 @@
 
 
 def test_frame_groupby_columns(tsframe):
+    """
+
+    Parameters
+    ----------
+    tsframe :
+        
+
+    Returns
+    -------
+
+    """
     mapping = {"A": 0, "B": 0, "C": 1, "D": 1}
     grouped = tsframe.groupby(mapping, axis=1)
 
@@ -435,6 +669,17 @@
 
 
 def test_frame_set_name_single(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     grouped = df.groupby("A")
 
     result = grouped.mean()
@@ -462,6 +707,17 @@
 
 
 def test_multi_func(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     col1 = df["A"]
     col2 = df["B"]
 
@@ -490,6 +746,17 @@
 
 
 def test_multi_key_multiple_functions(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     grouped = df.groupby(["A", "B"])["C"]
 
     agged = grouped.agg([np.mean, np.std])
@@ -498,6 +765,7 @@
 
 
 def test_frame_multi_key_function_list():
+    """ """
     data = DataFrame(
         {
             "A": [
@@ -560,6 +828,19 @@
 
 @pytest.mark.parametrize("op", [lambda x: x.sum(), lambda x: x.mean()])
 def test_groupby_multiple_columns(df, op):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+    op :
+        
+
+    Returns
+    -------
+
+    """
     data = df
     grouped = data.groupby(["A", "B"])
 
@@ -592,6 +873,7 @@
 
 
 def test_as_index_select_column():
+    """ """
     # GH 5764
     df = pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=["A", "B"])
     result = df.groupby("A", as_index=False)["B"].get_group(1)
@@ -606,6 +888,7 @@
 
 
 def test_groupby_as_index_select_column_sum_empty_df():
+    """ """
     # GH 35246
     df = DataFrame(columns=["A", "B", "C"])
     left = df.groupby(by="A", as_index=False)["B"].sum()
@@ -614,6 +897,17 @@
 
 
 def test_groupby_as_index_agg(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     grouped = df.groupby("A", as_index=False)
 
     # single-key
@@ -670,6 +964,17 @@
 
 
 def test_ops_not_as_index(reduction_func):
+    """
+
+    Parameters
+    ----------
+    reduction_func :
+        
+
+    Returns
+    -------
+
+    """
     # GH 10355, 21090
     # Using as_index=False should not modify grouped column
 
@@ -701,6 +1006,17 @@
 
 
 def test_as_index_series_return_frame(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     grouped = df.groupby("A", as_index=False)
     grouped2 = df.groupby(["A", "B"], as_index=False)
 
@@ -726,6 +1042,17 @@
 
 
 def test_as_index_series_column_slice_raises(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     # GH15072
     grouped = df.groupby("A", as_index=False)
     msg = r"Column\(s\) C already selected"
@@ -735,6 +1062,17 @@
 
 
 def test_groupby_as_index_cython(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     data = df
 
     # single-key
@@ -758,6 +1096,17 @@
 
 
 def test_groupby_as_index_series_scalar(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     grouped = df.groupby(["A", "B"], as_index=False)
 
     # GH #421
@@ -768,6 +1117,19 @@
 
 
 def test_groupby_as_index_corner(df, ts):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+    ts :
+        
+
+    Returns
+    -------
+
+    """
     msg = "as_index=False only valid with DataFrame"
     with pytest.raises(TypeError, match=msg):
         ts.groupby(lambda x: x.weekday(), as_index=False)
@@ -778,6 +1140,17 @@
 
 
 def test_groupby_multiple_key(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     df = tm.makeTimeDataFrame()
     grouped = df.groupby([lambda x: x.year, lambda x: x.month, lambda x: x.day])
     agged = grouped.sum()
@@ -796,6 +1169,17 @@
 
 
 def test_groupby_multi_corner(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     # test that having an all-NA column doesn't mess you up
     df = df.copy()
     df["bad"] = np.nan
@@ -808,6 +1192,17 @@
 
 
 def test_omit_nuisance(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     grouped = df.groupby("A")
 
     result = grouped.mean()
@@ -833,6 +1228,17 @@
 
 
 def test_omit_nuisance_python_multiple(three_group):
+    """
+
+    Parameters
+    ----------
+    three_group :
+        
+
+    Returns
+    -------
+
+    """
     grouped = three_group.groupby(["A", "B"])
 
     agged = grouped.agg(np.mean)
@@ -841,6 +1247,17 @@
 
 
 def test_empty_groups_corner(mframe):
+    """
+
+    Parameters
+    ----------
+    mframe :
+        
+
+    Returns
+    -------
+
+    """
     # handle empty groups
     df = DataFrame(
         {
@@ -865,6 +1282,7 @@
 
 
 def test_nonsense_func():
+    """ """
     df = DataFrame([0])
     msg = r"unsupported operand type\(s\) for \+: 'int' and 'str'"
     with pytest.raises(TypeError, match=msg):
@@ -872,6 +1290,17 @@
 
 
 def test_wrap_aggregated_output_multindex(mframe):
+    """
+
+    Parameters
+    ----------
+    mframe :
+        
+
+    Returns
+    -------
+
+    """
     df = mframe.T
     df["baz", "two"] = "peekaboo"
 
@@ -880,6 +1309,17 @@
     assert isinstance(agged.columns, MultiIndex)
 
     def aggfun(ser):
+        """
+
+        Parameters
+        ----------
+        ser :
+            
+
+        Returns
+        -------
+
+        """
         if ser.name == ("foo", "one"):
             raise TypeError
         else:
@@ -890,6 +1330,17 @@
 
 
 def test_groupby_level_apply(mframe):
+    """
+
+    Parameters
+    ----------
+    mframe :
+        
+
+    Returns
+    -------
+
+    """
 
     result = mframe.groupby(level=0).count()
     assert result.index.name == "first"
@@ -901,6 +1352,17 @@
 
 
 def test_groupby_level_mapper(mframe):
+    """
+
+    Parameters
+    ----------
+    mframe :
+        
+
+    Returns
+    -------
+
+    """
     deleveled = mframe.reset_index()
 
     mapper0 = {"foo": 0, "bar": 0, "baz": 1, "qux": 1}
@@ -920,6 +1382,7 @@
 
 
 def test_groupby_level_nonmulti():
+    """ """
     # GH 1313, GH 13901
     s = Series([1, 2, 3, 10, 4, 5, 20, 6], Index([1, 2, 3, 1, 4, 5, 2, 6], name="foo"))
     expected = Series([11, 22, 3, 4, 5, 6], Index(range(1, 7), name="foo"))
@@ -952,6 +1415,7 @@
 
 
 def test_groupby_complex():
+    """ """
     # GH 12902
     a = Series(data=np.arange(4) * (1 + 2j), index=[0, 0, 1, 1])
     expected = Series((1 + 2j, 5 + 10j))
@@ -964,6 +1428,7 @@
 
 
 def test_groupby_series_indexed_differently():
+    """ """
     s1 = Series(
         [5.0, -9.0, 4.0, 100.0, -5.0, 55.0, 6.7],
         index=Index(["a", "b", "c", "d", "e", "f", "g"]),
@@ -979,6 +1444,7 @@
 
 
 def test_groupby_with_hier_columns():
+    """ """
     tuples = list(
         zip(
             *[
@@ -1017,6 +1483,17 @@
 
 
 def test_grouping_ndarray(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     grouped = df.groupby(df["A"].values)
 
     result = grouped.sum()
@@ -1027,12 +1504,18 @@
 
 
 def test_groupby_wrong_multi_labels():
-    data = """index,foo,bar,baz,spam,data
-0,foo1,bar1,baz1,spam2,20
-1,foo1,bar2,baz1,spam3,30
-2,foo2,bar2,baz1,spam2,40
-3,foo1,bar1,baz2,spam1,50
-4,foo3,bar1,baz2,spam1,60"""
+    """data = """index,foo,bar,baz,spam,data
+    0,foo1,bar1,baz1,spam2,20
+    1,foo1,bar2,baz1,spam3,30
+    2,foo2,bar2,baz1,spam2,40
+    3,foo1,bar1,baz2,spam1,50
+    4,foo3,bar1,baz2,spam1,60
+
+    Parameters
+    ----------
+
+    Returns
+    -------
 
     data = read_csv(StringIO(data), index_col=0)
 
@@ -1044,6 +1527,17 @@
 
 
 def test_groupby_series_with_name(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     result = df.groupby(df["A"]).mean()
     result2 = df.groupby(df["A"], as_index=False).mean()
     assert result.index.name == "A"
@@ -1057,6 +1551,17 @@
 
 
 def test_seriesgroupby_name_attr(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     # GH 6265
     result = df.groupby("A")["C"]
     assert result.count().name == "C"
@@ -1067,6 +1572,7 @@
 
 
 def test_consistency_name():
+    """ """
     # GH 12363
 
     df = DataFrame(
@@ -1084,11 +1590,46 @@
 
 
 def test_groupby_name_propagation(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     # GH 6124
     def summarize(df, name=None):
+        """
+
+        Parameters
+        ----------
+        df :
+            
+        name :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         return Series({"count": 1, "mean": 2, "omissions": 3}, name=name)
 
     def summarize_random_name(df):
+        """
+
+        Parameters
+        ----------
+        df :
+            
+
+        Returns
+        -------
+
+        """
         # Provide a different name for each Series.  In this case, groupby
         # should not attempt to propagate the Series name since they are
         # inconsistent.
@@ -1103,6 +1644,7 @@
 
 
 def test_groupby_nonstring_columns():
+    """ """
     df = DataFrame([np.arange(10) for x in range(10)])
     grouped = df.groupby(0)
     result = grouped.mean()
@@ -1111,6 +1653,7 @@
 
 
 def test_groupby_mixed_type_columns():
+    """ """
     # GH 13432, unorderable types in py3
     df = DataFrame([[0, 1, 2]], columns=["A", "B", 0])
     expected = DataFrame([[1, 2]], columns=["B", 0], index=Index([0], name="A"))
@@ -1125,6 +1668,7 @@
 # TODO: Ensure warning isn't emitted in the first place
 @pytest.mark.filterwarnings("ignore:Mean of:RuntimeWarning")
 def test_cython_grouper_series_bug_noncontig():
+    """ """
     arr = np.empty((100, 100))
     arr.fill(np.nan)
     obj = Series(arr[:, 0])
@@ -1135,6 +1679,7 @@
 
 
 def test_series_grouper_noncontig_index():
+    """ """
     index = Index(tm.rands_array(10, 100))
 
     values = Series(np.random.randn(50), index=index[::2])
@@ -1149,14 +1694,37 @@
 
 
 def test_convert_objects_leave_decimal_alone():
+    """ """
 
     s = Series(range(5))
     labels = np.array(["a", "b", "c", "d", "e"], dtype="O")
 
     def convert_fast(x):
+        """
+
+        Parameters
+        ----------
+        x :
+            
+
+        Returns
+        -------
+
+        """
         return Decimal(str(x.mean()))
 
     def convert_force_pure(x):
+        """
+
+        Parameters
+        ----------
+        x :
+            
+
+        Returns
+        -------
+
+        """
         # base will be length 0
         assert len(x.values.base) > 0
         return Decimal(str(x.mean()))
@@ -1173,6 +1741,7 @@
 
 
 def test_groupby_dtype_inference_empty():
+    """ """
     # GH 6733
     df = DataFrame({"x": [], "range": np.arange(0, dtype="int64")})
     assert df["x"].dtype == np.float64
@@ -1184,6 +1753,17 @@
 
 
 def test_groupby_list_infer_array_like(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     result = df.groupby(list(df["A"])).mean()
     expected = df.groupby(df["A"]).mean()
     tm.assert_frame_equal(result, expected, check_names=False)
@@ -1199,6 +1779,7 @@
 
 
 def test_groupby_keys_same_size_as_index():
+    """ """
     # GH 11185
     freq = "s"
     index = pd.date_range(
@@ -1212,6 +1793,7 @@
 
 
 def test_groupby_one_row():
+    """ """
     # GH 11741
     msg = r"^'Z'$"
     df1 = pd.DataFrame(np.random.randn(1, 4), columns=list("ABCD"))
@@ -1223,6 +1805,7 @@
 
 
 def test_groupby_nat_exclude():
+    """ """
     # GH 6992
     df = pd.DataFrame(
         {
@@ -1286,6 +1869,7 @@
 
 
 def test_groupby_2d_malformed():
+    """ """
     d = DataFrame(index=range(2))
     d["group"] = ["g1", "g2"]
     d["zeros"] = [0, 0]
@@ -1298,6 +1882,7 @@
 
 
 def test_int32_overflow():
+    """ """
     B = np.concatenate((np.arange(10000), np.arange(10000), np.arange(5000)))
     A = np.arange(25000)
     df = DataFrame({"A": A, "B": B, "C": A, "D": B, "E": np.random.randn(25000)})
@@ -1308,6 +1893,7 @@
 
 
 def test_groupby_sort_multi():
+    """ """
     df = DataFrame(
         {
             "a": ["foo", "bar", "baz"],
@@ -1339,6 +1925,25 @@
     result = grouped.sum()
 
     def _check_groupby(df, result, keys, field, f=lambda x: x.sum()):
+        """
+
+        Parameters
+        ----------
+        df :
+            
+        result :
+            
+        keys :
+            
+        field :
+            
+        f :
+             (Default value = lambda x: x.sum())
+
+        Returns
+        -------
+
+        """
         tups = [tuple(row) for row in df[keys].values]
         tups = com.asarray_tuplesafe(tups)
         expected = f(df.groupby(tups)[field])
@@ -1349,6 +1954,7 @@
 
 
 def test_dont_clobber_name_column():
+    """ """
     df = DataFrame(
         {"key": ["a", "a", "a", "b", "b", "b"], "name": ["foo", "bar", "baz"] * 2}
     )
@@ -1358,6 +1964,7 @@
 
 
 def test_skip_group_keys():
+    """ """
 
     tsf = tm.makeTimeDataFrame()
 
@@ -1379,6 +1986,17 @@
 
 
 def test_no_nonsense_name(float_frame):
+    """
+
+    Parameters
+    ----------
+    float_frame :
+        
+
+    Returns
+    -------
+
+    """
     # GH #995
     s = float_frame["C"].copy()
     s.name = None
@@ -1388,6 +2006,7 @@
 
 
 def test_multifunc_sum_bug():
+    """ """
     # GH #1065
     x = DataFrame(np.arange(9).reshape(3, 3))
     x["test"] = 0
@@ -1399,10 +2018,43 @@
 
 
 def test_handle_dict_return_value(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     def f(group):
+        """
+
+        Parameters
+        ----------
+        group :
+            
+
+        Returns
+        -------
+
+        """
         return {"max": group.max(), "min": group.min()}
 
     def g(group):
+        """
+
+        Parameters
+        ----------
+        group :
+            
+
+        Returns
+        -------
+
+        """
         return Series({"max": group.max(), "min": group.min()})
 
     result = df.groupby("A")["C"].apply(f)
@@ -1414,15 +2066,61 @@
 
 @pytest.mark.parametrize("grouper", ["A", ["A", "B"]])
 def test_set_group_name(df, grouper):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+    grouper :
+        
+
+    Returns
+    -------
+
+    """
     def f(group):
+        """
+
+        Parameters
+        ----------
+        group :
+            
+
+        Returns
+        -------
+
+        """
         assert group.name is not None
         return group
 
     def freduce(group):
+        """
+
+        Parameters
+        ----------
+        group :
+            
+
+        Returns
+        -------
+
+        """
         assert group.name is not None
         return group.sum()
 
     def foo(x):
+        """
+
+        Parameters
+        ----------
+        x :
+            
+
+        Returns
+        -------
+
+        """
         return freduce(x)
 
     grouped = df.groupby(grouper)
@@ -1440,12 +2138,24 @@
 
 
 def test_group_name_available_in_inference_pass():
+    """ """
     # gh-15062
     df = pd.DataFrame({"a": [0, 0, 1, 1, 2, 2], "b": np.arange(6)})
 
     names = []
 
     def f(group):
+        """
+
+        Parameters
+        ----------
+        group :
+            
+
+        Returns
+        -------
+
+        """
         names.append(group.name)
         return group.copy()
 
@@ -1456,6 +2166,17 @@
 
 
 def test_no_dummy_key_names(df):
+    """
+
+    Parameters
+    ----------
+    df :
+        
+
+    Returns
+    -------
+
+    """
     # see gh-1291
     result = df.groupby(df["A"].values).sum()
     assert result.index.name is None
@@ -1465,6 +2186,7 @@
 
 
 def test_groupby_sort_multiindex_series():
+    """ """
     # series multiindex groupby sort argument was not being passed through
     # _compress_group_index
     # GH 9444
@@ -1486,17 +2208,41 @@
 
 
 def test_groupby_reindex_inside_function():
+    """ """
 
     periods = 1000
     ind = date_range(start="2012/1/1", freq="5min", periods=periods)
     df = DataFrame({"high": np.arange(periods), "low": np.arange(periods)}, index=ind)
 
     def agg_before(hour, func, fix=False):
-        """
-        Run an aggregate func on the subset of data.
+        """Run an aggregate func on the subset of data.
+
+        Parameters
+        ----------
+        hour :
+            
+        func :
+            
+        fix :
+             (Default value = False)
+
+        Returns
+        -------
+
         """
 
         def _func(data):
+            """
+
+            Parameters
+            ----------
+            data :
+                
+
+            Returns
+            -------
+
+            """
             d = data.loc[data.index.map(lambda x: x.hour < 11)].dropna()
             if fix:
                 data[data.index[0]]
@@ -1507,6 +2253,17 @@
         return _func
 
     def afunc(data):
+        """
+
+        Parameters
+        ----------
+        data :
+            
+
+        Returns
+        -------
+
+        """
         d = data.select(lambda x: x.hour < 11).dropna()
         return np.max(d)
 
@@ -1518,6 +2275,7 @@
 
 
 def test_groupby_multiindex_missing_pair():
+    """ """
     # GH9049
     df = DataFrame(
         {
@@ -1539,6 +2297,7 @@
 
 
 def test_groupby_multiindex_not_lexsorted():
+    """ """
     # GH 11640
 
     # define the lexsorted version
@@ -1589,6 +2348,7 @@
 
 
 def test_index_label_overlaps_location():
+    """ """
     # checking we don't have any label/location confusion in the
     # the wake of GH5375
     df = DataFrame(list("ABCDE"), index=[2, 0, 2, 1, 1])
@@ -1618,6 +2378,7 @@
 
 
 def test_transform_doesnt_clobber_ints():
+    """ """
     # GH 7972
     n = 6
     x = np.arange(n)
@@ -1640,6 +2401,19 @@
     "group_column", ["int_groups", "string_groups", ["int_groups", "string_groups"]]
 )
 def test_groupby_preserves_sort(sort_column, group_column):
+    """
+
+    Parameters
+    ----------
+    sort_column :
+        
+    group_column :
+        
+
+    Returns
+    -------
+
+    """
     # Test to ensure that groupby always preserves sort order of original
     # object. Issue #8588 and #9651
 
@@ -1659,12 +2433,24 @@
     g = df.groupby(group_column)
 
     def test_sort(x):
+        """
+
+        Parameters
+        ----------
+        x :
+            
+
+        Returns
+        -------
+
+        """
         tm.assert_frame_equal(x, x.sort_values(by=sort_column))
 
     g.apply(test_sort)
 
 
 def test_group_shift_with_null_key():
+    """ """
     # This test is designed to replicate the segfault in issue #13813.
     n_rows = 1200
 
@@ -1692,6 +2478,7 @@
 
 
 def test_group_shift_with_fill_value():
+    """ """
     # GH #24128
     n_rows = 24
     df = DataFrame(
@@ -1714,6 +2501,7 @@
 
 
 def test_group_shift_lose_timezone():
+    """ """
     # GH 30134
     now_dt = pd.Timestamp.utcnow()
     df = DataFrame({"a": [1, 1], "date": now_dt})
@@ -1723,6 +2511,7 @@
 
 
 def test_pivot_table_values_key_error():
+    """ """
     # This test is designed to replicate the error in issue #14938
     df = pd.DataFrame(
         {
@@ -1741,6 +2530,7 @@
 
 
 def test_empty_dataframe_groupby():
+    """ """
     # GH8093
     df = DataFrame(columns=["A", "B", "C"])
 
@@ -1752,6 +2542,7 @@
 
 
 def test_tuple_as_grouping():
+    """ """
     # https://github.com/pandas-dev/pandas/issues/18314
     df = pd.DataFrame(
         {
@@ -1771,6 +2562,7 @@
 
 
 def test_tuple_correct_keyerror():
+    """ """
     # https://github.com/pandas-dev/pandas/issues/18798
     df = pd.DataFrame(
         1, index=range(3), columns=pd.MultiIndex.from_product([[1, 2], [3, 4]])
@@ -1780,6 +2572,7 @@
 
 
 def test_groupby_agg_ohlc_non_first():
+    """ """
     # GH 21716
     df = pd.DataFrame(
         [[1], [1]],
@@ -1807,6 +2600,7 @@
 
 
 def test_groupby_multiindex_nat():
+    """ """
     # GH 9236
     values = [
         (pd.NaT, "a"),
@@ -1823,6 +2617,7 @@
 
 
 def test_groupby_empty_list_raises():
+    """ """
     # GH 5289
     values = zip(range(10), range(10))
     df = DataFrame(values, columns=["apple", "b"])
@@ -1832,6 +2627,7 @@
 
 
 def test_groupby_multiindex_series_keys_len_equal_group_axis():
+    """ """
     # GH 25704
     index_array = [["x", "x"], ["a", "b"], ["k", "k"]]
     index_names = ["first", "second", "third"]
@@ -1848,6 +2644,7 @@
 
 
 def test_groupby_groups_in_BaseGrouper():
+    """ """
     # GH 26326
     # Test if DataFrame grouped with a pandas.Grouper has correct groups
     mi = pd.MultiIndex.from_product([["A", "B"], ["C", "D"]], names=["alpha", "beta"])
@@ -1863,6 +2660,17 @@
 
 @pytest.mark.parametrize("group_name", ["x", ["x"]])
 def test_groupby_axis_1(group_name):
+    """
+
+    Parameters
+    ----------
+    group_name :
+        
+
+    Returns
+    -------
+
+    """
     # GH 27614
     df = pd.DataFrame(
         np.arange(12).reshape(3, 4), index=[0, 1, 0], columns=[10, 20, 10, 20]
@@ -1928,6 +2736,21 @@
     ],
 )
 def test_shift_bfill_ffill_tz(tz_naive_fixture, op, expected):
+    """
+
+    Parameters
+    ----------
+    tz_naive_fixture :
+        
+    op :
+        
+    expected :
+        
+
+    Returns
+    -------
+
+    """
     # GH19995, GH27992: Check that timezone does not drop in shift, bfill, and ffill
     tz = tz_naive_fixture
     data = {
@@ -1950,6 +2773,7 @@
 
 
 def test_ffill_missing_arguments():
+    """ """
     # GH 14955
     df = pd.DataFrame({"a": [1, 2], "b": [1, 1]})
     with pytest.raises(ValueError, match="Must specify a fill"):
@@ -1957,6 +2781,7 @@
 
 
 def test_groupby_only_none_group():
+    """ """
     # see GH21624
     # this was crashing with "ValueError: Length of passed values is 1, index implies 0"
     df = pd.DataFrame({"g": [None], "x": 1})
@@ -1967,6 +2792,7 @@
 
 
 def test_groupby_duplicate_index():
+    """ """
     # GH#29189 the groupby call here used to raise
     ser = pd.Series([2, 5, 6, 8], index=[2.0, 4.0, 4.0, 5.0])
     gb = ser.groupby(level=0)
@@ -1978,6 +2804,17 @@
 
 @pytest.mark.parametrize("bool_agg_func", ["any", "all"])
 def test_bool_aggs_dup_column_labels(bool_agg_func):
+    """
+
+    Parameters
+    ----------
+    bool_agg_func :
+        
+
+    Returns
+    -------
+
+    """
     # 21668
     df = pd.DataFrame([[True, True]], columns=["a", "a"])
     grp_by = df.groupby([0])
@@ -1992,6 +2829,19 @@
 )
 @pytest.mark.filterwarnings("ignore:tshift is deprecated:FutureWarning")
 def test_dup_labels_output_shape(groupby_func, idx):
+    """
+
+    Parameters
+    ----------
+    groupby_func :
+        
+    idx :
+        
+
+    Returns
+    -------
+
+    """
     if groupby_func in {"size", "ngroup", "cumcount"}:
         pytest.skip("Not applicable")
 
@@ -2014,6 +2864,17 @@
 
 
 def test_groupby_crash_on_nunique(axis):
+    """
+
+    Parameters
+    ----------
+    axis :
+        
+
+    Returns
+    -------
+
+    """
     # Fix following 30253
     df = pd.DataFrame({("A", "B"): [1, 2], ("A", "C"): [1, 3], ("D", "B"): [0, 0]})
 
@@ -2031,6 +2892,7 @@
 
 
 def test_groupby_list_level():
+    """ """
     # GH 9790
     expected = pd.DataFrame(np.arange(0, 9).reshape(3, 3))
     result = expected.groupby(level=[0]).mean()
@@ -2045,6 +2907,19 @@
     ],
 )
 def test_groups_repr_truncates(max_seq_items, expected):
+    """
+
+    Parameters
+    ----------
+    max_seq_items :
+        
+    expected :
+        
+
+    Returns
+    -------
+
+    """
     # GH 1135
     df = pd.DataFrame(np.random.randn(5, 1))
     df["a"] = df.index
