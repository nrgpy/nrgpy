# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/core/reshape/reshape.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/core/reshape/reshape.py
@@ -36,12 +36,12 @@
 
 
 class _Unstacker:
-    """
-    Helper class to unstack data / pivot with multi-level index
+    """Helper class to unstack data / pivot with multi-level index
 
     Parameters
     ----------
     index : MultiIndex
+        
     level : int or str, default last level
         Level to "unstack". Accepts a name for the level.
     fill_value : scalar, optional
@@ -54,6 +54,9 @@
         Pandas ``DataFrame`` or subclass used to create unstacked
         response.  If None, DataFrame will be used.
 
+    Returns
+    -------
+
     Examples
     --------
     >>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),
@@ -65,20 +68,16 @@
     two  a    3
          b    4
     dtype: int64
-
+    
     >>> s.unstack(level=-1)
          a  b
     one  1  2
     two  3  4
-
+    
     >>> s.unstack(level=0)
        one  two
     a    1    3
     b    2    4
-
-    Returns
-    -------
-    unstacked : DataFrame
     """
 
     def __init__(
@@ -121,6 +120,7 @@
 
     @cache_readonly
     def _indexer_and_to_sort(self):
+        """ """
         v = self.level
 
         codes = list(self.index.codes)
@@ -138,16 +138,29 @@
 
     @cache_readonly
     def sorted_labels(self):
+        """ """
         indexer, to_sort = self._indexer_and_to_sort
         return [l.take(indexer) for l in to_sort]
 
     def _make_sorted_values(self, values: np.ndarray) -> np.ndarray:
+        """
+
+        Parameters
+        ----------
+        values: np.ndarray :
+            
+
+        Returns
+        -------
+
+        """
         indexer, _ = self._indexer_and_to_sort
 
         sorted_values = algos.take_nd(values, indexer, axis=0)
         return sorted_values
 
     def _make_selectors(self):
+        """ """
         new_levels = self.new_index_levels
 
         # make the mask
@@ -174,6 +187,21 @@
         self.compressor = comp_index.searchsorted(np.arange(ngroups))
 
     def get_result(self, values, value_columns, fill_value):
+        """
+
+        Parameters
+        ----------
+        values :
+            
+        value_columns :
+            
+        fill_value :
+            
+
+        Returns
+        -------
+
+        """
 
         if values.ndim == 1:
             values = values[:, np.newaxis]
@@ -188,6 +216,19 @@
         return self.constructor(values, index=index, columns=columns)
 
     def get_new_values(self, values, fill_value=None):
+        """
+
+        Parameters
+        ----------
+        values :
+            
+        fill_value :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
 
         if values.ndim == 1:
             values = values[:, np.newaxis]
@@ -258,6 +299,17 @@
         return new_values, new_mask
 
     def get_new_columns(self, value_columns):
+        """
+
+        Parameters
+        ----------
+        value_columns :
+            
+
+        Returns
+        -------
+
+        """
         if value_columns is None:
             if self.lift == 0:
                 return self.removed_level._shallow_copy(name=self.removed_name)
@@ -296,6 +348,7 @@
 
     @cache_readonly
     def new_index(self):
+        """ """
         # Does not depend on values or value_columns
         result_codes = [lab.take(self.compressor) for lab in self.sorted_labels[:-1]]
 
@@ -315,6 +368,21 @@
 
 
 def _unstack_multiple(data, clocs, fill_value=None):
+    """
+
+    Parameters
+    ----------
+    data :
+        
+    clocs :
+        
+    fill_value :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     if len(clocs) == 0:
         return data
 
@@ -401,6 +469,21 @@
 
 
 def unstack(obj, level, fill_value=None):
+    """
+
+    Parameters
+    ----------
+    obj :
+        
+    level :
+        
+    fill_value :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     if isinstance(level, (tuple, list)):
         if len(level) != 1:
             # _unstack_multiple only handles MultiIndexes,
@@ -430,6 +513,21 @@
 
 
 def _unstack_frame(obj, level, fill_value=None):
+    """
+
+    Parameters
+    ----------
+    obj :
+        
+    level :
+        
+    fill_value :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     if not obj._can_fast_transpose:
         unstacker = _Unstacker(obj.index, level=level)
         mgr = obj._mgr.unstack(unstacker, fill_value=fill_value)
@@ -441,9 +539,8 @@
 
 
 def _unstack_extension_series(series, level, fill_value):
-    """
-    Unstack an ExtensionArray-backed Series.
-
+    """Unstack an ExtensionArray-backed Series.
+    
     The ExtensionDtype is preserved.
 
     Parameters
@@ -459,9 +556,8 @@
 
     Returns
     -------
-    DataFrame
-        Each column of the DataFrame will have the same dtype as
-        the input Series.
+
+    
     """
     # Defer to the logic in ExtensionBlock._unstack
     df = series.to_frame()
@@ -470,16 +566,36 @@
 
 
 def stack(frame, level=-1, dropna=True):
-    """
-    Convert DataFrame to Series with multi-level Index. Columns become the
+    """Convert DataFrame to Series with multi-level Index. Columns become the
     second level of the resulting hierarchical index
+
+    Parameters
+    ----------
+    frame :
+        
+    level :
+         (Default value = -1)
+    dropna :
+         (Default value = True)
 
     Returns
     -------
-    stacked : Series
+
+    
     """
 
     def factorize(index):
+        """
+
+        Parameters
+        ----------
+        index :
+            
+
+        Returns
+        -------
+
+        """
         if index.is_unique:
             return index, np.arange(len(index))
         codes, categories = factorize_from_iterable(index)
@@ -544,6 +660,21 @@
 
 
 def stack_multiple(frame, level, dropna=True):
+    """
+
+    Parameters
+    ----------
+    frame :
+        
+    level :
+        
+    dropna :
+         (Default value = True)
+
+    Returns
+    -------
+
+    """
     # If all passed levels match up to column names, no
     # ambiguity about what to do
     if all(lev in frame.columns.names for lev in level):
@@ -585,13 +716,38 @@
 
 
 def _stack_multi_columns(frame, level_num=-1, dropna=True):
+    """
+
+    Parameters
+    ----------
+    frame :
+        
+    level_num :
+         (Default value = -1)
+    dropna :
+         (Default value = True)
+
+    Returns
+    -------
+
+    """
     def _convert_level_number(level_num, columns):
-        """
-        Logic for converting the level number to something we can safely pass
+        """Logic for converting the level number to something we can safely pass
         to swaplevel.
-
+        
         If `level_num` matches a column name return the name from
         position `level_num`, otherwise return `level_num`.
+
+        Parameters
+        ----------
+        level_num :
+            
+        columns :
+            
+
+        Returns
+        -------
+
         """
         if level_num in columns.names:
             return columns.names[level_num]
@@ -732,8 +888,7 @@
     drop_first=False,
     dtype=None,
 ) -> "DataFrame":
-    """
-    Convert categorical variable into dummy/indicator variables.
+    """Convert categorical variable into dummy/indicator variables.
 
     Parameters
     ----------
@@ -743,26 +898,25 @@
         String to append DataFrame column names.
         Pass a list with length equal to the number of columns
         when calling get_dummies on a DataFrame. Alternatively, `prefix`
-        can be a dictionary mapping column names to prefixes.
+        can be a dictionary mapping column names to prefixes. (Default value = None)
     prefix_sep : str, default '_'
         If appending prefix, separator/delimiter to use. Or pass a
-        list or dictionary as with `prefix`.
+        list or dictionary as with `prefix`. (Default value = "_")
     dummy_na : bool, default False
-        Add a column to indicate NaNs, if False NaNs are ignored.
+        Add a column to indicate NaNs, if False NaNs are ignored. (Default value = False)
     columns : list-like, default None
         Column names in the DataFrame to be encoded.
         If `columns` is None then all the columns with
-        `object` or `category` dtype will be converted.
+        `object` or `category` dtype will be converted. (Default value = None)
     sparse : bool, default False
         Whether the dummy-encoded columns should be backed by
-        a :class:`SparseArray` (True) or a regular NumPy array (False).
+        a :class:`SparseArray` (True) or a regular NumPy array (False). (Default value = False)
     drop_first : bool, default False
         Whether to get k-1 dummies out of k categorical levels by removing the
-        first level.
+        first level. (Default value = False)
     dtype : dtype, default np.uint8
         Data type for new columns. Only a single dtype is allowed.
-
-        .. versionadded:: 0.23.0
+        .. versionadded:: 0.23.0 (Default value = None)
 
     Returns
     -------
@@ -772,41 +926,40 @@
     See Also
     --------
     Series.str.get_dummies : Convert Series to dummy codes.
-
     Examples
     --------
     >>> s = pd.Series(list('abca'))
-
+    
     >>> pd.get_dummies(s)
        a  b  c
     0  1  0  0
     1  0  1  0
     2  0  0  1
     3  1  0  0
-
+    
     >>> s1 = ['a', 'b', np.nan]
-
+    
     >>> pd.get_dummies(s1)
        a  b
     0  1  0
     1  0  1
     2  0  0
-
+    
     >>> pd.get_dummies(s1, dummy_na=True)
        a  b  NaN
     0  1  0    0
     1  0  1    0
     2  0  0    1
-
+    
     >>> df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'],
     ...                    'C': [1, 2, 3]})
-
+    
     >>> pd.get_dummies(df, prefix=['col1', 'col2'])
        C  col1_a  col1_b  col2_a  col2_b  col2_c
     0  1       1       0       0       1       0
     1  2       0       1       1       0       0
     2  3       1       0       0       0       1
-
+    
     >>> pd.get_dummies(pd.Series(list('abcaa')))
        a  b  c
     0  1  0  0
@@ -814,7 +967,7 @@
     2  0  0  1
     3  1  0  0
     4  1  0  0
-
+    
     >>> pd.get_dummies(pd.Series(list('abcaa')), drop_first=True)
        b  c
     0  0  0
@@ -822,7 +975,7 @@
     2  0  1
     3  0  0
     4  0  0
-
+    
     >>> pd.get_dummies(pd.Series(list('abc')), dtype=float)
          a    b    c
     0  1.0  0.0  0.0
@@ -844,6 +997,19 @@
 
         # validate prefixes and separator to avoid silently dropping cols
         def check_len(item, name):
+            """
+
+            Parameters
+            ----------
+            item :
+                
+            name :
+                
+
+            Returns
+            -------
+
+            """
 
             if is_list_like(item):
                 if not len(item) == data_to_encode.shape[1]:
@@ -919,6 +1085,29 @@
     drop_first=False,
     dtype=None,
 ):
+    """
+
+    Parameters
+    ----------
+    data :
+        
+    prefix :
+        
+    prefix_sep :
+         (Default value = "_")
+    dummy_na :
+         (Default value = False)
+    sparse :
+         (Default value = False)
+    drop_first :
+         (Default value = False)
+    dtype :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     from pandas.core.reshape.concat import concat
 
     # Series avoids inconsistent NaN handling
@@ -932,6 +1121,17 @@
         raise ValueError("dtype=object is not a valid dtype for get_dummies")
 
     def get_empty_frame(data) -> DataFrame:
+        """
+
+        Parameters
+        ----------
+        data :
+            
+
+        Returns
+        -------
+
+        """
         if isinstance(data, Series):
             index = data.index
         else:
@@ -1016,17 +1216,21 @@
 
 
 def _reorder_for_extension_array_stack(arr, n_rows: int, n_columns: int):
-    """
-    Re-orders the values when stacking multiple extension-arrays.
-
+    """Re-orders the values when stacking multiple extension-arrays.
+    
     The indirect stacking method used for EAs requires a followup
     take to get the order correct.
 
     Parameters
     ----------
     arr : ExtensionArray
+        
     n_rows, n_columns : int
         The number of rows and columns in the original DataFrame.
+    n_rows: int :
+        
+    n_columns: int :
+        
 
     Returns
     -------
@@ -1038,7 +1242,7 @@
     >>> arr = np.array(['a', 'b', 'c', 'd', 'e', 'f'])
     >>> _reorder_for_extension_array_stack(arr, 2, 3)
     array(['a', 'c', 'e', 'b', 'd', 'f'], dtype='<U1')
-
+    
     >>> _reorder_for_extension_array_stack(arr, 3, 2)
     array(['a', 'd', 'b', 'e', 'c', 'f'], dtype='<U1')
     """
