# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pycparser/c_lexer.py
+++ b/..//venv/lib/python3.8/site-packages/pycparser/c_lexer.py
@@ -14,13 +14,20 @@
 
 
 class CLexer(object):
-    """ A lexer for the C language. After building it, set the
+    """A lexer for the C language. After building it, set the
         input text with input(), and call token() to get new
         tokens.
-
+    
         The public attribute filename can be set to an initial
         filename, but the lexer will update it upon #line
         directives.
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
     def __init__(self, error_func, on_lbrace_func, on_rbrace_func,
                  type_lookup_func):
@@ -56,29 +63,58 @@
         self.pragma_pattern = re.compile(r'[ \t]*pragma\W')
 
     def build(self, **kwargs):
-        """ Builds the lexer from the specification. Must be
+        """Builds the lexer from the specification. Must be
             called after the lexer object is created.
-
+        
             This method exists separately, because the PLY
             manual warns against calling lex.lex inside
             __init__
+
+        Parameters
+        ----------
+        **kwargs :
+            
+
+        Returns
+        -------
+
         """
         self.lexer = lex.lex(object=self, **kwargs)
 
     def reset_lineno(self):
-        """ Resets the internal line number counter of the lexer.
-        """
+        """Resets the internal line number counter of the lexer."""
         self.lexer.lineno = 1
 
     def input(self, text):
+        """
+
+        Parameters
+        ----------
+        text :
+            
+
+        Returns
+        -------
+
+        """
         self.lexer.input(text)
 
     def token(self):
+        """ """
         self.last_token = self.lexer.token()
         return self.last_token
 
     def find_tok_column(self, token):
-        """ Find the column of the token in its line.
+        """Find the column of the token in its line.
+
+        Parameters
+        ----------
+        token :
+            
+
+        Returns
+        -------
+
         """
         last_cr = self.lexer.lexdata.rfind('\n', 0, token.lexpos)
         return token.lexpos - last_cr
@@ -89,11 +125,35 @@
     ## Internal auxiliary methods
     ##
     def _error(self, msg, token):
+        """
+
+        Parameters
+        ----------
+        msg :
+            
+        token :
+            
+
+        Returns
+        -------
+
+        """
         location = self._make_tok_location(token)
         self.error_func(msg, location[0], location[1])
         self.lexer.skip(1)
 
     def _make_tok_location(self, token):
+        """
+
+        Parameters
+        ----------
+        token :
+            
+
+        Returns
+        -------
+
+        """
         return (token.lineno, self.find_tok_column(token))
 
     ##
@@ -271,6 +331,17 @@
     )
 
     def t_PPHASH(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         r'[ \t]*\#'
         if self.line_pattern.match(t.lexer.lexdata, pos=t.lexer.lexpos):
             t.lexer.begin('ppline')
@@ -286,6 +357,17 @@
     ##
     @TOKEN(string_literal)
     def t_ppline_FILENAME(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         if self.pp_line is None:
             self._error('filename before line number in #line', t)
         else:
@@ -293,6 +375,17 @@
 
     @TOKEN(decimal_constant)
     def t_ppline_LINE_NUMBER(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         if self.pp_line is None:
             self.pp_line = t.value
         else:
@@ -301,6 +394,17 @@
             pass
 
     def t_ppline_NEWLINE(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         r'\n'
         if self.pp_line is None:
             self._error('line number missing in #line', t)
@@ -313,34 +417,100 @@
         t.lexer.begin('INITIAL')
 
     def t_ppline_PPLINE(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         r'line'
         pass
 
     t_ppline_ignore = ' \t'
 
     def t_ppline_error(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         self._error('invalid #line directive', t)
 
     ##
     ## Rules for the pppragma state
     ##
     def t_pppragma_NEWLINE(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         r'\n'
         t.lexer.lineno += 1
         t.lexer.begin('INITIAL')
 
     def t_pppragma_PPPRAGMA(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         r'pragma'
         return t
 
     t_pppragma_ignore = ' \t'
 
     def t_pppragma_STR(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         '.+'
         t.type = 'PPPRAGMASTR'
         return t
 
     def t_pppragma_error(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         self._error('invalid #pragma directive', t)
 
     ##
@@ -350,6 +520,17 @@
 
     # Newlines
     def t_NEWLINE(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         r'\n+'
         t.lexer.lineno += t.value.count("\n")
 
@@ -423,10 +604,32 @@
     #
     @TOKEN(r'\{')
     def t_LBRACE(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         self.on_lbrace_func()
         return t
     @TOKEN(r'\}')
     def t_RBRACE(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         self.on_rbrace_func()
         return t
 
@@ -439,31 +642,108 @@
     #
     @TOKEN(floating_constant)
     def t_FLOAT_CONST(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         return t
 
     @TOKEN(hex_floating_constant)
     def t_HEX_FLOAT_CONST(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         return t
 
     @TOKEN(hex_constant)
     def t_INT_CONST_HEX(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         return t
 
     @TOKEN(bin_constant)
     def t_INT_CONST_BIN(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         return t
 
     @TOKEN(bad_octal_constant)
     def t_BAD_CONST_OCT(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         msg = "Invalid octal constant"
         self._error(msg, t)
 
     @TOKEN(octal_constant)
     def t_INT_CONST_OCT(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         return t
 
     @TOKEN(decimal_constant)
     def t_INT_CONST_DEC(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         return t
 
     # Must come before bad_char_const, to prevent it from
@@ -471,44 +751,143 @@
     #
     @TOKEN(multicharacter_constant)
     def t_INT_CONST_CHAR(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         return t
 
     @TOKEN(char_const)
     def t_CHAR_CONST(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         return t
 
     @TOKEN(wchar_const)
     def t_WCHAR_CONST(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         return t
 
     @TOKEN(unmatched_quote)
     def t_UNMATCHED_QUOTE(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         msg = "Unmatched '"
         self._error(msg, t)
 
     @TOKEN(bad_char_const)
     def t_BAD_CHAR_CONST(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         msg = "Invalid char constant %s" % t.value
         self._error(msg, t)
 
     @TOKEN(wstring_literal)
     def t_WSTRING_LITERAL(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         return t
 
     # unmatched string literals are caught by the preprocessor
 
     @TOKEN(bad_string_literal)
     def t_BAD_STRING_LITERAL(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         msg = "String contains invalid escape code"
         self._error(msg, t)
 
     @TOKEN(identifier)
     def t_ID(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         t.type = self.keyword_map.get(t.value, "ID")
         if t.type == 'ID' and self.type_lookup_func(t.value):
             t.type = "TYPEID"
         return t
 
     def t_error(self, t):
+        """
+
+        Parameters
+        ----------
+        t :
+            
+
+        Returns
+        -------
+
+        """
         msg = 'Illegal character %s' % repr(t.value[0])
         self._error(msg, t)
