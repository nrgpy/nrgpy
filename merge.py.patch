# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/core/reshape/merge.py
@@ -71,6 +71,43 @@
     indicator: bool = False,
     validate=None,
 ) -> "DataFrame":
+    """
+
+    Parameters
+    ----------
+    left :
+        
+    right :
+        
+    how: str :
+         (Default value = "inner")
+    on :
+         (Default value = None)
+    left_on :
+         (Default value = None)
+    right_on :
+         (Default value = None)
+    left_index: bool :
+         (Default value = False)
+    right_index: bool :
+         (Default value = False)
+    sort: bool :
+         (Default value = False)
+    suffixes :
+         (Default value = ("_x")
+    "_y") :
+        
+    copy: bool :
+         (Default value = True)
+    indicator: bool :
+         (Default value = False)
+    validate :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     op = _MergeOperation(
         left,
         right,
@@ -94,16 +131,25 @@
 
 
 def _groupby_and_merge(by, on, left: "DataFrame", right: "DataFrame", merge_pieces):
-    """
-    groupby & merge; we are always performing a left-by type operation
+    """groupby & merge; we are always performing a left-by type operation
 
     Parameters
     ----------
-    by: field to group
-    on: duplicates field
-    left: DataFrame
-    right: DataFrame
-    merge_pieces: function for merging
+    by :
+        
+    on :
+        
+    left: "DataFrame" :
+        
+    right: "DataFrame" :
+        
+    merge_pieces :
+        
+
+    Returns
+    -------
+
+    
     """
     pieces = []
     if not isinstance(by, (list, tuple)):
@@ -167,33 +213,34 @@
     suffixes=("_x", "_y"),
     how: str = "outer",
 ) -> "DataFrame":
-    """
-    Perform merge with optional filling/interpolation.
-
+    """Perform merge with optional filling/interpolation.
+    
     Designed for ordered data like time series data. Optionally
     perform group-wise merge (see examples).
 
     Parameters
     ----------
     left : DataFrame
+        
     right : DataFrame
+        
     on : label or list
-        Field names to join on. Must be found in both DataFrames.
+        Field names to join on. Must be found in both DataFrames. (Default value = None)
     left_on : label or list, or array-like
         Field names to join on in left DataFrame. Can be a vector or list of
         vectors of the length of the DataFrame to use a particular vector as
-        the join key instead of columns.
+        the join key instead of columns. (Default value = None)
     right_on : label or list, or array-like
         Field names to join on in right DataFrame or vector/list of vectors per
-        left_on docs.
+        left_on docs. (Default value = None)
     left_by : column name or list of column names
         Group left DataFrame by group columns and merge piece by piece with
-        right DataFrame.
+        right DataFrame. (Default value = None)
     right_by : column name or list of column names
         Group right DataFrame by group columns and merge piece by piece with
-        left DataFrame.
+        left DataFrame. (Default value = None)
     fill_method : {'ffill', None}, default None
-        Interpolation method for data.
+        Interpolation method for data. (Default value = None)
     suffixes : list-like, default is ("_x", "_y")
         A length-2 sequence where each element is optionally a string
         indicating the suffix to add to overlapping column names in
@@ -201,13 +248,16 @@
         of a string to indicate that the column name from `left` or
         `right` should be left as-is, with no suffix. At least one of the
         values must not be None.
-
-        .. versionchanged:: 0.25.0
+        .. versionchanged:: 0.25.0 (Default value = ("_x")
     how : {'left', 'right', 'outer', 'inner'}, default 'outer'
         * left: use only keys from left frame (SQL: left outer join)
         * right: use only keys from right frame (SQL: right outer join)
         * outer: use union of keys from both frames (SQL: full outer join)
         * inner: use intersection of keys from both frames (SQL: inner join).
+    "_y") :
+        
+    how: str :
+         (Default value = "outer")
 
     Returns
     -------
@@ -219,7 +269,6 @@
     --------
     merge : Merge with a database-style join.
     merge_asof : Merge on nearest keys.
-
     Examples
     --------
     >>> df1 = pd.DataFrame(
@@ -237,14 +286,14 @@
     3   a       1     b
     4   c       2     b
     5   e       3     b
-
+    
     >>> df2 = pd.DataFrame({"key": ["b", "c", "d"], "rvalue": [1, 2, 3]})
     >>> df2
           key  rvalue
     0   b       1
     1   c       2
     2   d       3
-
+    
     >>> merge_ordered(df1, df2, fill_method="ffill", left_by="group")
       key  lvalue group  rvalue
     0   a       1     a     NaN
@@ -260,6 +309,19 @@
     """
 
     def _merger(x, y):
+        """
+
+        Parameters
+        ----------
+        x :
+            
+        y :
+            
+
+        Returns
+        -------
+
+        """
         # perform the ordered merge operation
         op = _OrderedMerge(
             x,
@@ -304,86 +366,119 @@
     allow_exact_matches: bool = True,
     direction: str = "backward",
 ) -> "DataFrame":
-    """
-    Perform an asof merge.
-
+    """Perform an asof merge.
+    
     This is similar to a left-join except that we match on nearest
     key rather than equal keys. Both DataFrames must be sorted by the key.
-
+    
     For each row in the left DataFrame:
-
+    
       - A "backward" search selects the last row in the right DataFrame whose
         'on' key is less than or equal to the left's key.
-
+    
       - A "forward" search selects the first row in the right DataFrame whose
         'on' key is greater than or equal to the left's key.
-
+    
       - A "nearest" search selects the row in the right DataFrame whose 'on'
         key is closest in absolute distance to the left's key.
-
+    
     The default is "backward" and is compatible in versions below 0.20.0.
     The direction parameter was added in version 0.20.0 and introduces
     "forward" and "nearest".
-
+    
     Optionally match on equivalent keys with 'by' before searching with 'on'.
 
     Parameters
     ----------
     left : DataFrame
+        
     right : DataFrame
+        
     on : label
         Field name to join on. Must be found in both DataFrames.
         The data MUST be ordered. Furthermore this must be a numeric column,
         such as datetimelike, integer, or float. On or left_on/right_on
-        must be given.
+        must be given. (Default value = None)
     left_on : label
-        Field name to join on in left DataFrame.
+        Field name to join on in left DataFrame. (Default value = None)
     right_on : label
-        Field name to join on in right DataFrame.
+        Field name to join on in right DataFrame. (Default value = None)
     left_index : bool
         Use the index of the left DataFrame as the join key.
     right_index : bool
         Use the index of the right DataFrame as the join key.
     by : column name or list of column names
-        Match on these columns before performing merge operation.
+        Match on these columns before performing merge operation. (Default value = None)
     left_by : column name
-        Field names to match on in the left DataFrame.
+        Field names to match on in the left DataFrame. (Default value = None)
     right_by : column name
-        Field names to match on in the right DataFrame.
+        Field names to match on in the right DataFrame. (Default value = None)
     suffixes : 2-length sequence (tuple, list, ...)
         Suffix to apply to overlapping column names in the left and right
-        side, respectively.
+        side, respectively. (Default value = ("_x")
     tolerance : int or Timedelta, optional, default None
         Select asof tolerance within this range; must be compatible
-        with the merge index.
+        with the merge index. (Default value = None)
     allow_exact_matches : bool, default True
-
         - If True, allow matching with the same 'on' value
-          (i.e. less-than-or-equal-to / greater-than-or-equal-to)
+        (i.e. less-than-or-equal-to / greater-than-or-equal-to)
         - If False, don't match the same 'on' value
-          (i.e., strictly less-than / strictly greater-than).
-
+        (i.e., strictly less-than / strictly greater-than).
     direction : 'backward' (default), 'forward', or 'nearest'
         Whether to search for prior, subsequent, or closest matches.
+    left_index: bool :
+         (Default value = False)
+    right_index: bool :
+         (Default value = False)
+    "_y") :
+        
+    allow_exact_matches: bool :
+         (Default value = True)
+    direction: str :
+         (Default value = "backward")
 
     Returns
     -------
     merged : DataFrame
+        
 
     See Also
     --------
     merge : Merge with a database-style join.
     merge_ordered : Merge with optional filling/interpolation.
-
     Examples
     --------
+    
+    
+    
+    
+    
+    
+    We can use indexed DataFrames as well.
+    
+    
+    
+    
+    Here is a real-world times-series example
+    
+    
+    
+    By default we are taking the asof of the quotes
+    
+    
+    We only asof within 2ms between the quote time and the trade time
+    
+    
+    We only asof within 10ms between the quote time and the trade time
+    and we exclude exact matches on time. However *prior* data will
+    propagate forward
     >>> left = pd.DataFrame({"a": [1, 5, 10], "left_val": ["a", "b", "c"]})
     >>> left
         a left_val
     0   1        a
     1   5        b
     2  10        c
-
+    
     >>> right = pd.DataFrame({"a": [1, 2, 3, 6, 7], "right_val": [1, 2, 3, 6, 7]})
     >>> right
        a  right_val
@@ -392,40 +487,38 @@
     2  3          3
     3  6          6
     4  7          7
-
+    
     >>> pd.merge_asof(left, right, on="a")
         a left_val  right_val
     0   1        a          1
     1   5        b          3
     2  10        c          7
-
+    
     >>> pd.merge_asof(left, right, on="a", allow_exact_matches=False)
         a left_val  right_val
     0   1        a        NaN
     1   5        b        3.0
     2  10        c        7.0
-
+    
     >>> pd.merge_asof(left, right, on="a", direction="forward")
         a left_val  right_val
     0   1        a        1.0
     1   5        b        6.0
     2  10        c        NaN
-
+    
     >>> pd.merge_asof(left, right, on="a", direction="nearest")
         a left_val  right_val
     0   1        a          1
     1   5        b          6
     2  10        c          7
-
-    We can use indexed DataFrames as well.
-
+    
     >>> left = pd.DataFrame({"left_val": ["a", "b", "c"]}, index=[1, 5, 10])
     >>> left
        left_val
     1         a
     5         b
     10        c
-
+    
     >>> right = pd.DataFrame({"right_val": [1, 2, 3, 6, 7]}, index=[1, 2, 3, 6, 7])
     >>> right
        right_val
@@ -434,15 +527,13 @@
     3          3
     6          6
     7          7
-
+    
     >>> pd.merge_asof(left, right, left_index=True, right_index=True)
        left_val  right_val
     1         a          1
     5         b          3
     10        c          7
-
-    Here is a real-world times-series example
-
+    
     >>> quotes = pd.DataFrame(
     ...     {
     ...         "time": [
@@ -479,7 +570,7 @@
     5 2016-05-25 13:30:00.049   AAPL   97.99   98.01
     6 2016-05-25 13:30:00.072   GOOG  720.50  720.88
     7 2016-05-25 13:30:00.075   MSFT   52.01   52.03
-
+    
     >>> trades = pd.DataFrame(
     ...        {
     ...            "time": [
@@ -501,9 +592,7 @@
     2 2016-05-25 13:30:00.048   GOOG  720.77       100
     3 2016-05-25 13:30:00.048   GOOG  720.92       100
     4 2016-05-25 13:30:00.048   AAPL   98.00       100
-
-    By default we are taking the asof of the quotes
-
+    
     >>> pd.merge_asof(trades, quotes, on="time", by="ticker")
                          time ticker   price  quantity     bid     ask
     0 2016-05-25 13:30:00.023   MSFT   51.95        75   51.95   51.96
@@ -511,9 +600,7 @@
     2 2016-05-25 13:30:00.048   GOOG  720.77       100  720.50  720.93
     3 2016-05-25 13:30:00.048   GOOG  720.92       100  720.50  720.93
     4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN
-
-    We only asof within 2ms between the quote time and the trade time
-
+    
     >>> pd.merge_asof(
     ...     trades, quotes, on="time", by="ticker", tolerance=pd.Timedelta("2ms")
     ... )
@@ -523,11 +610,7 @@
     2 2016-05-25 13:30:00.048   GOOG  720.77       100  720.50  720.93
     3 2016-05-25 13:30:00.048   GOOG  720.92       100  720.50  720.93
     4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN
-
-    We only asof within 10ms between the quote time and the trade time
-    and we exclude exact matches on time. However *prior* data will
-    propagate forward
-
+    
     >>> pd.merge_asof(
     ...     trades,
     ...     quotes,
@@ -566,9 +649,15 @@
 # TODO: transformations??
 # TODO: only copy DataFrames when modification necessary
 class _MergeOperation:
-    """
-    Perform a database (SQL) merge operation between two DataFrame or Series
+    """Perform a database (SQL) merge operation between two DataFrame or Series
     objects using either columns as keys or their row indexes
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
 
     _merge_type = "merge"
@@ -662,6 +751,7 @@
             self._validate(validate)
 
     def get_result(self):
+        """ """
         if self.indicator:
             self.left, self.right = self._indicator_pre_merge(self.left, self.right)
 
@@ -696,6 +786,19 @@
     def _indicator_pre_merge(
         self, left: "DataFrame", right: "DataFrame"
     ) -> Tuple["DataFrame", "DataFrame"]:
+        """
+
+        Parameters
+        ----------
+        left: "DataFrame" :
+            
+        right: "DataFrame" :
+            
+
+        Returns
+        -------
+
+        """
 
         columns = left.columns.union(right.columns)
 
@@ -722,6 +825,17 @@
         return left, right
 
     def _indicator_post_merge(self, result):
+        """
+
+        Parameters
+        ----------
+        result :
+            
+
+        Returns
+        -------
+
+        """
 
         result["_left_indicator"] = result["_left_indicator"].fillna(0)
         result["_right_indicator"] = result["_right_indicator"].fillna(0)
@@ -738,24 +852,24 @@
         return result
 
     def _maybe_restore_index_levels(self, result):
-        """
-        Restore index levels specified as `on` parameters
-
+        """Restore index levels specified as `on` parameters
+        
         Here we check for cases where `self.left_on` and `self.right_on` pairs
         each reference an index level in their respective DataFrames. The
         joined columns corresponding to these pairs are then restored to the
         index of `result`.
-
+        
         **Note:** This method has side effects. It modifies `result` in-place
 
         Parameters
         ----------
-        result: DataFrame
+        result : DataFrame
             merge result
 
         Returns
         -------
-        None
+
+        
         """
         names_to_restore = []
         for name, left_key, right_key in zip(
@@ -773,6 +887,21 @@
             result.set_index(names_to_restore, inplace=True)
 
     def _maybe_add_join_keys(self, result, left_indexer, right_indexer):
+        """
+
+        Parameters
+        ----------
+        result :
+            
+        left_indexer :
+            
+        right_indexer :
+            
+
+        Returns
+        -------
+
+        """
 
         left_has_missing = None
         right_has_missing = None
@@ -858,12 +987,13 @@
                     result.insert(i, name or f"key_{i}", key_col)
 
     def _get_join_indexers(self):
-        """ return the join indexers """
+        """ """
         return _get_join_indexers(
             self.left_join_keys, self.right_join_keys, sort=self.sort, how=self.how
         )
 
     def _get_join_info(self):
+        """ """
         left_ax = self.left.axes[self.axis]
         right_ax = self.right.axes[self.axis]
 
@@ -922,19 +1052,31 @@
         other_indexer,
         how: str = "left",
     ):
-        """
-        Create a join index by rearranging one index to match another
+        """Create a join index by rearranging one index to match another
 
         Parameters
         ----------
-        index: Index being rearranged
-        other_index: Index used to supply values not found in index
-        indexer: how to rearrange index
-        how: replacement is only necessary if indexer based on other_index
+        index : Index being rearranged
+            
+        other_index : Index used to supply values not found in index
+            
+        indexer : how to rearrange index
+            
+        how : replacement is only necessary if indexer based on other_index
+            
+        index: Index :
+            
+        other_index: Index :
+            
+        other_indexer :
+            
+        how: str :
+             (Default value = "left")
 
         Returns
         -------
-        join_index
+
+        
         """
         if self.how in (how, "outer") and not isinstance(other_index, MultiIndex):
             # if final index requires values in other_index but not target
@@ -949,18 +1091,21 @@
         return index.take(indexer)
 
     def _get_merge_keys(self):
-        """
-        Note: has side effects (copy/delete key columns)
+        """Note: has side effects (copy/delete key columns)
 
         Parameters
         ----------
-        left
-        right
-        on
+        left :
+            
+        right :
+            
+        on :
+            
 
         Returns
         -------
-        left_keys, right_keys
+
+        
         """
         left_keys = []
         right_keys = []
@@ -1065,6 +1210,7 @@
         return left_keys, right_keys, join_names
 
     def _maybe_coerce_merge_keys(self):
+        """ """
         # we have valid merges but we may have to further
         # coerce these if they are originally incompatible types
         #
@@ -1196,6 +1342,7 @@
                 self.right = self.right.assign(**{name: self.right[name].astype(typ)})
 
     def _validate_specification(self):
+        """ """
         # Hm, any way to make this logic less complicated??
         if self.on is None and self.left_on is None and self.right_on is None:
 
@@ -1250,6 +1397,17 @@
             raise ValueError("len(right_on) must equal len(left_on)")
 
     def _validate(self, validate: str):
+        """
+
+        Parameters
+        ----------
+        validate: str :
+            
+
+        Returns
+        -------
+
+        """
 
         # Check uniqueness of each
         if self.left_index:
@@ -1305,16 +1463,25 @@
 
     Parameters
     ----------
-    left_keys: ndarray, Index, Series
-    right_keys: ndarray, Index, Series
-    sort: bool, default False
-    how: string {'inner', 'outer', 'left', 'right'}, default 'inner'
+    left_keys : ndarray, Index, Series
+        
+    right_keys : ndarray, Index, Series
+        
+    sort : bool, default False
+        
+    how : string {'inner', 'outer', 'left', 'right'}, default 'inner'
+        
+    sort: bool :
+         (Default value = False)
+    how: str :
+         (Default value = "inner")
+    **kwargs :
+        
 
     Returns
     -------
-    tuple of (left_indexer, right_indexer)
-        indexers into the left_keys, right_keys
-
+
+    
     """
     assert len(left_keys) == len(
         right_keys
@@ -1358,9 +1525,8 @@
     lindexer,
     rindexer,
 ):
-    """
-    *this is an internal non-public method*
-
+    """*this is an internal non-public method*
+    
     Returns the levels, labels and names of a multi-index to multi-index join.
     Depending on the type of join, this method restores the appropriate
     dropped levels of the joined multi-index.
@@ -1382,19 +1548,29 @@
         left indexer
     rindexer : intp array
         right indexer
+    left: MultiIndex :
+        
+    right: MultiIndex :
+        
 
     Returns
     -------
-    levels : list of Index
-        levels of combined multiindexes
-    labels : intp array
-        labels of combined multiindexes
-    names : str array
-        names of combined multiindexes
-
+
+    
     """
 
     def _convert_to_multiindex(index) -> MultiIndex:
+        """
+
+        Parameters
+        ----------
+        index :
+            
+
+        Returns
+        -------
+
+        """
         if isinstance(index, MultiIndex):
             return index
         else:
@@ -1445,6 +1621,7 @@
 
 
 class _OrderedMerge(_MergeOperation):
+    """ """
     _merge_type = "ordered_merge"
 
     def __init__(
@@ -1480,6 +1657,7 @@
         )
 
     def get_result(self):
+        """ """
         join_index, left_indexer, right_indexer = self._get_join_info()
 
         llabels, rlabels = _items_overlap_with_suffix(
@@ -1512,11 +1690,33 @@
 
 
 def _asof_function(direction: str):
+    """
+
+    Parameters
+    ----------
+    direction: str :
+        
+
+    Returns
+    -------
+
+    """
     name = f"asof_join_{direction}"
     return getattr(libjoin, name, None)
 
 
 def _asof_by_function(direction: str):
+    """
+
+    Parameters
+    ----------
+    direction: str :
+        
+
+    Returns
+    -------
+
+    """
     name = f"asof_join_{direction}_on_X_by_Y"
     return getattr(libjoin, name, None)
 
@@ -1529,7 +1729,17 @@
 
 
 def _get_cython_type_upcast(dtype):
-    """ Upcast a dtype to 'int64_t', 'double', or 'object' """
+    """Upcast a dtype to 'int64_t', 'double', or 'object'
+
+    Parameters
+    ----------
+    dtype :
+        
+
+    Returns
+    -------
+
+    """
     if is_integer_dtype(dtype):
         return "int64_t"
     elif is_float_dtype(dtype):
@@ -1539,6 +1749,7 @@
 
 
 class _AsOfMerge(_OrderedMerge):
+    """ """
     _merge_type = "asof_merge"
 
     def __init__(
@@ -1586,6 +1797,7 @@
         )
 
     def _validate_specification(self):
+        """ """
         super()._validate_specification()
 
         # we only allow on to be a single item for on
@@ -1630,6 +1842,7 @@
             raise MergeError(f"direction invalid: {self.direction}")
 
     def _get_merge_keys(self):
+        """ """
 
         # note this function has side effects
         (left_join_keys, right_join_keys, join_names) = super()._get_merge_keys()
@@ -1702,10 +1915,20 @@
         return left_join_keys, right_join_keys, join_names
 
     def _get_join_indexers(self):
-        """ return the join indexers """
+        """ """
 
         def flip(xs) -> np.ndarray:
-            """ unlike np.transpose, this returns an array of tuples """
+            """unlike np.transpose, this returns an array of tuples
+
+            Parameters
+            ----------
+            xs :
+                
+
+            Returns
+            -------
+
+            """
             xs = [
                 x
                 if not is_extension_array_dtype(x)
@@ -1790,6 +2013,21 @@
 
 
 def _get_multiindex_indexer(join_keys, index: MultiIndex, sort: bool):
+    """
+
+    Parameters
+    ----------
+    join_keys :
+        
+    index: MultiIndex :
+        
+    sort: bool :
+        
+
+    Returns
+    -------
+
+    """
 
     # left & right join labels and num. of levels at each location
     mapped = (
@@ -1826,6 +2064,21 @@
 
 
 def _get_single_indexer(join_key, index, sort: bool = False):
+    """
+
+    Parameters
+    ----------
+    join_key :
+        
+    index :
+        
+    sort: bool :
+         (Default value = False)
+
+    Returns
+    -------
+
+    """
     left_key, right_key, count = _factorize_keys(join_key, index, sort=sort)
 
     left_indexer, right_indexer = libjoin.left_outer_join(
@@ -1836,6 +2089,23 @@
 
 
 def _left_join_on_index(left_ax: Index, right_ax: Index, join_keys, sort: bool = False):
+    """
+
+    Parameters
+    ----------
+    left_ax: Index :
+        
+    right_ax: Index :
+        
+    join_keys :
+        
+    sort: bool :
+         (Default value = False)
+
+    Returns
+    -------
+
+    """
     if len(join_keys) > 1:
         if not (
             (isinstance(right_ax, MultiIndex) and len(join_keys) == right_ax.nlevels)
@@ -1864,6 +2134,21 @@
 
 
 def _right_outer_join(x, y, max_groups):
+    """
+
+    Parameters
+    ----------
+    x :
+        
+    y :
+        
+    max_groups :
+        
+
+    Returns
+    -------
+
+    """
     right_indexer, left_indexer = libjoin.left_outer_join(y, x, max_groups)
     return left_indexer, right_indexer
 
@@ -1871,9 +2156,8 @@
 def _factorize_keys(
     lk: ArrayLike, rk: ArrayLike, sort: bool = True, how: str = "inner"
 ) -> Tuple[np.array, np.array, int]:
-    """
-    Encode left and right keys as enumerated types.
-
+    """Encode left and right keys as enumerated types.
+    
     This is used to get the join indexers to be used when merging DataFrames.
 
     Parameters
@@ -1887,6 +2171,14 @@
         keys are sorted.
     how : {‘left’, ‘right’, ‘outer’, ‘inner’}, default ‘inner’
         Type of merge.
+    lk: ArrayLike :
+        
+    rk: ArrayLike :
+        
+    sort: bool :
+         (Default value = True)
+    how: str :
+         (Default value = "inner")
 
     Returns
     -------
@@ -1903,21 +2195,21 @@
         with a database-style join.
     algorithms.factorize : Encode the object as an enumerated type
         or categorical variable.
-
     Examples
     --------
+    
+    Here, the unique values are `'a', 'b', 'c'`. With the default
+    `sort=True`, the encoding will be `{0: 'a', 1: 'b', 2: 'c'}`:
+    
+    
+    With the `sort=False`, the encoding will correspond to the order
+    in which the unique elements first appear: `{0: 'a', 1: 'c', 2: 'b'}`:
     >>> lk = np.array(["a", "c", "b"])
     >>> rk = np.array(["a", "c"])
-
-    Here, the unique values are `'a', 'b', 'c'`. With the default
-    `sort=True`, the encoding will be `{0: 'a', 1: 'b', 2: 'c'}`:
-
+    
     >>> pd.core.reshape.merge._factorize_keys(lk, rk)
     (array([0, 2, 1]), array([0, 2]), 3)
-
-    With the `sort=False`, the encoding will correspond to the order
-    in which the unique elements first appear: `{0: 'a', 1: 'c', 2: 'b'}`:
-
+    
     >>> pd.core.reshape.merge._factorize_keys(lk, rk, sort=False)
     (array([0, 1, 2]), array([0, 1]), 3)
     """
@@ -1998,6 +2290,21 @@
 
 
 def _sort_labels(uniques: np.ndarray, left, right):
+    """
+
+    Parameters
+    ----------
+    uniques: np.ndarray :
+        
+    left :
+        
+    right :
+        
+
+    Returns
+    -------
+
+    """
 
     llength = len(left)
     labels = np.concatenate([left, right])
@@ -2010,6 +2317,23 @@
 
 
 def _get_join_keys(llab, rlab, shape, sort: bool):
+    """
+
+    Parameters
+    ----------
+    llab :
+        
+    rlab :
+        
+    shape :
+        
+    sort: bool :
+        
+
+    Returns
+    -------
+
+    """
 
     # how many levels can be done without overflow
     pred = lambda i: not is_int64_overflow_possible(shape[:i])
@@ -2040,16 +2364,51 @@
 
 
 def _should_fill(lname, rname) -> bool:
+    """
+
+    Parameters
+    ----------
+    lname :
+        
+    rname :
+        
+
+    Returns
+    -------
+
+    """
     if not isinstance(lname, str) or not isinstance(rname, str):
         return True
     return lname == rname
 
 
 def _any(x) -> bool:
+    """
+
+    Parameters
+    ----------
+    x :
+        
+
+    Returns
+    -------
+
+    """
     return x is not None and com.any_not_none(*x)
 
 
 def _validate_operand(obj: FrameOrSeries) -> "DataFrame":
+    """
+
+    Parameters
+    ----------
+    obj: FrameOrSeries :
+        
+
+    Returns
+    -------
+
+    """
     if isinstance(obj, ABCDataFrame):
         return obj
     elif isinstance(obj, ABCSeries):
@@ -2064,12 +2423,25 @@
 
 
 def _items_overlap_with_suffix(left: Index, right: Index, suffixes: Tuple[str, str]):
-    """
-    Suffixes type validation.
-
+    """Suffixes type validation.
+    
     If two indices overlap, add suffixes to overlapping entries.
-
+    
     If corresponding suffix is empty, the entry is simply converted to string.
+
+    Parameters
+    ----------
+    left: Index :
+        
+    right: Index :
+        
+    suffixes: Tuple[str :
+        
+    str] :
+        
+
+    Returns
+    -------
 
     """
     if not is_list_like(suffixes, allow_sets=False):
@@ -2091,20 +2463,22 @@
         raise ValueError(f"columns overlap but no suffix specified: {to_rename}")
 
     def renamer(x, suffix):
-        """
-        Rename the left and right indices.
-
+        """Rename the left and right indices.
+        
         If there is overlap, and suffix is not None, add
         suffix, otherwise, leave it as-is.
 
         Parameters
         ----------
         x : original column name
+            
         suffix : str or None
+            
 
         Returns
         -------
-        x : renamed column name
+
+        
         """
         if x in to_rename and suffix is not None:
             return f"{x}{suffix}"
