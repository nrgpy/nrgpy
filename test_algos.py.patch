# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/tests/test_algos.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/tests/test_algos.py
@@ -37,7 +37,9 @@
 
 
 class TestFactorize:
+    """ """
     def test_basic(self):
+        """ """
 
         codes, uniques = algos.factorize(["a", "b", "b", "a", "a", "c", "c", "c"])
         tm.assert_numpy_array_equal(uniques, np.array(["a", "b", "c"], dtype=object))
@@ -76,6 +78,7 @@
         tm.assert_numpy_array_equal(uniques, exp)
 
     def test_mixed(self):
+        """ """
 
         # doc example reshaping.rst
         x = Series(["A", "A", np.nan, "B", 3.14, np.inf])
@@ -93,6 +96,7 @@
         tm.assert_index_equal(uniques, exp)
 
     def test_datelike(self):
+        """ """
 
         # M8
         v1 = Timestamp("20130101 09:00:00.00004")
@@ -142,6 +146,7 @@
         tm.assert_index_equal(uniques, pd.to_timedelta([v2, v1]))
 
     def test_factorize_nan(self):
+        """ """
         # nan should map to na_sentinel, not reverse_indexer[na_sentinel]
         # rizer.factorize should not raise an exception if na_sentinel indexes
         # outside of reverse_indexer
@@ -181,6 +186,21 @@
         ],
     )
     def test_factorize_tuple_list(self, data, expected_codes, expected_uniques):
+        """
+
+        Parameters
+        ----------
+        data :
+            
+        expected_codes :
+            
+        expected_uniques :
+            
+
+        Returns
+        -------
+
+        """
         # GH9454
         codes, uniques = pd.factorize(data)
 
@@ -190,6 +210,7 @@
         tm.assert_numpy_array_equal(uniques, expected_uniques_array)
 
     def test_complex_sorting(self):
+        """ """
         # gh 12666 - check no segfault
         x17 = np.array([complex(i) for i in range(17)], dtype=object)
 
@@ -202,6 +223,17 @@
             algos.factorize(x17[::-1], sort=True)
 
     def test_float64_factorize(self, writable):
+        """
+
+        Parameters
+        ----------
+        writable :
+            
+
+        Returns
+        -------
+
+        """
         data = np.array([1.0, 1e8, 1.0, 1e-8, 1e8, 1.0], dtype=np.float64)
         data.setflags(write=writable)
         expected_codes = np.array([0, 1, 0, 2, 1, 0], dtype=np.intp)
@@ -212,6 +244,17 @@
         tm.assert_numpy_array_equal(uniques, expected_uniques)
 
     def test_uint64_factorize(self, writable):
+        """
+
+        Parameters
+        ----------
+        writable :
+            
+
+        Returns
+        -------
+
+        """
         data = np.array([2 ** 64 - 1, 1, 2 ** 64 - 1], dtype=np.uint64)
         data.setflags(write=writable)
         expected_codes = np.array([0, 1, 0], dtype=np.intp)
@@ -222,6 +265,17 @@
         tm.assert_numpy_array_equal(uniques, expected_uniques)
 
     def test_int64_factorize(self, writable):
+        """
+
+        Parameters
+        ----------
+        writable :
+            
+
+        Returns
+        -------
+
+        """
         data = np.array([2 ** 63 - 1, -(2 ** 63), 2 ** 63 - 1], dtype=np.int64)
         data.setflags(write=writable)
         expected_codes = np.array([0, 1, 0], dtype=np.intp)
@@ -232,6 +286,17 @@
         tm.assert_numpy_array_equal(uniques, expected_uniques)
 
     def test_string_factorize(self, writable):
+        """
+
+        Parameters
+        ----------
+        writable :
+            
+
+        Returns
+        -------
+
+        """
         data = np.array(["a", "c", "a", "b", "c"], dtype=object)
         data.setflags(write=writable)
         expected_codes = np.array([0, 1, 0, 2, 1], dtype=np.intp)
@@ -242,6 +307,17 @@
         tm.assert_numpy_array_equal(uniques, expected_uniques)
 
     def test_object_factorize(self, writable):
+        """
+
+        Parameters
+        ----------
+        writable :
+            
+
+        Returns
+        -------
+
+        """
         data = np.array(["a", "c", None, np.nan, "a", "b", pd.NaT, "c"], dtype=object)
         data.setflags(write=writable)
         expected_codes = np.array([0, 1, -1, -1, 0, 2, -1, 1], dtype=np.intp)
@@ -252,6 +328,7 @@
         tm.assert_numpy_array_equal(uniques, expected_uniques)
 
     def test_deprecate_order(self):
+        """ """
         # gh 19727 - check warning is raised for deprecated keyword, order.
         # Test not valid once order keyword is removed.
         data = np.array([2 ** 63, 1, 2 ** 63], dtype=np.uint64)
@@ -269,6 +346,17 @@
         ],
     )
     def test_parametrized_factorize_na_value_default(self, data):
+        """
+
+        Parameters
+        ----------
+        data :
+            
+
+        Returns
+        -------
+
+        """
         # arrays that include the NA default for that type, but isn't used.
         codes, uniques = algos.factorize(data)
         expected_uniques = data[[0, 1]]
@@ -289,6 +377,19 @@
         ],
     )
     def test_parametrized_factorize_na_value(self, data, na_value):
+        """
+
+        Parameters
+        ----------
+        data :
+            
+        na_value :
+            
+
+        Returns
+        -------
+
+        """
         codes, uniques = algos._factorize_array(data, na_value=na_value)
         expected_uniques = data[[1, 3]]
         expected_codes = np.array([-1, 0, -1, 1], dtype=np.intp)
@@ -312,6 +413,23 @@
         ids=["numpy_array", "extension_array"],
     )
     def test_factorize_na_sentinel(self, sort, na_sentinel, data, uniques):
+        """
+
+        Parameters
+        ----------
+        sort :
+            
+        na_sentinel :
+            
+        data :
+            
+        uniques :
+            
+
+        Returns
+        -------
+
+        """
         codes, uniques = algos.factorize(data, sort=sort, na_sentinel=na_sentinel)
         if sort:
             expected_codes = np.array([1, 0, na_sentinel, 1], dtype=np.intp)
@@ -343,6 +461,21 @@
     def test_object_factorize_na_sentinel_none(
         self, data, expected_codes, expected_uniques
     ):
+        """
+
+        Parameters
+        ----------
+        data :
+            
+        expected_codes :
+            
+        expected_uniques :
+            
+
+        Returns
+        -------
+
+        """
         codes, uniques = algos.factorize(data, na_sentinel=None)
 
         tm.assert_numpy_array_equal(uniques, expected_uniques)
@@ -366,6 +499,21 @@
     def test_int_factorize_na_sentinel_none(
         self, data, expected_codes, expected_uniques
     ):
+        """
+
+        Parameters
+        ----------
+        data :
+            
+        expected_codes :
+            
+        expected_uniques :
+            
+
+        Returns
+        -------
+
+        """
         codes, uniques = algos.factorize(data, na_sentinel=None)
 
         tm.assert_numpy_array_equal(uniques, expected_uniques)
@@ -373,24 +521,29 @@
 
 
 class TestUnique:
+    """ """
     def test_ints(self):
+        """ """
         arr = np.random.randint(0, 100, size=50)
 
         result = algos.unique(arr)
         assert isinstance(result, np.ndarray)
 
     def test_objects(self):
+        """ """
         arr = np.random.randint(0, 100, size=50).astype("O")
 
         result = algos.unique(arr)
         assert isinstance(result, np.ndarray)
 
     def test_object_refcount_bug(self):
+        """ """
         lst = ["A", "B", "C", "D", "E"]
         for i in range(1000):
             len(algos.unique(lst))
 
     def test_on_index_object(self):
+        """ """
 
         mindex = pd.MultiIndex.from_arrays(
             [np.arange(5).repeat(5), np.tile(np.arange(5), 5)]
@@ -406,6 +559,17 @@
         tm.assert_almost_equal(result, expected)
 
     def test_dtype_preservation(self, any_numpy_dtype):
+        """
+
+        Parameters
+        ----------
+        any_numpy_dtype :
+            
+
+        Returns
+        -------
+
+        """
         # GH 15442
         if any_numpy_dtype in (tm.BYTES_DTYPES + tm.STRING_DTYPES):
             pytest.skip("skip string dtype")
@@ -435,6 +599,7 @@
         tm.assert_numpy_array_equal(result, expected)
 
     def test_datetime64_dtype_array_returned(self):
+        """ """
         # GH 9431
         expected = np_array_datetime64_compat(
             [
@@ -466,18 +631,21 @@
         assert result.dtype == expected.dtype
 
     def test_datetime_non_ns(self):
+        """ """
         a = np.array(["2000", "2000", "2001"], dtype="datetime64[s]")
         result = pd.unique(a)
         expected = np.array(["2000", "2001"], dtype="datetime64[ns]")
         tm.assert_numpy_array_equal(result, expected)
 
     def test_timedelta_non_ns(self):
+        """ """
         a = np.array(["2000", "2000", "2001"], dtype="timedelta64[s]")
         result = pd.unique(a)
         expected = np.array([2000000000000, 2001000000000], dtype="timedelta64[ns]")
         tm.assert_numpy_array_equal(result, expected)
 
     def test_timedelta64_dtype_array_returned(self):
+        """ """
         # GH 9431
         expected = np.array([31200, 45678, 10000], dtype="m8[ns]")
 
@@ -497,17 +665,20 @@
         assert result.dtype == expected.dtype
 
     def test_uint64_overflow(self):
+        """ """
         s = Series([1, 2, 2 ** 63, 2 ** 63], dtype=np.uint64)
         exp = np.array([1, 2, 2 ** 63], dtype=np.uint64)
         tm.assert_numpy_array_equal(algos.unique(s), exp)
 
     def test_nan_in_object_array(self):
+        """ """
         duplicated_items = ["a", np.nan, "c", "c"]
         result = pd.unique(duplicated_items)
         expected = np.array(["a", np.nan, "c"], dtype=object)
         tm.assert_numpy_array_equal(result, expected)
 
     def test_categorical(self):
+        """ """
 
         # we are expecting to return in the order
         # of appearance
@@ -550,6 +721,7 @@
         tm.assert_index_equal(result, expected)
 
     def test_datetime64tz_aware(self):
+        """ """
         # GH 15939
 
         result = Series(
@@ -605,6 +777,7 @@
         tm.assert_index_equal(result, expected)
 
     def test_order_of_appearance(self):
+        """ """
         # 9346
         # light testing of guarantee of order of appearance
         # these also are the doc-examples
@@ -647,11 +820,25 @@
         ],
     )
     def test_tuple_with_strings(self, arg, expected):
+        """
+
+        Parameters
+        ----------
+        arg :
+            
+        expected :
+            
+
+        Returns
+        -------
+
+        """
         # see GH 17108
         result = pd.unique(arg)
         tm.assert_numpy_array_equal(result, expected)
 
     def test_obj_none_preservation(self):
+        """ """
         # GH 20866
         arr = np.array(["foo", None], dtype=object)
         result = pd.unique(arr)
@@ -660,6 +847,7 @@
         tm.assert_numpy_array_equal(result, expected, strict_nan=True)
 
     def test_signed_zero(self):
+        """ """
         # GH 21866
         a = np.array([-0.0, 0.0])
         result = pd.unique(a)
@@ -667,6 +855,7 @@
         tm.assert_numpy_array_equal(result, expected)
 
     def test_different_nans(self):
+        """ """
         # GH 21866
         # create different nans from bit-patterns:
         NAN1 = struct.unpack("d", struct.pack("=Q", 0x7FF8000000000000))[0]
@@ -679,6 +868,7 @@
         tm.assert_numpy_array_equal(result, expected)
 
     def test_first_nan_kept(self):
+        """ """
         # GH 22295
         # create different nans from bit-patterns:
         bits_for_nan1 = 0xFFF8000000000001
@@ -696,6 +886,19 @@
             assert result_nan_bits == bits_for_nan1
 
     def test_do_not_mangle_na_values(self, unique_nulls_fixture, unique_nulls_fixture2):
+        """
+
+        Parameters
+        ----------
+        unique_nulls_fixture :
+            
+        unique_nulls_fixture2 :
+            
+
+        Returns
+        -------
+
+        """
         # GH 22295
         if unique_nulls_fixture is unique_nulls_fixture2:
             return  # skip it, values not unique
@@ -707,7 +910,9 @@
 
 
 class TestIsin:
+    """ """
     def test_invalid(self):
+        """ """
 
         msg = (
             r"only list-like objects are allowed to be passed to isin\(\), "
@@ -721,6 +926,7 @@
             algos.isin([1], 1)
 
     def test_basic(self):
+        """ """
 
         result = algos.isin([1, 2], [1])
         expected = np.array([True, False])
@@ -759,6 +965,7 @@
         tm.assert_numpy_array_equal(result, expected)
 
     def test_i8(self):
+        """ """
 
         arr = pd.date_range("20130101", periods=3).values
         result = algos.isin(arr, [arr[0]])
@@ -787,6 +994,7 @@
         tm.assert_numpy_array_equal(result, expected)
 
     def test_large(self):
+        """ """
         s = pd.date_range("20000101", periods=2000000, freq="s").values
         result = algos.isin(s, s[0:2])
         expected = np.zeros(len(s), dtype=bool)
@@ -795,6 +1003,7 @@
         tm.assert_numpy_array_equal(result, expected)
 
     def test_categorical_from_codes(self):
+        """ """
         # GH 16639
         vals = np.array([0, 1, 2, 0])
         cats = ["a", "b", "c"]
@@ -805,6 +1014,7 @@
         tm.assert_numpy_array_equal(expected, result)
 
     def test_categorical_isin(self):
+        """ """
         vals = np.array([0, 1, 2, 0])
         cats = ["a", "b", "c"]
         cat = Categorical(1).from_codes(vals, cats)
@@ -815,6 +1025,7 @@
         tm.assert_numpy_array_equal(expected, result)
 
     def test_same_nan_is_in(self):
+        """ """
         # GH 22160
         # nan is special, because from " a is b" doesn't follow "a == b"
         # at least, isin() should follow python's "np.nan in [nan] == True"
@@ -827,6 +1038,7 @@
         tm.assert_numpy_array_equal(expected, result)
 
     def test_same_nan_is_in_large(self):
+        """ """
         # https://github.com/pandas-dev/pandas/issues/22205
         s = np.tile(1.0, 1_000_001)
         s[0] = np.nan
@@ -835,6 +1047,7 @@
         tm.assert_numpy_array_equal(result, expected)
 
     def test_same_nan_is_in_large_series(self):
+        """ """
         # https://github.com/pandas-dev/pandas/issues/22205
         s = np.tile(1.0, 1_000_001)
         series = pd.Series(s)
@@ -844,12 +1057,14 @@
         tm.assert_series_equal(result, expected)
 
     def test_same_object_is_in(self):
+        """ """
         # GH 22160
         # there could be special treatment for nans
         # the user however could define a custom class
         # with similar behavior, then we at least should
         # fall back to usual python's behavior: "a in [a] == True"
         class LikeNan:
+            """ """
             def __eq__(self, other) -> bool:
                 return False
 
@@ -863,6 +1078,7 @@
         tm.assert_numpy_array_equal(algos.isin([a], [b]), np.array([False]))
 
     def test_different_nans(self):
+        """ """
         # GH 22160
         # all nans are handled as equivalent
 
@@ -887,6 +1103,7 @@
         tm.assert_numpy_array_equal(np.array([True]), result)
 
     def test_no_cast(self):
+        """ """
         # GH 22160
         # ensure 42 is not casted to a string
         comps = ["ss", 42]
@@ -897,6 +1114,17 @@
 
     @pytest.mark.parametrize("empty", [[], Series(dtype=object), np.array([])])
     def test_empty(self, empty):
+        """
+
+        Parameters
+        ----------
+        empty :
+            
+
+        Returns
+        -------
+
+        """
         # see gh-16991
         vals = Index(["a", "b"])
         expected = np.array([False, False])
@@ -905,6 +1133,7 @@
         tm.assert_numpy_array_equal(expected, result)
 
     def test_different_nan_objects(self):
+        """ """
         # GH 22119
         comps = np.array(["nan", np.nan * 1j, float("nan")], dtype=object)
         vals = np.array([float("nan")], dtype=object)
@@ -913,6 +1142,7 @@
         tm.assert_numpy_array_equal(expected, result)
 
     def test_different_nans_as_float64(self):
+        """ """
         # GH 21866
         # create different nans from bit-patterns,
         # these nans will land in different buckets in the hash-table
@@ -937,7 +1167,15 @@
     @pytest.mark.xfail(reason="problem related with issue #34125")
     def test_isin_int_df_string_search(self):
         """Comparing df with int`s (1,2) with a string at isin() ("1")
-        -> should not match values because int 1 is not equal str 1"""
+        -> should not match values because int 1 is not equal str 1
+
+        Parameters
+        ----------
+
+        Returns
+        -------
+
+        """
         df = pd.DataFrame({"values": [1, 2]})
         result = df.isin(["1"])
         expected_false = pd.DataFrame({"values": [False, False]})
@@ -946,7 +1184,15 @@
     @pytest.mark.xfail(reason="problem related with issue #34125")
     def test_isin_nan_df_string_search(self):
         """Comparing df with nan value (np.nan,2) with a string at isin() ("NaN")
-        -> should not match values because np.nan is not equal str NaN """
+        -> should not match values because np.nan is not equal str NaN
+
+        Parameters
+        ----------
+
+        Returns
+        -------
+
+        """
         df = pd.DataFrame({"values": [np.nan, 2]})
         result = df.isin(["NaN"])
         expected_false = pd.DataFrame({"values": [False, False]})
@@ -955,7 +1201,15 @@
     @pytest.mark.xfail(reason="problem related with issue #34125")
     def test_isin_float_df_string_search(self):
         """Comparing df with floats (1.4245,2.32441) with a string at isin() ("1.4245")
-        -> should not match values because float 1.4245 is not equal str 1.4245"""
+        -> should not match values because float 1.4245 is not equal str 1.4245
+
+        Parameters
+        ----------
+
+        Returns
+        -------
+
+        """
         df = pd.DataFrame({"values": [1.4245, 2.32441]})
         result = df.isin(["1.4245"])
         expected_false = pd.DataFrame({"values": [False, False]})
@@ -963,7 +1217,9 @@
 
 
 class TestValueCounts:
+    """ """
     def test_value_counts(self):
+        """ """
         np.random.seed(1234)
         from pandas.core.reshape.tile import cut
 
@@ -978,6 +1234,7 @@
         tm.assert_series_equal(result.sort_index(), expected.sort_index())
 
     def test_value_counts_bins(self):
+        """ """
         s = [1, 2, 3, 4]
         result = algos.value_counts(s, bins=1)
         expected = Series([4], index=IntervalIndex.from_tuples([(0.996, 4.0)]))
@@ -990,6 +1247,7 @@
         tm.assert_series_equal(result, expected)
 
     def test_value_counts_dtypes(self):
+        """ """
         result = algos.value_counts([1, 1.0])
         assert len(result) == 1
 
@@ -1004,6 +1262,7 @@
             algos.value_counts(["1", 1], bins=1)
 
     def test_value_counts_nat(self):
+        """ """
         td = Series([np.timedelta64(10000), pd.NaT], dtype="timedelta64[ns]")
         dt = pd.to_datetime(["NaT", "2014-01-01"])
 
@@ -1018,6 +1277,7 @@
         # TODO same for (timedelta)
 
     def test_value_counts_datetime_outofbounds(self):
+        """ """
         # GH 13663
         s = Series(
             [
@@ -1044,6 +1304,7 @@
         tm.assert_series_equal(res, exp)
 
     def test_categorical(self):
+        """ """
         s = Series(Categorical(list("aaabbc")))
         result = s.value_counts()
         expected = Series([3, 2, 1], index=CategoricalIndex(["a", "b", "c"]))
@@ -1057,6 +1318,7 @@
         tm.assert_series_equal(result, expected, check_index_type=True)
 
     def test_categorical_nans(self):
+        """ """
         s = Series(Categorical(list("aaaaabbbcc")))  # 4,3,2,1 (nan)
         s.iloc[1] = np.nan
         result = s.value_counts()
@@ -1093,6 +1355,7 @@
         tm.assert_series_equal(result, expected, check_index_type=True)
 
     def test_categorical_zeroes(self):
+        """ """
         # keep the `d` category with 0
         s = Series(Categorical(list("bbbaac"), categories=list("abcd"), ordered=True))
         result = s.value_counts()
@@ -1105,6 +1368,7 @@
         tm.assert_series_equal(result, expected, check_index_type=True)
 
     def test_dropna(self):
+        """ """
         # https://github.com/pandas-dev/pandas/issues/9443#issuecomment-73719328
 
         tm.assert_series_equal(
@@ -1145,6 +1409,7 @@
             tm.assert_series_equal(result, expected)
 
     def test_value_counts_normalized(self):
+        """ """
         # GH12558
         s = Series([1, 2, np.nan, np.nan, np.nan])
         dtypes = (np.float64, object, "M8[ns]")
@@ -1161,6 +1426,7 @@
             tm.assert_series_equal(result, expected)
 
     def test_value_counts_uint64(self):
+        """ """
         arr = np.array([2 ** 63], dtype=np.uint64)
         expected = Series([1], index=[2 ** 63])
         result = algos.value_counts(arr)
@@ -1177,7 +1443,9 @@
 
 
 class TestDuplicated:
+    """ """
     def test_duplicated_with_nas(self):
+        """ """
         keys = np.array([0, 1, np.nan, 0, 2, np.nan], dtype=object)
 
         result = algos.duplicated(keys)
@@ -1242,6 +1510,17 @@
         ],
     )
     def test_numeric_object_likes(self, case):
+        """
+
+        Parameters
+        ----------
+        case :
+            
+
+        Returns
+        -------
+
+        """
         exp_first = np.array(
             [False, False, True, False, False, True, False, True, True, False]
         )
@@ -1282,6 +1561,7 @@
             tm.assert_series_equal(res_false, Series(exp_false))
 
     def test_datetime_likes(self):
+        """ """
 
         dt = [
             "2011-01-01",
@@ -1365,6 +1645,7 @@
                 tm.assert_series_equal(res_false, Series(exp_false))
 
     def test_unique_index(self):
+        """ """
         cases = [Index([1, 2, 3]), pd.RangeIndex(0, 3)]
         for case in cases:
             assert case.is_unique is True
@@ -1387,6 +1668,19 @@
         ],
     )
     def test_unique_tuples(self, arr, unique):
+        """
+
+        Parameters
+        ----------
+        arr :
+            
+        unique :
+            
+
+        Returns
+        -------
+
+        """
         # https://github.com/pandas-dev/pandas/issues/16519
         expected = np.empty(len(unique), dtype=object)
         expected[:] = unique
@@ -1396,7 +1690,9 @@
 
 
 class GroupVarTestMixin:
+    """ """
     def test_group_var_generic_1d(self):
+        """ """
         prng = RandomState(1234)
 
         out = (np.nan * np.ones((5, 1))).astype(self.dtype)
@@ -1414,6 +1710,7 @@
         tm.assert_numpy_array_equal(counts, expected_counts)
 
     def test_group_var_generic_1d_flat_labels(self):
+        """ """
         prng = RandomState(1234)
 
         out = (np.nan * np.ones((1, 1))).astype(self.dtype)
@@ -1430,6 +1727,7 @@
         tm.assert_numpy_array_equal(counts, expected_counts)
 
     def test_group_var_generic_2d_all_finite(self):
+        """ """
         prng = RandomState(1234)
 
         out = (np.nan * np.ones((5, 2))).astype(self.dtype)
@@ -1445,6 +1743,7 @@
         tm.assert_numpy_array_equal(counts, expected_counts)
 
     def test_group_var_generic_2d_some_nan(self):
+        """ """
         prng = RandomState(1234)
 
         out = (np.nan * np.ones((5, 2))).astype(self.dtype)
@@ -1466,6 +1765,7 @@
         tm.assert_numpy_array_equal(counts, expected_counts)
 
     def test_group_var_constant(self):
+        """ """
         # Regression test from GH 10448.
 
         out = np.array([[np.nan]], dtype=self.dtype)
@@ -1481,6 +1781,7 @@
 
 
 class TestGroupVarFloat64(GroupVarTestMixin):
+    """ """
     __test__ = True
 
     algo = staticmethod(libgroupby.group_var_float64)
@@ -1488,6 +1789,7 @@
     rtol = 1e-5
 
     def test_group_var_large_inputs(self):
+        """ """
 
         prng = RandomState(1234)
 
@@ -1504,6 +1806,7 @@
 
 
 class TestGroupVarFloat32(GroupVarTestMixin):
+    """ """
     __test__ = True
 
     algo = staticmethod(libgroupby.group_var_float32)
@@ -1512,7 +1815,9 @@
 
 
 class TestHashTable:
+    """ """
     def test_string_hashtable_set_item_signature(self):
+        """ """
         # GH#30419 fix typing in StringHashTable.set_item to prevent segfault
         tbl = ht.StringHashTable()
 
@@ -1526,6 +1831,17 @@
             tbl.get_item(4)
 
     def test_lookup_nan(self, writable):
+        """
+
+        Parameters
+        ----------
+        writable :
+            
+
+        Returns
+        -------
+
+        """
         xs = np.array([2.718, 3.14, np.nan, -7, 5, 2, 3])
         # GH 21688 ensure we can deal with readonly memory views
         xs.setflags(write=writable)
@@ -1534,6 +1850,7 @@
         tm.assert_numpy_array_equal(m.lookup(xs), np.arange(len(xs), dtype=np.int64))
 
     def test_add_signed_zeros(self):
+        """ """
         # GH 21866 inconsistent hash-function for float64
         # default hash-function would lead to different hash-buckets
         # for 0.0 and -0.0 if there are more than 2^30 hash-buckets
@@ -1545,6 +1862,7 @@
         assert len(m) == 1  # 0.0 and -0.0 are equivalent
 
     def test_add_different_nans(self):
+        """ """
         # GH 21866 inconsistent hash-function for float64
         # create different nans from bit-patterns:
         NAN1 = struct.unpack("d", struct.pack("=Q", 0x7FF8000000000000))[0]
@@ -1559,6 +1877,17 @@
         assert len(m) == 1  # NAN1 and NAN2 are equivalent
 
     def test_lookup_overflow(self, writable):
+        """
+
+        Parameters
+        ----------
+        writable :
+            
+
+        Returns
+        -------
+
+        """
         xs = np.array([1, 2, 2 ** 63], dtype=np.uint64)
         # GH 21688 ensure we can deal with readonly memory views
         xs.setflags(write=writable)
@@ -1567,6 +1896,7 @@
         tm.assert_numpy_array_equal(m.lookup(xs), np.arange(len(xs), dtype=np.int64))
 
     def test_get_unique(self):
+        """ """
         s = Series([1, 2, 2 ** 63, 2 ** 63], dtype=np.uint64)
         exp = np.array([1, 2, 2 ** 63], dtype=np.uint64)
         tm.assert_numpy_array_equal(s.unique(), exp)
@@ -1585,6 +1915,27 @@
     def test_vector_resize(
         self, writable, htable, uniques, dtype, safely_resizes, nvals
     ):
+        """
+
+        Parameters
+        ----------
+        writable :
+            
+        htable :
+            
+        uniques :
+            
+        dtype :
+            
+        safely_resizes :
+            
+        nvals :
+            
+
+        Returns
+        -------
+
+        """
         # Test for memory errors after internal vector
         # reallocations (GH 7157)
         vals = np.array(np.random.randn(1000), dtype=dtype)
@@ -1626,6 +1977,21 @@
         ],
     )
     def test_hashtable_unique(self, htable, tm_dtype, writable):
+        """
+
+        Parameters
+        ----------
+        htable :
+            
+        tm_dtype :
+            
+        writable :
+            
+
+        Returns
+        -------
+
+        """
         # output of maker has guaranteed unique elements
         maker = getattr(tm, "make" + tm_dtype + "Index")
         s = Series(maker(1000))
@@ -1666,6 +2032,21 @@
         ],
     )
     def test_hashtable_factorize(self, htable, tm_dtype, writable):
+        """
+
+        Parameters
+        ----------
+        htable :
+            
+        tm_dtype :
+            
+        writable :
+            
+
+        Returns
+        -------
+
+        """
         # output of maker has guaranteed unique elements
         maker = getattr(tm, "make" + tm_dtype + "Index")
         s = Series(maker(1000))
@@ -1706,12 +2087,24 @@
         ],
     )
     def test_hashtable_large_sizehint(self, hashtable):
+        """
+
+        Parameters
+        ----------
+        hashtable :
+            
+
+        Returns
+        -------
+
+        """
         # GH 22729
         size_hint = np.iinfo(np.uint32).max + 1
         tbl = hashtable(size_hint=size_hint)  # noqa
 
 
 def test_quantile():
+    """ """
     s = Series(np.random.randn(100))
 
     result = algos.quantile(s, [0, 0.25, 0.5, 0.75, 1.0])
@@ -1720,6 +2113,7 @@
 
 
 def test_unique_label_indices():
+    """ """
 
     a = np.random.randint(1, 1 << 10, 1 << 15).astype("i8")
 
@@ -1735,11 +2129,24 @@
 
 
 class TestRank:
+    """ """
     @td.skip_if_no_scipy
     def test_scipy_compat(self):
+        """ """
         from scipy.stats import rankdata
 
         def _check(arr):
+            """
+
+            Parameters
+            ----------
+            arr :
+                
+
+            Returns
+            -------
+
+            """
             mask = ~np.isfinite(arr)
             arr = arr.copy()
             result = libalgos.rank_1d(arr)
@@ -1752,6 +2159,17 @@
         _check(np.array([4.0, np.nan, 5.0, 5.0, 5.0, np.nan, 1, 2, 4.0, np.nan]))
 
     def test_basic(self, writable):
+        """
+
+        Parameters
+        ----------
+        writable :
+            
+
+        Returns
+        -------
+
+        """
         exp = np.array([1, 2], dtype=np.float64)
 
         for dtype in np.typecodes["AllInteger"]:
@@ -1761,6 +2179,7 @@
             tm.assert_numpy_array_equal(algos.rank(s), exp)
 
     def test_uint64_overflow(self):
+        """ """
         exp = np.array([1, 2], dtype=np.float64)
 
         for dtype in [np.float64, np.uint64]:
@@ -1768,6 +2187,7 @@
             tm.assert_numpy_array_equal(algos.rank(s), exp)
 
     def test_too_many_ndims(self):
+        """ """
         arr = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]])
         msg = "Array with ndim > 2 are not supported"
 
@@ -1782,12 +2202,24 @@
         ids=["1d", "2d"],
     )
     def test_pct_max_many_rows(self, values):
+        """
+
+        Parameters
+        ----------
+        values :
+            
+
+        Returns
+        -------
+
+        """
         # GH 18271
         result = algos.rank(values, pct=True).max()
         assert result == 1
 
 
 def test_pad_backfill_object_segfault():
+    """ """
 
     old = np.array([], dtype="O")
     new = np.array([datetime(2010, 12, 31)], dtype="O")
@@ -1810,22 +2242,29 @@
 
 
 class TestTseriesUtil:
+    """ """
     def test_combineFunc(self):
+        """ """
         pass
 
     def test_reindex(self):
+        """ """
         pass
 
     def test_isna(self):
+        """ """
         pass
 
     def test_groupby(self):
+        """ """
         pass
 
     def test_groupby_withnull(self):
+        """ """
         pass
 
     def test_backfill(self):
+        """ """
         old = Index([1, 5, 10])
         new = Index(list(range(12)))
 
@@ -1843,6 +2282,7 @@
         tm.assert_numpy_array_equal(filler, expect_filler)
 
     def test_pad(self):
+        """ """
         old = Index([1, 5, 10])
         new = Index(list(range(12)))
 
@@ -1860,6 +2300,7 @@
 
 
 def test_is_lexsorted():
+    """ """
     failure = [
         np.array(
             [
@@ -2125,6 +2566,7 @@
 
 
 def test_groupsort_indexer():
+    """ """
     a = np.random.randint(0, 1000, 100).astype(np.int64)
     b = np.random.randint(0, 1000, 100).astype(np.int64)
 
@@ -2150,6 +2592,7 @@
 
 
 def test_infinity_sort():
+    """ """
     # GH 13445
     # numpy's argsort can be unhappy if something is less than
     # itself.  Instead, let's give our infinities a self-consistent
@@ -2183,6 +2626,7 @@
 
 
 def test_infinity_against_nan():
+    """ """
     Inf = libalgos.Infinity()
     NegInf = libalgos.NegInfinity()
 
@@ -2202,6 +2646,7 @@
 
 
 def test_ensure_platform_int():
+    """ """
     arr = np.arange(100, dtype=np.intp)
 
     result = libalgos.ensure_platform_int(arr)
@@ -2209,6 +2654,7 @@
 
 
 def test_int64_add_overflow():
+    """ """
     # see gh-14068
     msg = "Overflow in int64 addition"
     m = np.iinfo(np.int64).max
@@ -2261,11 +2707,14 @@
 
 
 class TestMode:
+    """ """
     def test_no_mode(self):
+        """ """
         exp = Series([], dtype=np.float64)
         tm.assert_series_equal(algos.mode([]), exp)
 
     def test_mode_single(self):
+        """ """
         # GH 15714
         exp_single = [1]
         data_single = [1]
@@ -2289,6 +2738,7 @@
         tm.assert_series_equal(algos.mode(["a", "b", "c"]), exp)
 
     def test_number_mode(self):
+        """ """
         exp_single = [1]
         data_single = [1] * 5 + [2] * 3
 
@@ -2305,6 +2755,7 @@
             tm.assert_series_equal(algos.mode(s), exp)
 
     def test_strobj_mode(self):
+        """ """
         exp = ["b"]
         data = ["a"] * 2 + ["b"] * 3
 
@@ -2321,6 +2772,7 @@
             tm.assert_series_equal(algos.mode(s), exp)
 
     def test_datelike_mode(self):
+        """ """
         exp = Series(["1900-05-03", "2011-01-03", "2013-01-02"], dtype="M8[ns]")
         s = Series(["2011-01-03", "2013-01-02", "1900-05-03"], dtype="M8[ns]")
         tm.assert_series_equal(algos.mode(s), exp)
@@ -2333,6 +2785,7 @@
         tm.assert_series_equal(algos.mode(s), exp)
 
     def test_timedelta_mode(self):
+        """ """
         exp = Series(["-1 days", "0 days", "1 days"], dtype="timedelta64[ns]")
         s = Series(["1 days", "-1 days", "0 days"], dtype="timedelta64[ns]")
         tm.assert_series_equal(algos.mode(s), exp)
@@ -2345,11 +2798,13 @@
         tm.assert_series_equal(algos.mode(s), exp)
 
     def test_mixed_dtype(self):
+        """ """
         exp = Series(["foo"])
         s = Series([1, "foo", "foo"])
         tm.assert_series_equal(algos.mode(s), exp)
 
     def test_uint64_overflow(self):
+        """ """
         exp = Series([2 ** 63], dtype=np.uint64)
         s = Series([1, 2 ** 63, 2 ** 63], dtype=np.uint64)
         tm.assert_series_equal(algos.mode(s), exp)
@@ -2359,6 +2814,7 @@
         tm.assert_series_equal(algos.mode(s), exp)
 
     def test_categorical(self):
+        """ """
         c = Categorical([1, 2])
         exp = c
         tm.assert_categorical_equal(algos.mode(c), exp)
@@ -2375,6 +2831,7 @@
         tm.assert_categorical_equal(c.mode(), exp)
 
     def test_index(self):
+        """ """
         idx = Index([1, 2, 3])
         exp = Series([1, 2, 3], dtype=np.int64)
         tm.assert_series_equal(algos.mode(idx), exp)
