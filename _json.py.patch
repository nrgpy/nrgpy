# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/io/json/_json.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/io/json/_json.py
@@ -45,6 +45,41 @@
     index: bool = True,
     indent: int = 0,
 ):
+    """
+
+    Parameters
+    ----------
+    path_or_buf :
+        
+    obj :
+        
+    orient: Optional[str] :
+         (Default value = None)
+    date_format: str :
+         (Default value = "epoch")
+    double_precision: int :
+         (Default value = 10)
+    force_ascii: bool :
+         (Default value = True)
+    date_unit: str :
+         (Default value = "ms")
+    default_handler: Optional[Callable[[Any] :
+        
+    JSONSerializable]] :
+         (Default value = None)
+    lines: bool :
+         (Default value = False)
+    compression: Optional[str] :
+         (Default value = "infer")
+    index: bool :
+         (Default value = True)
+    indent: int :
+         (Default value = 0)
+
+    Returns
+    -------
+
+    """
 
     if not index and orient not in ["split", "table"]:
         raise ValueError(
@@ -100,6 +135,7 @@
 
 
 class Writer:
+    """ """
     def __init__(
         self,
         obj,
@@ -130,9 +166,11 @@
         self._format_axes()
 
     def _format_axes(self):
+        """ """
         raise AbstractMethodError(self)
 
     def write(self):
+        """ """
         return self._write(
             self.obj,
             self.orient,
@@ -155,6 +193,33 @@
         default_handler: Optional[Callable[[Any], JSONSerializable]],
         indent: int,
     ):
+        """
+
+        Parameters
+        ----------
+        obj :
+            
+        orient: Optional[str] :
+            
+        double_precision: int :
+            
+        ensure_ascii: bool :
+            
+        date_unit: str :
+            
+        iso_dates: bool :
+            
+        default_handler: Optional[Callable[[Any] :
+            
+        JSONSerializable]] :
+            
+        indent: int :
+            
+
+        Returns
+        -------
+
+        """
         return dumps(
             obj,
             orient=orient,
@@ -168,9 +233,11 @@
 
 
 class SeriesWriter(Writer):
+    """ """
     _default_orient = "index"
 
     def _format_axes(self):
+        """ """
         if not self.obj.index.is_unique and self.orient == "index":
             raise ValueError(f"Series index must be unique for orient='{self.orient}'")
 
@@ -185,6 +252,33 @@
         default_handler: Optional[Callable[[Any], JSONSerializable]],
         indent: int,
     ):
+        """
+
+        Parameters
+        ----------
+        obj :
+            
+        orient: Optional[str] :
+            
+        double_precision: int :
+            
+        ensure_ascii: bool :
+            
+        date_unit: str :
+            
+        iso_dates: bool :
+            
+        default_handler: Optional[Callable[[Any] :
+            
+        JSONSerializable]] :
+            
+        indent: int :
+            
+
+        Returns
+        -------
+
+        """
         if not self.index and orient == "split":
             obj = {"name": obj.name, "data": obj.values}
         return super()._write(
@@ -200,12 +294,11 @@
 
 
 class FrameWriter(Writer):
+    """ """
     _default_orient = "columns"
 
     def _format_axes(self):
-        """
-        Try to format axes if they are datelike.
-        """
+        """Try to format axes if they are datelike."""
         if not self.obj.index.is_unique and self.orient in ("index", "columns"):
             raise ValueError(
                 f"DataFrame index must be unique for orient='{self.orient}'."
@@ -230,6 +323,33 @@
         default_handler: Optional[Callable[[Any], JSONSerializable]],
         indent: int,
     ):
+        """
+
+        Parameters
+        ----------
+        obj :
+            
+        orient: Optional[str] :
+            
+        double_precision: int :
+            
+        ensure_ascii: bool :
+            
+        date_unit: str :
+            
+        iso_dates: bool :
+            
+        default_handler: Optional[Callable[[Any] :
+            
+        JSONSerializable]] :
+            
+        indent: int :
+            
+
+        Returns
+        -------
+
+        """
         if not self.index and orient == "split":
             obj = obj.to_dict(orient="split")
             del obj["index"]
@@ -246,6 +366,7 @@
 
 
 class JSONTableWriter(FrameWriter):
+    """ """
     _default_orient = "records"
 
     def __init__(
@@ -329,6 +450,31 @@
         default_handler,
         indent,
     ):
+        """
+
+        Parameters
+        ----------
+        obj :
+            
+        orient :
+            
+        double_precision :
+            
+        ensure_ascii :
+            
+        date_unit :
+            
+        iso_dates :
+            
+        default_handler :
+            
+        indent :
+            
+
+        Returns
+        -------
+
+        """
         table_obj = {"schema": self.schema, "data": obj}
         serialized = super()._write(
             table_obj,
@@ -365,8 +511,7 @@
     compression="infer",
     nrows: Optional[int] = None,
 ):
-    """
-    Convert a JSON string to pandas object.
+    """Convert a JSON string to pandas object.
 
     Parameters
     ----------
@@ -375,71 +520,52 @@
         URL schemes include http, ftp, s3, and file. For file URLs, a host is
         expected. A local file could be:
         ``file://localhost/path/to/table.json``.
-
         If you want to pass in a path object, pandas accepts any
         ``os.PathLike``.
-
         By file-like object, we refer to objects with a ``read()`` method,
         such as a file handler (e.g. via builtin ``open`` function)
-        or ``StringIO``.
+        or ``StringIO``. (Default value = None)
     orient : str
         Indication of expected JSON string format.
         Compatible JSON strings can be produced by ``to_json()`` with a
         corresponding orient value.
         The set of possible orients is:
-
         - ``'split'`` : dict like
-          ``{index -> [index], columns -> [columns], data -> [values]}``
+        ``{index -> [index], columns -> [columns], data -> [values]}``
         - ``'records'`` : list like
-          ``[{column -> value}, ... , {column -> value}]``
+        ``[{column -> value}, ... , {column -> value}]``
         - ``'index'`` : dict like ``{index -> {column -> value}}``
         - ``'columns'`` : dict like ``{column -> {index -> value}}``
         - ``'values'`` : just the values array
-
         The allowed and default values depend on the value
         of the `typ` parameter.
-
         * when ``typ == 'series'``,
-
-          - allowed orients are ``{'split','records','index'}``
-          - default is ``'index'``
-          - The Series index must be unique for orient ``'index'``.
-
+        - allowed orients are ``{'split','records','index'}``
+        - default is ``'index'``
+        - The Series index must be unique for orient ``'index'``.
         * when ``typ == 'frame'``,
-
-          - allowed orients are ``{'split','records','index',
-            'columns','values', 'table'}``
-          - default is ``'columns'``
-          - The DataFrame index must be unique for orients ``'index'`` and
-            ``'columns'``.
-          - The DataFrame columns must be unique for orients ``'index'``,
-            ``'columns'``, and ``'records'``.
-
+        - allowed orients are ``{'split','records','index',
+        'columns','values', 'table'}``
+        - default is ``'columns'``
+        - The DataFrame index must be unique for orients ``'index'`` and
+        ``'columns'``.
+        - The DataFrame columns must be unique for orients ``'index'``,
+        ``'columns'``, and ``'records'``.
         .. versionadded:: 0.23.0
-           'table' as an allowed value for the ``orient`` argument
-
+        'table' as an allowed value for the ``orient`` argument
     typ : {'frame', 'series'}, default 'frame'
-        The type of object to recover.
-
+        The type of object to recover. (Default value = "frame")
     dtype : bool or dict, default None
         If True, infer dtypes; if a dict of column to dtype, then use those;
         if False, then don't infer dtypes at all, applies only to the data.
-
         For all ``orient`` values except ``'table'``, default is True.
-
         .. versionchanged:: 0.25.0
-
-           Not applicable for ``orient='table'``.
-
+        Not applicable for ``orient='table'``.
     convert_axes : bool, default None
         Try to convert the axes to the proper dtypes.
-
         For all ``orient`` values except ``'table'``, default is True.
-
         .. versionchanged:: 0.25.0
-
-           Not applicable for ``orient='table'``.
-
+        Not applicable for ``orient='table'``.
     convert_dates : bool or list of str, default True
         If True then default datelike columns may be converted (depending on
         keep_default_dates).
@@ -447,46 +573,33 @@
         If a list of column names, then those columns will be converted and
         default datelike columns may also be converted (depending on
         keep_default_dates).
-
     keep_default_dates : bool, default True
         If parsing dates (convert_dates is not False), then try to parse the
         default datelike columns.
         A column label is datelike if
-
         * it ends with ``'_at'``,
-
         * it ends with ``'_time'``,
-
         * it begins with ``'timestamp'``,
-
         * it is ``'modified'``, or
-
         * it is ``'date'``.
-
     numpy : bool, default False
         Direct decoding to numpy arrays. Supports numeric data only, but
         non-numeric column and index labels are supported. Note also that the
         JSON ordering MUST be the same for each term if numpy=True.
-
         .. deprecated:: 1.0.0
-
     precise_float : bool, default False
         Set to enable usage of higher precision (strtod) function when
         decoding string to double values. Default (False) is to use fast but
         less precise builtin functionality.
-
     date_unit : str, default None
         The timestamp unit to detect if converting dates. The default behaviour
         is to try and detect the correct precision, but if this is not desired
         then pass one of 's', 'ms', 'us' or 'ns' to force parsing only seconds,
         milliseconds, microseconds or nanoseconds respectively.
-
     encoding : str, default is 'utf-8'
-        The encoding to use to decode py3 bytes.
-
+        The encoding to use to decode py3 bytes. (Default value = None)
     lines : bool, default False
         Read the file as a json object per line.
-
     chunksize : int, optional
         Return JsonReader object for iteration.
         See the `line-delimited json docs
@@ -494,20 +607,29 @@
         for more information on ``chunksize``.
         This can only be passed if `lines=True`.
         If this is None, the file will be read into memory all at once.
-
     compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'
         For on-the-fly decompression of on-disk data. If 'infer', then use
         gzip, bz2, zip or xz if path_or_buf is a string ending in
         '.gz', '.bz2', '.zip', or 'xz', respectively, and no decompression
         otherwise. If using 'zip', the ZIP file must contain only one data
-        file to be read in. Set to None for no decompression.
-
+        file to be read in. Set to None for no decompression. (Default value = "infer")
     nrows : int, optional
         The number of lines from the line-delimited jsonfile that has to be read.
         This can only be passed if `lines=True`.
         If this is None, all the rows will be returned.
-
         .. versionadded:: 1.1
+    keep_default_dates: bool :
+         (Default value = True)
+    numpy: bool :
+         (Default value = False)
+    precise_float: bool :
+         (Default value = False)
+    lines: bool :
+         (Default value = False)
+    chunksize: Optional[int] :
+         (Default value = None)
+    nrows: Optional[int] :
+         (Default value = None)
 
     Returns
     -------
@@ -518,7 +640,6 @@
     --------
     DataFrame.to_json : Convert a DataFrame to a JSON string.
     Series.to_json : Convert a Series to a JSON string.
-
     Notes
     -----
     Specific to ``orient='table'``, if a :class:`DataFrame` with a literal
@@ -529,15 +650,24 @@
     :func:`read_json` operation cannot distinguish between the two. The same
     limitation is encountered with a :class:`MultiIndex` and any names
     beginning with ``'level_'``.
-
     Examples
     --------
+    
+    Encoding/decoding a Dataframe using ``'split'`` formatted JSON:
+    
+    
+    Encoding/decoding a Dataframe using ``'index'`` formatted JSON:
+    
+    
+    Encoding/decoding a Dataframe using ``'records'`` formatted JSON.
+    Note that index labels are not preserved with this encoding.
+    
+    
+    Encoding with Table Schema
     >>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],
     ...                   index=['row 1', 'row 2'],
     ...                   columns=['col 1', 'col 2'])
-
-    Encoding/decoding a Dataframe using ``'split'`` formatted JSON:
-
+    
     >>> df.to_json(orient='split')
     '{"columns":["col 1","col 2"],
       "index":["row 1","row 2"],
@@ -546,28 +676,21 @@
           col 1 col 2
     row 1     a     b
     row 2     c     d
-
-    Encoding/decoding a Dataframe using ``'index'`` formatted JSON:
-
+    
     >>> df.to_json(orient='index')
     '{"row 1":{"col 1":"a","col 2":"b"},"row 2":{"col 1":"c","col 2":"d"}}'
     >>> pd.read_json(_, orient='index')
           col 1 col 2
     row 1     a     b
     row 2     c     d
-
-    Encoding/decoding a Dataframe using ``'records'`` formatted JSON.
-    Note that index labels are not preserved with this encoding.
-
+    
     >>> df.to_json(orient='records')
     '[{"col 1":"a","col 2":"b"},{"col 1":"c","col 2":"d"}]'
     >>> pd.read_json(_, orient='records')
       col 1 col 2
     0     a     b
     1     c     d
-
-    Encoding with Table Schema
-
+    
     >>> df.to_json(orient='table')
     '{"schema": {"fields": [{"name": "index", "type": "string"},
                             {"name": "col 1", "type": "string"},
@@ -623,12 +746,18 @@
 
 
 class JsonReader(abc.Iterator):
-    """
-    JsonReader provides an interface for reading in a JSON file.
-
+    """JsonReader provides an interface for reading in a JSON file.
+    
     If initialized with ``lines=True`` and ``chunksize``, can be iterated over
     ``chunksize`` lines at a time. Otherwise, calling ``read`` reads in the
     whole document.
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+
     """
 
     def __init__(
@@ -680,12 +809,20 @@
         self.data = self._preprocess_data(data)
 
     def _preprocess_data(self, data):
-        """
-        At this point, the data either has a `read` attribute (e.g. a file
+        """At this point, the data either has a `read` attribute (e.g. a file
         object or a StringIO) or is a string that is a JSON document.
-
+        
         If self.chunksize, we prepare the data for the `__next__` method.
         Otherwise, we read it into memory for the `read` method.
+
+        Parameters
+        ----------
+        data :
+            
+
+        Returns
+        -------
+
         """
         if hasattr(data, "read") and (not self.chunksize or not self.nrows):
             data = data.read()
@@ -695,14 +832,22 @@
         return data
 
     def _get_data_from_filepath(self, filepath_or_buffer):
-        """
-        The function read_json accepts three input types:
+        """The function read_json accepts three input types:
             1. filepath (string-like)
             2. file-like object (e.g. open file object, StringIO)
             3. JSON string
-
+        
         This method turns (1) into (2) to simplify the rest of the processing.
         It returns input types (2) and (3) unchanged.
+
+        Parameters
+        ----------
+        filepath_or_buffer :
+            
+
+        Returns
+        -------
+
         """
         data = filepath_or_buffer
 
@@ -730,16 +875,22 @@
         return data
 
     def _combine_lines(self, lines) -> str:
-        """
-        Combines a list of JSON objects into one JSON object.
+        """Combines a list of JSON objects into one JSON object.
+
+        Parameters
+        ----------
+        lines :
+            
+
+        Returns
+        -------
+
         """
         lines = filter(None, map(lambda x: x.strip(), lines))
         return "[" + ",".join(lines) + "]"
 
     def read(self):
-        """
-        Read the whole JSON input into a pandas object.
-        """
+        """Read the whole JSON input into a pandas object."""
         if self.lines:
             if self.chunksize:
                 obj = concat(self)
@@ -757,8 +908,16 @@
         return obj
 
     def _get_object_parser(self, json):
-        """
-        Parses a json document into a pandas object.
+        """Parses a json document into a pandas object.
+
+        Parameters
+        ----------
+        json :
+            
+
+        Returns
+        -------
+
         """
         typ = self.typ
         dtype = self.dtype
@@ -784,11 +943,17 @@
         return obj
 
     def close(self):
-        """
-        If we opened a stream earlier, in _get_data_from_filepath, we should
+        """If we opened a stream earlier, in _get_data_from_filepath, we should
         close it.
-
+        
         If an open stream or file was passed, we leave it open.
+
+        Parameters
+        ----------
+
+        Returns
+        -------
+
         """
         if self.should_close:
             try:
@@ -818,6 +983,7 @@
 
 
 class Parser:
+    """ """
 
     _STAMP_UNITS = ("s", "ms", "us", "ns")
     _MIN_STAMPS = {
@@ -867,8 +1033,16 @@
         self.obj = None
 
     def check_keys_split(self, decoded):
-        """
-        Checks that dict has only the appropriate keys for orient='split'.
+        """Checks that dict has only the appropriate keys for orient='split'.
+
+        Parameters
+        ----------
+        decoded :
+            
+
+        Returns
+        -------
+
         """
         bad_keys = set(decoded.keys()).difference(set(self._split_keys))
         if bad_keys:
@@ -876,6 +1050,7 @@
             raise ValueError(f"JSON data had unexpected key(s): {bad_keys}")
 
     def parse(self):
+        """ """
 
         # try numpy
         numpy = self.numpy
@@ -893,9 +1068,7 @@
         return self.obj
 
     def _convert_axes(self):
-        """
-        Try to convert axes.
-        """
+        """Try to convert axes."""
         for axis_name in self.obj._AXIS_ORDERS:
             new_axis, result = self._try_convert_data(
                 name=axis_name,
@@ -907,11 +1080,26 @@
                 setattr(self.obj, axis_name, new_axis)
 
     def _try_convert_types(self):
+        """ """
         raise AbstractMethodError(self)
 
     def _try_convert_data(self, name, data, use_dtypes=True, convert_dates=True):
-        """
-        Try to parse a ndarray like into a column by inferring dtype.
+        """Try to parse a ndarray like into a column by inferring dtype.
+
+        Parameters
+        ----------
+        name :
+            
+        data :
+            
+        use_dtypes :
+             (Default value = True)
+        convert_dates :
+             (Default value = True)
+
+        Returns
+        -------
+
         """
         # don't try to coerce, unless a force conversion
         if use_dtypes:
@@ -983,11 +1171,19 @@
         return data, result
 
     def _try_convert_to_date(self, data):
-        """
-        Try to parse a ndarray like into a date column.
-
+        """Try to parse a ndarray like into a date column.
+        
         Try to coerce object in epoch/iso formats and integer/float in epoch
         formats. Return a boolean if parsing was successful.
+
+        Parameters
+        ----------
+        data :
+            
+
+        Returns
+        -------
+
         """
         # no conversion on empty
         if not len(data):
@@ -1020,14 +1216,17 @@
         return data, False
 
     def _try_convert_dates(self):
+        """ """
         raise AbstractMethodError(self)
 
 
 class SeriesParser(Parser):
+    """ """
     _default_orient = "index"
     _split_keys = ("name", "index", "data")
 
     def _parse_no_numpy(self):
+        """ """
         data = loads(self.json, precise_float=self.precise_float)
 
         if self.orient == "split":
@@ -1038,6 +1237,7 @@
             self.obj = create_series_with_explicit_dtype(data, dtype_if_empty=object)
 
     def _parse_numpy(self):
+        """ """
         load_kwargs = {
             "dtype": None,
             "numpy": True,
@@ -1058,6 +1258,7 @@
             self.obj = create_series_with_explicit_dtype(data, dtype_if_empty=object)
 
     def _try_convert_types(self):
+        """ """
         if self.obj is None:
             return
         obj, result = self._try_convert_data(
@@ -1068,10 +1269,12 @@
 
 
 class FrameParser(Parser):
+    """ """
     _default_orient = "columns"
     _split_keys = ("columns", "index", "data")
 
     def _parse_numpy(self):
+        """ """
 
         json = self.json
         orient = self.orient
@@ -1110,6 +1313,7 @@
             )
 
     def _parse_no_numpy(self):
+        """ """
 
         json = self.json
         orient = self.orient
@@ -1139,8 +1343,18 @@
             )
 
     def _process_converter(self, f, filt=None):
-        """
-        Take a conversion function and possibly recreate the frame.
+        """Take a conversion function and possibly recreate the frame.
+
+        Parameters
+        ----------
+        f :
+            
+        filt :
+             (Default value = None)
+
+        Returns
+        -------
+
         """
         if filt is None:
             filt = lambda col, c: True
@@ -1163,6 +1377,7 @@
             self.obj = new_obj
 
     def _try_convert_types(self):
+        """ """
         if self.obj is None:
             return
         if self.convert_dates:
@@ -1173,6 +1388,7 @@
         )
 
     def _try_convert_dates(self):
+        """ """
         if self.obj is None:
             return
 
@@ -1184,7 +1400,17 @@
 
         def is_ok(col) -> bool:
             """
-            Return if this col is ok to try for a date parse.
+
+            Parameters
+            ----------
+            col :
+                
+
+            Returns
+            -------
+            type
+                
+
             """
             if not isinstance(col, str):
                 return False
