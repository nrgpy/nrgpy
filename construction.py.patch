# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/core/internals/construction.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/core/internals/construction.py
@@ -65,10 +65,28 @@
     dtype: Optional[DtypeObj] = None,
     verify_integrity: bool = True,
 ):
-    """
-    Segregate Series based on type and coerce into matrices.
-
+    """Segregate Series based on type and coerce into matrices.
+    
     Needs to handle a lot of exceptional cases.
+
+    Parameters
+    ----------
+    arrays :
+        
+    arr_names :
+        
+    index :
+        
+    columns :
+        
+    dtype: Optional[DtypeObj] :
+         (Default value = None)
+    verify_integrity: bool :
+         (Default value = True)
+
+    Returns
+    -------
+
     """
     arr_names = ensure_index(arr_names)
 
@@ -96,8 +114,24 @@
 def masked_rec_array_to_mgr(
     data, index, columns, dtype: Optional[DtypeObj], copy: bool
 ):
-    """
-    Extract from a masked rec array and create the manager.
+    """Extract from a masked rec array and create the manager.
+
+    Parameters
+    ----------
+    data :
+        
+    index :
+        
+    columns :
+        
+    dtype: Optional[DtypeObj] :
+        
+    copy: bool :
+        
+
+    Returns
+    -------
+
     """
     # essentially process a record array then fill it
     fill_value = data.fill_value
@@ -141,6 +175,25 @@
 
 
 def init_ndarray(values, index, columns, dtype: Optional[DtypeObj], copy: bool):
+    """
+
+    Parameters
+    ----------
+    values :
+        
+    index :
+        
+    columns :
+        
+    dtype: Optional[DtypeObj] :
+        
+    copy: bool :
+        
+
+    Returns
+    -------
+
+    """
     # input must be a ndarray, list, Series, index
 
     if isinstance(values, ABCSeries):
@@ -235,9 +288,23 @@
 
 
 def init_dict(data: Dict, index, columns, dtype: Optional[DtypeObj] = None):
-    """
-    Segregate Series based on type and coerce into matrices.
+    """Segregate Series based on type and coerce into matrices.
     Needs to handle a lot of exceptional cases.
+
+    Parameters
+    ----------
+    data: Dict :
+        
+    index :
+        
+    columns :
+        
+    dtype: Optional[DtypeObj] :
+         (Default value = None)
+
+    Returns
+    -------
+
     """
     arrays: Union[Sequence[Any], "Series"]
 
@@ -287,6 +354,19 @@
 
 
 def _prep_ndarray(values, copy: bool = True) -> np.ndarray:
+    """
+
+    Parameters
+    ----------
+    values :
+        
+    copy: bool :
+         (Default value = True)
+
+    Returns
+    -------
+
+    """
     if not isinstance(values, (np.ndarray, ABCSeries, Index)):
         if len(values) == 0:
             return np.empty((0, 0), dtype=object)
@@ -295,6 +375,17 @@
             return arr[..., np.newaxis]
 
         def convert(v):
+            """
+
+            Parameters
+            ----------
+            v :
+                
+
+            Returns
+            -------
+
+            """
             return maybe_convert_platform(v)
 
         # we could have a 1-dim or 2-dim list here
@@ -327,6 +418,21 @@
 
 
 def _homogenize(data, index, dtype: Optional[DtypeObj]):
+    """
+
+    Parameters
+    ----------
+    data :
+        
+    index :
+        
+    dtype: Optional[DtypeObj] :
+        
+
+    Returns
+    -------
+
+    """
     oindex = None
     homogenized = []
 
@@ -358,8 +464,16 @@
 
 
 def extract_index(data) -> Index:
-    """
-    Try to infer an Index from the passed data, raise ValueError on failure.
+    """Try to infer an Index from the passed data, raise ValueError on failure.
+
+    Parameters
+    ----------
+    data :
+        
+
+    Returns
+    -------
+
     """
     index = None
     if len(data) == 0:
@@ -416,6 +530,21 @@
 
 
 def reorder_arrays(arrays, arr_columns, columns):
+    """
+
+    Parameters
+    ----------
+    arrays :
+        
+    arr_columns :
+        
+    columns :
+        
+
+    Returns
+    -------
+
+    """
     # reorder according to the columns
     if (
         columns is not None
@@ -430,6 +559,17 @@
 
 
 def get_names_from_index(data):
+    """
+
+    Parameters
+    ----------
+    data :
+        
+
+    Returns
+    -------
+
+    """
     has_some_name = any(getattr(s, "name", None) is not None for s in data)
     if not has_some_name:
         return ibase.default_index(len(data))
@@ -448,6 +588,23 @@
 
 
 def _get_axes(N, K, index, columns) -> Tuple[Index, Index]:
+    """
+
+    Parameters
+    ----------
+    N :
+        
+    K :
+        
+    index :
+        
+    columns :
+        
+
+    Returns
+    -------
+
+    """
     # helper to create the axes as indexes
     # return axes or defaults
 
@@ -464,16 +621,17 @@
 
 
 def dataclasses_to_dicts(data):
-    """
-    Converts a list of dataclass instances to a list of dictionaries.
+    """Converts a list of dataclass instances to a list of dictionaries.
 
     Parameters
     ----------
     data : List[Type[dataclass]]
-
-    Returns
-    --------
+        
+
+    Returns
+    -------
     list_dict : List[dict]
+        
 
     Examples
     --------
@@ -481,10 +639,9 @@
     >>> class Point:
     ...     x: int
     ...     y: int
-
+    
     >>> dataclasses_to_dicts([Point(1,2), Point(2,3)])
     [{"x":1,"y":2},{"x":2,"y":3}]
-
     """
     from dataclasses import asdict
 
@@ -499,7 +656,23 @@
     data, columns, coerce_float: bool = False, dtype: Optional[DtypeObj] = None
 ):
     """
-    Return list of arrays, columns.
+
+    Parameters
+    ----------
+    data :
+        
+    columns :
+        
+    coerce_float: bool :
+         (Default value = False)
+    dtype: Optional[DtypeObj] :
+         (Default value = None)
+
+    Returns
+    -------
+    type
+        
+
     """
     if isinstance(data, ABCDataFrame):
         if columns is not None:
@@ -554,6 +727,25 @@
     coerce_float: bool = False,
     dtype: Optional[DtypeObj] = None,
 ) -> Tuple[List[Scalar], Union[Index, List[Axis]]]:
+    """
+
+    Parameters
+    ----------
+    data: List[Scalar] :
+        
+    columns: Union[Index :
+        
+    List] :
+        
+    coerce_float: bool :
+         (Default value = False)
+    dtype: Optional[DtypeObj] :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     if len(data) > 0 and isinstance(data[0], tuple):
         content = list(lib.to_object_array_tuples(data).T)
     else:
@@ -574,6 +766,25 @@
     coerce_float: bool = False,
     dtype: Optional[DtypeObj] = None,
 ) -> Tuple[List[Scalar], Union[Index, List[Axis]]]:
+    """
+
+    Parameters
+    ----------
+    data: List :
+        
+    columns: Union[Index :
+        
+    List] :
+        
+    coerce_float: bool :
+         (Default value = False)
+    dtype: Optional[DtypeObj] :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     if columns is None:
         # We know pass_data is non-empty because data[0] is a Series
         pass_data = [x for x in data if isinstance(x, (ABCSeries, ABCDataFrame))]
@@ -612,9 +823,8 @@
     coerce_float: bool = False,
     dtype: Optional[DtypeObj] = None,
 ) -> Tuple[List[Scalar], Union[Index, List[Axis]]]:
-    """
-    Convert list of dicts to numpy arrays
-
+    """Convert list of dicts to numpy arrays
+    
     if `columns` is not passed, column names are inferred from the records
     - for OrderedDict and dicts, the column names match
       the key insertion-order from the first record to the last.
@@ -624,14 +834,27 @@
     ----------
     data : iterable
         collection of records (OrderedDict, dict)
-    columns: iterables or None
+    columns : iterables or None
+        
     coerce_float : bool
+        
     dtype : np.dtype
-
-    Returns
-    -------
-    tuple
-        arrays, columns
+        
+    data: List :
+        
+    columns: Union[Index :
+        
+    List] :
+        
+    coerce_float: bool :
+         (Default value = False)
+    dtype: Optional[DtypeObj] :
+         (Default value = None)
+
+    Returns
+    -------
+
+    
     """
     if columns is None:
         gen = (list(x.keys()) for x in data)
@@ -651,28 +874,30 @@
 def _validate_or_indexify_columns(
     content: List, columns: Optional[Union[Index, List]]
 ) -> Union[Index, List[Axis]]:
-    """
-    If columns is None, make numbers as column names; Otherwise, validate that
+    """If columns is None, make numbers as column names; Otherwise, validate that
     columns have valid length.
 
     Parameters
     ----------
-    content: list of data
-    columns: Iterable or None
-
-    Returns
-    -------
-    columns: If columns is Iterable, return as is; If columns is None, assign
+    content : list of data
+        
+    columns : Iterable or None
+        
+    content: List :
+        
+    columns: Optional[Union[Index :
+        
+    List]] :
+        
+
+    Returns
+    -------
+    columns : If columns is Iterable, return as is; If columns is None, assign
+        
     positional column index value as columns.
-
-    Raises
-    ------
-    1. AssertionError when content is not composed of list of lists, and if
-        length of columns is not equal to length of content.
-    2. ValueError when content is list of lists, but length of each sub-list
-        is not equal
-    3. ValueError when content is list of lists, but length of sub-list is
-        not equal to length of content
+        
+
+    
     """
     if columns is None:
         columns = ibase.default_index(len(content))
@@ -709,21 +934,41 @@
 def _convert_object_array(
     content: List[Scalar], coerce_float: bool = False, dtype: Optional[DtypeObj] = None
 ) -> List[Scalar]:
-    """
-    Internal function ot convert object array.
-
-    Parameters
-    ----------
-    content: list of processed data records
-    coerce_float: bool, to coerce floats or not, default is False
-    dtype: np.dtype, default is None
-
-    Returns
-    -------
-    arrays: casted content if not object dtype, otherwise return as is in list.
+    """Internal function ot convert object array.
+
+    Parameters
+    ----------
+    content : list of processed data records
+        
+    coerce_float : bool, to coerce floats or not, default is False
+        
+    dtype : np.dtype, default is None
+        
+    content: List[Scalar] :
+        
+    coerce_float: bool :
+         (Default value = False)
+    dtype: Optional[DtypeObj] :
+         (Default value = None)
+
+    Returns
+    -------
+
+    
     """
     # provide soft conversion of object dtypes
     def convert(arr):
+        """
+
+        Parameters
+        ----------
+        arr :
+            
+
+        Returns
+        -------
+
+        """
         if dtype != np.dtype("O"):
             arr = lib.maybe_convert_objects(arr, try_float=coerce_float)
             arr = maybe_cast_to_datetime(arr, dtype)
@@ -739,9 +984,19 @@
 
 
 def sanitize_index(data, index: Index):
-    """
-    Sanitize an index type to return an ndarray of the underlying, pass
+    """Sanitize an index type to return an ndarray of the underlying, pass
     through a non-Index.
+
+    Parameters
+    ----------
+    data :
+        
+    index: Index :
+        
+
+    Returns
+    -------
+
     """
     if len(data) != len(index):
         raise ValueError(
