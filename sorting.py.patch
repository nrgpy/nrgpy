# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/core/sorting.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/core/sorting.py
@@ -21,8 +21,7 @@
 
 
 def get_group_index(labels, shape, sort: bool, xnull: bool):
-    """
-    For the particular label_list, gets the offsets into the hypothetical list
+    """For the particular label_list, gets the offsets into the hypothetical list
     representing the totally ordered cartesian product of all possible label
     combinations, *as long as* this space fits within int64 bounds;
     otherwise, though group indices identify unique combinations of
@@ -42,11 +41,17 @@
     xnull : bool
         If true nulls are excluded. i.e. -1 values in the labels are
         passed through.
+    sort: bool :
+        
+    xnull: bool :
+        
 
     Returns
     -------
     An array of type int64 where two elements are equal if their corresponding
+        
     labels are equal at all location.
+        
 
     Notes
     -----
@@ -54,6 +59,17 @@
     """
 
     def _int64_cut_off(shape) -> int:
+        """
+
+        Parameters
+        ----------
+        shape :
+            
+
+        Returns
+        -------
+
+        """
         acc = 1
         for i, mul in enumerate(shape):
             acc *= int(mul)
@@ -62,6 +78,19 @@
         return len(shape)
 
     def maybe_lift(lab, size):
+        """
+
+        Parameters
+        ----------
+        lab :
+            
+        size :
+            
+
+        Returns
+        -------
+
+        """
         # promote nan values (assigned -1 label in lab array)
         # so that all output values are non-negative
         return (lab + 1, size + 1) if (lab == -1).any() else (lab, size)
@@ -110,25 +139,38 @@
 
 
 def get_compressed_ids(labels, sizes):
-    """
-    Group_index is offsets into cartesian product of all possible labels. This
+    """Group_index is offsets into cartesian product of all possible labels. This
     space can be huge, so this function compresses it, by computing offsets
     (comp_ids) into the list of unique labels (obs_group_ids).
 
     Parameters
     ----------
     labels : list of label arrays
+        
     sizes : list of size of the levels
-
-    Returns
-    -------
-    tuple of (comp_ids, obs_group_ids)
+        
+
+    Returns
+    -------
+
+    
     """
     ids = get_group_index(labels, sizes, sort=True, xnull=False)
     return compress_group_index(ids, sort=True)
 
 
 def is_int64_overflow_possible(shape) -> bool:
+    """
+
+    Parameters
+    ----------
+    shape :
+        
+
+    Returns
+    -------
+
+    """
     the_prod = 1
     for x in shape:
         the_prod *= int(x)
@@ -137,6 +179,19 @@
 
 
 def decons_group_index(comp_labels, shape):
+    """
+
+    Parameters
+    ----------
+    comp_labels :
+        
+    shape :
+        
+
+    Returns
+    -------
+
+    """
     # reconstruct labels
     if is_int64_overflow_possible(shape):
         # at some point group indices are factorized,
@@ -157,13 +212,25 @@
 
 
 def decons_obs_group_ids(comp_ids, obs_ids, shape, labels, xnull: bool):
-    """
-    Reconstruct labels from observed group ids.
-
-    Parameters
-    ----------
-    xnull : bool
-        If nulls are excluded; i.e. -1 labels are passed through.
+    """Reconstruct labels from observed group ids.
+
+    Parameters
+    ----------
+    comp_ids :
+        
+    obs_ids :
+        
+    shape :
+        
+    labels :
+        
+    xnull: bool :
+        
+
+    Returns
+    -------
+
+    
     """
     if not xnull:
         lift = np.fromiter(((a == -1).any() for a in labels), dtype="i8")
@@ -180,6 +247,21 @@
 
 
 def indexer_from_factorized(labels, shape, compress: bool = True):
+    """
+
+    Parameters
+    ----------
+    labels :
+        
+    shape :
+        
+    compress: bool :
+         (Default value = True)
+
+    Returns
+    -------
+
+    """
     ids = get_group_index(labels, shape, sort=True, xnull=False)
 
     if not compress:
@@ -194,25 +276,23 @@
 def lexsort_indexer(
     keys, orders=None, na_position: str = "last", key: Optional[Callable] = None
 ):
-    """
-    Performs lexical sorting on a set of keys
-
-    Parameters
-    ----------
-    keys : sequence of arrays
-        Sequence of ndarrays to be sorted by the indexer
-    orders : boolean or list of booleans, optional
-        Determines the sorting order for each element in keys. If a list,
-        it must be the same length as keys. This determines whether the
-        corresponding element in keys should be sorted in ascending
-        (True) or descending (False) order. if bool, applied to all
-        elements as above. if None, defaults to True.
-    na_position : {'first', 'last'}, default 'last'
-        Determines placement of NA elements in the sorted list ("last" or "first")
-    key : Callable, optional
-        Callable key function applied to every element in keys before sorting
-
-        .. versionadded:: 1.0.0
+    """Performs lexical sorting on a set of keys
+
+    Parameters
+    ----------
+    keys :
+        
+    orders :
+         (Default value = None)
+    na_position: str :
+         (Default value = "last")
+    key: Optional[Callable] :
+         (Default value = None)
+
+    Returns
+    -------
+
+    
     """
     from pandas.core.arrays import Categorical
 
@@ -261,19 +341,29 @@
     na_position: str = "last",
     key: Optional[Callable] = None,
 ):
-    """
-    Intended to be a drop-in replacement for np.argsort which handles NaNs.
-
+    """Intended to be a drop-in replacement for np.argsort which handles NaNs.
+    
     Adds ascending, na_position, and key parameters.
-
+    
     (GH #6399, #5231, #27237)
 
     Parameters
     ----------
-    kind : str, default 'quicksort'
-    ascending : bool, default True
-    na_position : {'first', 'last'}, default 'last'
-    key : Optional[Callable], default None
+    items :
+        
+    kind: str :
+         (Default value = "quicksort")
+    ascending: bool :
+         (Default value = True)
+    na_position: str :
+         (Default value = "last")
+    key: Optional[Callable] :
+         (Default value = None)
+
+    Returns
+    -------
+
+    
     """
 
     if key is not None:
@@ -313,18 +403,22 @@
 
 
 def nargminmax(values, method: str):
-    """
-    Implementation of np.argmin/argmax but for ExtensionArray and which
+    """Implementation of np.argmin/argmax but for ExtensionArray and which
     handles missing values.
 
     Parameters
     ----------
     values : ExtensionArray
+        
     method : {"argmax", "argmin"}
-
-    Returns
-    -------
-    int
+        
+    method: str :
+        
+
+    Returns
+    -------
+
+    
     """
     assert method in {"argmax", "argmin"}
     func = np.argmax if method == "argmax" else np.argmin
@@ -340,8 +434,7 @@
 
 
 def ensure_key_mapped_multiindex(index, key: Callable, level=None):
-    """
-    Returns a new MultiIndex in which key has been applied
+    """Returns a new MultiIndex in which key has been applied
     to all levels specified in level (or all levels if level
     is None). Used for key sorting for MultiIndex.
 
@@ -358,12 +451,14 @@
     level : list-like, int or str, default None
         Level or list of levels to apply the key function to.
         If None, key function is applied to all levels. Other
-        levels are left unchanged.
-
-    Returns
-    -------
-    labels : MultiIndex
-        Resulting MultiIndex with modified levels.
+        levels are left unchanged. (Default value = None)
+    key: Callable :
+        
+
+    Returns
+    -------
+
+    
     """
     from pandas.core.indexes.api import MultiIndex
 
@@ -390,17 +485,23 @@
 
 
 def ensure_key_mapped(values, key: Optional[Callable], levels=None):
-    """
-    Applies a callable key function to the values function and checks
+    """Applies a callable key function to the values function and checks
     that the resulting value has the same shape. Can be called on Index
     subclasses, Series, DataFrames, or ndarrays.
 
     Parameters
     ----------
-    values : Series, DataFrame, Index subclass, or ndarray
-    key : Optional[Callable], key to be called on the values array
-    levels : Optional[List], if values is a MultiIndex, list of levels to
-    apply the key to.
+    values :
+        
+    key: Optional[Callable] :
+        
+    levels :
+         (Default value = None)
+
+    Returns
+    -------
+
+    
     """
     from pandas.core.indexes.api import Index
 
@@ -434,9 +535,7 @@
 
 
 class _KeyMapper:
-    """
-    Map compressed group id -> key tuple.
-    """
+    """Map compressed group id -> key tuple."""
 
     def __init__(self, comp_ids, ngroups: int, levels, labels):
         self.levels = levels
@@ -449,10 +548,22 @@
         self._populate_tables()
 
     def _populate_tables(self):
+        """ """
         for labs, table in zip(self.labels, self.tables):
             table.map(self.comp_ids, labs.astype(np.int64))
 
     def get_key(self, comp_id):
+        """
+
+        Parameters
+        ----------
+        comp_id :
+            
+
+        Returns
+        -------
+
+        """
         return tuple(
             level[table.get_item(comp_id)]
             for table, level in zip(self.tables, self.levels)
@@ -460,6 +571,23 @@
 
 
 def get_flattened_iterator(comp_ids, ngroups, levels, labels):
+    """
+
+    Parameters
+    ----------
+    comp_ids :
+        
+    ngroups :
+        
+    levels :
+        
+    labels :
+        
+
+    Returns
+    -------
+
+    """
     # provide "flattened" iterator for multi-group setting
     mapper = _KeyMapper(comp_ids, ngroups, levels, labels)
     return [mapper.get_key(i) for i in range(ngroups)]
@@ -467,10 +595,18 @@
 
 def get_indexer_dict(label_list, keys):
     """
-    Returns
-    -------
-    dict
-        Labels mapped to indexers.
+
+    Parameters
+    ----------
+    label_list :
+        
+    keys :
+        
+
+    Returns
+    -------
+
+    
     """
     shape = [len(x) for x in keys]
 
@@ -494,8 +630,7 @@
 
 
 def get_group_index_sorter(group_index, ngroups: int):
-    """
-    algos.groupsort_indexer implements `counting sort` and it is at least
+    """algos.groupsort_indexer implements `counting sort` and it is at least
     O(ngroups), where
         ngroups = prod(shape)
         shape = map(len, keys)
@@ -506,6 +641,17 @@
     Both algorithms are `stable` sort and that is necessary for correctness of
     groupby operations. e.g. consider:
         df.groupby(key)[col].transform('first')
+
+    Parameters
+    ----------
+    group_index :
+        
+    ngroups: int :
+        
+
+    Returns
+    -------
+
     """
     count = len(group_index)
     alpha = 0.0  # taking complexities literally; there may be
@@ -519,10 +665,20 @@
 
 
 def compress_group_index(group_index, sort: bool = True):
-    """
-    Group_index is offsets into cartesian product of all possible labels. This
+    """Group_index is offsets into cartesian product of all possible labels. This
     space can be huge, so this function compresses it, by computing offsets
     (comp_ids) into the list of unique labels (obs_group_ids).
+
+    Parameters
+    ----------
+    group_index :
+        
+    sort: bool :
+         (Default value = True)
+
+    Returns
+    -------
+
     """
     size_hint = min(len(group_index), hashtable._SIZE_HINT_LIMIT)
     table = hashtable.Int64HashTable(size_hint)
@@ -539,6 +695,19 @@
 
 
 def _reorder_by_uniques(uniques, labels):
+    """
+
+    Parameters
+    ----------
+    uniques :
+        
+    labels :
+        
+
+    Returns
+    -------
+
+    """
     # sorter is index where elements ought to go
     sorter = uniques.argsort()
 
