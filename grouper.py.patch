# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/core/groupby/grouper.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/core/groupby/grouper.py
@@ -33,13 +33,12 @@
 
 
 class Grouper:
-    """
-    A Grouper allows the user to specify a groupby instruction for an object.
-
+    """A Grouper allows the user to specify a groupby instruction for an object.
+    
     This specification will select a column via the key parameter, or if the
     level and/or axis parameters are given, a level of the index of the target
     object.
-
+    
     If `axis` and/or `level` are passed as keywords to both `Grouper` and
     `groupby`, the values passed to `Grouper` take precedence.
 
@@ -70,43 +69,53 @@
         For frequencies that evenly subdivide 1 day, the "origin" of the
         aggregated intervals. For example, for '5min' frequency, base could
         range from 0 through 4. Defaults to 0.
-
         .. deprecated:: 1.1.0
-            The new arguments that you should use are 'offset' or 'origin'.
-
+        The new arguments that you should use are 'offset' or 'origin'.
     loffset : str, DateOffset, timedelta object
         Only when `freq` parameter is passed.
-
         .. deprecated:: 1.1.0
-            loffset is only working for ``.resample(...)`` and not for
-            Grouper (:issue:`28302`).
-            However, loffset is also deprecated for ``.resample(...)``
-            See: :class:`DataFrame.resample`
-
+        loffset is only working for ``.resample(...)`` and not for
+        Grouper (:issue:`28302`).
+        However, loffset is also deprecated for ``.resample(...)``
+        See: :class:`DataFrame.resample`
     origin : {'epoch', 'start', 'start_day'}, Timestamp or str, default 'start_day'
         The timestamp on which to adjust the grouping. The timezone of origin must
         match the timezone of the index.
         If a timestamp is not used, these values are also supported:
-
         - 'epoch': `origin` is 1970-01-01
         - 'start': `origin` is the first value of the timeseries
         - 'start_day': `origin` is the first day at midnight of the timeseries
-
         .. versionadded:: 1.1.0
-
     offset : Timedelta or str, default is None
         An offset timedelta added to the origin.
-
         .. versionadded:: 1.1.0
 
     Returns
     -------
     A specification for a groupby instruction
+        
 
     Examples
     --------
     Syntactic sugar for ``df.groupby('A')``
-
+    
+    
+    Specify a resample operation on the column 'Publish date'
+    
+    
+    If you want to adjust the start of the bins based on a fixed timestamp:
+    
+    
+    
+    
+    
+    If you want to adjust the start of the bins with an `offset` Timedelta, the two
+    following lines are equivalent:
+    
+    
+    
+    To replace the use of the deprecated `base` argument, you can now use `offset`,
+    in this example it is equivalent to have `base=2`:
     >>> df = pd.DataFrame(
     ...     {
     ...         "Animal": ["Falcon", "Parrot", "Falcon", "Falcon", "Parrot"],
@@ -125,9 +134,7 @@
     Animal
     Falcon    200
     Parrot     10
-
-    Specify a resample operation on the column 'Publish date'
-
+    
     >>> df = pd.DataFrame(
     ...    {
     ...        "Publish date": [
@@ -152,9 +159,7 @@
     2000-01-02    0.5   15.0
     2000-01-09    2.0   30.0
     2000-01-16    3.0   40.0
-
-    If you want to adjust the start of the bins based on a fixed timestamp:
-
+    
     >>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'
     >>> rng = pd.date_range(start, end, freq='7min')
     >>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)
@@ -169,7 +174,7 @@
     2000-10-02 00:19:00    21
     2000-10-02 00:26:00    24
     Freq: 7T, dtype: int64
-
+    
     >>> ts.groupby(pd.Grouper(freq='17min')).sum()
     2000-10-01 23:14:00     0
     2000-10-01 23:31:00     9
@@ -177,7 +182,7 @@
     2000-10-02 00:05:00    54
     2000-10-02 00:22:00    24
     Freq: 17T, dtype: int64
-
+    
     >>> ts.groupby(pd.Grouper(freq='17min', origin='epoch')).sum()
     2000-10-01 23:18:00     0
     2000-10-01 23:35:00    18
@@ -185,34 +190,28 @@
     2000-10-02 00:09:00    39
     2000-10-02 00:26:00    24
     Freq: 17T, dtype: int64
-
+    
     >>> ts.groupby(pd.Grouper(freq='17min', origin='2000-01-01')).sum()
     2000-10-01 23:24:00     3
     2000-10-01 23:41:00    15
     2000-10-01 23:58:00    45
     2000-10-02 00:15:00    45
     Freq: 17T, dtype: int64
-
-    If you want to adjust the start of the bins with an `offset` Timedelta, the two
-    following lines are equivalent:
-
+    
     >>> ts.groupby(pd.Grouper(freq='17min', origin='start')).sum()
     2000-10-01 23:30:00     9
     2000-10-01 23:47:00    21
     2000-10-02 00:04:00    54
     2000-10-02 00:21:00    24
     Freq: 17T, dtype: int64
-
+    
     >>> ts.groupby(pd.Grouper(freq='17min', offset='23h30min')).sum()
     2000-10-01 23:30:00     9
     2000-10-01 23:47:00    21
     2000-10-02 00:04:00    54
     2000-10-02 00:21:00    24
     Freq: 17T, dtype: int64
-
-    To replace the use of the deprecated `base` argument, you can now use `offset`,
-    in this example it is equivalent to have `base=2`:
-
+    
     >>> ts.groupby(pd.Grouper(freq='17min', offset='2min')).sum()
     2000-10-01 23:16:00     0
     2000-10-01 23:33:00     9
@@ -285,19 +284,25 @@
 
     @property
     def ax(self):
+        """ """
         return self.grouper
 
     def _get_grouper(self, obj, validate: bool = True):
         """
+
         Parameters
         ----------
         obj : the subject object
+            
         validate : boolean, default True
             if True, validate the grouper
+        validate: bool :
+             (Default value = True)
 
         Returns
         -------
-        a tuple of binner, grouper, obj (possibly sorted)
+
+        
         """
         self._set_grouper(obj)
         self.grouper, _, self.obj = get_grouper(
@@ -312,15 +317,20 @@
         return self.binner, self.grouper, self.obj
 
     def _set_grouper(self, obj: FrameOrSeries, sort: bool = False):
-        """
-        given an object and the specifications, setup the internal grouper
+        """given an object and the specifications, setup the internal grouper
         for this particular specification
 
         Parameters
         ----------
-        obj : Series or DataFrame
-        sort : bool, default False
-            whether the resulting grouper should be sorted
+        obj: FrameOrSeries :
+            
+        sort: bool :
+             (Default value = False)
+
+        Returns
+        -------
+
+        
         """
         assert obj is not None
 
@@ -372,6 +382,7 @@
 
     @property
     def groups(self):
+        """ """
         return self.grouper.groups
 
     def __repr__(self) -> str:
@@ -386,16 +397,20 @@
 
 
 class Grouping:
-    """
-    Holds the grouping information for a single key
+    """Holds the grouping information for a single key
 
     Parameters
     ----------
     index : Index
+        
     grouper :
-    obj Union[DataFrame, Series]:
+        
+    obj Union[DataFrame, Series] :
+        
     name : Label
+        
     level :
+        
     observed : bool, default False
         If we are a Categorical, use the observed values
     in_axis : if the Grouping is a column in self.obj and hence among
@@ -403,11 +418,8 @@
 
     Returns
     -------
-    **Attributes**:
-      * indices : dict of {group -> index_list}
-      * codes : ndarray, group codes
-      * group_index : unique groups
-      * groups : dict of {group -> label_list}
+
+    
     """
 
     def __init__(
@@ -548,10 +560,12 @@
 
     @property
     def ngroups(self) -> int:
+        """ """
         return len(self.group_index)
 
     @cache_readonly
     def indices(self):
+        """ """
         # we have a list of groupers
         if isinstance(self.grouper, ops.BaseGrouper):
             return self.grouper.indices
@@ -566,24 +580,28 @@
 
     @property
     def codes(self) -> np.ndarray:
+        """ """
         if self._codes is None:
             self._make_codes()
         return self._codes
 
     @cache_readonly
     def result_index(self) -> Index:
+        """ """
         if self.all_grouper is not None:
             return recode_from_groupby(self.all_grouper, self.sort, self.group_index)
         return self.group_index
 
     @property
     def group_index(self) -> Index:
+        """ """
         if self._group_index is None:
             self._make_codes()
         assert self._group_index is not None
         return self._group_index
 
     def _make_codes(self) -> None:
+        """ """
         if self._codes is None or self._group_index is None:
             # we have a list of groupers
             if isinstance(self.grouper, ops.BaseGrouper):
@@ -604,6 +622,7 @@
 
     @cache_readonly
     def groups(self) -> Dict[Hashable, np.ndarray]:
+        """ """
         return self.index.groupby(Categorical.from_codes(self.codes, self.group_index))
 
 
@@ -618,26 +637,49 @@
     validate: bool = True,
     dropna: bool = True,
 ) -> "Tuple[ops.BaseGrouper, List[Hashable], FrameOrSeries]":
-    """
-    Create and return a BaseGrouper, which is an internal
+    """Create and return a BaseGrouper, which is an internal
     mapping of how to create the grouper indexers.
     This may be composed of multiple Grouping objects, indicating
     multiple groupers
-
+    
     Groupers are ultimately index mappings. They can originate as:
     index mappings, keys to columns, functions, or Groupers
-
+    
     Groupers enable local references to axis,level,sort, while
     the passed in axis, level, and sort are 'global'.
-
+    
     This routine tries to figure out what the passing in references
     are and then creates a Grouping for each one, combined into
     a BaseGrouper.
-
+    
     If observed & we have a categorical grouper, only show the observed
     values.
-
+    
     If validate, then check for key/level overlaps.
+
+    Parameters
+    ----------
+    obj: FrameOrSeries :
+        
+    key :
+         (Default value = None)
+    axis: int :
+         (Default value = 0)
+    level :
+         (Default value = None)
+    sort: bool :
+         (Default value = True)
+    observed: bool :
+         (Default value = False)
+    mutated: bool :
+         (Default value = False)
+    validate: bool :
+         (Default value = True)
+    dropna: bool :
+         (Default value = True)
+
+    Returns
+    -------
 
     """
     group_axis = obj._get_axis(axis)
@@ -746,6 +788,17 @@
 
     # if the actual grouper should be obj[key]
     def is_in_axis(key) -> bool:
+        """
+
+        Parameters
+        ----------
+        key :
+            
+
+        Returns
+        -------
+
+        """
         if not _is_label_like(key):
             # items -> .columns for DataFrame, .index for Series
             items = obj.axes[-1]
@@ -759,6 +812,17 @@
 
     # if the grouper is obj[name]
     def is_in_obj(gpr) -> bool:
+        """
+
+        Parameters
+        ----------
+        gpr :
+            
+
+        Returns
+        -------
+
+        """
         if not hasattr(gpr, "name"):
             return False
         try:
@@ -828,10 +892,34 @@
 
 
 def _is_label_like(val) -> bool:
+    """
+
+    Parameters
+    ----------
+    val :
+        
+
+    Returns
+    -------
+
+    """
     return isinstance(val, (str, tuple)) or (val is not None and is_scalar(val))
 
 
 def _convert_grouper(axis: Index, grouper):
+    """
+
+    Parameters
+    ----------
+    axis: Index :
+        
+    grouper :
+        
+
+    Returns
+    -------
+
+    """
     if isinstance(grouper, dict):
         return grouper.get
     elif isinstance(grouper, Series):
