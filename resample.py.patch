# Patch generated by Pyment v0.3.3

--- a/..//venv/lib/python3.8/site-packages/pandas/core/resample.py
+++ b/..//venv/lib/python3.8/site-packages/pandas/core/resample.py
@@ -41,23 +41,26 @@
 
 
 class Resampler(_GroupBy, ShallowMixin):
-    """
-    Class for resampling datetimelike data, a groupby-like operation.
+    """Class for resampling datetimelike data, a groupby-like operation.
     See aggregate, transform, and apply functions on this object.
-
+    
     It's easiest to use obj.resample(...) to use Resampler.
 
     Parameters
     ----------
     obj : pandas object
+        
     groupby : a TimeGrouper object
+        
     axis : int, default 0
+        
     kind : str or None
         'period', 'timestamp' to override default index treatment
 
     Returns
     -------
     a Resampler of the appropriate type
+        
 
     Notes
     -----
@@ -132,26 +135,24 @@
 
     @property
     def obj(self):
+        """ """
         return self.groupby.obj
 
     @property
     def ax(self):
+        """ """
         return self.groupby.ax
 
     @property
     def _typ(self) -> str:
-        """
-        Masquerade for compat as a Series or a DataFrame.
-        """
+        """Masquerade for compat as a Series or a DataFrame."""
         if isinstance(self._selected_obj, ABCSeries):
             return "series"
         return "dataframe"
 
     @property
     def _from_selection(self) -> bool:
-        """
-        Is the resampling from a DataFrame column or MultiIndex level.
-        """
+        """Is the resampling from a DataFrame column or MultiIndex level."""
         # upsampling and PeriodIndex resampling do not work
         # with selection, this state used to catch and raise an error
         return self.groupby is not None and (
@@ -159,36 +160,50 @@
         )
 
     def _convert_obj(self, obj):
-        """
-        Provide any conversions for the object in order to correctly handle.
+        """Provide any conversions for the object in order to correctly handle.
 
         Parameters
         ----------
         obj : the object to be resampled
-
-        Returns
-        -------
-        obj : converted object
+            
+
+        Returns
+        -------
+
+        
         """
         obj = obj._consolidate()
         return obj
 
     def _get_binner_for_time(self):
+        """ """
         raise AbstractMethodError(self)
 
     def _set_binner(self):
-        """
-        Setup our binners.
-
+        """Setup our binners.
+        
         Cache these as we are an immutable object
+
+        Parameters
+        ----------
+
+        Returns
+        -------
+
         """
         if self.binner is None:
             self.binner, self.grouper = self._get_binner()
 
     def _get_binner(self):
-        """
-        Create the BinGrouper, assume that self.set_grouper(obj)
+        """Create the BinGrouper, assume that self.set_grouper(obj)
         has already been called.
+
+        Parameters
+        ----------
+
+        Returns
+        -------
+
         """
         binner, bins, binlabels = self._get_binner_for_time()
         assert len(bins) == len(binlabels)
@@ -196,9 +211,7 @@
         return binner, bin_grouper
 
     def _assure_grouper(self):
-        """
-        Make sure that we are creating our binner & grouper.
-        """
+        """Make sure that we are creating our binner & grouper."""
         self._set_binner()
 
     @Substitution(
@@ -224,6 +237,21 @@
     )
     @Appender(_pipe_template)
     def pipe(self, func, *args, **kwargs):
+        """
+
+        Parameters
+        ----------
+        func :
+            
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         return super().pipe(func, *args, **kwargs)
 
     _agg_see_also_doc = dedent(
@@ -283,6 +311,21 @@
         axis="",
     )
     def aggregate(self, func, *args, **kwargs):
+        """
+
+        Parameters
+        ----------
+        func :
+            
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
 
         self._set_binner()
         result, how = self._aggregate(func, *args, **kwargs)
@@ -298,18 +341,22 @@
     apply = aggregate
 
     def transform(self, arg, *args, **kwargs):
-        """
-        Call function producing a like-indexed Series on each group and return
+        """Call function producing a like-indexed Series on each group and return
         a Series with the transformed values.
 
         Parameters
         ----------
         arg : function
             To apply to each group. Should return a Series with the same index.
+        *args :
+            
+        **kwargs :
+            
 
         Returns
         -------
         transformed : Series
+            
 
         Examples
         --------
@@ -318,22 +365,53 @@
         return self._selected_obj.groupby(self.groupby).transform(arg, *args, **kwargs)
 
     def _downsample(self, f):
+        """
+
+        Parameters
+        ----------
+        f :
+            
+
+        Returns
+        -------
+
+        """
         raise AbstractMethodError(self)
 
     def _upsample(self, f, limit=None, fill_value=None):
+        """
+
+        Parameters
+        ----------
+        f :
+            
+        limit :
+             (Default value = None)
+        fill_value :
+             (Default value = None)
+
+        Returns
+        -------
+
+        """
         raise AbstractMethodError(self)
 
     def _gotitem(self, key, ndim: int, subset=None):
-        """
-        Sub-classes to define. Return a sliced object.
-
-        Parameters
-        ----------
-        key : string / list of selections
-        ndim : {1, 2}
-            requested ndim of result
-        subset : object, default None
-            subset to act on
+        """Sub-classes to define. Return a sliced object.
+
+        Parameters
+        ----------
+        key :
+            
+        ndim: int :
+            
+        subset :
+             (Default value = None)
+
+        Returns
+        -------
+
+        
         """
         self._set_binner()
         grouper = self.grouper
@@ -348,8 +426,22 @@
             return grouped
 
     def _groupby_and_aggregate(self, how, grouper=None, *args, **kwargs):
-        """
-        Re-evaluate the obj with a groupby aggregation.
+        """Re-evaluate the obj with a groupby aggregation.
+
+        Parameters
+        ----------
+        how :
+            
+        grouper :
+             (Default value = None)
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
         """
         if grouper is None:
             self._set_binner()
@@ -392,16 +484,20 @@
         return self._wrap_result(result)
 
     def _apply_loffset(self, result):
-        """
-        If loffset is set, offset the result index.
-
+        """If loffset is set, offset the result index.
+        
         This is NOT an idempotent routine, it will be applied
         exactly once to the result.
 
         Parameters
         ----------
-        result : Series or DataFrame
-            the result of resample
+        result :
+            
+
+        Returns
+        -------
+
+        
         """
         needs_offset = (
             isinstance(self.loffset, (DateOffset, timedelta, np.timedelta64))
@@ -417,13 +513,33 @@
 
     def _get_resampler_for_grouping(self, groupby, **kwargs):
         """
-        Return the correct class for resampling with groupby.
+
+        Parameters
+        ----------
+        groupby :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+        type
+            
+
         """
         return self._resampler_for_grouping(self, groupby=groupby, **kwargs)
 
     def _wrap_result(self, result):
-        """
-        Potentially wrap any results.
+        """Potentially wrap any results.
+
+        Parameters
+        ----------
+        result :
+            
+
+        Returns
+        -------
+
         """
         if isinstance(result, ABCSeries) and self._selection is not None:
             result.name = self._selection
@@ -436,17 +552,17 @@
         return result
 
     def pad(self, limit=None):
-        """
-        Forward fill the values.
+        """Forward fill the values.
 
         Parameters
         ----------
         limit : int, optional
-            Limit of how many values to fill.
+            Limit of how many values to fill. (Default value = None)
 
         Returns
         -------
         An upsampled Series.
+            
 
         See Also
         --------
@@ -458,9 +574,8 @@
     ffill = pad
 
     def nearest(self, limit=None):
-        """
-        Resample by using the nearest value.
-
+        """Resample by using the nearest value.
+        
         When resampling data, missing values may appear (e.g., when the
         resampling frequency is higher than the original frequency).
         The `nearest` method will replace ``NaN`` values that appeared in
@@ -473,7 +588,7 @@
         Parameters
         ----------
         limit : int, optional
-            Limit of how many values to fill.
+            Limit of how many values to fill. (Default value = None)
 
         Returns
         -------
@@ -485,9 +600,11 @@
         --------
         backfill : Backward fill the new missing values in the resampled data.
         pad : Forward fill ``NaN`` values.
-
         Examples
         --------
+        
+        
+        Limit the number of upsampled values imputed by the nearest:
         >>> s = pd.Series([1, 2],
         ...               index=pd.date_range('20180101',
         ...                                   periods=2,
@@ -496,7 +613,7 @@
         2018-01-01 00:00:00    1
         2018-01-01 01:00:00    2
         Freq: H, dtype: int64
-
+        
         >>> s.resample('15min').nearest()
         2018-01-01 00:00:00    1
         2018-01-01 00:15:00    1
@@ -504,9 +621,7 @@
         2018-01-01 00:45:00    2
         2018-01-01 01:00:00    2
         Freq: 15T, dtype: int64
-
-        Limit the number of upsampled values imputed by the nearest:
-
+        
         >>> s.resample('15min').nearest(limit=1)
         2018-01-01 00:00:00    1.0
         2018-01-01 00:15:00    1.0
@@ -518,9 +633,8 @@
         return self._upsample("nearest", limit=limit)
 
     def backfill(self, limit=None):
-        """
-        Backward fill the new missing values in the resampled data.
-
+        """Backward fill the new missing values in the resampled data.
+        
         In statistics, imputation is the process of replacing missing data with
         substituted values [1]_. When resampling data, missing values may
         appear (e.g., when the resampling frequency is higher than the original
@@ -531,7 +645,7 @@
         Parameters
         ----------
         limit : int, optional
-            Limit of how many values to fill.
+            Limit of how many values to fill. (Default value = None)
 
         Returns
         -------
@@ -549,15 +663,17 @@
             specified method, which can be 'backfill'.
         DataFrame.fillna : Fill NaN values in the DataFrame using the
             specified method, which can be 'backfill'.
-
         References
         ----------
         .. [1] https://en.wikipedia.org/wiki/Imputation_(statistics)
-
         Examples
         --------
         Resampling a Series:
-
+        
+        
+        
+        
+        Resampling a DataFrame that has missing values:
         >>> s = pd.Series([1, 2, 3],
         ...               index=pd.date_range('20180101', periods=3, freq='h'))
         >>> s
@@ -565,7 +681,7 @@
         2018-01-01 01:00:00    2
         2018-01-01 02:00:00    3
         Freq: H, dtype: int64
-
+        
         >>> s.resample('30min').backfill()
         2018-01-01 00:00:00    1
         2018-01-01 00:30:00    2
@@ -573,7 +689,7 @@
         2018-01-01 01:30:00    3
         2018-01-01 02:00:00    3
         Freq: 30T, dtype: int64
-
+        
         >>> s.resample('15min').backfill(limit=2)
         2018-01-01 00:00:00    1.0
         2018-01-01 00:15:00    NaN
@@ -585,9 +701,7 @@
         2018-01-01 01:45:00    3.0
         2018-01-01 02:00:00    3.0
         Freq: 15T, dtype: float64
-
-        Resampling a DataFrame that has missing values:
-
+        
         >>> df = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},
         ...                   index=pd.date_range('20180101', periods=3,
         ...                                       freq='h'))
@@ -596,7 +710,7 @@
         2018-01-01 00:00:00  2.0  1
         2018-01-01 01:00:00  NaN  3
         2018-01-01 02:00:00  6.0  5
-
+        
         >>> df.resample('30min').backfill()
                                a  b
         2018-01-01 00:00:00  2.0  1
@@ -604,7 +718,7 @@
         2018-01-01 01:00:00  NaN  3
         2018-01-01 01:30:00  6.0  5
         2018-01-01 02:00:00  6.0  5
-
+        
         >>> df.resample('15min').backfill(limit=2)
                                a    b
         2018-01-01 00:00:00  2.0  1.0
@@ -622,14 +736,13 @@
     bfill = backfill
 
     def fillna(self, method, limit=None):
-        """
-        Fill missing values introduced by upsampling.
-
+        """Fill missing values introduced by upsampling.
+        
         In statistics, imputation is the process of replacing missing data with
         substituted values [1]_. When resampling data, missing values may
         appear (e.g., when the resampling frequency is higher than the original
         frequency).
-
+        
         Missing values that existed in the original data will
         not be modified.
 
@@ -637,14 +750,12 @@
         ----------
         method : {'pad', 'backfill', 'ffill', 'bfill', 'nearest'}
             Method to use for filling holes in resampled data
-
             * 'pad' or 'ffill': use previous valid observation to fill gap
-              (forward fill).
+            (forward fill).
             * 'backfill' or 'bfill': use next valid observation to fill gap.
             * 'nearest': use nearest valid observation to fill gap.
-
         limit : int, optional
-            Limit of how many consecutive missing values to fill.
+            Limit of how many consecutive missing values to fill. (Default value = None)
 
         Returns
         -------
@@ -662,15 +773,29 @@
             specified method, which can be 'bfill' and 'ffill'.
         DataFrame.fillna : Fill NaN values in the DataFrame using the
             specified method, which can be 'bfill' and 'ffill'.
-
         References
         ----------
         .. [1] https://en.wikipedia.org/wiki/Imputation_(statistics)
-
         Examples
         --------
         Resampling a Series:
-
+        
+        
+        Without filling the missing values you get:
+        
+        
+        
+        
+        
+        
+        Missing values present before the upsampling are not affected.
+        
+        
+        
+        
+        
+        DataFrame resampling is done column-wise. All the same options are
+        available.
         >>> s = pd.Series([1, 2, 3],
         ...               index=pd.date_range('20180101', periods=3, freq='h'))
         >>> s
@@ -678,9 +803,7 @@
         2018-01-01 01:00:00    2
         2018-01-01 02:00:00    3
         Freq: H, dtype: int64
-
-        Without filling the missing values you get:
-
+        
         >>> s.resample("30min").asfreq()
         2018-01-01 00:00:00    1.0
         2018-01-01 00:30:00    NaN
@@ -688,7 +811,7 @@
         2018-01-01 01:30:00    NaN
         2018-01-01 02:00:00    3.0
         Freq: 30T, dtype: float64
-
+        
         >>> s.resample('30min').fillna("backfill")
         2018-01-01 00:00:00    1
         2018-01-01 00:30:00    2
@@ -696,7 +819,7 @@
         2018-01-01 01:30:00    3
         2018-01-01 02:00:00    3
         Freq: 30T, dtype: int64
-
+        
         >>> s.resample('15min').fillna("backfill", limit=2)
         2018-01-01 00:00:00    1.0
         2018-01-01 00:15:00    NaN
@@ -708,7 +831,7 @@
         2018-01-01 01:45:00    3.0
         2018-01-01 02:00:00    3.0
         Freq: 15T, dtype: float64
-
+        
         >>> s.resample('30min').fillna("pad")
         2018-01-01 00:00:00    1
         2018-01-01 00:30:00    1
@@ -716,7 +839,7 @@
         2018-01-01 01:30:00    2
         2018-01-01 02:00:00    3
         Freq: 30T, dtype: int64
-
+        
         >>> s.resample('30min').fillna("nearest")
         2018-01-01 00:00:00    1
         2018-01-01 00:30:00    2
@@ -724,9 +847,7 @@
         2018-01-01 01:30:00    3
         2018-01-01 02:00:00    3
         Freq: 30T, dtype: int64
-
-        Missing values present before the upsampling are not affected.
-
+        
         >>> sm = pd.Series([1, None, 3],
         ...               index=pd.date_range('20180101', periods=3, freq='h'))
         >>> sm
@@ -734,7 +855,7 @@
         2018-01-01 01:00:00    NaN
         2018-01-01 02:00:00    3.0
         Freq: H, dtype: float64
-
+        
         >>> sm.resample('30min').fillna('backfill')
         2018-01-01 00:00:00    1.0
         2018-01-01 00:30:00    NaN
@@ -742,7 +863,7 @@
         2018-01-01 01:30:00    3.0
         2018-01-01 02:00:00    3.0
         Freq: 30T, dtype: float64
-
+        
         >>> sm.resample('30min').fillna('pad')
         2018-01-01 00:00:00    1.0
         2018-01-01 00:30:00    1.0
@@ -750,7 +871,7 @@
         2018-01-01 01:30:00    NaN
         2018-01-01 02:00:00    3.0
         Freq: 30T, dtype: float64
-
+        
         >>> sm.resample('30min').fillna('nearest')
         2018-01-01 00:00:00    1.0
         2018-01-01 00:30:00    NaN
@@ -758,10 +879,7 @@
         2018-01-01 01:30:00    3.0
         2018-01-01 02:00:00    3.0
         Freq: 30T, dtype: float64
-
-        DataFrame resampling is done column-wise. All the same options are
-        available.
-
+        
         >>> df = pd.DataFrame({'a': [2, np.nan, 6], 'b': [1, 3, 5]},
         ...                   index=pd.date_range('20180101', periods=3,
         ...                                       freq='h'))
@@ -770,7 +888,7 @@
         2018-01-01 00:00:00  2.0  1
         2018-01-01 01:00:00  NaN  3
         2018-01-01 02:00:00  6.0  5
-
+        
         >>> df.resample('30min').fillna("bfill")
                                a  b
         2018-01-01 00:00:00  2.0  1
@@ -793,8 +911,30 @@
         downcast=None,
         **kwargs,
     ):
-        """
-        Interpolate values according to different methods.
+        """Interpolate values according to different methods.
+
+        Parameters
+        ----------
+        method :
+             (Default value = "linear")
+        axis :
+             (Default value = 0)
+        limit :
+             (Default value = None)
+        inplace :
+             (Default value = False)
+        limit_direction :
+             (Default value = "forward")
+        limit_area :
+             (Default value = None)
+        downcast :
+             (Default value = None)
+        **kwargs :
+            
+
+        Returns
+        -------
+
         """
         result = self._upsample(None)
         return result.interpolate(
@@ -809,14 +949,13 @@
         )
 
     def asfreq(self, fill_value=None):
-        """
-        Return the values at the new freq, essentially a reindex.
+        """Return the values at the new freq, essentially a reindex.
 
         Parameters
         ----------
         fill_value : scalar, optional
             Value to use for missing values, applied during upsampling (note
-            this does not fill NaNs that already were present).
+            this does not fill NaNs that already were present). (Default value = None)
 
         Returns
         -------
@@ -831,41 +970,48 @@
         return self._upsample("asfreq", fill_value=fill_value)
 
     def std(self, ddof=1, *args, **kwargs):
-        """
-        Compute standard deviation of groups, excluding missing values.
+        """Compute standard deviation of groups, excluding missing values.
 
         Parameters
         ----------
         ddof : int, default 1
-            Degrees of freedom.
-
-        Returns
-        -------
-        DataFrame or Series
-            Standard deviation of values within each group.
+            Degrees of freedom. (Default value = 1)
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        
         """
         nv.validate_resampler_func("std", args, kwargs)
         return self._downsample("std", ddof=ddof)
 
     def var(self, ddof=1, *args, **kwargs):
-        """
-        Compute variance of groups, excluding missing values.
+        """Compute variance of groups, excluding missing values.
 
         Parameters
         ----------
         ddof : int, default 1
-            Degrees of freedom.
-
-        Returns
-        -------
-        DataFrame or Series
-            Variance of values within each group.
+            Degrees of freedom. (Default value = 1)
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        
         """
         nv.validate_resampler_func("var", args, kwargs)
         return self._downsample("var", ddof=ddof)
 
     @doc(GroupBy.size)
     def size(self):
+        """ """
         result = self._downsample("size")
         if not len(self.ax):
             from pandas import Series
@@ -879,6 +1025,7 @@
 
     @doc(GroupBy.count)
     def count(self):
+        """ """
         result = self._downsample("count")
         if not len(self.ax):
             if self._selected_obj.ndim == 1:
@@ -895,14 +1042,16 @@
         return result
 
     def quantile(self, q=0.5, **kwargs):
-        """
-        Return value at the given quantile.
-
+        """Return value at the given quantile.
+        
         .. versionadded:: 0.24.0
 
         Parameters
         ----------
         q : float or array-like, default 0.5 (50% quantile)
+             (Default value = 0.5)
+        **kwargs :
+            
 
         Returns
         -------
@@ -922,6 +1071,23 @@
 for method in ["sum", "prod"]:
 
     def f(self, _method=method, min_count=0, *args, **kwargs):
+        """
+
+        Parameters
+        ----------
+        _method :
+             (Default value = method)
+        min_count :
+             (Default value = 0)
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         nv.validate_resampler_func(_method, args, kwargs)
         return self._downsample(_method, min_count=min_count)
 
@@ -933,6 +1099,21 @@
 for method in ["min", "max", "first", "last", "mean", "sem", "median", "ohlc"]:
 
     def g(self, _method=method, *args, **kwargs):
+        """
+
+        Parameters
+        ----------
+        _method :
+             (Default value = method)
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        """
         nv.validate_resampler_func(_method, args, kwargs)
         return self._downsample(_method)
 
@@ -944,6 +1125,17 @@
 for method in ["nunique"]:
 
     def h(self, _method=method):
+        """
+
+        Parameters
+        ----------
+        _method :
+             (Default value = method)
+
+        Returns
+        -------
+
+        """
         return self._downsample(_method)
 
     h.__doc__ = getattr(SeriesGroupBy, method).__doc__
@@ -951,9 +1143,7 @@
 
 
 class _GroupByMixin(GroupByMixin):
-    """
-    Provide the groupby facilities.
-    """
+    """Provide the groupby facilities."""
 
     def __init__(self, obj, *args, **kwargs):
 
@@ -976,12 +1166,37 @@
 
     @no_type_check
     def _apply(self, f, grouper=None, *args, **kwargs):
-        """
-        Dispatch to _upsample; we are stripping all of the _upsample kwargs and
+        """Dispatch to _upsample; we are stripping all of the _upsample kwargs and
         performing the original function call on the grouped object.
+
+        Parameters
+        ----------
+        f :
+            
+        grouper :
+             (Default value = None)
+        *args :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
         """
 
         def func(x):
+            """
+
+            Parameters
+            ----------
+            x :
+                
+
+            Returns
+            -------
+
+            """
             x = self._shallow_copy(x, groupby=self.groupby)
 
             if isinstance(f, str):
@@ -998,11 +1213,14 @@
 
 
 class DatetimeIndexResampler(Resampler):
+    """ """
     @property
     def _resampler_for_grouping(self):
+        """ """
         return DatetimeIndexResamplerGroupby
 
     def _get_binner_for_time(self):
+        """ """
 
         # this is how we are actually creating the bins
         if self.kind == "period":
@@ -1010,13 +1228,19 @@
         return self.groupby._get_time_bins(self.ax)
 
     def _downsample(self, how, **kwargs):
-        """
-        Downsample the cython defined function.
-
-        Parameters
-        ----------
-        how : string / cython mapped function
-        **kwargs : kw args passed to how function
+        """Downsample the cython defined function.
+
+        Parameters
+        ----------
+        how :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        
         """
         self._set_binner()
         how = self._get_cython_func(how) or how
@@ -1046,10 +1270,18 @@
         return self._wrap_result(result)
 
     def _adjust_binner_for_upsample(self, binner):
-        """
-        Adjust our binner when upsampling.
-
+        """Adjust our binner when upsampling.
+        
         The range of a new index should not be outside specified range
+
+        Parameters
+        ----------
+        binner :
+            
+
+        Returns
+        -------
+
         """
         if self.closed == "right":
             binner = binner[1:]
@@ -1059,19 +1291,22 @@
 
     def _upsample(self, method, limit=None, fill_value=None):
         """
+
         Parameters
         ----------
         method : string {'backfill', 'bfill', 'pad',
             'ffill', 'asfreq'} method for upsampling
         limit : int, default None
-            Maximum size gap to fill when reindexing
+            Maximum size gap to fill when reindexing (Default value = None)
         fill_value : scalar, default None
-            Value to use for missing values
+            Value to use for missing values (Default value = None)
+
+        Returns
+        -------
 
         See Also
         --------
         .fillna
-
         """
         self._set_binner()
         if self.axis:
@@ -1101,6 +1336,17 @@
         return self._wrap_result(result)
 
     def _wrap_result(self, result):
+        """
+
+        Parameters
+        ----------
+        result :
+            
+
+        Returns
+        -------
+
+        """
         result = super()._wrap_result(result)
 
         # we may have a different kind that we were asked originally
@@ -1111,26 +1357,39 @@
 
 
 class DatetimeIndexResamplerGroupby(_GroupByMixin, DatetimeIndexResampler):
-    """
-    Provides a resample of a groupby implementation
-    """
+    """Provides a resample of a groupby implementation"""
 
     @property
     def _constructor(self):
+        """ """
         return DatetimeIndexResampler
 
 
 class PeriodIndexResampler(DatetimeIndexResampler):
+    """ """
     @property
     def _resampler_for_grouping(self):
+        """ """
         return PeriodIndexResamplerGroupby
 
     def _get_binner_for_time(self):
+        """ """
         if self.kind == "timestamp":
             return super()._get_binner_for_time()
         return self.groupby._get_period_bins(self.ax)
 
     def _convert_obj(self, obj):
+        """
+
+        Parameters
+        ----------
+        obj :
+            
+
+        Returns
+        -------
+
+        """
         obj = super()._convert_obj(obj)
 
         if self._from_selection:
@@ -1154,13 +1413,19 @@
         return obj
 
     def _downsample(self, how, **kwargs):
-        """
-        Downsample the cython defined function.
-
-        Parameters
-        ----------
-        how : string / cython mapped function
-        **kwargs : kw args passed to how function
+        """Downsample the cython defined function.
+
+        Parameters
+        ----------
+        how :
+            
+        **kwargs :
+            
+
+        Returns
+        -------
+
+        
         """
         # we may need to actually resample as if we are timestamps
         if self.kind == "timestamp":
@@ -1191,19 +1456,22 @@
 
     def _upsample(self, method, limit=None, fill_value=None):
         """
+
         Parameters
         ----------
         method : string {'backfill', 'bfill', 'pad', 'ffill'}
             Method for upsampling.
         limit : int, default None
-            Maximum size gap to fill when reindexing.
+            Maximum size gap to fill when reindexing. (Default value = None)
         fill_value : scalar, default None
-            Value to use for missing values.
+            Value to use for missing values. (Default value = None)
+
+        Returns
+        -------
 
         See Also
         --------
         .fillna
-
         """
         # we may need to actually resample as if we are timestamps
         if self.kind == "timestamp":
@@ -1225,46 +1493,67 @@
 
 
 class PeriodIndexResamplerGroupby(_GroupByMixin, PeriodIndexResampler):
-    """
-    Provides a resample of a groupby implementation.
-    """
+    """Provides a resample of a groupby implementation."""
 
     @property
     def _constructor(self):
+        """ """
         return PeriodIndexResampler
 
 
 class TimedeltaIndexResampler(DatetimeIndexResampler):
+    """ """
     @property
     def _resampler_for_grouping(self):
+        """ """
         return TimedeltaIndexResamplerGroupby
 
     def _get_binner_for_time(self):
+        """ """
         return self.groupby._get_time_delta_bins(self.ax)
 
     def _adjust_binner_for_upsample(self, binner):
-        """
-        Adjust our binner when upsampling.
-
+        """Adjust our binner when upsampling.
+        
         The range of a new index is allowed to be greater than original range
         so we don't need to change the length of a binner, GH 13022
+
+        Parameters
+        ----------
+        binner :
+            
+
+        Returns
+        -------
+
         """
         return binner
 
 
 class TimedeltaIndexResamplerGroupby(_GroupByMixin, TimedeltaIndexResampler):
-    """
-    Provides a resample of a groupby implementation.
-    """
+    """Provides a resample of a groupby implementation."""
 
     @property
     def _constructor(self):
+        """ """
         return TimedeltaIndexResampler
 
 
 def get_resampler(obj, kind=None, **kwds):
-    """
-    Create a TimeGrouper and return our resampler.
+    """Create a TimeGrouper and return our resampler.
+
+    Parameters
+    ----------
+    obj :
+        
+    kind :
+         (Default value = None)
+    **kwds :
+        
+
+    Returns
+    -------
+
     """
     tg = TimeGrouper(**kwds)
     return tg._get_resampler(obj, kind=kind)
@@ -1277,7 +1566,29 @@
     groupby, rule, how=None, fill_method=None, limit=None, kind=None, **kwargs
 ):
     """
-    Return our appropriate resampler when grouping as well.
+
+    Parameters
+    ----------
+    groupby :
+        
+    rule :
+        
+    how :
+         (Default value = None)
+    fill_method :
+         (Default value = None)
+    limit :
+         (Default value = None)
+    kind :
+         (Default value = None)
+    **kwargs :
+        
+
+    Returns
+    -------
+    type
+        
+
     """
     # .resample uses 'on' similar to how .groupby uses 'key'
     kwargs["key"] = kwargs.pop("on", None)
@@ -1288,17 +1599,7 @@
 
 
 class TimeGrouper(Grouper):
-    """
-    Custom groupby class for time-interval grouping.
-
-    Parameters
-    ----------
-    freq : pandas date offset or offset alias for identifying bin edges
-    closed : closed end of interval; 'left' or 'right'
-    label : interval boundary to use for labeling; 'left' or 'right'
-    convention : {'start', 'end', 'e', 's'}
-        If axis is PeriodIndex
-    """
+    """Custom groupby class for time-interval grouping."""
 
     _attributes = Grouper._attributes + (
         "closed",
@@ -1404,23 +1705,21 @@
         super().__init__(freq=freq, axis=axis, **kwargs)
 
     def _get_resampler(self, obj, kind=None):
-        """
-        Return my resampler or raise if we have an invalid axis.
+        """Return my resampler or raise if we have an invalid axis.
 
         Parameters
         ----------
         obj : input object
+            
         kind : string, optional
-            'period','timestamp','timedelta' are valid
+            'period','timestamp','timedelta' are valid (Default value = None)
 
         Returns
         -------
         a Resampler
-
-        Raises
-        ------
-        TypeError if incompatible axis
-
+            
+
+        
         """
         self._set_grouper(obj)
 
@@ -1439,12 +1738,36 @@
         )
 
     def _get_grouper(self, obj, validate: bool = True):
+        """
+
+        Parameters
+        ----------
+        obj :
+            
+        validate: bool :
+             (Default value = True)
+
+        Returns
+        -------
+
+        """
         # create the resampler and return our binner
         r = self._get_resampler(obj)
         r._set_binner()
         return r.binner, r.grouper, r.obj
 
     def _get_time_bins(self, ax):
+        """
+
+        Parameters
+        ----------
+        ax :
+            
+
+        Returns
+        -------
+
+        """
         if not isinstance(ax, DatetimeIndex):
             raise TypeError(
                 "axis must be a DatetimeIndex, but got "
@@ -1508,6 +1831,19 @@
         return binner, bins, labels
 
     def _adjust_bin_edges(self, binner, ax_values):
+        """
+
+        Parameters
+        ----------
+        binner :
+            
+        ax_values :
+            
+
+        Returns
+        -------
+
+        """
         # Some hacks for > daily data, see #1471, #1458, #1483
 
         if self.freq != "D" and is_superperiod(self.freq, "D"):
@@ -1528,6 +1864,17 @@
         return binner, bin_edges
 
     def _get_time_delta_bins(self, ax):
+        """
+
+        Parameters
+        ----------
+        ax :
+            
+
+        Returns
+        -------
+
+        """
         if not isinstance(ax, TimedeltaIndex):
             raise TypeError(
                 "axis must be a TimedeltaIndex, but got "
@@ -1556,6 +1903,17 @@
         return binner, bins, labels
 
     def _get_time_period_bins(self, ax: DatetimeIndex):
+        """
+
+        Parameters
+        ----------
+        ax: DatetimeIndex :
+            
+
+        Returns
+        -------
+
+        """
         if not isinstance(ax, DatetimeIndex):
             raise TypeError(
                 "axis must be a DatetimeIndex, but got "
@@ -1578,6 +1936,17 @@
         return binner, bins, labels
 
     def _get_period_bins(self, ax: PeriodIndex):
+        """
+
+        Parameters
+        ----------
+        ax: PeriodIndex :
+            
+
+        Returns
+        -------
+
+        """
         if not isinstance(ax, PeriodIndex):
             raise TypeError(
                 "axis must be a PeriodIndex, but got "
@@ -1652,6 +2021,23 @@
 
 
 def _take_new_index(obj, indexer, new_index, axis=0):
+    """
+
+    Parameters
+    ----------
+    obj :
+        
+    indexer :
+        
+    new_index :
+        
+    axis :
+         (Default value = 0)
+
+    Returns
+    -------
+
+    """
 
     if isinstance(obj, ABCSeries):
         new_values = algos.take_1d(obj._values, indexer)
@@ -1669,8 +2055,7 @@
 def _get_timestamp_range_edges(
     first, last, freq, closed="left", origin="start_day", offset=None
 ):
-    """
-    Adjust the `first` Timestamp to the preceding Timestamp that resides on
+    """Adjust the `first` Timestamp to the preceding Timestamp that resides on
     the provided offset. Adjust the `last` Timestamp to the following
     Timestamp that resides on the provided offset. Input Timestamps that
     already reside on the offset will be adjusted depending on the type of
@@ -1685,21 +2070,21 @@
     freq : pd.DateOffset
         The dateoffset to which the Timestamps will be adjusted.
     closed : {'right', 'left'}, default None
-        Which side of bin interval is closed.
+        Which side of bin interval is closed. (Default value = "left")
     origin : {'epoch', 'start', 'start_day'} or Timestamp, default 'start_day'
         The timestamp on which to adjust the grouping. The timezone of origin must
         match the timezone of the index.
         If a timestamp is not used, these values are also supported:
-
         - 'epoch': `origin` is 1970-01-01
         - 'start': `origin` is the first value of the timeseries
-        - 'start_day': `origin` is the first day at midnight of the timeseries
+        - 'start_day': `origin` is the first day at midnight of the timeseries (Default value = "start_day")
     offset : pd.Timedelta, default is None
-        An offset timedelta added to the origin.
+        An offset timedelta added to the origin. (Default value = None)
 
     Returns
     -------
-    A tuple of length 2, containing the adjusted pd.Timestamp objects.
+
+    
     """
     if isinstance(freq, Tick):
         index_tz = first.tz
@@ -1742,8 +2127,7 @@
 def _get_period_range_edges(
     first, last, freq, closed="left", origin="start_day", offset=None
 ):
-    """
-    Adjust the provided `first` and `last` Periods to the respective Period of
+    """Adjust the provided `first` and `last` Periods to the respective Period of
     the given offset that encompasses them.
 
     Parameters
@@ -1755,22 +2139,21 @@
     freq : pd.DateOffset
         The freq to which the Periods will be adjusted.
     closed : {'right', 'left'}, default None
-        Which side of bin interval is closed.
+        Which side of bin interval is closed. (Default value = "left")
     origin : {'epoch', 'start', 'start_day'}, Timestamp, default 'start_day'
         The timestamp on which to adjust the grouping. The timezone of origin must
         match the timezone of the index.
-
         If a timestamp is not used, these values are also supported:
-
         - 'epoch': `origin` is 1970-01-01
         - 'start': `origin` is the first value of the timeseries
-        - 'start_day': `origin` is the first day at midnight of the timeseries
+        - 'start_day': `origin` is the first day at midnight of the timeseries (Default value = "start_day")
     offset : pd.Timedelta, default is None
-        An offset timedelta added to the origin.
+        An offset timedelta added to the origin. (Default value = None)
 
     Returns
     -------
-    A tuple of length 2, containing the adjusted pd.Period objects.
+
+    
     """
     if not all(isinstance(obj, Period) for obj in [first, last]):
         raise TypeError("'first' and 'last' must be instances of type Period")
@@ -1793,6 +2176,27 @@
 def _adjust_dates_anchored(
     first, last, freq, closed="right", origin="start_day", offset=None
 ):
+    """
+
+    Parameters
+    ----------
+    first :
+        
+    last :
+        
+    freq :
+        
+    closed :
+         (Default value = "right")
+    origin :
+         (Default value = "start_day")
+    offset :
+         (Default value = None)
+
+    Returns
+    -------
+
+    """
     # First and last offsets should be calculated from the start day to fix an
     # error cause by resampling across multiple days when a one day period is
     # not a multiple of the frequency. See GH 8683
@@ -1855,8 +2259,26 @@
 
 
 def asfreq(obj, freq, method=None, how=None, normalize=False, fill_value=None):
-    """
-    Utility frequency conversion method for Series/DataFrame.
+    """Utility frequency conversion method for Series/DataFrame.
+
+    Parameters
+    ----------
+    obj :
+        
+    freq :
+        
+    method :
+         (Default value = None)
+    how :
+         (Default value = None)
+    normalize :
+         (Default value = False)
+    fill_value :
+         (Default value = None)
+
+    Returns
+    -------
+
     """
     if isinstance(obj.index, PeriodIndex):
         if method is not None:
@@ -1883,17 +2305,19 @@
 
 
 def _asfreq_compat(index, freq):
-    """
-    Helper to mimic asfreq on (empty) DatetimeIndex and TimedeltaIndex.
+    """Helper to mimic asfreq on (empty) DatetimeIndex and TimedeltaIndex.
 
     Parameters
     ----------
     index : PeriodIndex, DatetimeIndex, or TimedeltaIndex
+        
     freq : DateOffset
+        
 
     Returns
     -------
-    same type as index
+
+    
     """
     if len(index) != 0:
         # This should never be reached, always checked by the caller
